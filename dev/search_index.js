var documenterSearchIndex = {"docs":
[{"location":"copies/Surrogates/rosenbrock/#Rosenbrock-function","page":"Rosenbrock","title":"Rosenbrock function","text":"","category":"section"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"The Rosenbrock function is defined as: f(x) = sum_i=1^d-1 (x_i+1-x_i)^2 + (x_i - 1)^2","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"I will treat the 2D version, which is commonly defined as: f(xy) = (1-x)^2 + 100(y-x^2)^2 Let's import Surrogates and Plots:","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"Define the objective function:","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"function f(x)\n    x1 = x[1]\n    x2 = x[2]\n    return (1-x1)^2 + 100*(x2-x1^2)^2\nend","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"Let's plot it:","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"n = 100\nlb = [0.0,0.0]\nub = [8.0,8.0]\nxys = sample(n,lb,ub,SobolSample());\nzs = f.(xys);\nx, y = 0:8, 0:8\np1 = surface(x, y, (x1,x2) -> f((x1,x2)))\nxs = [xy[1] for xy in xys]\nys = [xy[2] for xy in xys]\nscatter!(xs, ys, zs) # hide\np2 = contour(x, y, (x1,x2) -> f((x1,x2)))\nscatter!(xs, ys)\nplot(p1, p2, title=\"True function\")","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"Fitting different Surrogates:","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"mypoly = PolynomialChaosSurrogate(xys, zs,  lb, ub)\nloba = LobachevskySurrogate(xys, zs, lb, ub)\ninver = InverseDistanceSurrogate(xys, zs,  lb, ub)","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"Plotting:","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"p1 = surface(x, y, (x, y) -> mypoly([x y]))\nscatter!(xs, ys, zs, marker_z=zs)\np2 = contour(x, y, (x, y) -> mypoly([x y]))\nscatter!(xs, ys, marker_z=zs)\nplot(p1, p2, title=\"Polynomial expansion\")","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"p1 = surface(x, y, (x, y) -> loba([x y]))\nscatter!(xs, ys, zs, marker_z=zs)\np2 = contour(x, y, (x, y) -> loba([x y]))\nscatter!(xs, ys, marker_z=zs)\nplot(p1, p2, title=\"Lobachevsky\")","category":"page"},{"location":"copies/Surrogates/rosenbrock/","page":"Rosenbrock","title":"Rosenbrock","text":"p1 = surface(x, y, (x, y) -> inver([x y]))\nscatter!(xs, ys, zs, marker_z=zs)\np2 = contour(x, y, (x, y) -> inver([x y]))\nscatter!(xs, ys, marker_z=zs)\nplot(p1, p2, title=\"Inverse distance surrogate\")","category":"page"},{"location":"copies/ModelingToolkit/basics/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/FAQ/#Getting-the-index-for-a-symbol","page":"Frequently Asked Questions","title":"Getting the index for a symbol","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Since ordering of symbols is not guaranteed after symbolic transformations, one should normally refer to values by their name. For example, sol[lorenz.x] from the solution. But what if you need to get the index? The following helper function will do the trick:","category":"page"},{"location":"copies/ModelingToolkit/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"indexof(sym,syms) = findfirst(isequal(sym),syms)\nindexof(σ,parameters(sys))","category":"page"},{"location":"copies/ModelingToolkit/basics/FAQ/#Transforming-value-maps-to-arrays","page":"Frequently Asked Questions","title":"Transforming value maps to arrays","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"ModelingToolkit.jl allows (and recommends) input maps like [x => 2.0, y => 3.0] because symbol ordering is not guaranteed. However, what if you want to get the lowered array? You can use the internal function varmap_to_vars. For example:","category":"page"},{"location":"copies/ModelingToolkit/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"pnew = varmap_to_vars([β=>3.0, c=>10.0, γ=>2.0],parameters(sys))","category":"page"},{"location":"copies/ModelingToolkit/basics/FAQ/#How-do-I-handle-if-statements-in-my-symbolic-forms?","page":"Frequently Asked Questions","title":"How do I handle if statements in my symbolic forms?","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"For statements that are in the if then else form, use IfElse.ifelse from the IfElse.jl package to represent the code in a functional form. For handling direct if statements, you can use equivalent boolean mathematical expressions. For example if x > 0 ... can be implemented as just (x > 0) *, where if x <= 0 then the boolean will evaluate to 0 and thus the term will be excluded from the model.","category":"page"},{"location":"copies/ModelingToolkit/basics/FAQ/#ERROR:-TypeError:-non-boolean-(Num)-used-in-boolean-context?","page":"Frequently Asked Questions","title":"ERROR: TypeError: non-boolean (Num) used in boolean context?","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"If you see the error:","category":"page"},{"location":"copies/ModelingToolkit/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"ERROR: TypeError: non-boolean (Num) used in boolean context","category":"page"},{"location":"copies/ModelingToolkit/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"then it's likely you are trying to trace through a function which cannot be directly represented in Julia symbols. The techniques to handle this problem, such as @register_symbolic, are described in detail  in the Symbolics.jl documentation.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"The Inverse Distance Surrogate is an interpolating method and in this method the unknown points are calculated with a weighted average of the sampling points. This model uses the inverse distance between the unknown and training points to predict the unknown point. We do not need to fit this model because the response of an unknown point x is computed with respect to the distance between x and the training points.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"Let's optimize following function to use Inverse Distance Surrogate:","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"f(x) = sin(x) + sin(x)^2 + sin(x)^3","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":".","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"First of all, we have to import these two packages: Surrogates and Plots.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"using Surrogates\r\nusing Plots\r\ndefault()","category":"page"},{"location":"copies/Surrogates/InverseDistance/#Sampling","page":"InverseDistance","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"We choose to sample f in 25 points between 0 and 10 using the sample function. The sampling points are chosen using a Low Discrepancy, this can be done by passing LowDiscrepancySample() to the sample function.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"f(x) = sin(x) + sin(x)^2 + sin(x)^3\r\n\r\nn_samples = 25\r\nlower_bound = 0.0\r\nupper_bound = 10.0\r\nx = sample(n_samples, lower_bound, upper_bound, LowDiscrepancySample(2))\r\ny = f.(x)\r\n\r\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(f, label=\"True function\", xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/InverseDistance/#Building-a-Surrogate","page":"InverseDistance","title":"Building a Surrogate","text":"","category":"section"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"InverseDistance = InverseDistanceSurrogate(x, y, lower_bound, upper_bound)\r\nadd_point!(InverseDistance, 5.0, f(5.0))\r\nadd_point!(InverseDistance, [5.1,5.2], [f(5.1),f(5.2)])\r\nprediction = InverseDistance(5.0)","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"Now, we will simply plot InverseDistance:","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"plot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(InverseDistance, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/InverseDistance/#Optimizing","page":"InverseDistance","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"Having built a surrogate, we can now use it to search for minimas in our original function f.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"To optimize using our surrogate we call surrogate_optimize method. We choose to use Stochastic RBF as optimization technique and again Sobol sampling as sampling technique.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"@show surrogate_optimize(f, SRBF(), lower_bound, upper_bound, InverseDistance, SobolSample())\r\nscatter(x, y, label=\"Sampled points\", legend=:top)\r\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(InverseDistance, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/InverseDistance/#Inverse-Distance-Surrogate-Tutorial-(ND):","page":"InverseDistance","title":"Inverse Distance Surrogate Tutorial (ND):","text":"","category":"section"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"First of all we will define the Schaffer function we are going to build surrogate for. Notice, one how its argument is a vector of numbers, one for each coordinate, and its output is a scalar.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"using Plots # hide\r\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\r\nusing Surrogates # hide\r\n\r\nfunction schaffer(x)\r\n    x1=x[1]\r\n    x2=x[2]\r\n    fact1 = (sin(x1^2-x2^2))^2 - 0.5;\r\n    fact2 = (1 + 0.001*(x1^2+x2^2))^2;\r\n    y = 0.5 + fact1/fact2;\r\nend","category":"page"},{"location":"copies/Surrogates/InverseDistance/#Sampling-2","page":"InverseDistance","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension x to have bounds -5, 10, and 0, 15 for the second dimension. We are taking 60 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"n_samples = 60\r\nlower_bound = [-5.0, 0.0]\r\nupper_bound = [10.0, 15.0]\r\n\r\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\nzs = schaffer.(xys);","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"x, y = -5:10, 0:15 # hide\r\np1 = surface(x, y, (x1,x2) -> schaffer((x1,x2))) # hide\r\nxs = [xy[1] for xy in xys] # hide\r\nys = [xy[2] for xy in xys] # hide\r\nscatter!(xs, ys, zs) # hide\r\np2 = contour(x, y, (x1,x2) -> schaffer((x1,x2))) # hide\r\nscatter!(xs, ys) # hide\r\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/InverseDistance/#Building-a-surrogate","page":"InverseDistance","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"Using the sampled points we build the surrogate, the steps are analogous to the 1-dimensional case.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"InverseDistance = InverseDistanceSurrogate(xys, zs,  lower_bound, upper_bound)","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"p1 = surface(x, y, (x, y) -> InverseDistance([x y])) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> InverseDistance([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2, title=\"Surrogate\") # hide","category":"page"},{"location":"copies/Surrogates/InverseDistance/#Optimizing-2","page":"InverseDistance","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"With our surrogate we can now search for the minimas of the function.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"Notice how the new sampled points, which were created during the optimization process, are appended to the xys array. This is why its size changes.","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"surrogate_optimize(schaffer, SRBF(), lower_bound, upper_bound, InverseDistance, SobolSample(), maxiters=10)","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/InverseDistance/","page":"InverseDistance","title":"InverseDistance","text":"p1 = surface(x, y, (x, y) -> InverseDistance([x y])) # hide\r\nxs = [xy[1] for xy in xys] # hide\r\nys = [xy[2] for xy in xys] # hide\r\nzs = schaffer.(xys) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> InverseDistance([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2) # hide","category":"page"},{"location":"copies/ModelingToolkit/systems/SDESystem/#SDESystem","page":"SDESystem","title":"SDESystem","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/SDESystem/#System-Constructors","page":"SDESystem","title":"System Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/SDESystem/","page":"SDESystem","title":"SDESystem","text":"SDESystem","category":"page"},{"location":"copies/ModelingToolkit/systems/SDESystem/#ModelingToolkit.SDESystem","page":"SDESystem","title":"ModelingToolkit.SDESystem","text":"struct SDESystem <: ModelingToolkit.AbstractODESystem\n\nA system of stochastic differential equations.\n\nFields\n\neqs\nThe expressions defining the drift term.\nnoiseeqs\nThe expressions defining the diffusion term.\niv\nIndependent variable.\nstates\nDependent (state) variables. Must not contain the independent variable.\nps\nParameter variables. Must not contain the independent variable.\nvar_to_name\nArray variables.\nctrls\nControl parameters (some subset of ps).\nobserved\nObserved states.\ntgrad\nTime-derivative matrix. Note: this field will not be defined until calculate_tgrad is called on the system.\n\njac\nJacobian matrix. Note: this field will not be defined until calculate_jacobian is called on the system.\n\nctrl_jac\nControl Jacobian matrix. Note: this field will not be defined until calculate_control_jacobian is called on the system.\n\nWfact\nWfact matrix. Note: this field will not be defined until generate_factorized_W is called on the system.\n\nWfact_t\nWfact_t matrix. Note: this field will not be defined until generate_factorized_W is called on the system.\n\nname\nName: the name of the system\n\nsystems\nSystems: the internal systems. These are required to have unique names.\n\ndefaults\ndefaults: The default values to use when initial conditions and/or parameters are not supplied in ODEProblem.\n\nconnector_type\ntype: type of the system\n\nExample\n\nusing ModelingToolkit\n\n@parameters σ ρ β\n@variables t x(t) y(t) z(t)\nD = Differential(t)\n\neqs = [D(x) ~ σ*(y-x),\n       D(y) ~ x*(ρ-z)-y,\n       D(z) ~ x*y - β*z]\n\nnoiseeqs = [0.1*x,\n            0.1*y,\n            0.1*z]\n\n@named de = SDESystem(eqs,noiseeqs,t,[x,y,z],[σ,ρ,β])\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/SDESystem/","page":"SDESystem","title":"SDESystem","text":"To convert an ODESystem to an SDESystem directly:","category":"page"},{"location":"copies/ModelingToolkit/systems/SDESystem/","page":"SDESystem","title":"SDESystem","text":"ode = ODESystem(eqs,t,[x,y,z],[σ,ρ,β])\r\nsde = SDESystem(ode, noiseeqs)","category":"page"},{"location":"copies/ModelingToolkit/systems/SDESystem/#Composition-and-Accessor-Functions","page":"SDESystem","title":"Composition and Accessor Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/SDESystem/","page":"SDESystem","title":"SDESystem","text":"get_eqs(sys) or equations(sys): The equations that define the SDE.\nget_states(sys) or states(sys): The set of states in the SDE.\nget_ps(sys) or parameters(sys): The parameters of the SDE.\nget_iv(sys): The independent variable of the SDE.","category":"page"},{"location":"copies/ModelingToolkit/systems/SDESystem/#Transformations","page":"SDESystem","title":"Transformations","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/SDESystem/","page":"SDESystem","title":"SDESystem","text":"structural_simplify\r\nalias_elimination","category":"page"},{"location":"copies/ModelingToolkit/systems/SDESystem/#Analyses","page":"SDESystem","title":"Analyses","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/SDESystem/#Applicable-Calculation-and-Generation-Functions","page":"SDESystem","title":"Applicable Calculation and Generation Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/SDESystem/","page":"SDESystem","title":"SDESystem","text":"calculate_jacobian\r\ncalculate_tgrad\r\ncalculate_factorized_W\r\ngenerate_jacobian\r\ngenerate_tgrad\r\ngenerate_factorized_W\r\njacobian_sparsity","category":"page"},{"location":"copies/ModelingToolkit/systems/SDESystem/#Problem-Constructors","page":"SDESystem","title":"Problem Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/SDESystem/","page":"SDESystem","title":"SDESystem","text":"SDEFunction\r\nSDEProblem","category":"page"},{"location":"copies/ModelingToolkit/systems/SDESystem/#SciMLBase.SDEFunction","page":"SDESystem","title":"SciMLBase.SDEFunction","text":"SDEFunction{iip,F,G,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,GG,S,O,TCV} <: AbstractSDEFunction{iip}\n\nA representation of an SDE function f, defined by:\n\nM du = f(upt)dt + g(upt) dW \n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nSDEFunction{iip,recompile}(f,g;\n                           mass_matrix=I,\n                           analytic=nothing,\n                           tgrad=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           ggprime = nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           paramjac = nothing,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p,t) or du = f(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\nggprime(J,u,p,t) or J = ggprime(u,p,t): returns the Milstein derivative  fracdg(upt)du g(upt)\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the ODEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/SDESystem/#SciMLBase.SDEProblem","page":"SDESystem","title":"SciMLBase.SDEProblem","text":"Defines an stochastic differential equation (SDE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/sde_types/\n\nMathematical Specification of a SDE Problem\n\nTo define an SDE Problem, you simply need to give the forcing function f, the noise function g, and the initial condition u₀ which define an SDE:\n\ndu = f(upt)dt + Σgᵢ(upt)dWⁱ\n\nf and g should be specified as f(u,p,t) and  g(u,p,t) respectively, and u₀ should be an AbstractArray whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well. A vector of gs can also be defined to determine an SDE of higher Ito dimension.\n\nProblem Type\n\nWraps the data which defines an SDE problem\n\nu = f(upt)dt + Σgᵢ(upt)dWⁱ\n\nwith initial condition u0.\n\nConstructors\n\nSDEProblem(f::SDEFunction,g,u0,tspan,p=NullParameters();noise=WHITE_NOISE,noise_rate_prototype=nothing)\nSDEProblem{isinplace}(f,g,u0,tspan,p=NullParameters();noise=WHITE_NOISE,noise_rate_prototype=nothing) : Defines the SDE with the specified functions. The default noise is WHITE_NOISE. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The drift function in the SDE.\ng: The noise function in the SDE.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The optional parameters for the problem. Defaults to NullParameters.\nnoise: The noise process applied to the noise upon generation. Defaults to Gaussian white noise. For information on defining different noise processes, see the noise process documentation page\nnoise_rate_prototype: A prototype type instance for the noise rates, that is the output g. It can be any type which overloads A_mul_B! with itself being the middle argument. Commonly, this is a matrix or sparse matrix. If this is not given, it defaults to nothing, which means the problem should be interpreted as having diagonal noise.  \nkwargs: The keyword arguments passed onto the solves.\n\nExample Problems\n\nExamples problems can be found in DiffEqProblemLibrary.jl.\n\nTo use a sample problem, such as prob_sde_linear, you can do something like:\n\n#] add DiffEqProblemLibrary\nusing DiffEqProblemLibrary.SDEProblemLibrary\n# load problems\nSDEProblemLibrary.importsdeproblems()\nprob = SDEProblemLibrary.prob_sde_linear\nsol = solve(prob)\n\n\n\n","category":"type"},{"location":"copies/Surrogates/samples/#Samples","page":"Samples","title":"Samples","text":"","category":"section"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Sampling methods are provided by the QuasiMonteCarlo package.","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"The syntax for sampling in an interval or region is the following:","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"sample(n,lb,ub,S::SamplingAlgorithm)","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"where lb and ub are, respectively, the lower and upper bounds. There are many sampling algorithms to choose from:","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Grid sample","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"GridSample{T}\nsample(n,lb,ub,S::GridSample)","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Uniform sample","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"sample(n,lb,ub,::UniformSample)","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Sobol sample","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"sample(n,lb,ub,::SobolSample)","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Latin Hypercube sample","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"sample(n,lb,ub,::LatinHypercubeSample)","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Low Discrepancy sample","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"LowDiscrepancySample{T}\nsample(n,lb,ub,S::LowDiscrepancySample)","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Sample on section","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"SectionSample\nsample(n,lb,ub,S::SectionSample)","category":"page"},{"location":"copies/Surrogates/samples/#Adding-a-new-sampling-method","page":"Samples","title":"Adding a new sampling method","text":"","category":"section"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Adding a new sampling method is a two- step process:","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Adding a new SamplingAlgorithm type\nOverloading the sample function with the new type.","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"Example","category":"page"},{"location":"copies/Surrogates/samples/","page":"Samples","title":"Samples","text":"struct NewAmazingSamplingAlgorithm{OPTIONAL} <: QuasiMonteCarlo.SamplingAlgorithm end\n\nfunction sample(n,lb,ub,::NewAmazingSamplingAlgorithm)\n    if lb is  Number\n        ...\n        return x\n    else\n        ...\n        return Tuple.(x)\n    end\nend","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/#MultiStartOptimization.jl","page":"MultistartOptimization.jl","title":"MultiStartOptimization.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"MultistartOptimization is a is a Julia package implementing a global optimization multistart method which performs local optimization after choosing multiple starting points.","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"MultistartOptimization requires both a global and local method to be defined. The global multistart method chooses a set of initial starting points from where local the local method starts from.","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"Currently, only one global method (TikTak) is implemented and called by MultiStartOptimization.TikTak(n) where n is the number of initial Sobol points. ","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/#Installation:-OptimizationMultiStartOptimization.jl","page":"MultistartOptimization.jl","title":"Installation: OptimizationMultiStartOptimization.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"To use this package, install the OptimizationMultiStartOptimization package:","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"import Pkg; Pkg.add(\"OptimizationMultiStartOptimization\")","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"note: Note\n","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"You also need to load the relevant subpackage for the local method of you choice, for example if you plan to use one of the NLopt.jl's optimizers, you'd install and load OptimizationNLopt as described in the NLopt.jl's section.","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/#Global-Optimizer","page":"MultistartOptimization.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/#Without-Constraint-Equations","page":"MultistartOptimization.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"The methods in MultistartOptimization is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/#Examples","page":"MultistartOptimization.jl","title":"Examples","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"The Rosenbrock function can optimized using MultistartOptimization.TikTak() with 100 initial points and the local method NLopt.LD_LBFGS() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), NLopt.LD_LBFGS())","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"You can use any Optimization optimizers you like. The global method of the MultiStartOptimization is a positional argument and followed by the local method. This for example means we can perform a multistartoptimization with LBFGS as the optimizer using either the NLopt.jl or Optim.jl implementation as follows. Moreover, this interface allows you access and adjust all the optimizer settings as you normally would:","category":"page"},{"location":"copies/Optimization/optimization_packages/multistartoptimization/","page":"MultistartOptimization.jl","title":"MultistartOptimization.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MultistartOptimization.TikTak(100), NLopt.LD_LBFGS())\nsol = solve(prob, MultistartOptimization.TikTak(100), LBFGS())","category":"page"},{"location":"copies/Optimization/optimization_packages/speedmapping/#SpeedMapping.jl","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"SpeedMapping accelerates the convergence of a mapping to a fixed point by the Alternating cyclic extrapolation algorithm which can also perform multivariate optimization based on the gradient function.","category":"page"},{"location":"copies/Optimization/optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The SpeedMapping algorithm is called by SpeedMappingOpt()","category":"page"},{"location":"copies/Optimization/optimization_packages/speedmapping/#Installation:-OptimizationSpeedMapping.jl","page":"SpeedMapping.jl","title":"Installation: OptimizationSpeedMapping.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"To use this package, install the OptimizationSpeedMapping package:","category":"page"},{"location":"copies/Optimization/optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"import Pkg; Pkg.add(\"OptimizationSpeedMapping\")","category":"page"},{"location":"copies/Optimization/optimization_packages/speedmapping/#Global-Optimizer","page":"SpeedMapping.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/speedmapping/#Without-Constraint-Equations","page":"SpeedMapping.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The method in SpeedMapping is performing optimization on problems without constraint equations. Lower and upper constraints set by lb and ub in the OptimizationProblem are optional.","category":"page"},{"location":"copies/Optimization/optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"If no AD backend is defined via OptimizationFunction the gradient is calculated via SpeedMapping's ForwardDiff AD backend.","category":"page"},{"location":"copies/Optimization/optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"The Rosenbrock function can be optimized using the SpeedMappingOpt() with and without bound as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/speedmapping/","page":"SpeedMapping.jl","title":"SpeedMapping.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(f, x0, _p)\nsol = solve(prob,SpeedMappingOpt())\n\nprob = OptimizationProblem(f, x0, _p;lb=[0.0,0.0], ub=[1.0,1.0])\nsol = solve(prob,SpeedMappingOpt())","category":"page"},{"location":"copies/Integrals/solvers/IntegralSolvers/#Integral-Solver-Algorithms","page":"Integral Solver Algorithms","title":"Integral Solver Algorithms","text":"","category":"section"},{"location":"copies/Integrals/solvers/IntegralSolvers/","page":"Integral Solver Algorithms","title":"Integral Solver Algorithms","text":"The following algorithms are available:","category":"page"},{"location":"copies/Integrals/solvers/IntegralSolvers/","page":"Integral Solver Algorithms","title":"Integral Solver Algorithms","text":"QuadGKJL: Uses QuadGK.jl. Requires nout=1 and batch=0.\nHCubatureJL: Uses HCubature.jl. Requires batch=0.\nVEGAS: Uses MonteCarloIntegration.jl. Requires nout=1.\nCubatureJLh: h-Cubature from Cubature.jl. Requires using IntegralsCubature.\nCubatureJLp: p-Cubature from Cubature.jl. Requires using IntegralsCubature.\nCubaVegas: Vegas from Cuba.jl. Requires using IntegralsCuba.\nCubaSUAVE: SUAVE from Cuba.jl. Requires using IntegralsCuba.\nCubaDivonne: Divonne from Cuba.jl. Requires using IntegralsCuba.\nCubaCuhre: Cuhre from Cuba.jl. Requires using IntegralsCuba.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/#direct_sensitivity","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"While sensitivity analysis tooling can be used implicitly via integration with automatic differentiation libraries, one can often times obtain more speed and flexibility with the direct sensitivity analysis interfaces. This tutorial demonstrates some of those functions.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/#Example-using-an-ODEForwardSensitivityProblem","page":"Direct Sensitivity Analysis Functionality","title":"Example using an ODEForwardSensitivityProblem","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"Forward sensitivity analysis is performed by defining and solving an augmented ODE. To define this augmented ODE, use the ODEForwardSensitivityProblem type instead of an ODE type. For example, we generate an ODE with the sensitivity equations attached for the Lotka-Volterra equations by:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"function f(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + u[1]*u[2]\nend\n\np = [1.5,1.0,3.0]\nprob = ODEForwardSensitivityProblem(f,[1.0;1.0],(0.0,10.0),p)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"This generates a problem which the ODE solvers can solve:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"sol = solve(prob,DP8())","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"Note that the solution is the standard ODE system and the sensitivity system combined. We can use the following helper functions to extract the sensitivity information:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"x,dp = extract_local_sensitivities(sol)\nx,dp = extract_local_sensitivities(sol,i)\nx,dp = extract_local_sensitivities(sol,t)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"In each case, x is the ODE values and dp is the matrix of sensitivities The first gives the full timeseries of values and dp[i] contains the time series of the sensitivities of all components of the ODE with respect to ith parameter. The second returns the ith time step, while the third interpolates to calculate the sensitivities at time t. For example, if we do:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"x,dp = extract_local_sensitivities(sol)\nda = dp[1]","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"then da is the timeseries for fracpartial u(t)partial p. We can plot this","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"plot(sol.t,da',lw=3)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"transposing so that the rows (the timeseries) is plotted.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"(Image: Local Sensitivity Solution)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"For more information on the internal representation of the ODEForwardSensitivityProblem solution, see the direct forward sensitivity analysis manual page.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/#Example-using-adjoint_sensitivities-for-discrete-adjoints","page":"Direct Sensitivity Analysis Functionality","title":"Example using adjoint_sensitivities for discrete adjoints","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"In this example we will show solving for the adjoint sensitivities of a discrete cost functional. First let's solve the ODE and get a high quality continuous solution:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"function f(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + u[1]*u[2]\nend\n\np = [1.5,1.0,3.0]\nprob = ODEProblem(f,[1.0;1.0],(0.0,10.0),p)\nsol = solve(prob,Vern9(),abstol=1e-10,reltol=1e-10)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"Now let's calculate the sensitivity of the ell_2 error against 1 at evenly spaced points in time, that is:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"L(upt)=sum_i=1^nfracVert1-u(t_ip)Vert^22","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"for t_i = 05i. This is the assumption that the data is data[i]=1.0. For this function, notice we have that:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"beginaligned\ndg_1=1-u_1 \ndg_2=1-u_2 \n quad vdots\nendaligned","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"and thus:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"dg(out,u,p,t,i) = (out.=1.0.-u)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"Also, we can omit dgdp, because the cost function doesn't dependent on p.  If we had data, we'd just replace 1.0 with data[i]. To get the adjoint sensitivities, call:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"ts = 0:0.5:10\nres = adjoint_sensitivities(sol,Vern9(),dg,ts,abstol=1e-14,\n                            reltol=1e-14)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"This is super high accuracy. As always, there's a tradeoff between accuracy and computation time. We can check this almost exactly matches the autodifferentiation and numerical differentiation results:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"using ForwardDiff,Calculus,Tracker\nfunction G(p)\n  tmp_prob = remake(prob,u0=convert.(eltype(p),prob.u0),p=p)\n  sol = solve(tmp_prob,Vern9(),abstol=1e-14,reltol=1e-14,saveat=ts,\n              sensealg=SensitivityADPassThrough())\n  A = convert(Array,sol)\n  sum(((1 .- A).^2)./2)\nend\nG([1.5,1.0,3.0])\nres2 = ForwardDiff.gradient(G,[1.5,1.0,3.0])\nres3 = Calculus.gradient(G,[1.5,1.0,3.0])\nres4 = Tracker.gradient(G,[1.5,1.0,3.0])\nres5 = ReverseDiff.gradient(G,[1.5,1.0,3.0])","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/direct_sensitivity/","page":"Direct Sensitivity Analysis Functionality","title":"Direct Sensitivity Analysis Functionality","text":"and see this gives the same values.","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/#PDESystem","page":"PDESystem","title":"PDESystem","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"PDESystem is the common symbolic PDE specification for the SciML ecosystem. It is currently being built as a component of the ModelingToolkit ecosystem,","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/#Vision","page":"PDESystem","title":"Vision","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"The vision for the common PDE interface is that a user should only have to specify their PDE once, mathematically, and have instant access to everything as simple as a finite difference method with constant grid spacing, to something as complex as a distributed multi-GPU discontinuous Galerkin method.","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"The key to the common PDE interface is a separation of the symbolic handling from the numerical world. All of the discretizers should not \"solve\" the PDE, but instead be a conversion of the mathematical specification to a numerical problem. Preferably, the transformation should be to another ModelingToolkit.jl AbstractSystem, but in some cases this cannot be done or will not be performant, so a SciMLProblem is the other choice.","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"These elementary problems, such as solving linear systems Ax=b, solving nonlinear systems f(x)=0, ODEs, etc. are all defined by SciMLBase.jl, which then numerical solvers can all target these common forms. Thus someone who works on linear solvers doesn't necessarily need to be working on a discontinuous Galerkin or finite element library, but instead \"linear solvers that are good for matrices A with properties ...\" which are then accessible by every other discretization method in the common PDE interface.","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"Similar to the rest of the AbstractSystem types, transformation and analysis functions will allow for simplifying the PDE before solving it, and constructing block symbolic functions like Jacobians.","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/#Constructors","page":"PDESystem","title":"Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"PDESystem","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/#ModelingToolkit.PDESystem","page":"PDESystem","title":"ModelingToolkit.PDESystem","text":"struct PDESystem <: AbstractMultivariateSystem\n\nA system of partial differential equations.\n\nFields\n\neqs\nThe equations which define the PDE\nbcs\nThe boundary conditions\ndomain\nThe domain for the independent variables.\nivs\nThe independent variables\ndvs\nThe dependent variables\nps\nThe parameters\ndefaults\ndefaults: The default values to use when initial conditions and/or parameters are not supplied in ODEProblem.\n\nconnector_type\ntype: type of the system\n\nsystems\nsystems: The internal systems. These are required to have unique names.\n\nname\nname: the name of the system\n\nExample\n\nusing ModelingToolkit\n\n@parameters x\n@variables t u(..)\nDxx = Differential(x)^2\nDtt = Differential(t)^2\nDt = Differential(t)\n\n#2D PDE\nC=1\neq  = Dtt(u(t,x)) ~ C^2*Dxx(u(t,x))\n\n# Initial and boundary conditions\nbcs = [u(t,0) ~ 0.,# for all t > 0\n       u(t,1) ~ 0.,# for all t > 0\n       u(0,x) ~ x*(1. - x), #for all 0 < x < 1\n       Dt(u(0,x)) ~ 0. ] #for all  0 < x < 1]\n\n# Space and time domains\ndomains = [t ∈ (0.0,1.0),\n           x ∈ (0.0,1.0)]\n\n@named pde_system = PDESystem(eq,bcs,domains,[t,x],[u])\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/PDESystem/#Domains-(WIP)","page":"PDESystem","title":"Domains (WIP)","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"Domains are specifying by saying indepvar in domain, where indepvar is a single or a collection of independent variables, and domain is the chosen domain type. A 2-tuple can be used to indicate an Interval.  Thus forms for the indepvar can be like:","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"t ∈ (0.0,1.0)\r\n(t,x) ∈ UnitDisk()\r\n[v,w,x,y,z] ∈ VectorUnitBall(5)","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/#Domain-Types-(WIP)","page":"PDESystem","title":"Domain Types (WIP)","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"Interval(a,b): Defines the domain of an interval from a to b (requires explicit","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"import from DomainSets.jl, but a 2-tuple can be used instead)","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/#discretize-and-symbolic_discretize","page":"PDESystem","title":"discretize and symbolic_discretize","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"The only functions which act on a PDESystem are the following:","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"discretize(sys,discretizer): produces the outputted AbstractSystem or SciMLProblem.\nsymbolic_discretize(sys,discretizer): produces a debugging symbolic description of the discretized problem.","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/#Boundary-Conditions-(WIP)","page":"PDESystem","title":"Boundary Conditions (WIP)","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/#Transformations","page":"PDESystem","title":"Transformations","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/#Analyses","page":"PDESystem","title":"Analyses","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/#Discretizer-Ecosystem","page":"PDESystem","title":"Discretizer Ecosystem","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/#NeuralPDE.jl:-PhysicsInformedNN","page":"PDESystem","title":"NeuralPDE.jl: PhysicsInformedNN","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"NeuralPDE.jl defines the PhysicsInformedNN discretizer which uses a DiffEqFlux.jl neural network to solve the differential equation.","category":"page"},{"location":"copies/ModelingToolkit/systems/PDESystem/#DiffEqOperators.jl:-MOLFiniteDifference-(WIP)","page":"PDESystem","title":"DiffEqOperators.jl: MOLFiniteDifference (WIP)","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/PDESystem/","page":"PDESystem","title":"PDESystem","text":"DiffEqOperators.jl defines the MOLFiniteDifference discretizer which performs a finite difference discretization using the DiffEqOperators.jl stencils. These stencils make use of NNLib.jl for fast operations on semi-linear domains.","category":"page"},{"location":"copies/GlobalSensitivity/methods/delta/#Delta-Moment-Independent-Method","page":"Delta Moment-Independent Method","title":"Delta Moment-Independent Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/delta/","page":"Delta Moment-Independent Method","title":"Delta Moment-Independent Method","text":"struct DeltaMoment{T} <: GSAMethod\n    nboot::Int\n    conf_level::Float64\n    Ygrid_length::Int\n    num_classes::T\nend","category":"page"},{"location":"copies/GlobalSensitivity/methods/delta/","page":"Delta Moment-Independent Method","title":"Delta Moment-Independent Method","text":"DeltaMoment has the following keyword arguments:","category":"page"},{"location":"copies/GlobalSensitivity/methods/delta/","page":"Delta Moment-Independent Method","title":"Delta Moment-Independent Method","text":"nboot: number of bootstrap repetions. Defaults to 500.\nconf_level: the level used for confidence interval calculation with bootstrap. Default value of 0.95.\nYgrid_length: number of quadrature points to consider when performing the kernel density estimation and the integration steps. Should be a power of 2 for efficient FFT in kernel density estimates. Defaults to 2048.\nnum_classes: Determine how many classes to split each factor into to when generating distributions of model output conditioned on class.","category":"page"},{"location":"copies/GlobalSensitivity/methods/delta/#Method-Details","page":"Delta Moment-Independent Method","title":"Method Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/delta/","page":"Delta Moment-Independent Method","title":"Delta Moment-Independent Method","text":"The Delta moment-independent method relies on new estimators for  density-based statistics.  It allows for the estimation of both  distribution-based sensitivity measures and of sensitivity measures that  look at contributions to a specific moment. One of the primary advantage  of this method is the independence of computation cost from the number of  parameters.","category":"page"},{"location":"copies/GlobalSensitivity/methods/delta/","page":"Delta Moment-Independent Method","title":"Delta Moment-Independent Method","text":"note: Note\nDeltaMoment only works for scalar output.","category":"page"},{"location":"copies/GlobalSensitivity/methods/delta/#API","page":"Delta Moment-Independent Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/delta/","page":"Delta Moment-Independent Method","title":"Delta Moment-Independent Method","text":"function gsa(f, method::DeltaMoment, p_range; N, batch = false, rng::AbstractRNG = Random.default_rng(), kwargs...)","category":"page"},{"location":"copies/GlobalSensitivity/methods/delta/#Example","page":"Delta Moment-Independent Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/delta/","page":"Delta Moment-Independent Method","title":"Delta Moment-Independent Method","text":"using GlobalSensitivity, Test\n\nfunction ishi(X)\n    A= 7\n    B= 0.1\n    sin(X[1]) + A*sin(X[2])^2+ B*X[3]^4 *sin(X[1])\nend\n\nlb = -ones(4)*π\nub = ones(4)*π\n\nm = gsa(ishi,DeltaMoment(),fill([lb[1], ub[1]], 3), N=1000)","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/#Automated-Index-Reduction-of-DAEs","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"In many cases one may accidentally write down a DAE that is not easily solvable by numerical methods. In this tutorial we will walk through an example of a pendulum which accidentally generates an index-3 DAE, and show how to use the modelingtoolkitize to correct the model definition before solving.","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/#Copy-Pastable-Example","page":"Automated Index Reduction of DAEs","title":"Copy-Pastable Example","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"using ModelingToolkit\nusing LinearAlgebra\nusing OrdinaryDiffEq\nusing Plots\n\nfunction pendulum!(du, u, p, t)\n    x, dx, y, dy, T = u\n    g, L = p\n    du[1] = dx\n    du[2] = T*x\n    du[3] = dy\n    du[4] = T*y - g\n    du[5] = x^2 + y^2 - L^2\n    return nothing\nend\npendulum_fun! = ODEFunction(pendulum!, mass_matrix=Diagonal([1,1,1,1,0]))\nu0 = [1.0, 0, 0, 0, 0]\np = [9.8, 1]\ntspan = (0, 10.0)\npendulum_prob = ODEProblem(pendulum_fun!, u0, tspan, p)\ntraced_sys = modelingtoolkitize(pendulum_prob)\npendulum_sys = structural_simplify(dae_index_lowering(traced_sys))\nprob = ODAEProblem(pendulum_sys, [], tspan)\nsol = solve(prob, Tsit5(),abstol=1e-8,reltol=1e-8)\nplot(sol, vars=states(traced_sys))","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/#Explanation","page":"Automated Index Reduction of DAEs","title":"Explanation","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/#Attempting-to-Solve-the-Equation","page":"Automated Index Reduction of DAEs","title":"Attempting to Solve the Equation","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"In this tutorial we will look at the pendulum system:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"beginaligned\n    x^prime = v_x\n    v_x^prime = Tx\n    y^prime = v_y\n    v_y^prime = Ty - g\n    0 = x^2 + y^2 - L^2\nendaligned","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"As a good DifferentialEquations.jl user, one would follow the mass matrix DAE tutorial to arrive at code for simulating the model:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"using OrdinaryDiffEq, LinearAlgebra\nfunction pendulum!(du, u, p, t)\n    x, dx, y, dy, T = u\n    g, L = p\n    du[1] = dx; du[2] = T*x\n    du[3] = dy; du[4] = T*y - g\n    du[5] = x^2 + y^2 - L^2\nend\npendulum_fun! = ODEFunction(pendulum!, mass_matrix=Diagonal([1,1,1,1,0]))\nu0 = [1.0, 0, 0, 0, 0]; p = [9.8, 1]; tspan = (0, 10.0)\npendulum_prob = ODEProblem(pendulum_fun!, u0, tspan, p)\nsolve(pendulum_prob,Rodas4())","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"However, one will quickly be greeted with the unfortunate message:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"┌ Warning: First function call produced NaNs. Exiting.\n└ @ OrdinaryDiffEq C:\\Users\\accou\\.julia\\packages\\OrdinaryDiffEq\\yCczp\\src\\initdt.jl:76\n┌ Warning: Automatic dt set the starting dt as NaN, causing instability.\n└ @ OrdinaryDiffEq C:\\Users\\accou\\.julia\\packages\\OrdinaryDiffEq\\yCczp\\src\\solve.jl:485\n┌ Warning: NaN dt detected. Likely a NaN value in the state, parameters, or derivative value caused this outcome.\n└ @ SciMLBase C:\\Users\\accou\\.julia\\packages\\SciMLBase\\DrPil\\src\\integrator_interface.jl:325","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"Did you implement the DAE incorrectly? No. Is the solver broken? No.","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/#Understanding-DAE-Index","page":"Automated Index Reduction of DAEs","title":"Understanding DAE Index","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"It turns out that this is a property of the DAE that we are attempting to solve. This kind of DAE is known as an index-3 DAE. For a complete discussion of DAE index, see this article. Essentially the issue here is that we have 4 differential variables (x, v_x, y, v_y) and one algebraic variable T (which we can know because there is no D(T) term in the equations). An index-1 DAE always satisfies that the Jacobian of the algebraic equations is non-singular. Here, the first 4 equations are differential equations, with the last term the algebraic relationship. However, the partial derivative of x^2 + y^2 - L^2 w.r.t. T is zero, and thus the Jacobian of the algebraic equations is the zero matrix and thus it's singular. This is a very quick way to see whether the DAE is index 1!","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"The problem with higher order DAEs is that the matrices used in Newton solves are singular or close to singular when applied to such problems. Because of this fact, the nonlinear solvers (or Rosenbrock methods) break down, making them difficult to solve. The classic paper DAEs are not ODEs goes into detail on this and shows that many methods are no longer convergent when index is higher than one. So it's not necessarily the fault of the solver or the implementation: this is known.","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"But that's not a satisfying answer, so what do you do about it?","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/#Transforming-Higher-Order-DAEs-to-Index-1-DAEs","page":"Automated Index Reduction of DAEs","title":"Transforming Higher Order DAEs to Index-1 DAEs","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"It turns out that higher order DAEs can be transformed into lower order DAEs. If you differentiate the last equation two times and perform a substitution, you can arrive at the following set of equations:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"beginaligned\nx^prime = v_x \nv_x^prime = x T \ny^prime = v_y \nv_y^prime = y T - g \n0 = 2 left(v_x^2 + v_y^2 + y ( y T - g ) + T x^2 right)\nendaligned","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"Note that this is mathematically-equivalent to the equation that we had before, but the Jacobian w.r.t. T of the algebraic equation is no longer zero because of the substitution. This means that if you wrote down this version of the model it will be index-1 and solve correctly! In fact, this is how DAE index is commonly defined: the number of differentiations it takes to transform the DAE into an ODE, where an ODE is an index-0 DAE by substituting out all of the algebraic relationships.","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/#Automating-the-Index-Reduction","page":"Automated Index Reduction of DAEs","title":"Automating the Index Reduction","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"However, requiring the user to sit there and work through this process on potentially millions of equations is an unfathomable mental overhead. But, we can avoid this by using methods like the Pantelides algorithm for automatically performing this reduction to index 1. While this requires the ModelingToolkit symbolic form, we use modelingtoolkitize to transform the numerical code into symbolic code, run dae_index_lowering lowering, then transform back to numerical code with ODEProblem, and solve with a numerical solver. Let's try that out:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"traced_sys = modelingtoolkitize(pendulum_prob)\npendulum_sys = structural_simplify(dae_index_lowering(traced_sys))\nprob = ODEProblem(pendulum_sys, Pair[], tspan)\nsol = solve(prob, Rodas4())\n\nusing Plots\nplot(sol, vars=states(traced_sys))","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"Note that plotting using states(traced_sys) is done so that any variables which are symbolically eliminated, or any variable reorderings done for enhanced parallelism/performance, still show up in the resulting plot and the plot is shown in the same order as the original numerical code.","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"Note that we can even go a little bit further. If we use the ODAEProblem constructor, we can remove the algebraic equations from the states of the system and fully transform the index-3 DAE into an index-0 ODE which can be solved via an explicit Runge-Kutta method:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"traced_sys = modelingtoolkitize(pendulum_prob)\npendulum_sys = structural_simplify(dae_index_lowering(traced_sys))\nprob = ODAEProblem(pendulum_sys, Pair[], tspan)\nsol = solve(prob, Tsit5(),abstol=1e-8,reltol=1e-8)\nplot(sol, vars=states(traced_sys))","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize_index_reduction/","page":"Automated Index Reduction of DAEs","title":"Automated Index Reduction of DAEs","text":"And there you go: this has transformed the model from being too hard to solve with implicit DAE solvers, to something that is easily solved with explicit Runge-Kutta methods for non-stiff equations.","category":"page"},{"location":"copies/Surrogates/tutorials/#Surrogates-101","page":"Basics","title":"Surrogates 101","text":"","category":"section"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"Let's start with something easy to get our hands dirty. I want to build a surrogate for f(x) = log(x) cdot x^2+x^3. Let's choose the radial basis surrogate.","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"using Surrogates\nf = x -> log(x)*x^2+x^3\nlb = 1.0\nub = 10.0\nx = sample(50,lb,ub,SobolSample())\ny = f.(x)\nmy_radial_basis = RadialBasis(x,y,lb,ub)\n\n#I want an approximation at 5.4\napprox = my_radial_basis(5.4)","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"Let's now see an example in 2D.","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"using Surrogates\nusing LinearAlgebra\nf = x -> x[1]*x[2]\nlb = [1.0,2.0]\nub = [10.0,8.5]\nx = sample(50,lb,ub,SobolSample())\ny = f.(x)\nmy_radial_basis = RadialBasis(x,y,lb,ub)\n\n#I want an approximation at (1.0,1.4)\napprox = my_radial_basis((1.0,1.4))","category":"page"},{"location":"copies/Surrogates/tutorials/#Kriging-standard-error","page":"Basics","title":"Kriging standard error","text":"","category":"section"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"Let's now use the Kriging surrogate, which is a single-output Gaussian process. This surrogate has a nice feature: not only does it approximate the solution at a point, it also calculates the standard error at such point. Let's see an example:","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"using Surrogates\nf = x -> exp(x)*x^2+x^3\nlb = 0.0\nub = 10.0\nx = sample(100,lb,ub,UniformSample())\ny = f.(x)\np = 1.9\nmy_krig = Kriging(x,y,lb,ub,p=p)\n\n#I want an approximation at 5.4\napprox = my_krig(5.4)\n\n#I want to find the standard error at 5.4\nstd_err = std_error_at_point(my_krig,5.4)","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"Let's now optimize the Kriging surrogate using Lower confidence bound method, this is just a one-liner:","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"surrogate_optimize(f,LCBS(),lb,ub,my_krig,UniformSample())","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"Surrogate optimization methods have two purposes: they both sample the space in unknown regions and look for the minima at the same time.","category":"page"},{"location":"copies/Surrogates/tutorials/#Lobachevsky-integral","page":"Basics","title":"Lobachevsky integral","text":"","category":"section"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"The Lobachevsky surrogate has the nice feature of having a closed formula for its integral, which is something that other surrogates are missing. Let's compare it with QuadGK:","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"using Surrogates\nusing QuadGK\nobj = x -> 3*x + log(x)\na = 1.0\nb = 4.0\nx = sample(2000,a,b,SobolSample())\ny = obj.(x)\nalpha = 2.0\nn = 6\nmy_loba = LobachevskySurrogate(x,y,a,b,alpha=alpha,n=n)\n\n#1D integral\nint_1D = lobachevsky_integral(my_loba,a,b)\nint = quadgk(obj,a,b)\nint_val_true = int[1]-int[2]\n@assert int_1D ≈ int_val_true","category":"page"},{"location":"copies/Surrogates/tutorials/#Example-of-NeuralSurrogate","page":"Basics","title":"Example of NeuralSurrogate","text":"","category":"section"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"Basic example of fitting a neural network on a simple function of two variables.","category":"page"},{"location":"copies/Surrogates/tutorials/","page":"Basics","title":"Basics","text":"using Surrogates\nusing Flux\nusing Statistics\n\nf = x -> x[1]^2 + x[2]^2\nbounds = Float32[-1.0, -1.0], Float32[1.0, 1.0]\n# Flux models are in single precision by default.\n# Thus, single precision will also be used here for our training samples.\n\nx_train = sample(100, bounds..., SobolSample())\ny_train = f.(x_train)\n\n# Perceptron with one hidden layer of 20 neurons.\nmodel = Chain(Dense(2, 20, relu), Dense(20, 1))\nloss(x, y) = Flux.mse(model(x), y)\n\n# Training of the neural network\nlearning_rate = 0.1\noptimizer = Descent(learning_rate)  # Simple gradient descent. See Flux documentation for other options.\nn_epochs = 50\nsgt = NeuralSurrogate(x_train, y_train, bounds..., model=model, loss=loss, opt=optimizer, n_echos=n_epochs)\n\n# Testing the new model\nx_test = sample(30, bounds..., SobolSample())\ntest_error = mean(abs2, sgt(x)[1] - f(x) for x in x_test)","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/#NLopt.jl","page":"NLopt.jl","title":"NLopt.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt is Julia package interfacing to the free/open-source NLopt library which implements many optimization methods both global and local NLopt Documentation.","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/#Installation:-OptimizationNLopt.jl","page":"NLopt.jl","title":"Installation: OptimizationNLopt.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"To use this package, install the OptimizationNLopt package:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"import Pkg; Pkg.add(\"OptimizationNLopt\")","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/#Methods","page":"NLopt.jl","title":"Methods","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.jl algorithms are chosen either via NLopt.Opt(:algname, nstates) where nstates is the number of states to be optimized but preferably via NLopt.AlgorithmName() where `AlgorithmName can be one of the following:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.LD_LBFGS_NOCEDAL()\nNLopt.LD_LBFGS()\nNLopt.LN_PRAXIS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.LD_MMA()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LD_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LN_BOBYQA()\nNLopt.GN_ISRES()\nNLopt.AUGLAG()\nNLopt.AUGLAG_EQ()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()\nNLopt.GN_ESCH()\nNLopt.GN_AGS()","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"See the NLopt Documentation for more details on each optimizer.","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Beyond the common arguments the following optimizer parameters can be set as kwargs:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"stopval\nxtol_rel\nxtol_abs\nconstrtol_abs\ninitial_step\npopulation\nvector_storage","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/#Local-Optimizer","page":"NLopt.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/#Derivative-Free","page":"NLopt.jl","title":"Derivative-Free","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the OptimizationProblem.","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt derivative-free optimizers are:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.LN_PRAXIS()\nNLopt.LN_COBYLA()\nNLopt.LN_NEWUOA()\nNLopt.LN_NEWUOA_BOUND()\nNLopt.LN_NELDERMEAD()\nNLopt.LN_SBPLX()\nNLopt.LN_AUGLAG()\nNLopt.LN_AUGLAG_EQ()\nNLopt.LN_BOBYQA()","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can optimized using the NLopt.LN_NELDERMEAD() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.LN_NELDERMEAD())","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/#Gradient-Based","page":"NLopt.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Gradient-based optimizers are optimizers which utilise the gradient information based on derivatives defined or automatic differentiation.","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt gradient-based optimizers are:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.LD_LBFGS_NOCEDAL()\nNLopt.LD_LBFGS()\nNLopt.LD_VAR1()\nNLopt.LD_VAR2()\nNLopt.LD_TNEWTON()\nNLopt.LD_TNEWTON_RESTART()\nNLopt.LD_TNEWTON_PRECOND()\nNLopt.LD_TNEWTON_PRECOND_RESTART()\nNLopt.LD_MMA()\nNLopt.LD_AUGLAG()\nNLopt.LD_AUGLAG_EQ()\nNLopt.LD_SLSQP()\nNLopt.LD_CCSAQ()","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can optimized using NLopt.LD_LBFGS() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.LD_LBFGS())","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/#Global-Optimizer","page":"NLopt.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/#Without-Constraint-Equations","page":"NLopt.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The following algorithms in NLopt are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt global optimizers which fall into this category are:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_DIRECT()\nNLopt.GN_DIRECT_L()\nNLopt.GN_DIRECT_L_RAND()\nNLopt.GN_DIRECT_NOSCAL()\nNLopt.GN_DIRECT_L_NOSCAL()\nNLopt.GN_DIRECT_L_RAND_NOSCAL()\nNLopt.GD_STOGO()\nNLopt.GD_STOGO_RAND()\nNLopt.GN_CRS2_LM()\nNLopt.GN_MLSL()\nNLopt.GD_MLSL()\nNLopt.GN_MLSL_LDS()\nNLopt.GD_MLSL_LDS()\nNLopt.G_MLSL()\nNLopt.G_MLSL_LDS()\nNLopt.GN_ESCH()","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can optimized using NLopt.GN_DIRECT() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.GN_DIRECT())","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"Algorithms such as NLopt.G_MLSL() or NLopt.G_MLSL_LDS() also require a local optimiser to be selected which via the local_method argument of solve.","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The Rosenbrock function can optimized using NLopt.G_MLSL_LDS() with NLopt.LN_NELDERMEAD() as the local optimizer. The local optimizer maximum iterations are set via local_maxiters:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, NLopt.G_MLSL_LDS(), local_method = NLopt.LD_LBFGS(), local_maxiters=10000)","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/#With-Constraint-Equations","page":"NLopt.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"The following algorithms in NLopt are performing global optimization on problems with constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"note: Constraints with NLopt\nEquality and inequality equation support for NLopt via Optimization is not supported directly. However, you can use the MOI wrapper to use constraints with NLopt optimisers.","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt global optimizers which fall into this category are:","category":"page"},{"location":"copies/Optimization/optimization_packages/nlopt/","page":"NLopt.jl","title":"NLopt.jl","text":"NLopt.GN_ORIG_DIRECT()\nNLopt.GN_ORIG_DIRECT_L()\nNLopt.GN_ISRES()\nNLopt.GN_AGS()","category":"page"},{"location":"copies/Surrogates/welded_beam/","page":"Welded beam function","title":"Welded beam function","text":"#Welded beam function","category":"page"},{"location":"copies/Surrogates/welded_beam/","page":"Welded beam function","title":"Welded beam function","text":"The welded beam function is defined as: f(hlt) = sqrtfraca^2 + b^2 + ablsqrt025(l^2+(h+t)^2) With: a = frac6000sqrt2hl b = frac6000(14 + 05l)*sqrt025(l^2+(h+t)^2)2*0707hl(fracl^212+025*(h+t)^2)","category":"page"},{"location":"copies/Surrogates/welded_beam/","page":"Welded beam function","title":"Welded beam function","text":"It has 3 dimension.","category":"page"},{"location":"copies/Surrogates/welded_beam/","page":"Welded beam function","title":"Welded beam function","text":"using Surrogates\nusing Plots\nusing LinearAlgebra\ndefault()","category":"page"},{"location":"copies/Surrogates/welded_beam/","page":"Welded beam function","title":"Welded beam function","text":"Define the objective function:","category":"page"},{"location":"copies/Surrogates/welded_beam/","page":"Welded beam function","title":"Welded beam function","text":"function f(x)\n    h = x[1]\n    l = x[2]\n    t = x[3]\n    a = 6000/(sqrt(2)*h*l)\n    b = (6000*(14+0.5*l)*sqrt(0.25*(l^2+(h+t)^2)))/(2*(0.707*h*l*(l^2/12 + 0.25*(h+t)^2)))\n    return (sqrt(a^2+b^2 + l*a*b))/(sqrt(0.25*(l^2+(h+t)^2)))\nend","category":"page"},{"location":"copies/Surrogates/welded_beam/","page":"Welded beam function","title":"Welded beam function","text":"n = 300\nd = 3\nlb = [0.125,5.0,5.0]\nub = [1.,10.,10.]\nx = sample(n,lb,ub,SobolSample())\ny = f.(x)\nn_test = 1000\nx_test = sample(n_test,lb,ub,GoldenSample());\ny_true = f.(x_test);","category":"page"},{"location":"copies/Surrogates/welded_beam/","page":"Welded beam function","title":"Welded beam function","text":"my_rad = RadialBasis(x,y,lb,ub)\ny_rad = my_rad.(x_test)\nmse_rad = norm(y_true - y_rad,2)/n_test\nprint(\"MSE Radial: $mse_rad\")\n\nmy_krig = Kriging(x,y,lb,ub)\ny_krig = my_krig.(x_test)\nmse_krig = norm(y_true - y_krig,2)/n_test\nprint(\"MSE Kriging: $mse_krig\")\n\nmy_loba = LobachevskySurrogate(x,y,lb,ub)\ny_loba = my_loba.(x_test)\nmse_rad = norm(y_true - y_loba,2)/n_test\nprint(\"MSE Lobachevsky: $mse_rad\")","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Convolutional-Neural-ODE-MNIST-Classifier-on-GPU","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"Training a Convolutional Neural Net Classifier for MNIST using a neural ordinary differential equation NN-ODE on GPUs with Minibatching.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"(Step-by-step description below)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"using DiffEqFlux, DifferentialEquations, Printf\nusing Flux.Losses: logitcrossentropy\nusing Flux.Data: DataLoader\nusing MLDatasets\nusing MLDataUtils:  LabelEnc, convertlabel, stratifiedobs\nusing CUDA\nCUDA.allowscalar(false)\n\nfunction loadmnist(batchsize = bs, train_split = 0.9)\n    # Use MLDataUtils LabelEnc for natural onehot conversion\n    onehot(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw,\n                                      LabelEnc.NativeLabels(collect(0:9)))\n    # Load MNIST\n    imgs, labels_raw = MNIST.traindata();\n    # Process images into (H,W,C,BS) batches\n    x_data = Float32.(reshape(imgs, size(imgs,1), size(imgs,2), 1, size(imgs,3)))\n    y_data = onehot(labels_raw)\n    (x_train, y_train), (x_test, y_test) = stratifiedobs((x_data, y_data),\n                                                         p = train_split)\n    return (\n        # Use Flux's DataLoader to automatically minibatch and shuffle the data\n        DataLoader(gpu.(collect.((x_train, y_train))); batchsize = batchsize,\n                   shuffle = true),\n        # Don't shuffle the test data\n        DataLoader(gpu.(collect.((x_test, y_test))); batchsize = batchsize,\n                   shuffle = false)\n    )\nend\n\n# Main\nconst bs = 128\nconst train_split = 0.9\ntrain_dataloader, test_dataloader = loadmnist(bs, train_split);\n\ndown = Chain(Conv((3, 3), 1=>64, relu, stride = 1), GroupNorm(64, 64),\n             Conv((4, 4), 64=>64, relu, stride = 2, pad=1), GroupNorm(64, 64),\n             Conv((4, 4), 64=>64, stride = 2, pad = 1)) |>gpu\n\ndudt = Chain(Conv((3, 3), 64=>64, tanh, stride=1, pad=1),\n             Conv((3, 3), 64=>64, tanh, stride=1, pad=1)) |>gpu\n\nfc = Chain(GroupNorm(64, 64), x -> relu.(x), MeanPool((6, 6)),\n           x -> reshape(x, (64, :)), Dense(64,10)) |> gpu\n          \nnn_ode = NeuralODE(dudt, (0.f0, 1.f0), Tsit5(),\n                   save_everystep = false,\n                   reltol = 1e-3, abstol = 1e-3,\n                   save_start = false) |> gpu\n\nfunction DiffEqArray_to_Array(x)\n    xarr = gpu(x)\n    return xarr[:,:,:,:,1]\nend\n\n# Build our over-all model topology\nmodel = Chain(down,                 # (28, 28, 1, BS) -> (6, 6, 64, BS)\n              nn_ode,               # (6, 6, 64, BS) -> (6, 6, 64, BS, 1)\n              DiffEqArray_to_Array, # (6, 6, 64, BS, 1) -> (6, 6, 64, BS)\n              fc)                   # (6, 6, 64, BS) -> (10, BS)\n\n# To understand the intermediate NN-ODE layer, we can examine it's dimensionality\nimg, lab = train_dataloader.data[1][:, :, :, 1:1], train_dataloader.data[2][:, 1:1]\n\nx_d = down(img)\n\n# We can see that we can compute the forward pass through the NN topology\n# featuring an NNODE layer.\nx_m = model(img)\n\nclassify(x) = argmax.(eachcol(x))\n\nfunction accuracy(model, data; n_batches = 100)\n    total_correct = 0\n    total = 0\n    for (i, (x, y)) in enumerate(data)\n        # Only evaluate accuracy for n_batches\n        i > n_batches && break\n        target_class = classify(cpu(y))\n        predicted_class = classify(cpu(model(x)))\n        total_correct += sum(target_class .== predicted_class)\n        total += length(target_class)\n    end\n    return total_correct / total\nend\n\n# burn in accuracy\naccuracy(model, train_dataloader)\n\nloss(x, y) = logitcrossentropy(model(x), y)\n\n# burn in loss\nloss(img, lab)\n\nopt = ADAM(0.05)\niter = 0\n\ncb() = begin\n    global iter += 1\n    # Monitor that the weights do infact update\n    # Every 10 training iterations show accuracy\n    if iter % 10 == 1\n        train_accuracy = accuracy(model, train_dataloader) * 100\n        test_accuracy = accuracy(model, test_dataloader;\n                                 n_batches = length(test_dataloader)) * 100\n        @printf(\"Iter: %3d || Train Accuracy: %2.3f || Test Accuracy: %2.3f\\n\",\n                iter, train_accuracy, test_accuracy)\n    end\nend\n\nFlux.train!(loss, Flux.params(down, nn_ode.p, fc), train_dataloader, opt, cb = cb)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Step-by-Step-Description","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Step-by-Step Description","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Load-Packages","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Load Packages","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"using DiffEqFlux, DifferentialEquations, Printf\nusing Flux.Losses: logitcrossentropy\nusing Flux.Data: DataLoader\nusing MLDatasets\nusing MLDataUtils:  LabelEnc, convertlabel, stratifiedobs","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#GPU","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"GPU","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"A good trick used here:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"using CUDA\nCUDA.allowscalar(false)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"Ensures that only optimized kernels are called when using the GPU. Additionally, the gpu function is shown as a way to translate models and data over to the GPU. Note that this function is CPU-safe, so if the GPU is disabled or unavailable, this code will fallback to the CPU.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Load-MNIST-Dataset-into-Minibatches","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Load MNIST Dataset into Minibatches","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"The preprocessing is done in loadmnist where the raw MNIST data is split into features x_train and labels y_train by specifying batchsize bs. The function convertlabel will then transform the current labels (labels_raw) from numbers 0 to 9 (LabelEnc.NativeLabels(collect(0:9))) into one hot encoding (LabelEnc.OneOfK).","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"Features are reshaped into format [Height, Width, Color, BatchSize] or in this case [28, 28, 1, 128] meaning that every minibatch will contain 128 images with a single color channel of 28x28 pixels. The entire dataset of 60,000 images is split into the train and test dataset, ensuring a balanced ratio of labels. These splits are then passed to Flux's DataLoader. This automatically minibatches both the images and labels. Additionally, it allows us to shuffle the train dataset in each epoch while keeping the order of the test data the same.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"function loadmnist(batchsize = bs, train_split = 0.9)\n    # Use MLDataUtils LabelEnc for natural onehot conversion\n    onehot(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw,\n                                      LabelEnc.NativeLabels(collect(0:9)))\n    # Load MNIST\n    imgs, labels_raw = MNIST.traindata();\n    # Process images into (H,W,C,BS) batches\n    x_data = Float32.(reshape(imgs, size(imgs,1), size(imgs,2), 1, size(imgs,3)))\n    y_data = onehot(labels_raw)\n    (x_train, y_train), (x_test, y_test) = stratifiedobs((x_data, y_data),\n                                                         p = train_split)\n    return (\n        # Use Flux's DataLoader to automatically minibatch and shuffle the data\n        DataLoader(gpu.(collect.((x_train, y_train))); batchsize = batchsize,\n                   shuffle = true),\n        # Don't shuffle the test data\n        DataLoader(gpu.(collect.((x_test, y_test))); batchsize = batchsize,\n                   shuffle = false)\n    )\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"and then loaded from main:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"# Main\nconst bs = 128\nconst train_split = 0.9\ntrain_dataloader, test_dataloader = loadmnist(bs, train_split)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Layers","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Layers","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"The Neural Network requires passing inputs sequentially through multiple layers. We use Chain which allows inputs to functions to come from previous layer and sends the outputs to the next. Four different sets of layers are used here:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"down = Chain(Conv((3, 3), 1=>64, relu, stride = 1), GroupNorm(64, 64),\n             Conv((4, 4), 64=>64, relu, stride = 2, pad=1), GroupNorm(64, 64),\n             Conv((4, 4), 64=>64, stride = 2, pad = 1)) |>gpu\n\ndudt = Chain(Conv((3, 3), 64=>64, tanh, stride=1, pad=1),\n             Conv((3, 3), 64=>64, tanh, stride=1, pad=1)) |>gpu\n\nfc = Chain(GroupNorm(64, 64), x -> relu.(x), MeanPool((6, 6)),\n           x -> reshape(x, (64, :)), Dense(64,10)) |> gpu\n          \nnn_ode = NeuralODE(dudt, (0.f0, 1.f0), Tsit5(),\n                   save_everystep = false,\n                   reltol = 1e-3, abstol = 1e-3,\n                   save_start = false) |> gpu","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"down: This layer downsamples our images into 6 x 6 x 64 dimensional features.         It takes a 28 x 28 image, and passes it through a convolutional neural network         layer with relu activation","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"nn: A 2 layer Convolutional Neural Network Chain with tanh activation which is used to model       our differential equation","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"nn_ode: ODE solver layer","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"fc: The final fully connected layer which maps our learned features to the probability of       the feature vector of belonging to a particular class","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"gpu: A utility function which transfers our model to GPU, if one is available","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Array-Conversion","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Array Conversion","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"When using NeuralODE, we can use the following function as a cheap conversion of DiffEqArray from the ODE solver into a Matrix that can be used in the following layer:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"function DiffEqArray_to_Array(x)\n    xarr = gpu(x)\n    return xarr[:,:,:,:,1]\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"For CPU: If this function does not automatically fallback to CPU when no GPU is present, we can change gpu(x) with Array(x).","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Build-Topology","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Build Topology","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"Next we connect all layers together in a single chain:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"# Build our over-all model topology\nmodel = Chain(down,                 # (28, 28, 1, BS) -> (6, 6, 64, BS)\n              nn_ode,               # (6, 6, 64, BS) -> (6, 6, 64, BS, 1)\n              DiffEqArray_to_Array, # (6, 6, 64, BS, 1) -> (6, 6, 64, BS)\n              fc)                   # (6, 6, 64, BS) -> (10, BS)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"There are a few things we can do to examine the inner workings of our neural network:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"img, lab = train_dataloader.data[1][:, :, :, 1:1], train_dataloader.data[2][:, 1:1]\n\n# To understand the intermediate NN-ODE layer, we can examine it's dimensionality\nx_d = down(img)\n\n# We can see that we can compute the forward pass through the NN topology\n# featuring an NNODE layer.\nx_m = model(img)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"This can also be built without the NN-ODE by replacing nn-ode with a simple nn:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"# We can also build the model topology without a NN-ODE\nm_no_ode = Chain(down, nn, fc) |> gpu\n\nx_m = m_no_ode(img)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Prediction","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Prediction","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"To convert the classification back into readable numbers, we use classify which returns the prediction by taking the arg max of the output for each column of the minibatch:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"classify(x) = argmax.(eachcol(x))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Accuracy","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Accuracy","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"We then evaluate the accuracy on n_batches at a time through the entire network:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"function accuracy(model, data; n_batches = 100)\n    total_correct = 0\n    total = 0\n    for (i, (x, y)) in enumerate(data)\n        # Only evaluate accuracy for n_batches\n        i > n_batches && break\n        target_class = classify(cpu(y))\n        predicted_class = classify(cpu(model(x)))\n        total_correct += sum(target_class .== predicted_class)\n        total += length(target_class)\n    end\n    return total_correct / total\nend\n\n# burn in accuracy\naccuracy(model, train_dataloader)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Training-Parameters","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Training Parameters","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"Once we have our model, we can train our neural network by backpropagation using Flux.train!. This function requires Loss, Optimizer and Callback functions.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Loss","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Loss","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"Cross Entropy is the loss function computed here which applies a Softmax operation on the final output of our model. logitcrossentropy takes in the prediction from our model model(x) and compares it to actual output y:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"loss(x, y) = logitcrossentropy(model(x), y)\n\n# burn in loss\nloss(img, lab)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Optimizer","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Optimizer","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"ADAM is specified here as our optimizer with a learning rate of 0.05:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"opt = ADAM(0.05)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#CallBack","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"CallBack","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"This callback function is used to print both the training and testing accuracy after 10 training iterations:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"cb() = begin\n    global iter += 1\n    # Monitor that the weights update\n    # Every 10 training iterations show accuracy\n    if iter % 10 == 1\n        train_accuracy = accuracy(model, train_dataloader) * 100\n        test_accuracy = accuracy(model, test_dataloader;\n                                 n_batches = length(test_dataloader)) * 100\n        @printf(\"Iter: %3d || Train Accuracy: %2.3f || Test Accuracy: %2.3f\\n\",\n                iter, train_accuracy, test_accuracy)\n    end\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Train","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Train","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"To train our model, we select the appropriate trainable parameters of our network with params. In our case, backpropagation is required for down, nn_ode and fc. Notice that the parameters for Neural ODE is given by nn_ode.p:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"# Train the NN-ODE and monitor the loss and weights.\nFlux.train!(loss, Flux.params(down, nn_ode.p, fc), train_dataloader, opt, cb = cb)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/#Expected-Output","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Expected Output","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_conv_neural_ode/","page":"Convolutional Neural ODE MNIST Classifier on GPU","title":"Convolutional Neural ODE MNIST Classifier on GPU","text":"Iter:   1 || Train Accuracy: 8.453 || Test Accuracy: 8.883\nIter:  11 || Train Accuracy: 14.773 || Test Accuracy: 14.967\nIter:  21 || Train Accuracy: 24.383 || Test Accuracy: 24.433\nIter:  31 || Train Accuracy: 38.820 || Test Accuracy: 38.000\nIter:  41 || Train Accuracy: 30.852 || Test Accuracy: 31.350\nIter:  51 || Train Accuracy: 29.852 || Test Accuracy: 29.433\nIter:  61 || Train Accuracy: 45.195 || Test Accuracy: 45.217\nIter:  71 || Train Accuracy: 70.336 || Test Accuracy: 68.850\nIter:  81 || Train Accuracy: 76.250 || Test Accuracy: 75.783\nIter:  91 || Train Accuracy: 80.867 || Test Accuracy: 81.017\nIter: 101 || Train Accuracy: 86.398 || Test Accuracy: 85.317\nIter: 111 || Train Accuracy: 90.852 || Test Accuracy: 90.650\nIter: 121 || Train Accuracy: 93.477 || Test Accuracy: 92.550\nIter: 131 || Train Accuracy: 93.320 || Test Accuracy: 92.483\nIter: 141 || Train Accuracy: 94.273 || Test Accuracy: 93.567\nIter: 151 || Train Accuracy: 94.531 || Test Accuracy: 93.583\nIter: 161 || Train Accuracy: 94.992 || Test Accuracy: 94.067\nIter: 171 || Train Accuracy: 95.398 || Test Accuracy: 94.883\nIter: 181 || Train Accuracy: 96.945 || Test Accuracy: 95.633\nIter: 191 || Train Accuracy: 96.430 || Test Accuracy: 95.750\nIter: 201 || Train Accuracy: 96.859 || Test Accuracy: 95.983\nIter: 211 || Train Accuracy: 97.359 || Test Accuracy: 96.500\nIter: 221 || Train Accuracy: 96.586 || Test Accuracy: 96.133\nIter: 231 || Train Accuracy: 96.992 || Test Accuracy: 95.833\nIter: 241 || Train Accuracy: 97.148 || Test Accuracy: 95.950\nIter: 251 || Train Accuracy: 96.422 || Test Accuracy: 95.950\nIter: 261 || Train Accuracy: 96.094 || Test Accuracy: 95.633\nIter: 271 || Train Accuracy: 96.719 || Test Accuracy: 95.767\nIter: 281 || Train Accuracy: 96.719 || Test Accuracy: 96.000\nIter: 291 || Train Accuracy: 96.609 || Test Accuracy: 95.817\nIter: 301 || Train Accuracy: 96.656 || Test Accuracy: 96.033\nIter: 311 || Train Accuracy: 97.594 || Test Accuracy: 96.500\nIter: 321 || Train Accuracy: 97.633 || Test Accuracy: 97.083\nIter: 331 || Train Accuracy: 98.008 || Test Accuracy: 97.067\nIter: 341 || Train Accuracy: 98.070 || Test Accuracy: 97.150\nIter: 351 || Train Accuracy: 97.875 || Test Accuracy: 97.050\nIter: 361 || Train Accuracy: 96.922 || Test Accuracy: 96.500\nIter: 371 || Train Accuracy: 97.188 || Test Accuracy: 96.650\nIter: 381 || Train Accuracy: 97.820 || Test Accuracy: 96.783\nIter: 391 || Train Accuracy: 98.156 || Test Accuracy: 97.567\nIter: 401 || Train Accuracy: 98.250 || Test Accuracy: 97.367\nIter: 411 || Train Accuracy: 97.969 || Test Accuracy: 97.267\nIter: 421 || Train Accuracy: 96.555 || Test Accuracy: 95.667","category":"page"},{"location":"copies/ModelingToolkit/tutorials/stochastic_diffeq/#Modeling-with-Stochasticity","page":"Modeling with Stochasticity","title":"Modeling with Stochasticity","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/stochastic_diffeq/","page":"Modeling with Stochasticity","title":"Modeling with Stochasticity","text":"All models with ODESystem are deterministic. SDESystem adds another element to the model: randomness. This is a stochastic differential equation which has a deterministic (drift) component and a stochastic (diffusion) component. Let's take the Lorenz equation from the first tutorial and extend it to have multiplicative noise.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/stochastic_diffeq/","page":"Modeling with Stochasticity","title":"Modeling with Stochasticity","text":"using ModelingToolkit, StochasticDiffEq\n\n# Define some variables\n@parameters σ ρ β\n@variables t x(t) y(t) z(t)\nD = Differential(t)\n\neqs = [D(x) ~ σ*(y-x),\n       D(y) ~ x*(ρ-z)-y,\n       D(z) ~ x*y - β*z]\n\nnoiseeqs = [0.1*x,\n            0.1*y,\n            0.1*z]\n\n@named de = SDESystem(eqs,noiseeqs,t,[x,y,z],[σ,ρ,β])\n\nu0map = [\n    x => 1.0,\n    y => 0.0,\n    z => 0.0\n]\n\nparammap = [\n    σ => 10.0,\n    β => 26.0,\n    ρ => 2.33\n]\n\nprob = SDEProblem(de,u0map,(0.0,100.0),parammap)\nsol = solve(prob,SOSRI())","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary:-Magnetic-Components","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary: Magnetic Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#Flux-Tubes","page":"Magnetic Components","title":"Flux Tubes","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/","page":"Magnetic Components","title":"Magnetic Components","text":"CurrentModule = ModelingToolkitStandardLibrary.Magnetic.FluxTubes","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#Flux-Tube-Utilities","page":"Magnetic Components","title":"Flux Tube Utilities","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/","page":"Magnetic Components","title":"Magnetic Components","text":"PositiveMagneticPort\nNegativeMagneticPort\nTwoPort","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.PositiveMagneticPort","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.PositiveMagneticPort","text":"Positive magnetic port\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.NegativeMagneticPort","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.NegativeMagneticPort","text":"Negative magnetic port\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.TwoPort","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.TwoPort","text":"TwoPort(;name, V_m_start=0.0, Phi_start=0.0)\n\nPartial component with magnetic potential difference between two magnetic ports p and n and magnetic flux Phi from p to n.\n\nParameters:\n\nV_m_start: Initial magnetic potential difference between both ports\nPhi_start: Initial magnetic flux from portp to portn\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#Basic-Flux-Tube-Blocks","page":"Magnetic Components","title":"Basic Flux Tube Blocks","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/","page":"Magnetic Components","title":"Magnetic Components","text":"Ground\nIdle\nShort\nCrossing\nConstantPermeance\nConstantReluctance\nEddyCurrent\nElectroMagneticConverter","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.Ground","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.Ground","text":"Ground(;name)\n\nZero magnetic potential.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.Idle","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.Idle","text":"Idle(;name)\n\nIdle running branch.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.Short","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.Short","text":"Short(;name)\n\nShort cut branch.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.Crossing","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.Crossing","text":"Crossing(;name)\n\nCrossing of two branches.\n\nThis is a simple crossing of two branches. The ports portp1 and portp2 are connected, as well as portn1 and portn2.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ConstantPermeance","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ConstantPermeance","text":"ConstantPermeance(;name, G_m=1.0)\n\nConstant permeance.\n\nParameters:\n\nG_m: [H] Magnetic permeance\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ConstantReluctance","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ConstantReluctance","text":"ConstantReluctance(;name, R_m=1.0)\n\nConstant reluctance.\n\nParameters:\n\nR_m: [H^-1] Magnetic reluctance\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.EddyCurrent","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.EddyCurrent","text":"EddyCurrent(;name, rho=0.098e-6, l=1, A=1, Phi_start=0.0)\n\nFor modelling of eddy current in a conductive magnetic flux tube.\n\nParameters:\n\nrho: [ohm * m] Resistivity of flux tube material (default: Iron at 20degC)\nl: [m] Average length of eddy current path\nA: [m^2] Cross sectional area of eddy current path\nPhi_start: [Wb] Initial magnetic flux flowing into the port_p\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ElectroMagneticConverter","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ElectroMagneticConverter","text":"ElectroMagneticConverter(;name, N, Phi_start=0.0)\n\nIdeal electromagnetic energy conversion.\n\nThe electromagnetic energy conversion is given by Ampere's law and Faraday's law respectively V_m = N * i N * dΦ/dt = -v\n\nParameters:\n\nN: Number of turns\nPhi_start: [Wb] Initial magnetic flux flowing into the port_p\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#Flux-Tube-Sources","page":"Magnetic Components","title":"Flux Tube Sources","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/","page":"Magnetic Components","title":"Magnetic Components","text":"ConstantMagneticPotentialDifference\nConstantMagneticFlux","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ConstantMagneticPotentialDifference","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ConstantMagneticPotentialDifference","text":"Constant magnetomotive force.\n\nParameters:\n\nV_m: [A] Magnetic potential difference\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/magnetic/#ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ConstantMagneticFlux","page":"Magnetic Components","title":"ModelingToolkitStandardLibrary.Magnetic.FluxTubes.ConstantMagneticFlux","text":"Source of constant magnetic flux.\n\nParameters:\n\nPhi: [Wb] Magnetic flux\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#NonlinearSystem","page":"NonlinearSystem","title":"NonlinearSystem","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#System-Constructors","page":"NonlinearSystem","title":"System Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/","page":"NonlinearSystem","title":"NonlinearSystem","text":"NonlinearSystem","category":"page"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#ModelingToolkit.NonlinearSystem","page":"NonlinearSystem","title":"ModelingToolkit.NonlinearSystem","text":"struct NonlinearSystem <: AbstractTimeIndependentSystem\n\nA nonlinear system of equations.\n\nFields\n\neqs\nVector of equations defining the system.\nstates\nUnknown variables.\nps\nParameters.\nvar_to_name\nArray variables.\nobserved\njac\nJacobian matrix. Note: this field will not be defined until calculate_jacobian is called on the system.\n\nname\nName: the name of the system. These are required to have unique names.\n\nsystems\nsystems: The internal systems\n\ndefaults\ndefaults: The default values to use when initial conditions and/or parameters are not supplied in ODEProblem.\n\nconnector_type\ntype: type of the system\n\nconnections\nconnections: connections in a system\n\ntearing_state\ntearing_state: cache for intermediate tearing state\n\nsubstitutions\nsubstitutions: substitutions generated by tearing.\n\nExamples\n\n@variables x y z\n@parameters σ ρ β\n\neqs = [0 ~ σ*(y-x),\n       0 ~ x*(ρ-z)-y,\n       0 ~ x*y - β*z]\n@named ns = NonlinearSystem(eqs, [x,y,z],[σ,ρ,β])\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#Composition-and-Accessor-Functions","page":"NonlinearSystem","title":"Composition and Accessor Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/","page":"NonlinearSystem","title":"NonlinearSystem","text":"get_eqs(sys) or equations(sys): The equations that define the nonlinear system.\nget_states(sys) or states(sys): The set of states in the nonlinear system.\nget_ps(sys) or parameters(sys): The parameters of the nonlinear system.","category":"page"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#Transformations","page":"NonlinearSystem","title":"Transformations","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/","page":"NonlinearSystem","title":"NonlinearSystem","text":"structural_simplify\r\nalias_elimination\r\ntearing","category":"page"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#ModelingToolkit.StructuralTransformations.tearing","page":"NonlinearSystem","title":"ModelingToolkit.StructuralTransformations.tearing","text":"tearing(sys; simplify=false)\n\nTear the nonlinear equations in system. When simplify=true, we simplify the new residual residual equations after tearing. End users are encouraged to call structural_simplify instead, which calls this function internally.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#Analyses","page":"NonlinearSystem","title":"Analyses","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/","page":"NonlinearSystem","title":"NonlinearSystem","text":"ModelingToolkit.isaffine\r\nModelingToolkit.islinear","category":"page"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#Applicable-Calculation-and-Generation-Functions","page":"NonlinearSystem","title":"Applicable Calculation and Generation Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/","page":"NonlinearSystem","title":"NonlinearSystem","text":"calculate_jacobian\r\ngenerate_jacobian\r\njacobian_sparsity","category":"page"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#Problem-Constructors","page":"NonlinearSystem","title":"Problem Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/","page":"NonlinearSystem","title":"NonlinearSystem","text":"NonlinearProblem","category":"page"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#SciMLBase.NonlinearProblem","page":"NonlinearSystem","title":"SciMLBase.NonlinearProblem","text":"Defines a nonlinear system problem. Documentation Page: https://nonlinearsolve.sciml.ai/dev/basics/NonlinearProblem/\n\nMathematical Specification of a Nonlinear Problem\n\nTo define a Nonlinear Problem, you simply need to give the function f which defines the nonlinear system:\n\nf(up) = 0\n\nand an initial guess u₀ of where f(u,p)=0. f should be specified as f(u,p) (or in-place as f(du,u,p)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher-dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nNonlinearProblem(f::NonlinearFunction,u0,p=NullParameters();kwargs...)\nNonlinearProblem{isinplace}(f,u0,p=NullParameters();kwargs...)\n\nisinplace optionally sets whether the function is in-place or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the NonlinearFunctions page.\n\nFields\n\nf: The function in the problem.\nu0: The initial guess for the steady state.\np: The parameters for the problem. Defaults to NullParameters.\nkwargs: The keyword arguments passed on to the solvers.\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/#Torn-Problem-Constructors","page":"NonlinearSystem","title":"Torn Problem Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/NonlinearSystem/","page":"NonlinearSystem","title":"NonlinearSystem","text":"BlockNonlinearProblem","category":"page"},{"location":"copies/NeuralOperators/apis/#APIs","page":"APIs","title":"APIs","text":"","category":"section"},{"location":"copies/NeuralOperators/apis/#Layers","page":"APIs","title":"Layers","text":"","category":"section"},{"location":"copies/NeuralOperators/apis/#Operator-convolutional-layer","page":"APIs","title":"Operator convolutional layer","text":"","category":"section"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"F(s) = mathcalF  v(x)  \nF(s) = g(F(s)) \nv(x) = mathcalF^-1  F(s) ","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"where v(x) and v(x) denotes input and output function, mathcalF  cdot , mathcalF^-1  cdot  are Fourier transform, inverse Fourier transform, respectively. Function g is a linear transform for lowering Fouier modes.","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"OperatorConv","category":"page"},{"location":"copies/NeuralOperators/apis/#NeuralOperators.OperatorConv","page":"APIs","title":"NeuralOperators.OperatorConv","text":"OperatorConv(\n    ch, modes, transform;\n    init=c_glorot_uniform, permuted=false, T=ComplexF32\n)\n\nArguments\n\nch: Input and output channel size, e.g. 64=>64.\nmodes: The modes to be preserved.\nTransform: The trafo to operate the transformation.\npermuted: Whether the dim is permuted. If permuted=true, layer accepts   data in the order of (ch, ..., batch), otherwise the order is (..., ch, batch).\n\nExample\n\njulia> OperatorConv(2=>5, (16, ), FourierTransform)\nOperatorConv(2 => 5, (16,), FourierTransform, permuted=false)\n\njulia> OperatorConv(2=>5, (16, ), FourierTransform, permuted=true)\nOperatorConv(2 => 5, (16,), FourierTransform, permuted=true)\n\n\n\n\n\n","category":"type"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"Reference: FNO2021","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"","category":"page"},{"location":"copies/NeuralOperators/apis/#Operator-kernel-layer","page":"APIs","title":"Operator kernel layer","text":"","category":"section"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"v_t+1(x) = sigma(W v_t(x) + mathcalK  v_t(x)  )","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"where v_t(x) is the input function for t-th layer and mathcalK  cdot  denotes spectral convolutional layer. Activation function sigma can be arbitrary non-linear function.","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"OperatorKernel","category":"page"},{"location":"copies/NeuralOperators/apis/#NeuralOperators.OperatorKernel","page":"APIs","title":"NeuralOperators.OperatorKernel","text":"OperatorKernel(ch, modes, σ=identity; permuted=false)\n\nArguments\n\nch: Input and output channel size for spectral convolution, e.g. 64=>64.\nmodes: The Fourier modes to be preserved for spectral convolution.\nσ: Activation function.\npermuted: Whether the dim is permuted. If permuted=true, layer accepts   data in the order of (ch, ..., batch), otherwise the order is (..., ch, batch).\n\nExample\n\njulia> OperatorKernel(2=>5, (16, ), FourierTransform)\nOperatorKernel(2 => 5, (16,), FourierTransform, σ=identity, permuted=false)\n\njulia> using Flux\n\njulia> OperatorKernel(2=>5, (16, ), FourierTransform, relu)\nOperatorKernel(2 => 5, (16,), FourierTransform, σ=relu, permuted=false)\n\njulia> OperatorKernel(2=>5, (16, ), FourierTransform, relu, permuted=true)\nOperatorKernel(2 => 5, (16,), FourierTransform, σ=relu, permuted=true)\n\n\n\n\n\n","category":"type"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"Reference: FNO2021","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"","category":"page"},{"location":"copies/NeuralOperators/apis/#Graph-kernel-layer","page":"APIs","title":"Graph kernel layer","text":"","category":"section"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"v_t+1(x_i) = sigma(W v_t(x_i) + frac1mathcalN(x_i) sum_x_j in mathcalN(x_i) kappa  v_t(x_i) v_t(x_j)  )","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"where v_t(x_i) is the input function for t-th layer, x_i is the node feature for i-th node and mathcalN(x_i) represents the neighbors for x_i. Activation function sigma can be arbitrary non-linear function.","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"GraphKernel","category":"page"},{"location":"copies/NeuralOperators/apis/#NeuralOperators.GraphKernel","page":"APIs","title":"NeuralOperators.GraphKernel","text":"GraphKernel(κ, ch, σ=identity)\n\nGraph kernel layer.\n\nArguments\n\nκ: A neural network layer for approximation, e.g. a Dense layer or a MLP.\nch: Channel size for linear transform, e.g. 32.\nσ: Activation function.\n\n\n\n\n\n","category":"type"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"Reference: NO2020","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"","category":"page"},{"location":"copies/NeuralOperators/apis/#Models","page":"APIs","title":"Models","text":"","category":"section"},{"location":"copies/NeuralOperators/apis/#Fourier-neural-operator","page":"APIs","title":"Fourier neural operator","text":"","category":"section"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"FourierNeuralOperator","category":"page"},{"location":"copies/NeuralOperators/apis/#NeuralOperators.FourierNeuralOperator","page":"APIs","title":"NeuralOperators.FourierNeuralOperator","text":"FourierNeuralOperator(;\n    ch=(2, 64, 64, 64, 64, 64, 128, 1),\n    modes=(16, ),\n    σ=gelu\n)\n\nFourier neural operator learns a neural operator with Dirichlet kernel to form a Fourier transformation. It performs Fourier transformation across infinite-dimensional function spaces and learns better than neural operator.\n\n\n\n\n\n","category":"function"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"Reference: FNO2021","category":"page"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"","category":"page"},{"location":"copies/NeuralOperators/apis/#Markov-neural-operator","page":"APIs","title":"Markov neural operator","text":"","category":"section"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"MarkovNeuralOperator","category":"page"},{"location":"copies/NeuralOperators/apis/#NeuralOperators.MarkovNeuralOperator","page":"APIs","title":"NeuralOperators.MarkovNeuralOperator","text":"MarkovNeuralOperator(;\n    ch=(1, 64, 64, 64, 64, 64, 1),\n    modes=(24, 24),\n    σ=gelu\n)\n\nMarkov neural operator learns a neural operator with Fourier operators. With only one time step information of learning, it can predict the following few steps with low loss by linking the operators into a Markov chain.\n\n\n\n\n\n","category":"function"},{"location":"copies/NeuralOperators/apis/","page":"APIs","title":"APIs","text":"Reference: MNO2021","category":"page"},{"location":"copies/Surrogates/gek/#Gradient-Enhanced-Kriging","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"","category":"section"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"Gradient-enhanced Kriging is an extension of kriging which supports gradient information. GEK is usually more accurate than kriging, however, it is not computationally efficient when the number of inputs, the number of sampling points, or both, are high. This is mainly due to the size of the corresponding correlation matrix that increases proportionally with both the number of inputs and the number of sampling points.","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"Let's have a look to the following function to use Gradient Enhanced Surrogate: f(x) = sin(x) + 2*x^2","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"First of all, we will import Surrogates and Plots packages:","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"using Surrogates\r\nusing Plots\r\ndefault()","category":"page"},{"location":"copies/Surrogates/gek/#Sampling","page":"Gradient Enhanced Kriging","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"We choose to sample f in 8 points between 0 to 1 using the sample function. The sampling points are chosen using a Sobol sequence, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"n_samples = 10\r\nlower_bound = 2\r\nupper_bound = 10\r\nxs = lower_bound:0.001:upper_bound\r\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\nf(x) = x^3 - 6x^2 + 4x + 12\r\ny1 = f.(x)\r\nder = x -> 3*x^2 - 12*x + 4\r\ny2 = der.(x)\r\ny = vcat(y1,y2)\r\nscatter(x, y1, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(f, label=\"True function\", xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/gek/#Building-a-surrogate","page":"Gradient Enhanced Kriging","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"With our sampled points we can build the Gradient Enhanced Kriging surrogate using the GEK function.","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"my_gek = GEK(x, y, lower_bound, upper_bound, p = 1.4);","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"scatter(x, y1, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(my_gek, label=\"Surrogate function\", ribbon=p->std_error_at_point(my_gek, p), xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/gek/#Gradient-Enhanced-Kriging-Surrogate-Tutorial-(ND)","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging Surrogate Tutorial (ND)","text":"","category":"section"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"First of all let's define the function we are going to build a surrogate for.","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"using Plots # hide\r\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\r\nusing Surrogates # hide","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"Now, let's define the function:","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"function leon(x)\r\n      x1 = x[1]\r\n      x2 = x[2]\r\n      term1 = 100*(x2 - x1^3)^2\r\n      term2 = (1 - x1)^2\r\n      y = term1 + term2\r\nend","category":"page"},{"location":"copies/Surrogates/gek/#Sampling-2","page":"Gradient Enhanced Kriging","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension x to have bounds 0, 10, and 0, 10 for the second dimension. We are taking 80 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points.","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"n_samples = 80\r\nlower_bound = [0, 0]\r\nupper_bound = [10, 10]\r\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\ny1 = leon.(xys);","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"x, y = 0:10, 0:10 # hide\r\np1 = surface(x, y, (x1,x2) -> leon((x1,x2))) # hide\r\nxs = [xy[1] for xy in xys] # hide\r\nys = [xy[2] for xy in xys] # hide\r\nscatter!(xs, ys, y1) # hide\r\np2 = contour(x, y, (x1,x2) -> leon((x1,x2))) # hide\r\nscatter!(xs, ys) # hide\r\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/gek/#Building-a-surrogate-2","page":"Gradient Enhanced Kriging","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"Using the sampled points we build the surrogate, the steps are analogous to the 1-dimensional case.","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"grad1 = x1 -> 2*(300*(x[1])^5 - 300*(x[1])^2*x[2] + x[1] -1)\r\ngrad2 = x2 -> 200*(x[2] - (x[1])^3)\r\nd = 2\r\nn = 10\r\nfunction create_grads(n, d, grad1, grad2, y)\r\n      c = 0\r\n      y2 = zeros(eltype(y[1]),n*d)\r\n      for i in 1:n\r\n            y2[i + c] = grad1(x[i])\r\n            y2[i + c + 1] = grad2(x[i])\r\n            c = c + 1\r\n      end\r\n      return y2\r\nend\r\ny2 = create_grads(n, d, grad2, grad2, y)\r\ny = vcat(y1,y2)","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"my_GEK = GEK(xys, y, lower_bound, upper_bound, p=[1.9, 1.9])","category":"page"},{"location":"copies/Surrogates/gek/","page":"Gradient Enhanced Kriging","title":"Gradient Enhanced Kriging","text":"p1 = surface(x, y, (x, y) -> my_GEK([x y])) # hide\r\nscatter!(xs, ys, y1, marker_z=y1) # hide\r\np2 = contour(x, y, (x, y) -> my_GEK([x y])) # hide\r\nscatter!(xs, ys, marker_z=y1) # hide\r\nplot(p1, p2, title=\"Surrogate\") # hide","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#components","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"The symbolic models of ModelingToolkit can be composed together to easily build large models. The composition is lazy and only instantiated at the time of conversion to numerical models, allowing a more performant way in terms of computation time and memory.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Simple-Model-Composition-Example","page":"Composing Models and Building Reusable Components","title":"Simple Model Composition Example","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"The following is an example of building a model in a library with an optional forcing function, and allowing the user to specify the forcing later. Here, the library author defines a component named decay. The user then builds two decay components and connects them, saying the forcing term of decay1 is a constant while the forcing term of decay2 is the value of the state variable x.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"using ModelingToolkit\n\nfunction decay(;name)\n  @parameters t a\n  @variables x(t) f(t)\n  D = Differential(t)\n  ODESystem([\n      D(x) ~ -a*x + f\n    ];\n    name=name)\nend\n\n@named decay1 = decay()\n@named decay2 = decay()\n\n@parameters t\nD = Differential(t)\nconnected = compose(ODESystem([\n                        decay2.f ~ decay1.x\n                        D(decay1.f) ~ 0\n                      ], t; name=:connected), decay1, decay2)\n\nequations(connected)\n\n#4-element Vector{Equation}:\n# Differential(t)(decay1₊f(t)) ~ 0\n# decay2₊f(t) ~ decay1₊x(t)\n# Differential(t)(decay1₊x(t)) ~ decay1₊f(t) - (decay1₊a*(decay1₊x(t)))\n# Differential(t)(decay2₊x(t)) ~ decay2₊f(t) - (decay2₊a*(decay2₊x(t)))\n\nsimplified_sys = structural_simplify(connected)\n\nequations(simplified_sys)","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"Now we can solve the system:","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"x0 = [\n  decay1.x => 1.0\n  decay1.f => 0.0\n  decay2.x => 1.0\n]\np = [\n  decay1.a => 0.1\n  decay2.a => 0.2\n]\n\nusing DifferentialEquations\nprob = ODEProblem(simplified_sys, x0, (0.0, 100.0), p)\nsol = solve(prob, Tsit5())\nsol[decay2.f]","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Basics-of-Model-Composition","page":"Composing Models and Building Reusable Components","title":"Basics of Model Composition","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"Every AbstractSystem has a system keyword argument for specifying subsystems. A model is the composition of itself and its subsystems. For example, if we have:","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"@named sys = compose(ODESystem(eqs,indepvar,states,ps),subsys)","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"the equations of sys is the concatenation of get_eqs(sys) and equations(subsys), the states are the concatenation of their states, etc. When the ODEProblem or ODEFunction is generated from this system, it will build and compile the functions associated with this composition.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"The new equations within the higher level system can access the variables in the lower level system by namespacing via the nameof(subsys). For example, let's say there is a variable x in states and a variable x in subsys. We can declare that these two variables are the same by specifying their equality: x ~ subsys.x in the eqs for sys. This algebraic relationship can then be simplified by transformations like structural_simplify which will be described later.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Numerics-with-Composed-Models","page":"Composing Models and Building Reusable Components","title":"Numerics with Composed Models","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"These composed models can then be directly transformed into their associated SciMLProblem type using the standard constructors. When this is done, the initial conditions and parameters must be specified in their namespaced form. For example:","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"u0 = [\n  x => 2.0\n  subsys.x => 2.0\n]","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"Note that any default values within the given subcomponent will be used if no override is provided at construction time. If any values for initial conditions or parameters are unspecified an error will be thrown.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"When the model is numerically solved, the solution can be accessed via its symbolic values. For example, if sol is the ODESolution, one can use sol[x] and sol[subsys.x] to access the respective timeseries in the solution. All other indexing rules stay the same, so sol[x,1:5] accesses the first through fifth values of x. Note that this can be done even if the variable x is eliminated from the system from transformations like alias_elimination or tearing: the variable will be lazily reconstructed on demand.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Variable-scope-and-parameter-expressions","page":"Composing Models and Building Reusable Components","title":"Variable scope and parameter expressions","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"In some scenarios, it could be useful for model parameters to be expressed in terms of other parameters, or shared between common subsystems. To facilitate this, ModelingToolkit supports symbolic expressions in default values, and scoped variables.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"With symbolic parameters, it is possible to set the default value of a parameter or initial condition to an expression of other variables.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"# ...\nsys = ODESystem(\n    # ...\n    # directly in the defauls argument\n    defaults=Pair{Num, Any}[\n    x => u,\n    y => σ,\n    z => u-0.1,\n])\n# by assigning to the parameter\nsys.y = u*1.1","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"In a hierarchical system, variables of the subsystem get namespaced by the name of the system they are in. This prevents naming clashes, but also enforces that every state and parameter is local to the subsystem it is used in. In some cases it might be desirable to have variables and parameters that are shared between subsystems, or even global. This can be accomplished as follows.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"@variables a b c d\n\n# a is a local variable\nb = ParentScope(b) # b is a variable that belongs to one level up in the hierarchy\nc = ParentScope(ParentScope(c)) # ParentScope can be nested\nd = GlobalScope(d) # global variables will never be namespaced","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Structural-Simplify","page":"Composing Models and Building Reusable Components","title":"Structural Simplify","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"In many cases, the nicest way to build a model may leave a lot of unnecessary variables. Thus one may want to remove these equations before numerically solving. The structural_simplify function removes these trivial equality relationships and trivial singularity equations, i.e. equations which result in 0~0 expressions, in over-specified systems.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Inheritance-and-Combine","page":"Composing Models and Building Reusable Components","title":"Inheritance and Combine","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"Model inheritance can be done in two ways: implicitly or explicitly. First, one can use the extend function to extend a base model with another set of equations, states, and parameters. An example can be found in the acausal components tutorial.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"The explicit way is to shadow variables with equality expressions. For example, let's assume we have three separate systems which we want to compose to a single one. This is how one could explicitly forward all states and parameters to the higher level system:","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"using ModelingToolkit, OrdinaryDiffEq, Plots\n\n## Library code\n\n@parameters t\nD = Differential(t)\n\n@variables S(t), I(t), R(t)\nN = S + I + R\n@parameters β,γ\n\n@named seqn = ODESystem([D(S) ~ -β*S*I/N])\n@named ieqn = ODESystem([D(I) ~ β*S*I/N-γ*I])\n@named reqn = ODESystem([D(R) ~ γ*I])\n\nsir = compose(ODESystem([\n                    S ~ ieqn.S,\n                    I ~ seqn.I,\n                    R ~ ieqn.R,\n                    ieqn.S ~ seqn.S,\n                    seqn.I ~ ieqn.I,\n                    seqn.R ~ reqn.R,\n                    ieqn.R ~ reqn.R,\n                    reqn.I ~ ieqn.I], t, [S,I,R], [β,γ],\n                    defaults = [\n                        seqn.β => β\n                        ieqn.β => β\n                        ieqn.γ => γ\n                        reqn.γ => γ\n                    ], name=:sir), seqn, ieqn, reqn)","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"Note that the states are forwarded by an equality relationship, while the parameters are forwarded through a relationship in their default values. The user of this model can then solve this model simply by specifying the values at the highest level:","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"sireqn_simple = structural_simplify(sir)\n\nequations(sireqn_simple)","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"## User Code\n\nu0 = [seqn.S => 990.0,\n      ieqn.I => 10.0,\n      reqn.R => 0.0]\n\np = [\n    β => 0.5\n    γ => 0.25\n]\n\ntspan = (0.0,40.0)\nprob = ODEProblem(sireqn_simple,u0,tspan,p,jac=true)\nsol = solve(prob,Tsit5())\nsol[reqn.R]","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Tearing-Problem-Construction","page":"Composing Models and Building Reusable Components","title":"Tearing Problem Construction","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"Some system types, specifically ODESystem and NonlinearSystem, can be further reduced if structural_simplify has already been applied to them. This is done by using the alternative problem constructors, ODAEProblem and BlockNonlinearProblem respectively. In these cases, the constructor uses the knowledge of the strongly connected components calculated during the process of simplification as the basis for building pre-simplified nonlinear systems in the implicit solving. In summary: these problems are structurally modified, but could be more efficient and more stable.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Components-with-discontinuous-dynamics","page":"Composing Models and Building Reusable Components","title":"Components with discontinuous dynamics","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"When modeling, e.g., impacts, saturations or Coulomb friction, the dynamic equations are discontinuous in either the state or one of its derivatives. This causes the solver to take very small steps around the discontinuity, and sometimes leads to early stopping due to dt <= dt_min. The correct way to handle such dynamics is to tell the solver about the discontinuity by means of a root-finding equation. ODEsystems accept a keyword argument continuous_events","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"ODESystem(eqs, ...; continuous_events::Vector{Equation})\nODESystem(eqs, ...; continuous_events::Pair{Vector{Equation}, Vector{Equation}})","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"where equations can be added that evaluate to 0 at discontinuities.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"To model events that have an effect on the state, provide events::Pair{Vector{Equation}, Vector{Equation}} where the first entry in the pair is a vector of equations describing event conditions, and the second vector of equations describe the effect on the state. The effect equations must be of the form","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"single_state_variable ~ expression_involving_any_variables","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Example:-Friction","page":"Composing Models and Building Reusable Components","title":"Example: Friction","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"The system below illustrates how this can be used to model Coulomb friction","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"using ModelingToolkit, OrdinaryDiffEq, Plots\nfunction UnitMassWithFriction(k; name)\n  @variables t x(t)=0 v(t)=0\n  D = Differential(t)\n  eqs = [\n    D(x) ~ v\n    D(v) ~ sin(t) - k*sign(v) # f = ma, sinusoidal force acting on the mass, and Coulomb friction opposing the movement\n  ]\n  ODESystem(eqs, t; continuous_events=[v ~ 0], name) # when v = 0 there is a discontinuity\nend\n@named m = UnitMassWithFriction(0.7)\nprob = ODEProblem(m, Pair[], (0, 10pi))\nsol = solve(prob, Tsit5())\nplot(sol)","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Example:-Bouncing-ball","page":"Composing Models and Building Reusable Components","title":"Example: Bouncing ball","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"In the documentation for DifferentialEquations, we have an example where a bouncing ball is simulated using callbacks which has an affect! on the state. We can model the same system using ModelingToolkit like this","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"@variables t x(t)=1 v(t)=0\nD = Differential(t)\n\nroot_eqs = [x ~ 0]  # the event happens at the ground x(t) = 0\naffect   = [v ~ -v] # the effect is that the velocity changes sign\n\n@named ball = ODESystem([\n    D(x) ~ v\n    D(v) ~ -9.8\n], t; continuous_events = root_eqs => affect) # equation => affect\n\nball = structural_simplify(ball)\n\ntspan = (0.0,5.0)\nprob = ODEProblem(ball, Pair[], tspan)\nsol = solve(prob,Tsit5())\n@assert 0 <= minimum(sol[x]) <= 1e-10 # the ball never went through the floor but got very close\nplot(sol)","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/#Test-bouncing-ball-in-2D-with-walls","page":"Composing Models and Building Reusable Components","title":"Test bouncing ball in 2D with walls","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"Multiple events? No problem! This example models a bouncing ball in 2D that is enclosed by two walls at y = pm 15.","category":"page"},{"location":"copies/ModelingToolkit/basics/Composition/","page":"Composing Models and Building Reusable Components","title":"Composing Models and Building Reusable Components","text":"@variables t x(t)=1 y(t)=0 vx(t)=0 vy(t)=2\nD = Differential(t)\n\ncontinuous_events = [ # This time we have a vector of pairs\n    [x ~ 0] => [vx ~ -vx]\n    [y ~ -1.5, y ~ 1.5] => [vy ~ -vy]\n]\n\n@named ball = ODESystem([\n    D(x)  ~ vx,\n    D(y)  ~ vy,\n    D(vx) ~ -9.8-0.1vx, # gravity + some small air resistance\n    D(vy) ~ -0.1vy,\n], t; continuous_events)\n\n\nball = structural_simplify(ball)\n\ntspan = (0.0,10.0)\nprob = ODEProblem(ball, Pair[], tspan)\n\nsol = solve(prob,Tsit5())\n@assert 0 <= minimum(sol[x]) <= 1e-10 # the ball never went through the floor but got very close\n@assert minimum(sol[y]) > -1.5 # check wall conditions\n@assert maximum(sol[y]) < 1.5  # check wall conditions\n\ntv = sort([LinRange(0, 10, 200); sol.t])\nplot(sol(tv)[y], sol(tv)[x], line_z=tv)\nvline!([-1.5, 1.5], l=(:black, 5), primary=false)\nhline!([0], l=(:black, 5), primary=false)","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/#Physics-Informed-Machine-Learning-(PIML)-with-TensorLayer","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"In this tutorial, we show how to use the DiffEqFlux TensorLayer to solve problems in Physics Informed Machine Learning.","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"Let's consider the anharmonic oscillator described by the ODE","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"x = - kx - αx³ - βx -γx³","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"To obtain the training data, we solve the equation of motion using one of the solvers in DifferentialEquations:","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"using DiffEqFlux, DifferentialEquations, LinearAlgebra\nk, α, β, γ = 1, 0.1, 0.2, 0.3\ntspan = (0.0,10.0)\n\nfunction dxdt_train(du,u,p,t)\n  du[1] = u[2]\n  du[2] = -k*u[1] - α*u[1]^3 - β*u[2] - γ*u[2]^3\nend\n\nu0 = [1.0,0.0]\nts = collect(0.0:0.1:tspan[2])\nprob_train = ODEProblem{true}(dxdt_train,u0,tspan,p=nothing)\ndata_train = Array(solve(prob_train,Tsit5(),saveat=ts))","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"Now, we create a TensorLayer that will be able to perform 10th order expansions in a Legendre Basis:","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"A = [LegendreBasis(10), LegendreBasis(10)]\nnn = TensorLayer(A, 1)","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"and we also instantiate the model we are trying to learn, \"informing\" the neural about the ∝x and ∝v dependencies in the equation of motion:","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"f = x -> min(30one(x),x)\n\nfunction dxdt_pred(du,u,p,t)\n  du[1] = u[2]\n  du[2] = -p[1]*u[1] - p[2]*u[2] + f(nn(u,p[3:end])[1])\nend\n\nα = zeros(102)\n\nprob_pred = ODEProblem{true}(dxdt_pred,u0,tspan,p=nothing)","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"Note that we introduced a \"cap\" in the neural network term to avoid instabilities in the solution of the ODE. We also initialized the vector of parameters to zero in order to obtain a faster convergence for this particular example.","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"Finally, we introduce the corresponding loss function:","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"\nfunction predict_adjoint(θ)\n  x = Array(solve(prob_pred,Tsit5(),p=θ,saveat=ts))\nend\n\nfunction loss_adjoint(θ)\n  x = predict_adjoint(θ)\n  loss = sum(norm.(x - data_train))\n  return loss\nend\n\nfunction cb(θ,l)\n  @show θ, l\n  return false\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"and we train the network using two rounds of ADAM:","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"res1 = DiffEqFlux.sciml_train(loss_adjoint, α, ADAM(0.05), cb = cb, maxiters = 150)\nres2 = DiffEqFlux.sciml_train(loss_adjoint, res1.u, ADAM(0.001), cb = cb,maxiters = 150)\nopt = res2.u","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"We plot the results and we obtain a fairly accurate learned model:","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"using Plots\ndata_pred = predict_adjoint(opt)\nplot(ts, data_train[1,:], label = \"X (ODE)\")\nplot!(ts, data_train[2,:], label = \"V (ODE)\")\nplot!(ts, data_pred[1,:], label = \"X (NN)\")\nplot!(ts, data_pred[2,:],label = \"V (NN)\")","category":"page"},{"location":"copies/DiffEqFlux/examples/tensor_layer/","page":"Physics-Informed Machine Learning (PIML) with TensorLayer","title":"Physics-Informed Machine Learning (PIML) with TensorLayer","text":"(Image: plot_tutorial)","category":"page"},{"location":"copies/NeuralOperators/references/#References","page":"References","title":"References","text":"","category":"section"},{"location":"copies/NeuralOperators/references/","page":"References","title":"References","text":"","category":"page"},{"location":"copies/Integrals/basics/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"copies/Integrals/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Ask more questions.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/#auto_diff","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"note: Note\nThis tutorial assumes familiarity with DifferentialEquations.jl   If you are not familiar with DifferentialEquations.jl, please consult   the DifferentialEquations.jl documentation","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"In this tutorial we will introduce how to use local sensitivity analysis via automatic differentiation. The automatic differentiation interfaces are the most common ways that local sensitivity analysis is done. It's fairly fast and flexible, but most notably, it's a very small natural extension to the  normal differential equation solving code and is thus the easiest way to do most things.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/#Setup","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Setup","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Let's first define a differential equation we wish to solve. We will choose the Lotka-Volterra equation. This is done via DifferentialEquations.jl using:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"using DifferentialEquations\n\nfunction lotka_volterra!(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\np = [1.5,1.0,3.0,1.0]; u0 = [1.0;1.0]\nprob = ODEProblem(lotka_volterra!,u0,(0.0,10.0),p)\nsol = solve(prob,Tsit5(),reltol=1e-6,abstol=1e-6)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Now let's differentiate the solution to this ODE using a few different automatic differentiation methods.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/#Forward-Mode-Automatic-Differentiation-with-ForwardDiff.jl","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Forward-Mode Automatic Differentiation with ForwardDiff.jl","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Let's say we need the derivative of the solution with respect to the initial condition u0 and its parameters p. One of the simplest ways to do this is via ForwardDiff.jl. To do this, all that one needs to do is use  the ForwardDiff.jl library to differentiate some function f which uses a differential equation solve inside of it. For example, let's say we want the derivative of the first component of ODE solution with respect to  these quantities at evenly spaced time points of dt = 1. We can compute this via:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"using ForwardDiff\n\nfunction f(x)\n    _prob = remake(prob,u0=x[1:2],p=x[3:end])\n    solve(_prob,Tsit5(),reltol=1e-6,abstol=1e-6,saveat=1)[1,:]\nend\nx = [u0;p]\ndx = ForwardDiff.jacobian(f,x)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Let's dig into what this is saying a bit. x is a vector which concatenates the initial condition and parameters, meaning that the first 2 values are the initial conditions and the last 4 are the parameters. We use the remake function to build a function f(x) which uses these new initial conditions and parameters to solve the differential equation and return the time series of the first component. ","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Then ForwardDiff.jacobian(f,x) computes the Jacobian of f with respect to x. The output dx[i,j] corresponds to the derivative of the solution of the first component at time t=j-1 with respect to x[i]. For example, dx[3,2] is the derivative of the first component of the solution at time t=1 with respect to p[1].","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"note: Note\nSince the global error is 1-2 orders of magnitude higher than the local error, we use accuracies of 1e-6 (instead of the default 1e-3) to get reasonable sensitivities","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/#Reverse-Mode-Automatic-Differentiation","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Reverse-Mode Automatic Differentiation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"The solve function is automatically compatible with AD systems like Zygote.jl and thus there is no machinery that is necessary to use other than to put solve inside of a function that is differentiated by Zygote. For example, the following computes the solution  to an ODE and computes the gradient of a loss function (the sum of the ODE's output at each  timepoint with dt=0.1) via the adjoint method:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"function sum_of_solution(u0,p)\n  _prob = remake(prob,u0=u0,p=p)\n  sum(solve(_prob,Tsit5(),reltol=1e-6,abstol=1e-6,saveat=0.1))\nend\ndu01,dp1 = Zygote.gradient(sum_of_solution,u0,p)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Zygote.jl's automatic differentiation system is overloaded to allow SciMLSensitivity.jl to redefine the way the derivatives are computed, allowing trade-offs between numerical stability, memory, and compute performance, similar to how ODE solver algorithms are chosen. The algorithms for differentiation calculation are called AbstractSensitivityAlgorithms, or sensealgs for short. These are choosen by passing the sensealg keyword argument into solve.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Let's demonstrate this by choosing the QuadratureAdjoint sensealg for the differentiation of this system:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"function sum_of_solution(u0,p)\n  _prob = remake(prob,u0=u0,p=p)\n  sum(solve(_prob,Tsit5(),reltol=1e-6,abstol=1e-6,saveat=0.1,sensealg=QuadratureAdjoint()))\nend\ndu01,dp1 = Zygote.gradient(sum_of_solution,u0,p)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Here this computes the derivative of the output with respect to the initial condition and the the derivative with respect to the parameters respectively using the QuadratureAdjoint(). For more information on the choices of sensitivity algorithms, see the reference documentation in choosing sensitivity algorithms","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/#When-Should-You-Use-Forward-or-Reverse-Mode?","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"When Should You Use Forward or Reverse Mode?","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/differentiating_ode/","page":"Differentiating an ODE Solution with Automatic Differentiation","title":"Differentiating an ODE Solution with Automatic Differentiation","text":"Good question! The simple answer is, if you are differentiating a system of 100 equations or less, use forward-mode, otherwise reverse-mode. But it can be a lot more complicated than that! For more information, see the  reference documentation in choosing sensitivity algorithms","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#MathOptInterface.jl","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"MathOptInterface is Julia abstration layer to interface with variety of mathematical optimization solvers.","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Installation:-OptimizationMOI.jl","page":"MathOptInterface.jl","title":"Installation: OptimizationMOI.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"To use this package, install the OptimizationMOI package:","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"import Pkg; Pkg.add(\"OptimizationMOI\")","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Details","page":"MathOptInterface.jl","title":"Details","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"As of now the Optimization interface to MathOptInterface implents only the maxtime common keyword arguments. An optimizer which is implemented in the MathOptInterface is can be called be called directly if no optimizer options have to be defined. For example using the Ipopt.jl optimizer:","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"sol = solve(prob, Ipopt.Optimizer())","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"The optimizer options are handled in one of two ways. They can either be set via Optimization.MOI.OptimizerWithAttributes() or as keyword argument to solve. For example using the Ipopt.jl optimizer:","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"opt = Optimization.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nsol = solve(prob, opt)\n\nsol = solve(prob,  Ipopt.Optimizer(); option_name = option_value, ...)","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Local-Optimizer","page":"MathOptInterface.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Local-constraint","page":"MathOptInterface.jl","title":"Local constraint","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Ipopt.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Ipopt.jl (MathOptInterface)","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Ipopt.Optimizer\nIpopt is a MathOptInterface optimizer, and thus its options are handled via Optimization.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the Ipopt Documentation","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#KNITRO.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"KNITRO.jl (MathOptInterface)","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"KNITRO.Optimizer\nKNITRO is a MathOptInterface optimizer, and thus its options are handled via Optimization.MOI.OptimizerWithAttributes(KNITRO.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the KNITRO Documentation","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#AmplNLWriter.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"AmplNLWriter.jl (MathOptInterface)","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"AmplNLWriter.Optimizer\nAmplNLWriter is a MathOptInterface optimizer, and thus its options are handled via Optimization.MOI.OptimizerWithAttributes(AmplNLWriter.Optimizer(algname), \"option_name\" => option_value, ...)\nPossible algnames are:\nBonmin_jll.amplexe\nCouenne_jll.amplexe\nIpopt_jll.amplexe\nSHOT_jll.amplexe","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"To use one of the JLLs, they must be added first. For example: Pkg.add(\"Bonmin_jll\").","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Juniper.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Juniper.jl (MathOptInterface)","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Juniper.Optimizer\nJuniper is a MathOptInterface optimizer, and thus its options are handled via Optimization.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nJuniper requires the choice of a relaxation method nl_solver which must be a MathOptInterface-based optimizer","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"using Optimization, ForwardDiff\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p  = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, _p)\n\nusing Juniper, Ipopt\noptimizer = Juniper.Optimizer\n# Choose a relaxation method\nnl_solver = Optimization.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"print_level\"=>0)\n\nopt = Optimization.MOI.OptimizerWithAttributes(optimizer, \"nl_solver\"=>nl_solver)\nsol = solve(prob, opt)","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#BARON.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"BARON.jl (MathOptInterface)","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"BARON.Optimizer\nBARON is a MathOptInterface optimizer, and thus its options are handled via Optimization.MOI.OptimizerWithAttributes(BARON.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the BARON Documentation","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Gradient-Based","page":"MathOptInterface.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Ipopt.jl-(MathOptInterface)-2","page":"MathOptInterface.jl","title":"Ipopt.jl (MathOptInterface)","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Ipopt.Optimizer\nIpopt is a MathOptInterface optimizer, and thus its options are handled via Optimization.MOI.OptimizerWithAttributes(Ipopt.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the Ipopt Documentation","category":"page"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Global-Optimizer","page":"MathOptInterface.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#With-Constraint-Equations","page":"MathOptInterface.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/#Alpine.jl-(MathOptInterface)","page":"MathOptInterface.jl","title":"Alpine.jl (MathOptInterface)","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/mathoptinterface/","page":"MathOptInterface.jl","title":"MathOptInterface.jl","text":"Alpine.Optimizer\nAlpine is a MathOptInterface optimizer, and thus its options are handled via Optimization.MOI.OptimizerWithAttributes(Alpine.Optimizer, \"option_name\" => option_value, ...)\nThe full list of optimizer options can be found in the Alpine Documentation","category":"page"},{"location":"copies/Surrogates/sphere_function/#Sphere-function","page":"Sphere function","title":"Sphere function","text":"","category":"section"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"The sphere function of dimension d is defined as: f(x) = sum_i=1^d x_i with lower bound -10 and upper bound 10.","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"Let's import Surrogates and Plots:","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"Define the objective function:","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"function sphere_function(x)\n    return sum(x.^2)\nend","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"The 1D case is just a simple parabola, let's plot it:","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"n = 20\nlb = -10\nub = 10\nx = sample(n,lb,ub,SobolSample())\ny = sphere_function.(x)\nxs = lb:0.001:ub\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lb, ub), ylims=(-2, 120), legend=:top)\nplot!(xs,sphere_function.(xs), label=\"True function\", legend=:top)","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"Fitting RadialSurrogate with different radial basis:","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"rad_1d_linear = RadialBasis(x,y,lb,ub)\nrad_1d_cubic = RadialBasis(x,y,lb,ub,rad = cubicRadial)\nrad_1d_multiquadric = RadialBasis(x,y,lb,ub, rad = multiquadricRadial)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lb, ub), ylims=(-2, 120), legend=:top)\nplot!(xs,sphere_function.(xs), label=\"True function\", legend=:top)\nplot!(xs, rad_1d_linear.(xs), label=\"Radial surrogate with linear\", legend=:top)\nplot!(xs, rad_1d_cubic.(xs), label=\"Radial surrogate with cubic\", legend=:top)\nplot!(xs, rad_1d_multiquadric.(xs), label=\"Radial surrogate with multiquadric\", legend=:top)","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"Fitting Lobachevsky Surrogate with different values of hyperparameters alpha:","category":"page"},{"location":"copies/Surrogates/sphere_function/","page":"Sphere function","title":"Sphere function","text":"loba_1 = LobachevskySurrogate(x,y,lb,ub)\nloba_2 = LobachevskySurrogate(x,y,lb,ub,alpha = 1.5, n = 6)\nloba_3 = LobachevskySurrogate(x,y,lb,ub,alpha = 0.3, n = 6)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lb, ub), ylims=(-2, 120), legend=:top)\nplot!(xs,sphere_function.(xs), label=\"True function\", legend=:top)\nplot!(xs, loba_1.(xs), label=\"Lobachevsky surrogate 1\", legend=:top)\nplot!(xs, loba_2.(xs), label=\"Lobachevsky surrogate 2\", legend=:top)\nplot!(xs, loba_3.(xs), label=\"Lobachevsky surrogate 3\", legend=:top)","category":"page"},{"location":"copies/DiffEqSensitivity/manual/direct_adjoint_sensitivities/#adjoint_sense","page":"Direct Adjoint Sensitivities of Differential Equations","title":"Direct Adjoint Sensitivities of Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/direct_adjoint_sensitivities/#First-Order-Adjoint-Sensitivities","page":"Direct Adjoint Sensitivities of Differential Equations","title":"First Order Adjoint Sensitivities","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/direct_adjoint_sensitivities/","page":"Direct Adjoint Sensitivities of Differential Equations","title":"Direct Adjoint Sensitivities of Differential Equations","text":"adjoint_sensitivities","category":"page"},{"location":"copies/DiffEqSensitivity/manual/direct_adjoint_sensitivities/#DiffEqSensitivity.adjoint_sensitivities","page":"Direct Adjoint Sensitivities of Differential Equations","title":"DiffEqSensitivity.adjoint_sensitivities","text":"adjointsensitivities(sol,alg,g,t=nothing,dg=nothing;                             abstol=1e-6,reltol=1e-3,                             checkpoints=sol.t,                             corfuncanalytical=nothing,                             callback = nothing,                             sensealg=InterpolatingAdjoint(),                             kwargs...)\n\nAdjoint sensitivity analysis is used to find the gradient of the solution with respect to some functional of the solution. In many cases this is used in an optimization problem to return the gradient with respect to some cost function. It is equivalent to \"backpropagation\" or reverse-mode automatic differentiation of a differential equation.\n\nUsing adjoint_sensitivities directly let's you do three things. One it can allow you to be more efficient, since the sensitivity calculation can be done directly on a cost function, avoiding the overhead of building the derivative of the full concretized solution. It can also allow you to be more efficient by directly controlling the forward solve that is then reversed over. Lastly, it allows one to define a continuous cost function on the continuous solution, instead of just at discrete data points.\n\nwarning: Warning\nNon-checkpointed InterpolatingAdjoint and QuadratureAdjoint sensealgs   require that the forward solution sol(t) has an accurate dense   solution unless checkpointing is used. This means that you should   not use solve(prob,alg,saveat=ts) unless checkpointing. If specific   saving is required, one should solve dense solve(prob,alg), use the   solution in the adjoint, and then sol(ts) interpolate.\n\nSyntax\n\nThere are two forms. For discrete adjoints, the form is:\n\ndu0,dp = adjoint_sensitivities(sol,alg,dg,ts;sensealg=InterpolatingAdjoint(),\n                               checkpoints=sol.t,kwargs...)\n\nwhere alg is the ODE algorithm to solve the adjoint problem, dg is the jump function, sensealg is the sensitivity algorithm, and ts is the time points for data. dg is given by:\n\ndg(out,u,p,t,i)\n\nwhich is the in-place gradient of the cost functional g at time point ts[i] with u=u(t).\n\nFor continuous functionals, the form is:\n\ndu0,dp = adjoint_sensitivities(sol,alg,g,nothing,(dgdu,dgdp);sensealg=InterpolatingAdjoint(),\n                               checkpoints=sol.t,,kwargs...)\n\nfor the cost functional\n\ng(u,p,t)\n\nwith in-place gradient\n\ndgdu(out,u,p,t)\ndgdp(out,u,p,t)\n\nIf the gradient is omitted, i.e.\n\ndu0,dp = adjoint_sensitivities(sol,alg,g,nothing;kwargs...)\n\nthen we assume dgdp is zero and dgdu will be computed automatically using ForwardDiff or finite differencing, depending on the autodiff setting in the AbstractSensitivityAlgorithm. Note that the keyword arguments are passed to the internal ODE solver for solving the adjoint problem.\n\nExample discrete adjoints on a cost function\n\nIn this example we will show solving for the adjoint sensitivities of a discrete cost functional. First let's solve the ODE and get a high quality continuous solution:\n\nfunction f(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + u[1]*u[2]\nend\n\np = [1.5,1.0,3.0]\nprob = ODEProblem(f,[1.0;1.0],(0.0,10.0),p)\nsol = solve(prob,Vern9(),abstol=1e-10,reltol=1e-10)\n\nNow let's calculate the sensitivity of the ell_2 error against 1 at evenly spaced points in time, that is:\n\nL(upt)=sum_i=1^nfracVert1-u(t_ip)Vert^22\n\nfor t_i = 05i. This is the assumption that the data is data[i]=1.0. For this function, notice we have that:\n\nbeginaligned\ndg_1=1-u_1 \r\ndg_2=1-u_2 \r\n quad vdots\nendaligned\n\nand thus:\n\ndg(out,u,p,t,i) = (out.=1.0.-u)\n\nAlso, we can omit dgdp, because the cost function doesn't dependent on p. If we had data, we'd just replace 1.0 with data[i]. To get the adjoint sensitivities, call:\n\nts = 0:0.5:10\nres = adjoint_sensitivities(sol,Vern9(),dg,ts,abstol=1e-14,\n                            reltol=1e-14)\n\nThis is super high accuracy. As always, there's a tradeoff between accuracy and computation time. We can check this almost exactly matches the autodifferentiation and numerical differentiation results:\n\nusing ForwardDiff,Calculus,Tracker\nfunction G(p)\n  tmp_prob = remake(prob,u0=convert.(eltype(p),prob.u0),p=p)\n  sol = solve(tmp_prob,Vern9(),abstol=1e-14,reltol=1e-14,saveat=ts,\n              sensealg=SensitivityADPassThrough())\n  A = convert(Array,sol)\n  sum(((1 .- A).^2)./2)\nend\nG([1.5,1.0,3.0])\nres2 = ForwardDiff.gradient(G,[1.5,1.0,3.0])\nres3 = Calculus.gradient(G,[1.5,1.0,3.0])\nres4 = Tracker.gradient(G,[1.5,1.0,3.0])\nres5 = ReverseDiff.gradient(G,[1.5,1.0,3.0])\n\nand see this gives the same values.\n\nExample controlling adjoint method choices and checkpointing\n\nIn the previous examples, all calculations were done using the interpolating method. This maximizes speed but at a cost of requiring a dense sol. If it is not possible to hold a dense forward solution in memory, then one can use checkpointing. For example:\n\nts = [0.0,0.2,0.5,0.7]\nsol = solve(prob,Vern9(),saveat=ts)\n\nCreates a non-dense solution with checkpoints at [0.0,0.2,0.5,0.7]. Now we can do:\n\nres = adjoint_sensitivities(sol,Vern9(),dg,ts,\n                            sensealg=InterpolatingAdjoint(checkpointing=true))\n\nWhen grabbing a Jacobian value during the backwards solution, it will no longer interpolate to get the value. Instead, it will start a forward solution at the nearest checkpoint to build local interpolants in a way that conserves memory. By default the checkpoints are at sol.t, but we can override this:\n\nres = adjoint_sensitivities(sol,Vern9(),dg,ts,\n                            sensealg=InterpolatingAdjoint(checkpointing=true),\n                            checkpoints = [0.0,0.5])\n\nExample continuous adjoints on an energy functional\n\nIn this case we'd like to calculate the adjoint sensitivity of the scalar energy functional:\n\nG(up)=int_0^Tfracsum_i=1^nu_i^2(t)2dt\n\nwhich is:\n\ng(u,p,t) = (sum(u).^2) ./ 2\n\nNotice that the gradient of this function with respect to the state u is:\n\nfunction dg(out,u,p,t)\n  out[1]= u[1] + u[2]\n  out[2]= u[1] + u[2]\nend\n\nTo get the adjoint sensitivities, we call:\n\nres = adjoint_sensitivities(sol,Vern9(),g,nothing,dg,abstol=1e-8,\n                                 reltol=1e-8,iabstol=1e-8,ireltol=1e-8)\n\nNotice that we can check this against autodifferentiation and numerical differentiation as follows:\n\nusing QuadGK\nfunction G(p)\n  tmp_prob = remake(prob,p=p)\n  sol = solve(tmp_prob,Vern9(),abstol=1e-14,reltol=1e-14)\n  res,err = quadgk((t)-> (sum(sol(t)).^2)./2,0.0,10.0,atol=1e-14,rtol=1e-10)\n  res\nend\nres2 = ForwardDiff.gradient(G,[1.5,1.0,3.0])\nres3 = Calculus.gradient(G,[1.5,1.0,3.0])\n\n\n\n","category":"function"},{"location":"copies/DiffEqSensitivity/manual/direct_adjoint_sensitivities/#Second-Order-Adjoint-Sensitivities","page":"Direct Adjoint Sensitivities of Differential Equations","title":"Second Order Adjoint Sensitivities","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/direct_adjoint_sensitivities/","page":"Direct Adjoint Sensitivities of Differential Equations","title":"Direct Adjoint Sensitivities of Differential Equations","text":"second_order_sensitivities\nsecond_order_sensitivity_product","category":"page"},{"location":"copies/DiffEqSensitivity/manual/direct_adjoint_sensitivities/#DiffEqSensitivity.second_order_sensitivities","page":"Direct Adjoint Sensitivities of Differential Equations","title":"DiffEqSensitivity.second_order_sensitivities","text":"H = secondordersensitivities(loss,prob,alg,args...;                                sensealg=ForwardDiffOverAdjoint(InterpolatingAdjoint(autojacvec=ReverseDiffVJP())),                                kwargs...)\n\nSecond order sensitivity analysis is used for the fast calculation of Hessian matrices. \n\nExample second order sensitivity analysis calculation\n\nusing DiffEqSensitivity, OrdinaryDiffEq, ForwardDiff\nusing Test\n\nfunction lotka!(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\n\np = [1.5,1.0,3.0,1.0]; u0 = [1.0;1.0]\nprob = ODEProblem(lotka!,u0,(0.0,10.0),p)\nloss(sol) = sum(sol)\nv = ones(4)\n\nH  = second_order_sensitivities(loss,prob,Vern9(),saveat=0.1,abstol=1e-12,reltol=1e-12)\n\nArguments\n\nThe arguments for this function match adjoint_sensitivities. The only notable difference is sensealg which requires a second order sensitivity algorithm, of which currently the only choice is ForwardDiffOverAdjoint which uses forward-over-reverse to mix a forward-mode sensitivity analysis with an adjoint sensitivity analysis for a faster computation than either double forward or double reverse. ForwardDiffOverAdjoint's positional argument just accepts a first order sensitivity algorithm.\n\n\n\n","category":"function"},{"location":"copies/DiffEqSensitivity/manual/direct_adjoint_sensitivities/#DiffEqSensitivity.second_order_sensitivity_product","page":"Direct Adjoint Sensitivities of Differential Equations","title":"DiffEqSensitivity.second_order_sensitivity_product","text":"Hv = secondordersensitivity_product(loss,v,prob,alg,args...;                                sensealg=ForwardDiffOverAdjoint(InterpolatingAdjoint(autojacvec=ReverseDiffVJP())),                                kwargs...)\n\nSecond order sensitivity analysis product is used for the fast calculation of  Hessian-vector products Hv without requiring the construction of the Hessian matrix.\n\nExample second order sensitivity analysis calculation\n\nusing DiffEqSensitivity, OrdinaryDiffEq, ForwardDiff\nusing Test\n\nfunction lotka!(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\n\np = [1.5,1.0,3.0,1.0]; u0 = [1.0;1.0]\nprob = ODEProblem(lotka!,u0,(0.0,10.0),p)\nloss(sol) = sum(sol)\nv = ones(4)\n\nHv = second_order_sensitivity_product(loss,v,prob,Vern9(),saveat=0.1,abstol=1e-12,reltol=1e-12)\n\nArguments\n\nThe arguments for this function match adjoint_sensitivities. The only notable difference is sensealg which requires a second order sensitivity algorithm, of which currently the only choice is ForwardDiffOverAdjoint which uses forward-over-reverse to mix a forward-mode sensitivity analysis with an adjoint sensitivity analysis for a faster computation than either double forward or double reverse. ForwardDiffOverAdjoint's positional argument just accepts a first order sensitivity algorithm.\n\n\n\n","category":"function"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/#BlackBoxOptim.jl","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"BlackBoxOptim is a is a Julia package implementing (Meta-)heuristic/stochastic algorithms that do not require for the optimized function to be differentiable.","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/#Installation:-OptimizationBBO.jl","page":"BlackBoxOptim.jl","title":"Installation: OptimizationBBO.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"To use this package, install the OptimizationBBO package:","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"import Pkg; Pkg.add(\"OptimizationBBO\")","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/#Global-Optimizers","page":"BlackBoxOptim.jl","title":"Global Optimizers","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/#Without-Constraint-Equations","page":"BlackBoxOptim.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The algorithms in BlackBoxOptim are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"A BlackBoxOptim algorithm is called by BBO_ prefix followed by the algorithm name:","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"Natural Evolution Strategies:\nSeparable NES: BBO_separable_nes()\nExponential NES: BBO_xnes()\nDistance-weighted Exponential NES: BBO_dxnes()\nDifferential Evolution optimizers, 5 different:\nAdaptive DE/rand/1/bin: BBO_adaptive_de_rand_1_bin()\nAdaptive DE/rand/1/bin with radius limited sampling: BBO_adaptive_de_rand_1_bin_radiuslimited()\nDE/rand/1/bin: BBO_de_rand_1_bin()\nDE/rand/1/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_1_bin_radiuslimited()\nDE/rand/2/bin: de_rand_2_bin()\nDE/rand/2/bin with radius limited sampling (a type of trivial geography): BBO_de_rand_2_bin_radiuslimited()\nDirect search:\nGenerating set search:\nCompass/coordinate search: BBO_generating_set_search()\nDirect search through probabilistic descent: BBO_probabilistic_descent()\nResampling Memetic Searchers:\nResampling Memetic Search (RS): BBO_resampling_memetic_search()\nResampling Inheritance Memetic Search (RIS): BBO_resampling_inheritance_memetic_search()\nStochastic Approximation:\nSimultaneous Perturbation Stochastic Approximation (SPSA): BBO_simultaneous_perturbation_stochastic_approximation()\nRandomSearch (to compare to): BBO_random_search()","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The recommended optimizer is BBO_adaptive_de_rand_1_bin_radiuslimited()","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The currently available algorithms are listed here","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/#Example","page":"BlackBoxOptim.jl","title":"Example","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"The Rosenbrock function can optimized using the BBO_adaptive_de_rand_1_bin_radiuslimited() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/blackboxoptim/","page":"BlackBoxOptim.jl","title":"BlackBoxOptim.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, BBO_adaptive_de_rand_1_bin_radiuslimited(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"copies/DiffEqSensitivity/manual/direct_forward_sensitivity/#forward_sense","page":"Direct Forward Sensitivity Analysis of ODEs","title":"Direct Forward Sensitivity Analysis of ODEs","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/direct_forward_sensitivity/","page":"Direct Forward Sensitivity Analysis of ODEs","title":"Direct Forward Sensitivity Analysis of ODEs","text":"ODEForwardSensitivityProblem\nextract_local_sensitivities","category":"page"},{"location":"copies/DiffEqSensitivity/manual/direct_forward_sensitivity/#DiffEqSensitivity.ODEForwardSensitivityProblem","page":"Direct Forward Sensitivity Analysis of ODEs","title":"DiffEqSensitivity.ODEForwardSensitivityProblem","text":"function ODEForwardSensitivityProblem(f::Union{Function,DiffEqBase.AbstractODEFunction},                                       u0,tspan,p=nothing,                                       alg::AbstractForwardSensitivityAlgorithm = ForwardSensitivity();                                       kwargs...)\n\nLocal forward sensitivity analysis gives a solution along with a timeseries of the sensitivities. Thus if one wishes to have a derivative at every possible time point, directly using the ODEForwardSensitivityProblem can be the most efficient method.\n\nODEForwardSensitivityProblem Syntax\n\nODEForwardSensitivityProblem is similar to an ODEProblem, but takes an AbstractForwardSensitivityAlgorithm that describes how to append the forward sensitivity equation calculation to the time evolution to simultaneously compute the derivative of the solution with respect to parameters.\n\nODEForwardSensitivityProblem(f::SciMLBase.AbstractODEFunction,u0,\n                             tspan,p=nothing,\n                             sensealg::AbstractForwardSensitivityAlgorithm = ForwardSensitivity();\n                             kwargs...)\n\nOnce constructed, this problem can be used in solve just like any other ODEProblem.  The solution can be deconstructed into the ODE solution and sensitivities parts using the extract_local_sensitivities function, with the following dispatches:\n\nextract_local_sensitivities(sol, asmatrix::Val=Val(false)) # Decompose the entire time series\nextract_local_sensitivities(sol, i::Integer, asmatrix::Val=Val(false)) # Decompose sol[i]\nextract_local_sensitivities(sol, t::Union{Number,AbstractVector}, asmatrix::Val=Val(false)) # Decompose sol(t)\n\nFor information on the mathematics behind these calculations, consult the sensitivity math page\n\nExample using an ODEForwardSensitivityProblem\n\nTo define a sensitivity problem, simply use the ODEForwardSensitivityProblem type instead of an ODE type. For example, we generate an ODE with the sensitivity equations attached for the Lotka-Volterra equations by:\n\nfunction f(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + u[1]*u[2]\nend\n\np = [1.5,1.0,3.0]\nprob = ODEForwardSensitivityProblem(f,[1.0;1.0],(0.0,10.0),p)\n\nThis generates a problem which the ODE solvers can solve:\n\nsol = solve(prob,DP8())\n\nNote that the solution is the standard ODE system and the sensitivity system combined. We can use the following helper functions to extract the sensitivity information:\n\nx,dp = extract_local_sensitivities(sol)\nx,dp = extract_local_sensitivities(sol,i)\nx,dp = extract_local_sensitivities(sol,t)\n\nIn each case, x is the ODE values and dp is the matrix of sensitivities The first gives the full timeseries of values and dp[i] contains the time series of the sensitivities of all components of the ODE with respect to ith parameter. The second returns the ith time step, while the third interpolates to calculate the sensitivities at time t. For example, if we do:\n\nx,dp = extract_local_sensitivities(sol)\nda = dp[1]\n\nthen da is the timeseries for fracpartial u(t)partial p. We can plot this\n\nplot(sol.t,da',lw=3)\n\ntransposing so that the rows (the timeseries) is plotted.\n\n(Image: Local Sensitivity Solution)\n\nHere we see that there is a periodicity to the sensitivity which matches the periodicity of the Lotka-Volterra solutions. However, as time goes on the sensitivity increases. This matches the analysis of Wilkins in Sensitivity Analysis for Oscillating Dynamical Systems.\n\nWe can also quickly see that these values are equivalent to those given by automatic differentiation and numerical differentiation through the ODE solver:\n\nusing ForwardDiff, Calculus\nfunction test_f(p)\n  prob = ODEProblem(f,eltype(p).([1.0,1.0]),eltype(p).((0.0,10.0)),p)\n  solve(prob,Vern9(),abstol=1e-14,reltol=1e-14,save_everystep=false)[end]\nend\n\np = [1.5,1.0,3.0]\nfd_res = ForwardDiff.jacobian(test_f,p)\ncalc_res = Calculus.finite_difference_jacobian(test_f,p)\n\nHere we just checked the derivative at the end point.\n\nInternal representation of the Solution\n\nFor completeness, we detail the internal representation. When using ForwardDiffSensitivity, the representation is with Dual numbers under the standard interpretation. The values for the ODE's solution at time i are the ForwardDiff.value.(sol[i]) portions, and the derivative with respect to parameter j is given by ForwardDiff.partials.(sol[i])[j].\n\nWhen using ForwardSensitivity, the solution to the ODE are the first n components of the solution. This means we can grab the matrix of solution values like:\n\nx = sol[1:sol.prob.indvars,:]\n\nSince each sensitivity is a vector of derivatives for each function, the sensitivities are each of size sol.prob.indvars. We can pull out the parameter sensitivities from the solution as follows:\n\nda = sol[sol.prob.indvars+1:sol.prob.indvars*2,:]\ndb = sol[sol.prob.indvars*2+1:sol.prob.indvars*3,:]\ndc = sol[sol.prob.indvars*3+1:sol.prob.indvars*4,:]\n\nThis means that da[1,i] is the derivative of the x(t) by the parameter a at time sol.t[i]. Note that all of the functionality available to ODE solutions is available in this case, including interpolations and plot recipes (the recipes will plot the expanded system).\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/direct_forward_sensitivity/#DiffEqSensitivity.extract_local_sensitivities","page":"Direct Forward Sensitivity Analysis of ODEs","title":"DiffEqSensitivity.extract_local_sensitivities","text":"extractlocalsensitivities\n\nExtracts the time series for the local sensitivities from the ODE solution. This requires that the ODE was defined via ODEForwardSensitivityProblem.\n\nextract_local_sensitivities(sol, asmatrix::Val=Val(false)) # Decompose the entire time series\nextract_local_sensitivities(sol, i::Integer, asmatrix::Val=Val(false)) # Decompose sol[i]\nextract_local_sensitivities(sol, t::Union{Number,AbstractVector}, asmatrix::Val=Val(false)) # Decompose sol(t)\n\n\n\n\n\n","category":"function"},{"location":"copies/NonlinearSolve/tutorials/iterator_interface/#Nonlinear-Solver-Iterator-Interface","page":"Nonlinear Solver Iterator Interface","title":"Nonlinear Solver Iterator Interface","text":"","category":"section"},{"location":"copies/NonlinearSolve/tutorials/iterator_interface/","page":"Nonlinear Solver Iterator Interface","title":"Nonlinear Solver Iterator Interface","text":"There is an iterator form of the nonlinear solver which mirrors the DiffEq integrator interface:","category":"page"},{"location":"copies/NonlinearSolve/tutorials/iterator_interface/","page":"Nonlinear Solver Iterator Interface","title":"Nonlinear Solver Iterator Interface","text":"f(u, p) = u .* u .- 2.0\nu0 = (1.0, 2.0) # brackets\nprobB = NonlinearProblem(f, u0)\nsolver = init(probB, Falsi()) # Can iterate the solver object\nsolver = solve!(solver)","category":"page"},{"location":"copies/NonlinearSolve/tutorials/iterator_interface/","page":"Nonlinear Solver Iterator Interface","title":"Nonlinear Solver Iterator Interface","text":"Note that the solver object is actually immutable since we want to make it live on the stack for the sake of performance.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#prec","page":"Preconditioners","title":"Preconditioners","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"Many linear solvers can be accelerated by using what is known as a preconditioner, an approximation to the matrix inverse action which is cheap to evaluate. These can improve the numerical conditioning of the solver process and in turn improve the performance. LinearSolve.jl provides an interface for the definition of preconditioners which works with the wrapped packages.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#Using-Preconditioners","page":"Preconditioners","title":"Using Preconditioners","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/#Mathematical-Definition","page":"Preconditioners","title":"Mathematical Definition","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"Preconditioners are specified in the keyword arguments of init or solve. The right preconditioner, Pr transforms the linear system Au = b into the form:","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"AP_r^-1(Pu) = AP_r^-1y = b","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"to add the solving step P_r u = y. The left preconditioner, Pl, transforms the linear system into the form:","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"P_l^-1(Au - b) = 0","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"A two-sided preconditioned system is of the form:","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"P_l A P_r^-1 (P_r u) = P_l b","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"By default, if no preconditioner is given the preconditioner is assumed to be the identity I.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#Using-Preconditioners-2","page":"Preconditioners","title":"Using Preconditioners","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"In the following, we will use the DiagonalPreconditioner to define a two-sided preconditioned system which first divides by some random numbers and then multiplies by the same values. This is commonly used in the case where if, instead of random, s is an approximation to the eigenvalues of a system.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"using LinearSolve, LinearAlgebra\r\ns = rand(n)\r\nPl = Diagonal(s)\r\n\r\nA = rand(n,n)\r\nb = rand(n)\r\n\r\nprob = LinearProblem(A,b)\r\nsol = solve(prob,IterativeSolvers_GMRES(),Pl=Pl)","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#Preconditioner-Interface","page":"Preconditioners","title":"Preconditioner Interface","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"To define a new preconditioner you define a Julia type which satisfies the following interface:","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"Base.eltype(::Preconditioner) (Required only for Krylov.jl)\nLinearAlgebra.ldiv!(::AbstractVector,::Preconditioner,::AbstractVector) and LinearAlgebra.ldiv!(::Preconditioner,::AbstractVector)","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#Curated-List-of-Pre-Defined-Preconditioners","page":"Preconditioners","title":"Curated List of Pre-Defined Preconditioners","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"The following preconditioners match the interface of LinearSolve.jl.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"LinearSolve.ComposePreconditioner(prec1,prec2): composes the preconditioners to apply prec1 before prec2.\nLinearSolve.InvPreconditioner(prec): inverts mul! and ldiv! in a preconditioner definition as a lazy inverse.\nLinearAlgera.Diagonal(s::Union{Number,AbstractVector}): the lazy Diagonal matrix type of Base.LinearAlgebra. Used for efficient construction of a diagonal preconditioner.\nOther Base.LinearAlgera types: all define the full Preconditioner interface.\nIncompleteLU.ilu: an implementation of the incomplete LU-factorization preconditioner. This requires A as a SparseMatrixCSC.\nPreconditioners.CholeskyPreconditioner(A, i): An incomplete Cholesky preconditioner with cut-off level i. Requires A as a AbstractMatrix and positive semi-definite.\nAlgebraicMultiGrid: Implementations of the algebraic multigrid method. Must be converted to a preconditioner via AlgebraicMultiGrid.aspreconditioner(AlgebraicMultiGrid.precmethod(A)). Requires A as a AbstractMatrix. Provides the following methods:\nAlgebraicMultiGrid.ruge_stuben(A)\nAlgebraicMultiGrid.smoothed_aggregation(A)\nPyAMG: Implementations of the algebraic multigrid method. Must be converted to a preconditioner via PyAMG.aspreconditioner(PyAMG.precmethod(A)). Requires A as a AbstractMatrix. Provides the following methods:\nPyAMG.RugeStubenSolver(A)\nPyAMG.SmoothedAggregationSolver(A)\nILUZero.ILU0Precon(A::SparseMatrixCSC{T,N}, b_type = T): An incomplete LU implementation. Requires A as a SparseMatrixCSC.\nLimitedLDLFactorizations.lldl: A limited-memory LDLᵀ factorization for symmetric matrices. Requires A as a SparseMatrixCSC. Applying F = lldl(A); F.D .= abs.(F.D) before usage as a preconditioner makes the preconditioner symmetric postive definite and thus is required for Krylov methods which are specialized for symmetric linear systems.\nRandomizedPreconditioners.NystromPreconditioner A randomized sketching method for positive semidefinite matrices A. Builds a preconditioner P  A + μ*I for the system (A + μ*I)x = b","category":"page"},{"location":"copies/ModelingToolkit/internals/#Internal-Details","page":"Internal Details","title":"Internal Details","text":"","category":"section"},{"location":"copies/ModelingToolkit/internals/","page":"Internal Details","title":"Internal Details","text":"This is a page for detailing some of the inner workings to help future contributors to the library.","category":"page"},{"location":"copies/ModelingToolkit/internals/#Observables-and-Variable-Elimination","page":"Internal Details","title":"Observables and Variable Elimination","text":"","category":"section"},{"location":"copies/ModelingToolkit/internals/","page":"Internal Details","title":"Internal Details","text":"In the variable \"elimination\" algorithms, what is actually done is that variables are removed from being states and equations are moved into the observed category of the system. The observed equations are explicit algebraic equations which are then substituted out to completely eliminate these variables from the other equations, allowing the system to act as though these variables no longer exist.","category":"page"},{"location":"copies/ModelingToolkit/internals/","page":"Internal Details","title":"Internal Details","text":"However, as a user may have wanted to interact with such variables, for example, plotting their output, these relationships are stored and are then used to generate the observed equation found in the SciMLFunction interface, so that sol[x] lazily reconstructs the observed variable when necessary. In this sense, there is an equivalence between observables and the variable elimination system.","category":"page"},{"location":"copies/ModelingToolkit/internals/","page":"Internal Details","title":"Internal Details","text":"The procedure for variable elimination inside structural_simplify is","category":"page"},{"location":"copies/ModelingToolkit/internals/","page":"Internal Details","title":"Internal Details","text":"ModelingToolkit.initialize_system_structure.\nModelingToolkit.alias_elimination. This step moves equations into observed(sys).\nModelingToolkit.dae_index_lowering by means of pantelides! (if the system is an ODESystem).\nModelingToolkit.tearing.","category":"page"},{"location":"copies/ModelingToolkit/internals/#Preparing-a-system-for-simulation","page":"Internal Details","title":"Preparing a system for simulation","text":"","category":"section"},{"location":"copies/ModelingToolkit/internals/","page":"Internal Details","title":"Internal Details","text":"Before a simulation or optimization can be performed, the symbolic equations stored in an AbstractSystem must be converted into executable code. This step is typically occurs after the simplification explained above, and is performed when an instance of a AbsSciMLBase.SciMLProblem, such as a ODEProblem, is constructed. The call chain typically looks like this, with the function names in the case of an ODESystem indicated in parenthesis","category":"page"},{"location":"copies/ModelingToolkit/internals/","page":"Internal Details","title":"Internal Details","text":"Problem constructor (ODEProblem)\nBuild an DEFunction (process_DEProblem -> ODEFunction\nWrite actual executable code (generate_function)","category":"page"},{"location":"copies/ModelingToolkit/internals/","page":"Internal Details","title":"Internal Details","text":"Apart from generate_function, which generates the dynamics function, ODEFunction also builds functions for observed equations (build_explicit_observed_function) and jacobians (generate_jacobian) etc. These are all stored in the ODEFunction.","category":"page"},{"location":"copies/Optimization/tutorials/minibatch/#Minibatch-examples","page":"Minibatch","title":"Minibatch examples","text":"","category":"section"},{"location":"copies/Optimization/tutorials/minibatch/","page":"Minibatch","title":"Minibatch","text":"note: Note\nThis example uses the OptimizationOptimJL.jl package. See the Optim.jl page for details on the installation and usage.","category":"page"},{"location":"copies/Optimization/tutorials/minibatch/","page":"Minibatch","title":"Minibatch","text":"using DiffEqFlux, Optimization, OptimizationOptimJL, OrdinaryDiffEq\n\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k*(temp-temp_m)\n  end\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2)/8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend\n\nfunction dudt_(u,p,t)\n    ann(u, p).* u\nend\n\ncallback = function (p,l,pred;doplot=false) #callback function to observe training\n    display(l)\n    # plot current prediction against data\n    if doplot\n      pl = scatter(t,ode_data[1,:],label=\"data\")\n      scatter!(pl,t,pred[1,:],label=\"prediction\")\n      display(plot(pl))\n    end\n    return false\nend\n\nu0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\n\nt = range(tspan[1], tspan[2], length=datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat=t))\n\nann = FastChain(FastDense(1,8,tanh), FastDense(8,1,tanh))\npp = initial_params(ann)\nprob = ODEProblem{false}(dudt_, u0, tspan, pp)\n\nfunction predict_adjoint(fullp, time_batch)\n    Array(solve(prob, Tsit5(), p = fullp, saveat = time_batch))\nend\n\nfunction loss_adjoint(fullp, batch, time_batch)\n    pred = predict_adjoint(fullp,time_batch)\n    sum(abs2, batch .- pred), pred\nend\n\n\nk = 10\ntrain_loader = Flux.Data.DataLoader((ode_data, t), batchsize = k)\n\nnumEpochs = 300\nl1 = loss_adjoint(pp, train_loader.data[1], train_loader.data[2])[1]\n\noptfun = OptimizationFunction((θ, p, batch, time_batch) -> loss_adjoint(θ, batch, time_batch), Optimization.AutoZygote())\noptprob = OptimizationProblem(optfun, pp)\nusing IterTools: ncycle\nres1 = Optimization.solve(optprob, ADAM(0.05), ncycle(train_loader, numEpochs), callback = callback)\n@test 10res1.minimum < l1","category":"page"},{"location":"copies/ModelingToolkit/systems/ODESystem/#ODESystem","page":"ODESystem","title":"ODESystem","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ODESystem/#System-Constructors","page":"ODESystem","title":"System Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ODESystem/","page":"ODESystem","title":"ODESystem","text":"ODESystem","category":"page"},{"location":"copies/ModelingToolkit/systems/ODESystem/#ModelingToolkit.ODESystem","page":"ODESystem","title":"ModelingToolkit.ODESystem","text":"struct ODESystem <: ModelingToolkit.AbstractODESystem\n\nA system of ordinary differential equations.\n\nFields\n\neqs\nThe ODEs defining the system.\niv\nIndependent variable.\nstates\nDependent (state) variables. Must not contain the independent variable.\nN.B.: If tornmatching !== nothing, this includes all variables. Actual ODE states are determined by the SelectedState() entries in `tornmatching`.\n\nps\nParameter variables. Must not contain the independent variable.\nvar_to_name\nArray variables.\nctrls\nControl parameters (some subset of ps).\nobserved\nObserved states.\ntgrad\nTime-derivative matrix. Note: this field will not be defined until calculate_tgrad is called on the system.\n\njac\nJacobian matrix. Note: this field will not be defined until calculate_jacobian is called on the system.\n\nctrl_jac\nControl Jacobian matrix. Note: this field will not be defined until calculate_control_jacobian is called on the system.\n\nWfact\nWfact matrix. Note: this field will not be defined until generate_factorized_W is called on the system.\n\nWfact_t\nWfact_t matrix. Note: this field will not be defined until generate_factorized_W is called on the system.\n\nname\nName: the name of the system\n\nsystems\nsystems: The internal systems. These are required to have unique names.\n\ndefaults\ndefaults: The default values to use when initial conditions and/or parameters are not supplied in ODEProblem.\n\ntorn_matching\ntorn_matching: Tearing result specifying how to solve the system.\n\nconnector_type\nconnector_type: type of the system\n\nconnections\nconnections: connections in a system\n\npreface\npreface: inject assignment statements before the evaluation of the RHS function.\n\ncontinuous_events\ncontinuous_events: A Vector{SymbolicContinuousCallback} that model events. The integrator will use root finding to guarantee that it steps at each zero crossing.\n\ntearing_state\ntearing_state: cache for intermediate tearing state\n\nsubstitutions\nsubstitutions: substitutions generated by tearing.\n\nExample\n\nusing ModelingToolkit\n\n@parameters σ ρ β\n@variables t x(t) y(t) z(t)\nD = Differential(t)\n\neqs = [D(x) ~ σ*(y-x),\n       D(y) ~ x*(ρ-z)-y,\n       D(z) ~ x*y - β*z]\n\n@named de = ODESystem(eqs,t,[x,y,z],[σ,ρ,β])\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/ODESystem/#Composition-and-Accessor-Functions","page":"ODESystem","title":"Composition and Accessor Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ODESystem/","page":"ODESystem","title":"ODESystem","text":"get_eqs(sys) or equations(sys): The equations that define the ODE.\nget_states(sys) or states(sys): The set of states in the ODE.\nget_ps(sys) or parameters(sys): The parameters of the ODE.\nget_iv(sys): The independent variable of the ODE.","category":"page"},{"location":"copies/ModelingToolkit/systems/ODESystem/#Transformations","page":"ODESystem","title":"Transformations","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ODESystem/","page":"ODESystem","title":"ODESystem","text":"structural_simplify\r\node_order_lowering\r\ndae_index_lowering\r\nliouville_transform\r\nalias_elimination\r\ntearing","category":"page"},{"location":"copies/ModelingToolkit/systems/ODESystem/#ModelingToolkit.ode_order_lowering","page":"ODESystem","title":"ModelingToolkit.ode_order_lowering","text":"ode_order_lowering(sys::ODESystem) -> Any\n\n\nTakes a Nth order ODESystem and returns a new ODESystem written in first order form by defining new variables which represent the N-1 derivatives.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/systems/ODESystem/#ModelingToolkit.StructuralTransformations.dae_index_lowering","page":"ODESystem","title":"ModelingToolkit.StructuralTransformations.dae_index_lowering","text":"dae_index_lowering(sys::ODESystem; kwargs...) -> ODESystem\n\nPerform the Pantelides algorithm to transform a higher index DAE to an index 1 DAE. kwargs are forwarded to pantelides!. End users are encouraged to call structural_simplify instead, which calls this function internally.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/systems/ODESystem/#ModelingToolkit.liouville_transform","page":"ODESystem","title":"ModelingToolkit.liouville_transform","text":"liouville_transform(sys::ModelingToolkit.AbstractODESystem)\n\n\nGenerates the Liouville transformed set of ODEs, which is the original ODE system with a new variable trJ appended, corresponding to the -tr(Jacobian). This variable is used for properties like uncertainty propagation from a given initial distribution density.\n\nFor example, if u=p*u and p follows a probability distribution f(p), then the probability density of a future value with a given choice of p is computed by setting the inital trJ = f(p), and the final value of trJ is the probability of u(t).\n\nExample:\n\nusing ModelingToolkit, OrdinaryDiffEq, Test\n\n@parameters t α β γ δ\n@variables x(t) y(t)\nD = Differential(t)\n\neqs = [D(x) ~ α*x - β*x*y,\n       D(y) ~ -δ*y + γ*x*y]\n\nsys = ODESystem(eqs)\nsys2 = liouville_transform(sys)\n@variables trJ\n\nu0 = [x => 1.0,\n      y => 1.0,\n      trJ => 1.0]\n\nprob = ODEProblem(sys2,u0,tspan,p)\nsol = solve(prob,Tsit5())\n\nWhere sol[3,:] is the evolution of trJ over time.\n\nSources:\n\nProbabilistic Robustness Analysis of F-16 Controller Performance: An Optimal Transport Approach\n\nAbhishek Halder, Kooktae Lee, and Raktim Bhattacharya https://abhishekhalder.bitbucket.io/F16ACC2013Final.pdf\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/systems/ODESystem/#Analyses","page":"ODESystem","title":"Analyses","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ODESystem/","page":"ODESystem","title":"ODESystem","text":"ModelingToolkit.islinear\r\nModelingToolkit.isautonomous\r\nModelingToolkit.isaffine","category":"page"},{"location":"copies/ModelingToolkit/systems/ODESystem/#Applicable-Calculation-and-Generation-Functions","page":"ODESystem","title":"Applicable Calculation and Generation Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ODESystem/","page":"ODESystem","title":"ODESystem","text":"calculate_jacobian\r\ncalculate_tgrad\r\ncalculate_factorized_W\r\ngenerate_jacobian\r\ngenerate_tgrad\r\ngenerate_factorized_W\r\njacobian_sparsity","category":"page"},{"location":"copies/ModelingToolkit/systems/ODESystem/#Standard-Problem-Constructors","page":"ODESystem","title":"Standard Problem Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ODESystem/","page":"ODESystem","title":"ODESystem","text":"ODEFunction\r\nODEProblem\r\nSteadyStateFunction\r\nSteadyStateProblem","category":"page"},{"location":"copies/ModelingToolkit/systems/ODESystem/#SciMLBase.ODEFunction","page":"ODESystem","title":"SciMLBase.ODEFunction","text":"ODEFunction{iip,F,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,S2,O,TCV} <: AbstractODEFunction{iip}\n\nA representation of an ODE function f, defined by:\n\nM fracdudt = f(upt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nODEFunction{iip,recompile}(f;\n                           mass_matrix=I,\n                           analytic=nothing,\n                           tgrad=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           paramjac = nothing,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p,t) or du = f(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\niip is the the optional boolean for determining whether a given function is written to be used in-place or out-of-place. In-place functions are f!(du,u,p,t) where the return is ignored and the result is expected to be mutated into the value of du. Out-of-place functions are du=f(u,p,t).\n\nNormally this is determined automatically by looking at the method table for f and seeing the maximum number of arguments in available dispatches. For this reason, the constructor ODEFunction(f) generally works (but is type-unstable). However, for type-stability or to enforce correctness, this option is passed via ODEFunction{true}(f).\n\nrecompile: Controlling Compilation and Specialization\n\nThe recompile parameter controls whether the ODEFunction will fully specialize on the typeof(f). This causes recompilation of the solver for each new f function, but gives the maximum compiler information and runtime speed. By default recompile = true. If recompile = false, the ODEFunction uses Any type parameters for each of the functions, allowing for the reuse of compilation caches but adding a dynamic dispatch at the f call sites, potentially leading to runtime regressions.\n\nOverriding the true default is done by passing a second type parameter after iip, for example ODEFunction{true,false}(f) is an in-place function with no recompilation specialization.\n\nFields\n\nThe fields of the ODEFunction type directly match the names of the inputs.\n\nMore Details on Jacobians\n\nThe following example creates an inplace ODEFunction whose jacobian is a Diagonal:\n\nusing LinearAlgebra\nf = (du,u,p,t) -> du .= t .* u\njac = (J,u,p,t) -> (J[1,1] = t; J[2,2] = t; J)\njp = Diagonal(zeros(2))\nfun = ODEFunction(f; jac=jac, jac_prototype=jp)\n\nNote that the integrators will always make a deep copy of fun.jac_prototype, so there's no worry of aliasing.\n\nIn general the jacobian prototype can be anything that has mul! defined, in particular sparse matrices or custom lazy types that support mul!. A special case is when the jac_prototype is a AbstractDiffEqLinearOperator, in which case you do not need to supply jac as it is automatically set to update_coefficients!. Refer to the AbstractSciMLOperators documentation for more information on setting up time/parameter dependent operators.\n\nExamples\n\nDeclaring Explicit Jacobians for ODEs\n\nThe most standard case, declaring a function for a Jacobian is done by overloading the function f(du,u,p,t) with an in-place updating function for the Jacobian: f_jac(J,u,p,t) where the value type is used for dispatch. For example, take the LotkaVolterra model:\n\nfunction f(du,u,p,t)\n  du[1] = 2.0 * u[1] - 1.2 * u[1]*u[2]\n  du[2] = -3 * u[2] + u[1]*u[2]\nend\n\nTo declare the Jacobian we simply add the dispatch:\n\nfunction f_jac(J,u,p,t)\n  J[1,1] = 2.0 - 1.2 * u[2]\n  J[1,2] = -1.2 * u[1]\n  J[2,1] = 1 * u[2]\n  J[2,2] = -3 + u[1]\n  nothing\nend\n\nThen we can supply the Jacobian with our ODE as:\n\nff = ODEFunction(f;jac=f_jac)\n\nand use this in an ODEProblem:\n\nprob = ODEProblem(ff,ones(2),(0.0,10.0))\n\nSymbolically Generating the Functions\n\nSee the modelingtoolkitize function from ModelingToolkit.jl for automatically symbolically generating the Jacobian and more from the  numerically-defined functions.\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/ODESystem/#SciMLBase.ODEProblem","page":"ODESystem","title":"SciMLBase.ODEProblem","text":"Defines an ordinary differential equation (ODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/ode_types/\n\nMathematical Specification of an ODE Problem\n\nTo define an ODE Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\nM fracdudt = f(upt)\n\nThere are two different ways of specifying f:\n\nf(du,u,p,t): in-place. Memory-efficient when avoiding allocations. Best option for most cases unless mutation is not allowed. \nf(u,p,t): returning du. Less memory-efficient way, particularly suitable when mutation is not allowed (e.g. with certain automatic differentiation packages such as Zygote).\n\nu₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nFor the mass matrix M, see the documentation of ODEFunction.\n\nProblem Type\n\nConstructors\n\nODEProblem can be constructed by first building an ODEFunction or by simply passing the ODE right-hand side to the constructor. The constructors are:\n\nODEProblem(f::ODEFunction,u0,tspan,p=NullParameters();kwargs...)\nODEProblem{isinplace}(f,u0,tspan,p=NullParameters();kwargs...) : Defines the ODE with the specified functions. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the ODEFunction documentation.\n\nFields\n\nf: The function in the ODE.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The parameters.\nkwargs: The keyword arguments passed onto the solves.\n\nExample Problems\n\nExample problems can be found in DiffEqProblemLibrary.jl.\n\nTo use a sample problem, such as prob_ode_linear, you can do something like:\n\n#] add DiffEqProblemLibrary\nusing DiffEqProblemLibrary.ODEProblemLibrary\n# load problems\nODEProblemLibrary.importodeproblems()\nprob = ODEProblemLibrary.prob_ode_linear\nsol = solve(prob)\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/ODESystem/#SciMLBase.SteadyStateProblem","page":"ODESystem","title":"SciMLBase.SteadyStateProblem","text":"Defines an Defines a steady state ODE problem. Documentation Page: https://diffeq.sciml.ai/stable/types/steadystatetypes/\n\nMathematical Specification of a Steady State Problem\n\nTo define an Steady State Problem, you simply need to give the function f which defines the ODE:\n\nfracdudt = f(upt)\n\nand an initial guess u_0 of where f(u,p,t)=0. f should be specified as f(u,p,t) (or in-place as f(du,u,p,t)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nNote that for the steady-state to be defined, we must have that f is autonomous, that is f is independent of t. But the form which matches the standard ODE solver should still be used. The steady state solvers interpret the f by fixing t=0.\n\nProblem Type\n\nConstructors\n\nSteadyStateProblem(f::ODEFunction,u0,p=NullParameters();kwargs...)\nSteadyStateProblem{isinplace}(f,u0,p=NullParameters();kwargs...)\n\nisinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred. Additionally, the constructor from ODEProblems is provided:\n\nSteadyStateProblem(prob::ODEProblem)\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The function in the ODE.\nu0: The initial guess for the steady state.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\nSpecial Solution Fields\n\nThe SteadyStateSolution type is different from the other DiffEq solutions because it does not have temporal information.\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/ODESystem/#Torn-Problem-Constructors","page":"ODESystem","title":"Torn Problem Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ODESystem/","page":"ODESystem","title":"ODESystem","text":"ODAEProblem","category":"page"},{"location":"copies/ModelingToolkit/systems/ODESystem/#ModelingToolkit.StructuralTransformations.ODAEProblem","page":"ODESystem","title":"ModelingToolkit.StructuralTransformations.ODAEProblem","text":"ODAEProblem{iip}(sys, u0map, tspan, parammap = DiffEqBase.NullParameters(); kw...)\n\nThis constructor acts similar to the one for ODEProblem with the following changes: ODESystems can sometimes be further reduced if structural_simplify has already been applied to them. In these cases, the constructor uses the knowledge of the strongly connected components calculated during the process of simplification as the basis for building pre-simplified nonlinear systems in the implicit solving. In summary: these problems are structurally modified, but could be more efficient and more stable. Note, the returned object is still of type ODEProblem.\n\n\n\n\n\n","category":"type"},{"location":"copies/LinearSolve/basics/CachingAPI/#Caching-Interface-API-Functions","page":"Caching Interface API Functions","title":"Caching Interface API Functions","text":"","category":"section"},{"location":"copies/LinearSolve/basics/CachingAPI/","page":"Caching Interface API Functions","title":"Caching Interface API Functions","text":"LinearSolve.set_A\r\nLinearSolve.set_b\r\nLinearSolve.set_u\r\nLinearSolve.set_p\r\nLinearSolve.set_prec","category":"page"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_A","page":"Caching Interface API Functions","title":"LinearSolve.set_A","text":"set_A(cache, A)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_b","page":"Caching Interface API Functions","title":"LinearSolve.set_b","text":"set_b(cache, b)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_u","page":"Caching Interface API Functions","title":"LinearSolve.set_u","text":"set_u(cache, u)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_p","page":"Caching Interface API Functions","title":"LinearSolve.set_p","text":"set_p(cache, p)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_prec","page":"Caching Interface API Functions","title":"LinearSolve.set_prec","text":"set_prec(cache, Pl, Pr)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/NonlinearSolve/#NonlinearSolve.jl:-High-Performance-Unified-Nonlinear-Solvers","page":"Home","title":"NonlinearSolve.jl: High-Performance Unified Nonlinear Solvers","text":"","category":"section"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"NonlinearSolve.jl is a unified interface for the nonlinear solving packages of Julia. It includes its own high-performance nonlinear solvers which include the ability to swap out to fast direct and iterative linear solvers, along with the ability to use sparse automatic differentiation for Jacobian construction and Jacobian-vector products. It interfaces with other packages of the Julia ecosystem to make it easy to test alternative solver packages and pass small types to control algorithm swapping. It also interfaces with the ModelingToolkit.jl world of symbolic modeling to allow for automatically generating high-performance code.","category":"page"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"Performance is key: the current methods are made to be highly performant on scalar and statically sized small problems, with options for large-scale systems. If you run into any performance issues, please file an issue. Note that this package is distinct from SciMLNLSolve.jl. Consult the NonlinearSystemSolvers page for information on how to import solvers from different packages.","category":"page"},{"location":"copies/NonlinearSolve/#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"To install NonlinearSolve.jl, use the Julia package manager:","category":"page"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"NonlinearSolve\")","category":"page"},{"location":"copies/NonlinearSolve/#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to ModelingToolkit.\nThere are a few community forums:\nthe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\non the Julia Discourse forums (look for the modelingtoolkit tag\nsee also SciML Community page","category":"page"},{"location":"copies/NonlinearSolve/#Roadmap","page":"Home","title":"Roadmap","text":"","category":"section"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"The current algorithms should support automatic differentiation, though improved adjoint overloads are planned to be added in the current update (which will make use of the f(u,p) form). Future updates will include standard methods for larger scale nonlinear solving like Newton-Krylov methods.","category":"page"},{"location":"copies/Optimization/optimization_packages/nomad/#NOMAD.jl","page":"NOMAD.jl","title":"NOMAD.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD is Julia package interfacing to NOMAD,which is a C++ implementation of the Mesh Adaptive Direct Search algorithm (MADS), designed for difficult blackbox optimization problems. These problems occur when the functions defining the objective and constraints are the result of costly computer simulations. NOMAD.jl documentation","category":"page"},{"location":"copies/Optimization/optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The NOMAD algorithm is called by NOMADOpt()","category":"page"},{"location":"copies/Optimization/optimization_packages/nomad/#Installation:-OptimizationNOMAD.jl","page":"NOMAD.jl","title":"Installation: OptimizationNOMAD.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"To use this package, install the OptimizationNOMAD package:","category":"page"},{"location":"copies/Optimization/optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"import Pkg; Pkg.add(\"OptimizationNOMAD\")","category":"page"},{"location":"copies/Optimization/optimization_packages/nomad/#Global-Optimizer","page":"NOMAD.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nomad/#Without-Constraint-Equations","page":"NOMAD.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The method in NOMAD is performing global optimization on problems both with and without constraint equations. Currently however, linear and nonlinear constraints  defined in Optimization are not passed.","category":"page"},{"location":"copies/Optimization/optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"NOMAD works both with and without lower and upper boxconstraints set by lb and ub in the OptimizationProblem.","category":"page"},{"location":"copies/Optimization/optimization_packages/nomad/#Examples","page":"NOMAD.jl","title":"Examples","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"The Rosenbrock function can optimized using the NOMADOpt() with and without boxcontraints as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/nomad/","page":"NOMAD.jl","title":"NOMAD.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\n\nprob = OptimizationProblem(f, x0, _p)\nsol = Optimization.solve(prob,NOMADOpt())\n\nprob = OptimizationProblem(f, x0, _p, lb = [-1.0,-1.0], ub = [1.5,1.5])\nsol = Optimization.solve(prob,NOMADOpt())","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/hybrid_diffeq/#Training-Neural-Networks-in-Hybrid-Differential-Equations","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"Hybrid differential equations are differential equations with implicit or explicit discontinuities as specified by callbacks. In the following example, explicit dosing times are given for a pharmacometric model and the universal differential equation is trained to uncover the missing dynamical equations.","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"using DiffEqFlux, DifferentialEquations, Plots\nu0 = Float32[2.; 0.]\ndatasize = 100\ntspan = (0.0f0,10.5f0)\ndosetimes = [1.0,2.0,4.0,8.0]\n\nfunction affect!(integrator)\n    integrator.u = integrator.u.+1\nend\ncb_ = PresetTimeCallback(dosetimes,affect!,save_positions=(false,false))\nfunction trueODEfunc(du,u,p,t)\n    du .= -u\nend\nt = range(tspan[1],tspan[2],length=datasize)\n\nprob = ODEProblem(trueODEfunc,u0,tspan)\node_data = Array(solve(prob,Tsit5(),callback=cb_,saveat=t))\ndudt2 = Chain(Dense(2,50,tanh),\n             Dense(50,2))\np,re = Flux.destructure(dudt2) # use this p as the initial condition!\n\nfunction dudt(du,u,p,t)\n    du[1:2] .= -u[1:2]\n    du[3:end] .= re(p)(u[1:2]) #re(p)(u[3:end])\nend\nz0 = Float32[u0;u0]\nprob = ODEProblem(dudt,z0,tspan)\n\naffect!(integrator) = integrator.u[1:2] .= integrator.u[3:end]\ncb = PresetTimeCallback(dosetimes,affect!,save_positions=(false,false))\n\nfunction predict_n_ode()\n    _prob = remake(prob,p=p)\n    Array(solve(_prob,Tsit5(),u0=z0,p=p,callback=cb,saveat=t,sensealg=ReverseDiffAdjoint()))[1:2,:]\n    #Array(solve(prob,Tsit5(),u0=z0,p=p,saveat=t))[1:2,:]\nend\n\nfunction loss_n_ode()\n    pred = predict_n_ode()\n    loss = sum(abs2,ode_data .- pred)\n    loss\nend\nloss_n_ode() # n_ode.p stores the initial parameters of the neural ODE\n\ncba = function (;doplot=false) #callback function to observe training\n  pred = predict_n_ode()\n  display(sum(abs2,ode_data .- pred))\n  # plot current prediction against data\n  pl = scatter(t,ode_data[1,:],label=\"data\")\n  scatter!(pl,t,pred[1,:],label=\"prediction\")\n  display(plot(pl))\n  return false\nend\ncba()\n\nps = Flux.params(p)\ndata = Iterators.repeated((), 200)\nFlux.train!(loss_n_ode, ps, data, ADAM(0.05), cb = cba)","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"(Image: Hybrid Universal Differential Equation)","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/hybrid_diffeq/#Note-on-Sensitivity-Methods","page":"Training Neural Networks in Hybrid Differential Equations","title":"Note on Sensitivity Methods","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"The continuous adjoint sensitivities BacksolveAdjoint, InterpolatingAdjoint, and QuadratureAdjoint are compatible with events for ODEs. BacksolveAdjoint and InterpolatingAdjoint can also handle events for SDEs. Use BacksolveAdjoint if the event terminates the time evolution and several states are saved. Currently, the continuous adjoint sensitivities do not support multiple events per time point.","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/hybrid_diffeq/","page":"Training Neural Networks in Hybrid Differential Equations","title":"Training Neural Networks in Hybrid Differential Equations","text":"All methods based on discrete sensitivity analysis via automatic differentiation, like ReverseDiffAdjoint, TrackerAdjoint, or ForwardDiffSensitivity are the methods to use (and ReverseDiffAdjoint is demonstrated above), are compatible with events. This applies to SDEs, DAEs, and DDEs as well.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Partial-Differential-Equation-(PDE)-Constrained-Optimization","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"This example uses a prediction model to optimize the one-dimensional Heat Equation. (Step-by-step description below)","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"using DelimitedFiles,Plots\nusing DifferentialEquations, DiffEqFlux\n\n# Problem setup parameters:\nLx = 10.0\nx  = 0.0:0.01:Lx\ndx = x[2] - x[1]\nNx = size(x)\n\nu0 = exp.(-(x.-3.0).^2) # I.C\n\n## Problem Parameters\np        = [1.0,1.0]    # True solution parameters\nxtrs     = [dx,Nx]      # Extra parameters\ndt       = 0.40*dx^2    # CFL condition\nt0, tMax = 0.0 ,1000*dt\ntspan    = (t0,tMax)\nt        = t0:dt:tMax;\n\n## Definition of Auxiliary functions\nfunction ddx(u,dx)\n    \"\"\"\n    2nd order Central difference for 1st degree derivative\n    \"\"\"\n    return [[zero(eltype(u))] ; (u[3:end] - u[1:end-2]) ./ (2.0*dx) ; [zero(eltype(u))]]\nend\n\n\nfunction d2dx(u,dx)\n    \"\"\"\n    2nd order Central difference for 2nd degree derivative\n    \"\"\"\n    return [[zero(eltype(u))]; (u[3:end] - 2.0.*u[2:end-1] + u[1:end-2]) ./ (dx^2); [zero(eltype(u))]]\nend\n\n## ODE description of the Physics:\nfunction heat(u,p,t)\n    # Model parameters\n    a0, a1 = p\n    dx,Nx = xtrs #[1.0,3.0,0.125,100]\n    return 2.0*a0 .* u +  a1 .* d2dx(u, dx)\nend\n\n# Testing Solver on linear PDE\nprob = ODEProblem(heat,u0,tspan,p)\nsol = solve(prob,Tsit5(), dt=dt,saveat=t);\n\nplot(x, sol.u[1], lw=3, label=\"t0\", size=(800,500))\nplot!(x, sol.u[end],lw=3, ls=:dash, label=\"tMax\")\n\nps  = [0.1, 0.2];   # Initial guess for model parameters\nfunction predict(θ)\n    Array(solve(prob,Tsit5(),p=θ,dt=dt,saveat=t))\nend\n\n## Defining Loss function\nfunction loss(θ)\n    pred = predict(θ)\n    l = predict(θ)  - sol\n    return sum(abs2, l), pred # Mean squared error\nend\n\nl,pred   = loss(ps)\nsize(pred), size(sol), size(t) # Checking sizes\n\nLOSS  = []                              # Loss accumulator\nPRED  = []                              # prediction accumulator\nPARS  = []                              # parameters accumulator\n\ncb = function (θ,l,pred) #callback function to observe training\n  display(l)\n  append!(PRED, [pred])\n  append!(LOSS, l)\n  append!(PARS, [θ])\n  false\nend\n\ncb(ps,loss(ps)...) # Testing callback function\n\n# Let see prediction vs. Truth\nscatter(sol[:,end], label=\"Truth\", size=(800,500))\nplot!(PRED[end][:,end], lw=2, label=\"Prediction\")\n\nres = DiffEqFlux.sciml_train(loss, ps, cb = cb)\n@show res.u # returns [0.999999999613485, 0.9999999991343996]","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Step-by-step-Description","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Step-by-step Description","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Load-Packages","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Load Packages","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"using DelimitedFiles,Plots\nusing DifferentialEquations, DiffEqFlux","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Parameters","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Parameters","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"First, we setup the 1-dimensional space over which our equations will be evaluated. x spans from 0.0 to 10.0 in steps of 0.01; t spans from 0.00 to 0.04 in steps of 4.0e-5.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"# Problem setup parameters:\nLx = 10.0\nx  = 0.0:0.01:Lx\ndx = x[2] - x[1]\nNx = size(x)\n\nu0 = exp.(-(x.-3.0).^2) # I.C\n\n## Problem Parameters\np        = [1.0,1.0]    # True solution parameters\nxtrs     = [dx,Nx]      # Extra parameters\ndt       = 0.40*dx^2    # CFL condition\nt0, tMax = 0.0 ,1000*dt\ntspan    = (t0,tMax)\nt        = t0:dt:tMax;","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"In plain terms, the quantities that were defined are:","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"x (to Lx) spans the specified 1D space\ndx = distance between two points\nNx = total size of space\nu0 = initial condition\np = true solution\nxtrs = convenient grouping of dx and Nx into Array\ndt = time distance between two points\nt (t0 to tMax) spans the specified time frame\ntspan = span of t","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Auxiliary-Functions","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Auxiliary Functions","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"We then define two functions to compute the derivatives numerically. The Central Difference is used in both the 1st and 2nd degree derivatives.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"## Definition of Auxiliary functions\nfunction ddx(u,dx)\n    \"\"\"\n    2nd order Central difference for 1st degree derivative\n    \"\"\"\n    return [[zero(eltype(u))] ; (u[3:end] - u[1:end-2]) ./ (2.0*dx) ; [zero(eltype(u))]]\nend\n\n\nfunction d2dx(u,dx)\n    \"\"\"\n    2nd order Central difference for 2nd degree derivative\n    \"\"\"\n    return [[zero(eltype(u))]; (u[3:end] - 2.0.*u[2:end-1] + u[1:end-2]) ./ (dx^2); [zero(eltype(u))]]\nend","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Heat-Differential-Equation","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Heat Differential Equation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"Next, we setup our desired set of equations in order to define our problem.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"## ODE description of the Physics:\nfunction heat(u,p,t)\n    # Model parameters\n    a0, a1 = p\n    dx,Nx = xtrs #[1.0,3.0,0.125,100]\n    return 2.0*a0 .* u +  a1 .* d2dx(u, dx)\nend","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Solve-and-Plot-Ground-Truth","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Solve and Plot Ground Truth","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"We then solve and plot our partial differential equation. This is the true solution which we will compare to further on.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"# Testing Solver on linear PDE\nprob = ODEProblem(heat,u0,tspan,p)\nsol = solve(prob,Tsit5(), dt=dt,saveat=t);\n\nplot(x, sol.u[1], lw=3, label=\"t0\", size=(800,500))\nplot!(x, sol.u[end],lw=3, ls=:dash, label=\"tMax\")","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Building-the-Prediction-Model","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Building the Prediction Model","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"Now we start building our prediction model to try to obtain the values p. We make an initial guess for the parameters and name it ps here. The predict function is a non-linear transformation in one layer using solve. If unfamiliar with the concept, refer to here.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"ps  = [0.1, 0.2];   # Initial guess for model parameters\nfunction predict(θ)\n    Array(solve(prob,Tsit5(),p=θ,dt=dt,saveat=t))\nend","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Train-Parameters","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Train Parameters","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"Training our model requires a loss function, an optimizer and a callback function to display the progress.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Loss","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Loss","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"We first make our predictions based on the current values of our parameters ps, then take the difference between the predicted solution and the truth above. For the loss, we use the Mean squared error.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"## Defining Loss function\nfunction loss(θ)\n    pred = predict(θ)\n    l = predict(θ)  - sol\n    return sum(abs2, l), pred # Mean squared error\nend\n\nl,pred   = loss(ps)\nsize(pred), size(sol), size(t) # Checking sizes","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Optimizer","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Optimizer","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"The optimizers ADAM with a learning rate of 0.01 and BFGS are directly passed in training (see below)","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Callback","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Callback","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"The callback function displays the loss during training. We also keep a history of the loss, the previous predictions and the previous parameters with LOSS, PRED and PARS accumulators.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"LOSS  = []                              # Loss accumulator\nPRED  = []                              # prediction accumulator\nPARS  = []                              # parameters accumulator\n\ncb = function (θ,l,pred) #callback function to observe training\n  display(l)\n  append!(PRED, [pred])\n  append!(LOSS, l)\n  append!(PARS, [θ])\n  false\nend\n\ncb(ps,loss(ps)...) # Testing callback function","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Plotting-Prediction-vs-Ground-Truth","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Plotting Prediction vs Ground Truth","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"The scatter points plotted here are the ground truth obtained from the actual solution we solved for above. The solid line represents our prediction. The goal is for both to overlap almost perfectly when the PDE finishes its training and the loss is close to 0.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"# Let see prediction vs. Truth\nscatter(sol[:,end], label=\"Truth\", size=(800,500))\nplot!(PRED[end][:,end], lw=2, label=\"Prediction\")","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Train","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Train","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"The parameters are trained using sciml_train and adjoint sensitivities. The resulting best parameters are stored in res and res.u returns the parameters that minimizes the cost function.","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"res = DiffEqFlux.sciml_train(loss, ps, cb = cb)\n@show res.u # returns [0.999999999613485, 0.9999999991343996]","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"We successfully predict the final ps to be equal to [0.999999999999975, 1.0000000000000213] vs the true solution of p = [1.0, 1.0]","category":"page"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/#Expected-Output","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Expected Output","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/pde_fitting/pde_constrained/","page":"Partial Differential Equation (PDE) Constrained Optimization","title":"Partial Differential Equation (PDE) Constrained Optimization","text":"153.74716386883014\n153.74716386883014\n150.31001476832154\n146.91327105278128\n143.55759898759374\n140.24363496931753\n136.97198347241257\n133.7432151677673\n130.55786524987215\n127.4164319720337\n124.31937540894337\n121.26711645161134\n118.26003603654628\n115.29847461603427\n112.3827318609633\n109.51306659138356\n106.68969692777314\n103.9128006498965\n101.18251574195561\n98.4989411191655\n95.8621374998964\n93.27212842357801\n90.7289013677808\n88.23240896985287\n85.7825703121191\n83.37927225399383\n81.02237079935475\n78.71169247246975\n76.44703568540336\n74.22817209335733\n72.05484791455291\n69.92678520204167\n67.84368308185877\n65.80521891873633\n63.81104944163126\n61.860811797059554\n59.95412455791812\n58.090588663826914\n56.26978832428055\n54.491291863817686\n52.75465253618253\n51.05940929392087\n49.405087540342564\n47.79119984816457\n46.217246667009626\n44.68271701552145\n43.18708916553295\n41.729831330086824\n40.310402328506555\n38.928252289762675\n37.58282331100446\n36.27355015737786\n34.99986094007708\n33.76117780641769\n32.55691762379305\n31.386492661205562\n30.249311268822595\n29.144778544729924\n28.07229699202965\n27.031267166855155\n26.0210883069299\n25.041158938495613\n24.09087747422764\n23.169642780270983\n22.276854715336583\n21.411914664407295\n20.57422602075309\n19.76319467338999\n18.978229434706996\n18.218742481097735\n17.48414972880479\n16.773871221320032\n16.087331469276343\n15.423959781047255\n14.78319057598673\n14.164463661389682\n13.567224508247984\n12.990924508800399\n12.435021204904853\n11.898978515303417\n11.382266943971572\n10.884363779196345\n10.404753276294088\n9.942926832732251\n9.49838314770057\n9.070628379941386\n8.659176278010788\n8.263548334737965\n7.883273889583058\n7.517890250788576\n7.1669427976429585\n6.829985075319055\n6.506578881124348\n6.19629433688754\n5.898709957062298\n5.613412692266443\n5.339997993203038\n5.078069839645422\n4.827240754206443\n4.587131834698446\n4.357372763056912\n4.357372763056912\n4.137601774726927\n1.5254536025963588\n0.0023707487489687726\n4.933077457357198e-7\n8.157805551380282e-14\n1.6648677430325974e-16\nres.u = [0.999999999999975, 1.0000000000000213]\n2-element Array{Float64,1}:\n 0.999999999999975\n 1.0000000000000213","category":"page"},{"location":"copies/Surrogates/randomforest/#Random-forests-surrogate-tutorial","page":"RandomForest","title":"Random forests surrogate tutorial","text":"","category":"section"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"note: Note\nThis surrogate requires the 'SurrogatesRandomForest' module which can be added by inputting \"]add SurrogatesRandomForest\" from the Julia command line. ","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"Random forests is a supervised learning algorithm that randomly creates and merges multiple decision trees into one forest.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"We are going to use a Random forests surrogate to optimize f(x)=sin(x)+sin(103 * x).","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"First of all import Surrogates and Plots.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"using Surrogates\nusing SurrogatesRandomForest\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/randomforest/#Sampling","page":"RandomForest","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"We choose to sample f in 4 points between 0 and 1 using the sample function. The sampling points are chosen using a Sobol sequence, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"f(x) = sin(x) + sin(10/3 * x)\nn_samples = 5\nlower_bound = 2.7\nupper_bound = 7.5\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\ny = f.(x)\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound))\nplot!(f, label=\"True function\", xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/randomforest/#Building-a-surrogate","page":"RandomForest","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"With our sampled points we can build the Random forests surrogate using the RandomForestSurrogate function.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"randomforest_surrogate behaves like an ordinary function which we can simply plot. Addtionally you can specify the number of trees created using the parameter num_round","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"num_round = 2\nrandomforest_surrogate = RandomForestSurrogate(x ,y ,lower_bound, upper_bound, num_round = 2)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\nplot!(randomforest_surrogate, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/randomforest/#Optimizing","page":"RandomForest","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"Having built a surrogate, we can now use it to search for minimas in our original function f.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"To optimize using our surrogate we call surrogate_optimize method. We choose to use Stochastic RBF as optimization technique and again Sobol sampling as sampling technique.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"@show surrogate_optimize(f, SRBF(), lower_bound, upper_bound, randomforest_surrogate, SobolSample())\nscatter(x, y, label=\"Sampled points\")\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\nplot!(randomforest_surrogate, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/randomforest/#Random-Forest-ND","page":"RandomForest","title":"Random Forest ND","text":"","category":"section"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"First of all we will define the Bukin Function N. 6 function we are going to build surrogate for.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"using Plots # hide\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\nusing Surrogates # hide\n\nfunction bukin6(x)\n    x1=x[1]\n    x2=x[2]\n    term1 = 100 * sqrt(abs(x2 - 0.01*x1^2));\n    term2 = 0.01 * abs(x1+10);\n    y = term1 + term2;\nend","category":"page"},{"location":"copies/Surrogates/randomforest/#Sampling-2","page":"RandomForest","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension x to have bounds -5, 10, and 0, 15 for the second dimension. We are taking 50 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"n_samples = 50\nlower_bound = [-5.0, 0.0]\nupper_bound = [10.0, 15.0]\n\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\nzs = bukin6.(xys);","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"x, y = -5:10, 0:15 # hide\np1 = surface(x, y, (x1,x2) -> bukin6((x1,x2))) # hide\nxs = [xy[1] for xy in xys] # hide\nys = [xy[2] for xy in xys] # hide\nscatter!(xs, ys, zs) # hide\np2 = contour(x, y, (x1,x2) -> bukin6((x1,x2))) # hide\nscatter!(xs, ys) # hide\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/randomforest/#Building-a-surrogate-2","page":"RandomForest","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"Using the sampled points we build the surrogate, the steps are analogous to the 1-dimensional case.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"using SurrogatesRandomForest\nRandomForest = RandomForestSurrogate(xys, zs,  lower_bound, upper_bound)","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"p1 = surface(x, y, (x, y) -> RandomForest([x y])) # hide\nscatter!(xs, ys, zs, marker_z=zs) # hide\np2 = contour(x, y, (x, y) -> RandomForest([x y])) # hide\nscatter!(xs, ys, marker_z=zs) # hide\nplot(p1, p2, title=\"Surrogate\") # hide","category":"page"},{"location":"copies/Surrogates/randomforest/#Optimizing-2","page":"RandomForest","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"With our surrogate we can now search for the minimas of the function.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"Notice how the new sampled points, which were created during the optimization process, are appended to the xys array. This is why its size changes.","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"surrogate_optimize(bukin6, SRBF(), lower_bound, upper_bound, RandomForest, SobolSample(), maxiters=20)","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/randomforest/","page":"RandomForest","title":"RandomForest","text":"p1 = surface(x, y, (x, y) -> RandomForest([x y])) # hide\nxs = [xy[1] for xy in xys] # hide\nys = [xy[2] for xy in xys] # hide\nzs = bukin6.(xys) # hide\nscatter!(xs, ys, zs, marker_z=zs) # hide\np2 = contour(x, y, (x, y) -> RandomForest([x y])) # hide\nscatter!(xs, ys, marker_z=zs) # hide\nplot(p1, p2) # hide","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/#Parameter-Estimation-for-Stochastic-Differential-Equations-and-Ensembles","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"We can use any DEProblem, which not only includes DAEProblem and DDEProblems, but also stochastic problems. In this case, let's use the generalized maximum likelihood to fit the parameters of an SDE's ensemble evaluation.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"Let's use the same Lotka-Volterra equation as before, but this time add noise:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"pf_func = function (du,u,p,t)\n  du[1] = p[1] * u[1] - p[2] * u[1]*u[2]\n  du[2] = -3 * u[2] + u[1]*u[2]\nend\n\nu0 = [1.0;1.0]\ntspan = (0.0,10.0)\np = [1.5,1.0]\npg_func = function (du,u,p,t)\n  du[1] = 1e-6u[1]\n  du[2] = 1e-6u[2]\nend\nprob = SDEProblem(pf_func,pg_func,u0,tspan,p)\nsol = solve(prob,SRIW1())","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"Now lets generate a dataset from 10,000 solutions of the SDE","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"using RecursiveArrayTools # for VectorOfArray\nt = collect(range(0, stop=10, length=200))\nfunction generate_data(t)\n  sol = solve(prob,SRIW1())\n  randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])\n  data = convert(Array,randomized)\nend\naggregate_data = convert(Array,VectorOfArray([generate_data(t) for i in 1:10000]))","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"Now let's estimate the parameters. Instead of using single runs from the SDE, we will use a EnsembleProblem. This means that it will solve the SDE N times to come up with an approximate probability distribution at each time point and use that in the likelihood estimate.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"monte_prob = EnsembleProblem(prob)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"We use Optim.jl for optimization below","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"obj = build_loss_objective(monte_prob,SOSRI(),L2Loss(t,aggregate_data),\n                                     maxiters=10000,verbose=false,num_monte = 1000,\n                                     parallel_type = :threads)\nresult = Optim.optimize(obj, [1.0,0.5], Optim.BFGS())","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"Parameter Estimation in case of SDE's with a regular L2Loss can have poor accuracy due to only fitting against the mean properties as mentioned in First Differencing.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"Results of Optimization Algorithm\n * Algorithm: BFGS\n * Starting Point: [1.0,0.5]\n * Minimizer: [6.070728870478734,5.113357737345448]\n * Minimum: 1.700440e+03\n * Iterations: 14\n * Convergence: false\n   * |x - x'| ≤ 0.0e+00: false\n     |x - x'| = 1.00e-03\n   * |f(x) - f(x')| ≤ 0.0e+00 |f(x)|: false\n     |f(x) - f(x')| = 1.81e-07 |f(x)|\n   * |g(x)| ≤ 1.0e-08: false\n     |g(x)| = 2.34e+00\n   * Stopped by an increasing objective: true\n   * Reached Maximum Number of Iterations: false\n * Objective Calls: 61\n * Gradient Calls: 61","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"Instead when we use L2Loss with first differencing enabled we get much more accurate estimates.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":" obj = build_loss_objective(monte_prob,SRIW1(),L2Loss(t,data,differ_weight=1.0,data_weight=0.5),maxiters=1000,\n                                  verbose=false,verbose_opt=false,verbose_steps=1,num_monte=50)\nresult = Optim.optimize(obj, [1.0,0.5], Optim.BFGS())\nResults of Optimization Algorithm\n * Algorithm: BFGS\n * Starting Point: [1.0,0.5]\n * Minimizer: [1.5010687426045128,1.0023453619050238]\n * Minimum: 1.166650e-01\n * Iterations: 16\n * Convergence: false\n   * |x - x'| ≤ 0.0e+00: false\n     |x - x'| = 6.84e-09\n   * |f(x) - f(x')| ≤ 0.0e+00 |f(x)|: false\n     |f(x) - f(x')| = 5.85e-06 |f(x)|\n   * |g(x)| ≤ 1.0e-08: false\n     |g(x)| = 1.81e-01\n   * Stopped by an increasing objective: true\n   * Reached Maximum Number of Iterations: false\n * Objective Calls: 118\n * Gradient Calls: 118","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/stochastic_evaluations/","page":"Parameter Estimation for Stochastic Differential Equations and Ensembles","title":"Parameter Estimation for Stochastic Differential Equations and Ensembles","text":"Here, we see that we successfully recovered the drift parameter, and got close to the original noise parameter after searching a two-orders-of-magnitude range.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/#Using-JuMP-with-DiffEqParamEstim","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"JuMP is a domain-specific modeling language for mathematical optimization embedded in Julia.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"using OrdinaryDiffEq, DiffEqParamEstim, JuMP, NLopt, Plots","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"Let's define the Lorenz equation to use as our example","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"function g(du,u,p,t)\n  σ,ρ,β = p\n  x,y,z = u\n  du[1] = dx = σ*(y-x)\n  du[2] = dy = x*(ρ-z) - y\n  du[3] = dz = x*y - β*z\nend","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"Let's get a solution of the system with parameter values σ=10.0 ρ=28.0 β=8/3 to use as our data. We define some convenience functions model_ode (to create an ODEProblem) and solve_model(to obtain solution of the ODEProblem) to use in a custom objective function later.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"u0 = [1.0;0.0;0.0]\nt = 0.0:0.01:1.0\ntspan = (0.0,1.0)\nmodel_ode(p_) = ODEProblem(g, u0, tspan,p_)\nsolve_model(mp_) = OrdinaryDiffEq.solve(model_ode(mp_), Tsit5(),saveat=0.01)\nmock_data = Array(solve_model([10.0,28.0,8/3]))","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"Now we define a custom objective function to pass for optimization to JuMP using the build_loss_objective described above provided by DiffEqParamEstim that defines an objective function for the parameter estimation problem.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"loss_objective(mp_, dat) = build_loss_objective(model_ode(mp_), Tsit5(), L2Loss(t,dat))","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"We create a JuMP model, variables, set the objective function and the choice of optimization algorithm to be used in the JuMP syntax. You can read more about this in JuMP's documentation.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"juobj(args...) = loss_objective(args, mock_data)(args)\njumodel = Model()\nJuMP.register(jumodel, :juobj, 3, juobj, autodiff=true)\n@variables jumodel begin\n    σ,(start=8)\n    ρ,(start=25.0)\n    β,(start=10/3)\nend\n@NLobjective(jumodel, Min, juobj(σ, ρ, β))\nsetsolver(jumodel, NLoptSolver(algorithm=:LD_MMA))","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"Let's call the optimizer to obtain the fitted parameter values.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"sol = JuMP.solve(jumodel)\nbest_mp = getvalue.(getindex.((jumodel,), Symbol.(jumodel.colNames)))","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"Let's compare the solution at the obtained parameter values and our data.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"sol = OrdinaryDiffEq.solve(best_mp |> model_ode, Tsit5())\nplot(getindex.(sol.(t),1))\nscatter!(mock_data, markersize=2)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/jump/","page":"Using JuMP with DiffEqParamEstim","title":"Using JuMP with DiffEqParamEstim","text":"(Image: jumpestimationplot)","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/#Linear-Solve-with-Caching-Interface","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"","category":"section"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"In many cases one may want to cache information that is reused between different linear solves. For example, if one is going to perform:","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"A\\b1\nA\\b2","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"then it would be more efficient to LU-factorize one time and reuse the factorization:","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"lu!(A)\nA\\b1\nA\\b2","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"LinearSolve.jl's caching interface automates this process to use the most efficient means of solving and resolving linear systems. To do this with LinearSolve.jl, you simply init a cache, solve, replace b, and solve again. This looks like:","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"using LinearSolve\n\nn = 4\nA = rand(n,n)\nb1 = rand(n); b2 = rand(n)\nprob = LinearProblem(A, b1)\n\nlinsolve = init(prob)\nsol1 = solve(linsolve)\n\nsol1.u\n#=\n4-element Vector{Float64}:\n -0.9247817429364165\n -0.0972021708185121\n  0.6839050402960025\n  1.8385599677530706\n=#\n\nlinsolve = LinearSolve.set_b(sol1.cache,b2)\nsol2 = solve(linsolve)\n\nsol2.u\n#=\n4-element Vector{Float64}:\n  1.0321556637762768\n  0.49724400693338083\n -1.1696540870182406\n -0.4998342686003478\n=#","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"Then refactorization will occur when a new A is given:","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"A2 = rand(n,n)\nlinsolve = LinearSolve.set_A(sol2.cache,A2)\nsol3 = solve(linsolve)\n\nsol3.u\n#=\n4-element Vector{Float64}:\n -6.793605395935224\n  2.8673042300837466\n  1.1665136934977371\n -0.4097250749016653\n=#","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"The factorization occurs on the first solve, and it stores the factorization in the cache. You can retrieve this cache via sol.cache, which is the same object as the init but updated to know not to re-solve the factorization.","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"The advantage of course with using LinearSolve.jl in this form is that it is efficient while being agnostic to the linear solver. One can easily swap in iterative solvers, sparse solvers, etc. and it will do all of the tricks like caching symbolic factorizations if the sparsity pattern is unchanged.","category":"page"},{"location":"copies/Surrogates/lobachevsky/#Lobachevsky-surrogate-tutorial","page":"Lobachevsky","title":"Lobachevsky surrogate tutorial","text":"","category":"section"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"Lobachevsky splines function is a function that used for univariate and multivariate scattered interpolation. Introduced by Lobachevsky in 1842 to investigate errors in astronomical measurements.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"We are going to use a Lobachevsky surrogate to optimize f(x)=sin(x)+sin(103 * x).","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"First of all import Surrogates and Plots.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/lobachevsky/#Sampling","page":"Lobachevsky","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"We choose to sample f in 4 points between 0 and 4 using the sample function. The sampling points are chosen using a Sobol sequence, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"f(x) = sin(x) + sin(10/3 * x)\nn_samples = 5\nlower_bound = 1.0\nupper_bound = 4.0\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\ny = f.(x)\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound))\nplot!(f, label=\"True function\", xlims=(lower_bound, upper_bound))","category":"page"},{"location":"copies/Surrogates/lobachevsky/#Building-a-surrogate","page":"Lobachevsky","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"With our sampled points we can build the Lobachevsky surrogate using the LobachevskySurrogate function.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"lobachevsky_surrogate behaves like an ordinary function which we can simply plot. Alpha is the shape parameters and n specify how close you want lobachevsky function to radial basis function.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"alpha = 2.0\nn = 6\nlobachevsky_surrogate = LobachevskySurrogate(x, y, lower_bound, upper_bound, alpha = 2.0, n = 6)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound))\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound))\nplot!(lobachevsky_surrogate, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound))","category":"page"},{"location":"copies/Surrogates/lobachevsky/#Optimizing","page":"Lobachevsky","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"Having built a surrogate, we can now use it to search for minimas in our original function f.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"To optimize using our surrogate we call surrogate_optimize method. We choose to use Stochastic RBF as optimization technique and again Sobol sampling as sampling technique.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"@show surrogate_optimize(f, SRBF(), lower_bound, upper_bound, lobachevsky_surrogate, SobolSample())\nscatter(x, y, label=\"Sampled points\")\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound))\nplot!(lobachevsky_surrogate, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound))","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"In the example below, it shows how to use lobachevsky_surrogate for higher dimension problems.","category":"page"},{"location":"copies/Surrogates/lobachevsky/#Lobachevsky-Surrogate-Tutorial-(ND):","page":"Lobachevsky","title":"Lobachevsky Surrogate Tutorial (ND):","text":"","category":"section"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"First of all we will define the Schaffer function we are going to build surrogate for. Notice, one how its argument is a vector of numbers, one for each coordinate, and its output is a scalar.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"using Plots # hide\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\nusing Surrogates # hide\n\nfunction schaffer(x)\n    x1=x[1]\n    x2=x[2]\n    fact1 = x1 ^2;\n    fact2 = x2 ^2;\n    y = fact1 + fact2;\nend","category":"page"},{"location":"copies/Surrogates/lobachevsky/#Sampling-2","page":"Lobachevsky","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension x to have bounds 0, 8, and 0, 8 for the second dimension. We are taking 60 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"n_samples = 60\nlower_bound = [0.0, 0.0]\nupper_bound = [8.0, 8.0]\n\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\nzs = schaffer.(xys);","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"x, y = 0:8, 0:8 # hide\np1 = surface(x, y, (x1,x2) -> schaffer((x1,x2))) # hide\nxs = [xy[1] for xy in xys] # hide\nys = [xy[2] for xy in xys] # hide\nscatter!(xs, ys, zs) # hide\np2 = contour(x, y, (x1,x2) -> schaffer((x1,x2))) # hide\nscatter!(xs, ys) # hide\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/lobachevsky/#Building-a-surrogate-2","page":"Lobachevsky","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"Using the sampled points we build the surrogate, the steps are analogous to the 1-dimensional case.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"Lobachevsky = LobachevskySurrogate(xys, zs,  lower_bound, upper_bound, alpha = [2.4,2.4], n=8)","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"p1 = surface(x, y, (x, y) -> Lobachevsky([x y])) # hide\nscatter!(xs, ys, zs, marker_z=zs) # hide\np2 = contour(x, y, (x, y) -> Lobachevsky([x y])) # hide\nscatter!(xs, ys, marker_z=zs) # hide\nplot(p1, p2, title=\"Surrogate\") # hide","category":"page"},{"location":"copies/Surrogates/lobachevsky/#Optimizing-2","page":"Lobachevsky","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"With our surrogate we can now search for the minimas of the function.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"Notice how the new sampled points, which were created during the optimization process, are appended to the xys array. This is why its size changes.","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"size(Lobachevsky.x)","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"surrogate_optimize(schaffer, SRBF(), lower_bound, upper_bound, Lobachevsky, SobolSample(), maxiters=1, num_new_samples=10)","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"size(Lobachevsky.x)","category":"page"},{"location":"copies/Surrogates/lobachevsky/","page":"Lobachevsky","title":"Lobachevsky","text":"p1 = surface(x, y, (x, y) -> Lobachevsky([x y])) # hide\nxys = Lobachevsky.x # hide\nxs = [i[1] for i in xys] # hide\nys = [i[2] for i in xys] # hide\nzs = schaffer.(xys) # hide\nscatter!(xs, ys, zs, marker_z=zs) # hide\np2 = contour(x, y, (x, y) -> Lobachevsky([x y])) # hide\nscatter!(xs, ys, marker_z=zs) # hide\nplot(p1, p2) # hide","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize/#Automatically-Accelerating-ODEProblem-Code","page":"Automatically Accelerating ODEProblem Code","title":"Automatically Accelerating ODEProblem Code","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize/","page":"Automatically Accelerating ODEProblem Code","title":"Automatically Accelerating ODEProblem Code","text":"For some DEProblem types, automatic tracing functionality is already included via the modelingtoolkitize function. Take, for example, the Robertson ODE defined as an ODEProblem for DifferentialEquations.jl:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize/","page":"Automatically Accelerating ODEProblem Code","title":"Automatically Accelerating ODEProblem Code","text":"using DifferentialEquations, ModelingToolkit\nfunction rober(du,u,p,t)\n  y₁,y₂,y₃ = u\n  k₁,k₂,k₃ = p\n  du[1] = -k₁*y₁+k₃*y₂*y₃\n  du[2] =  k₁*y₁-k₂*y₂^2-k₃*y₂*y₃\n  du[3] =  k₂*y₂^2\n  nothing\nend\nprob = ODEProblem(rober,[1.0,0.0,0.0],(0.0,1e5),(0.04,3e7,1e4))","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize/","page":"Automatically Accelerating ODEProblem Code","title":"Automatically Accelerating ODEProblem Code","text":"If we want to get a symbolic representation, we can simply call modelingtoolkitize on the prob, which will return an ODESystem:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize/","page":"Automatically Accelerating ODEProblem Code","title":"Automatically Accelerating ODEProblem Code","text":"sys = modelingtoolkitize(prob)","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize/","page":"Automatically Accelerating ODEProblem Code","title":"Automatically Accelerating ODEProblem Code","text":"Using this, we can symbolically build the Jacobian and then rebuild the ODEProblem:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/modelingtoolkitize/","page":"Automatically Accelerating ODEProblem Code","title":"Automatically Accelerating ODEProblem Code","text":"prob_jac = ODEProblem(sys,[],(0.0,1e5),jac=true)","category":"page"},{"location":"copies/SciMLBase/#The-SciML-Common-Interface-for-Julia-Equation-Solvers","page":"Home","title":"The SciML Common Interface for Julia Equation Solvers","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The SciML common interface ties together the numerical solvers of the Julia package ecosystem into a single unified interface. It is designed for maximal efficiency and parallelism, while incorporating essential features for large-scale scientific machine learning such as differentiability, composability, and sparsity.","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"This documentation is made to pool together the docs of the various SciML libraries to paint the overarching picture, establish development norms, and document the shared/common functionality.","category":"page"},{"location":"copies/SciMLBase/#Domains-of-SciML","page":"Home","title":"Domains of SciML","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The SciML common interface covers the following domains:","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"Linear systems (LinearProblem)\nDirect methods for dense and sparse\nIterative solvers with preconditioning\nNonlinear Systems (NonlinearProblem)\nSystems of nonlinear equations\nScalar bracketing systems\nIntegrals (quadrature) (QuadratureProblem)\nDifferential Equations\nDiscrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations) (DiscreteProblem)\nOrdinary differential equations (ODEs) (ODEProblem)\nSplit and Partitioned ODEs (Symplectic integrators, IMEX Methods) (SplitODEProblem)\nStochastic ordinary differential equations (SODEs or SDEs) (SDEProblem)\nStochastic differential-algebraic equations (SDAEs) (SDEProblem with mass matrices)\nRandom differential equations (RODEs or RDEs) (RODEProblem)\nDifferential algebraic equations (DAEs) (DAEProblem and ODEProblem with mass matrices)\nDelay differential equations (DDEs) (DDEProblem)\nNeutral, retarded, and algebraic delay differential equations (NDDEs, RDDEs, and DDAEs)\nStochastic delay differential equations (SDDEs) (SDDEProblem)\nExperimental support for stochastic neutral, retarded, and algebraic delay differential equations (SNDDEs, SRDDEs, and SDDAEs)\nMixed discrete and continuous equations (Hybrid Equations, Jump Diffusions) (DEProblems with callbacks)\nOptimization (OptimizationProblem)\nNonlinear (constrained) optimization\n(Stochastic/Delay/Differential-Algebraic) Partial Differential Equations (PDESystem)\nFinite difference and finite volume methods\nInterfaces to finite element methods\nPhysics-Informed Neural Networks (PINNs)\nIntegro-Differential Equations\nFractional Differential Equations","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The SciML common interface also includes ModelingToolkit.jl for defining such systems symbolically, allowing for optimizations like automated generation of parallel code, symbolic simplification, and generation of sparsity patterns.","category":"page"},{"location":"copies/SciMLBase/#Extended-SciML-Domain","page":"Home","title":"Extended SciML Domain","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"In addition to the purely numerical representations of mathematical objects, there are also sets of problem types associated with common mathematical algorithms. These are:","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"Data-driven modeling\nDiscrete-time data-driven dynamical systems (DiscreteDataDrivenProblem)\nContinuous-time data-driven dynamical systems (ContinuousDataDrivenProblem)\nSymbolic regression (DirectDataDrivenProblem)\nUncertainty quantification and expected values (ExpectationProblem)","category":"page"},{"location":"copies/SciMLBase/#Inverse-Problems,-Parameter-Estimation,-and-Structural-Identification","page":"Home","title":"Inverse Problems, Parameter Estimation, and Structural Identification","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"We note that parameter estimation and inverse problems are solved directly on their constituant problem types using tools like DiffEqFlux.jl. Thus for example, there is no ODEInverseProblem, and instead ODEProblem is used to find the parameters p that solve the inverse problem.","category":"page"},{"location":"copies/SciMLBase/#Common-Interface-High-Level","page":"Home","title":"Common Interface High Level","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The SciML interface is common as the usage of arguments is standardized across all of the problem domains. Underlying high level ideas include:","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"All domains use the same interface of defining a SciMLProblem which is then solved via solve(prob,alg;kwargs), where alg is a SciMLAlgorithm. The keyword argument namings are standardized across the organization.\nSciMLProblems are generally defined by a SciMLFunction which can define extra details about a model function, such as its analytical Jacobian, its sparsity patterns and so on.\nThere is an organization-wide method for defining linear and nonlinear solvers used within other solvers, giving maximum control of performance to the user.\nTypes used within the packages are defined by the input types. For example, packages attempt to internally use the type of the initial condition as the type for the state within differential equation solvers.\nsolve calls should be thread-safe and parallel-safe.\ninit(prob,alg;kwargs) returns an iterator which allows for directly iterating over the solution process\nHigh performance is key. Any performance that is not at the top level is considered a bug and should be reported as such.\nAll functions have an in-place and out-of-place form, where the in-place form is made to utilize mutation for high performance on large-scale problems and the out-of-place form is for compatibility with tooling like static arrays and some reverse-mode automatic differentiation systems.","category":"page"},{"location":"copies/SciMLBase/#User-Facing-Solver-Libraries","page":"Home","title":"User-Facing Solver Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"DifferentialEquations.jl\nMulti-package interface of high performance numerical solvers of differential equations\nModelingToolkit.jl\nThe symbolic modeling package which implements the SciML symbolic common interface.\nLinearSolve.jl\nMulti-package interface for specifying linear solvers (direct, sparse, and iterative), along with tools for caching and preconditioners for use in large-scale modeling.\nNonlinearSolve.jl\nHigh performance numerical solving of nonlinear systems.\nQuadrature.jl\nMulti-package interface for high performance, batched, and parallelized  numerical quadrature.\nGalacticOptim.jl\nMulti-package interface for numerical solving of optimization problems.\nNeuralPDE.jl\nPhysics-Informed Neural Network (PINN) package for transforming partial differential equations into optimization problems.\nDiffEqOperators.jl\nAutomated finite difference method (FDM) package for transforming partial differential equations into nonlinear problems and ordinary differential equations.\nDiffEqFlux.jl\nHigh level package for scientific machine learning applications, such as neural and universal differential equations, solving of inverse problems, parameter estimation, nonlinear optimal control, and more.\nDataDrivenDiffEq.jl\nMulti-package interface for data-driven modeling, Koopman dynamic mode decomposition, symbolic regression/sparsification, and automated model discovery.\nDiffEqUncertainty.jl\nExtension to the dynamical modeling tools for performing uncertainty quantification and calculating expectations.","category":"page"},{"location":"copies/SciMLBase/#Interface-Implementation-Libraries","page":"Home","title":"Interface Implementation Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"SciMLBase.jl\nThe core package defining the interface which is consumed by the modeling and solver packages.\nDiffEqBase.jl\nThe core package defining the extended interface which is consumed by the differential equation solver packages.\nDiffEqSensitivity.jl\nA package which pools together the definition of derivative overloads to define the common sensealg automatic differentiation interface.\nDiffEqNoiseProcess.jl\nA package which defines the stochastic AbstractNoiseProcess interface for the SciML ecosystem.\nRecursiveArrayTools.jl\nA package which defines the underlying AbstractVectorOfArray structure used as the output for all time series results.\nArrayInterface.jl\nThe package which defines the extended AbstractArray interface employed throughout the SciML ecosystem.","category":"page"},{"location":"copies/SciMLBase/#Using-Facing-Modeling-Libraries","page":"Home","title":"Using-Facing Modeling Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"There are too many to name here and this will be populated when there is time!","category":"page"},{"location":"copies/SciMLBase/#Flowchart-Example-for-PDE-Constrained-Optimal-Control","page":"Home","title":"Flowchart Example for PDE-Constrained Optimal Control","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The following example showcases how the pieces of the common interface connect to solve a problem that mixes inference, symbolics, and numerics.","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"(Image: )","category":"page"},{"location":"copies/SciMLBase/#External-Binding-Libraries","page":"Home","title":"External Binding Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"diffeqr\nSolving differential equations in R using DifferentialEquations.jl with ModelingToolkit for JIT compilation and GPU-acceleration\ndiffeqpy\nSolving differential equations in Python using DifferentialEquations.jl","category":"page"},{"location":"copies/SciMLBase/#Solver-Libraries","page":"Home","title":"Solver Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"There are too many to name here. Check out the SciML Organization Github Page for details.","category":"page"},{"location":"copies/SciMLBase/#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nJuliaDiffEq on Gitter\nOn the Julia Discourse forums (look for the modelingtoolkit tag\nSee also SciML Community page","category":"page"},{"location":"copies/Surrogates/optimizations/#Optimization-techniques","page":"Optimization","title":"Optimization techniques","text":"","category":"section"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"SRBF","category":"page"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"surrogate_optimize(obj::Function,::SRBF,lb,ub,surr::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)","category":"page"},{"location":"copies/Surrogates/optimizations/#Surrogates.surrogate_optimize-Tuple{Function, SRBF, Any, Any, AbstractSurrogate, SamplingAlgorithm}","page":"Optimization","title":"Surrogates.surrogate_optimize","text":"The main idea is to pick the new evaluations from a set of candidate points where each candidate point is generated as an N(0, sigma^2) distributed perturbation from the current best solution. The value of sigma is modified based on progress and follows the same logic as in many trust region methods: we increase sigma if we make a lot of progress (the surrogate is accurate) and decrease sigma when we aren’t able to make progress (the surrogate model is inaccurate). More details about how sigma is updated is given in the original papers.\n\nAfter generating the candidate points, we predict their objective function value and compute the minimum distance to the previously evaluated point. Let the candidate points be denoted by C and let the function value predictions be s(x_i) and the distance values be d(x_i), both rescaled through a linear transformation to the interval [0,1]. This is done to put the values on the same scale. The next point selected for evaluation is the candidate point x that minimizes the weighted-distance merit function:\n\nmerit(x) = ws(x) + (1-w)(1-d(x))\n\nwhere 0 leq w leq 1. That is, we want a small function value prediction and a large minimum distance from the previously evaluated points. The weight w is commonly cycled between a few values to achieve both exploitation and exploration. When w is close to zero, we do pure exploration, while w close to 1 corresponds to exploitation.\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"LCBS","category":"page"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"surrogate_optimize(obj::Function,::LCBS,lb,ub,krig,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)","category":"page"},{"location":"copies/Surrogates/optimizations/#Surrogates.surrogate_optimize-Tuple{Function, LCBS, Any, Any, Any, SamplingAlgorithm}","page":"Optimization","title":"Surrogates.surrogate_optimize","text":"This is an implementation of Lower Confidence Bound (LCB), a popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to minimize:\n\nLCB(x) = Ex - k * sqrt(Vx)\n\ndefault value k = 2.\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"EI","category":"page"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"surrogate_optimize(obj::Function,::EI,lb,ub,krig,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)","category":"page"},{"location":"copies/Surrogates/optimizations/#Surrogates.surrogate_optimize-Tuple{Function, EI, Any, Any, Any, SamplingAlgorithm}","page":"Optimization","title":"Surrogates.surrogate_optimize","text":"This is an implementation of Expected Improvement (EI), arguably the most popular acquisition function in Bayesian optimization. Under a Gaussian process (GP) prior, the goal is to maximize expected improvement:\n\nEI(x) = Emax(f_best-f(x)0)\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"DYCORS","category":"page"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"surrogate_optimize(obj::Function,::DYCORS,lb,ub,surrn::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)","category":"page"},{"location":"copies/Surrogates/optimizations/#Surrogates.surrogate_optimize-Tuple{Function, DYCORS, Any, Any, AbstractSurrogate, SamplingAlgorithm}","page":"Optimization","title":"Surrogates.surrogate_optimize","text":"  surrogate_optimize(obj::Function,::DYCORS,lb::Number,ub::Number,surr1::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)\n\nThis is an implementation of the DYCORS strategy by Regis and Shoemaker: Rommel G Regis and Christine A Shoemaker. Combining radial basis function surrogates and dynamic coordinate search in high-dimensional expensive black-box optimization. Engineering Optimization, 45(5): 529–555, 2013. This is an extension of the SRBF strategy that changes how the candidate points are generated. The main idea is that many objective functions depend only on a few directions so it may be advantageous to perturb only a few directions. In particular, we use a perturbation probability to perturb a given coordinate and decrease this probability after each function evaluation so fewer coordinates are perturbed later in the optimization.\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"SOP","category":"page"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"surrogate_optimize(obj::Function,sop1::SOP,lb::Number,ub::Number,surrSOP::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=min(500*1,5000))","category":"page"},{"location":"copies/Surrogates/optimizations/#Surrogates.surrogate_optimize-Tuple{Function, SOP, Number, Number, AbstractSurrogate, SamplingAlgorithm}","page":"Optimization","title":"Surrogates.surrogate_optimize","text":"surrogateoptimize(obj::Function,::SOP,lb::Number,ub::Number,surr::AbstractSurrogate,sampletype::SamplingAlgorithm;maxiters=100,numnewsamples=100)\n\nSOP Surrogate optimization method, following closely the following papers:\n\n- SOP: parallel surrogate global optimization with Pareto center selection for computationally expensive single objective problems by Tipaluck Krityakierne\n- Multiobjective Optimization Using Evolutionary Algorithms by Kalyan Deb\n\n#Suggested number of new_samples = min(500*d,5000)\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/optimizations/#Adding-another-optimization-method","page":"Optimization","title":"Adding another optimization method","text":"","category":"section"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"To add another optimization method, you just need to define a new SurrogateOptimizationAlgorithm and write its corresponding algorithm, overloading the following:","category":"page"},{"location":"copies/Surrogates/optimizations/","page":"Optimization","title":"Optimization","text":"surrogate_optimize(obj::Function,::NewOptimizatonType,lb,ub,surr::AbstractSurrogate,sample_type::SamplingAlgorithm;maxiters=100,num_new_samples=100)","category":"page"},{"location":"copies/Optimization/optimization_packages/flux/#Flux.jl","page":"Flux.jl","title":"Flux.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/flux/#Installation:-OptimizationFlux.jl","page":"Flux.jl","title":"Installation: OptimizationFlux.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/flux/","page":"Flux.jl","title":"Flux.jl","text":"To use this package, install the OptimizationFlux package:","category":"page"},{"location":"copies/Optimization/optimization_packages/flux/","page":"Flux.jl","title":"Flux.jl","text":"import Pkg; Pkg.add(\"OptimizationFlux\")","category":"page"},{"location":"copies/Optimization/optimization_packages/flux/#Local-Unconstrained-Optimizers","page":"Flux.jl","title":"Local Unconstrained Optimizers","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/flux/","page":"Flux.jl","title":"Flux.jl","text":"Flux.Optimise.Descent: Classic gradient descent optimizer with learning rate\nsolve(problem, Descent(η))\nη is the learning rate\nDefaults:\nη = 0.1\nFlux.Optimise.Momentum: Classic gradient descent optimizer with learning rate and momentum\nsolve(problem, Momentum(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.01\nρ = 0.9\nFlux.Optimise.Nesterov: Gradient descent optimizer with learning rate and Nesterov momentum\nsolve(problem, Nesterov(η, ρ))\nη is the learning rate\nρ is the Nesterov momentum\nDefaults:\nη = 0.01\nρ = 0.9\nFlux.Optimise.RMSProp: RMSProp optimizer\nsolve(problem, RMSProp(η, ρ))\nη is the learning rate\nρ is the momentum\nDefaults:\nη = 0.001\nρ = 0.9\nFlux.Optimise.ADAM: ADAM optimizer\nsolve(problem, ADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.RADAM: Rectified ADAM optimizer\nsolve(problem, RADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.AdaMax: AdaMax optimizer\nsolve(problem, AdaMax(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.ADAGRad: ADAGrad optimizer\nsolve(problem, ADAGrad(η))\nη is the learning rate\nDefaults:\nη = 0.1\nFlux.Optimise.ADADelta: ADADelta optimizer\nsolve(problem, ADADelta(ρ))\nρ is the gradient decay factor\nDefaults:\nρ = 0.9\nFlux.Optimise.AMSGrad: AMSGrad optimizer\nsolve(problem, AMSGrad(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.NADAM: Nesterov variant of the ADAM optimizer\nsolve(problem, NADAM(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\nFlux.Optimise.ADAMW: ADAMW optimizer\nsolve(problem, ADAMW(η, β::Tuple))\nη is the learning rate\nβ::Tuple is the decay of momentums\ndecay is the decay to weights\nDefaults:\nη = 0.001\nβ::Tuple = (0.9, 0.999)\ndecay = 0","category":"page"},{"location":"copies/DiffEqSensitivity/#DiffEqSensitivity:-Automatic-Differentiation-and-Adjoints-for-(Differential)-Equation-Solvers","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"DiffEqSensitivity.jl is the automatic differentiation and adjoints system for the SciML ecosystem. Also known as local sensitivity analysis, these methods allow for calculation of fast derivatives of SciML problem types which are commonly used to analyze model sensitivities, callibrate models to data, train neural ODEs, perform automated model discovery via universal differential equations, and more. SciMLSensitivity.jl is a high level interface that pulls together all of the tools with heuristics and helper functions to make solving inverse problems and inferring models as easy as possible without losing efficiency.","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Thus, what DiffEqSensitivity.jl provides is:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Automatic differentiation overloads for improving the performance and flexibility of AD calls over solve.\nA bunch of tutorials, documentation, and test cases for this combination with parameter estimation (data fitting / model calibration), neural network  libraries and GPUs.","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"note: Note\nThis documentation assumes familiarity with the solver packages for the respective problem types. If one is not familiar with the solver packages, please consult the documentation for pieces like DifferentialEquations.jl,  NonlinearSolve.jl,  LinearSolve.jl, etc. first.","category":"page"},{"location":"copies/DiffEqSensitivity/#High-Level-Interface:-sensealg","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"High Level Interface: sensealg","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"The highest level interface is provided by the function solve:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"solve(prob,args...;sensealg=InterpolatingAdjoint(),\n      checkpoints=sol.t,kwargs...)","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"solve is fully compatible with automatic differentiation libraries like:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Zygote.jl\nReverseDiff.jl\nTracker.jl\nForwardDiff.jl","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"and will automatically replace any calculations of the solution's derivative with a fast method. The keyword argument sensealg controls the dispatch to the AbstractSensitivityAlgorithm used for the sensitivity calculation. Note that solve in an AD context does not allow higher order interpolations unless sensealg=DiffEqBase.SensitivityADPassThrough() is used, i.e. going back to the AD mechanism.","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"note: Note\nThe behavior of ForwardDiff.jl is different from the other automatic differentiation libraries mentioned above. The sensealg keyword is ignored. Instead, the differential equations are solved using Dual numbers for u0 and p. If only p is perturbed in the sensitivity analysis, but not u0, the state is still implemented as a Dual number. ForwardDiff.jl will thus not dispatch into continuous forward nor adjoint sensitivity analysis even if a sensealg is provided.","category":"page"},{"location":"copies/DiffEqSensitivity/#Equation-Scope","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Equation Scope","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"SciMLSensitivity.jl supports all of the equation types of the  SciML Common Interface, extending the problem types by adding overloads for automatic differentiation to improve the performance and flexibility of the differentiation system. This includes:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Linear systems (LinearProblem)\nDirect methods for dense and sparse\nIterative solvers with preconditioning\nNonlinear Systems (NonlinearProblem)\nSystems of nonlinear equations\nScalar bracketing systems\nIntegrals (quadrature) (QuadratureProblem)\nDifferential Equations\nDiscrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations) (DiscreteProblem)\nOrdinary differential equations (ODEs) (ODEProblem)\nSplit and Partitioned ODEs (Symplectic integrators, IMEX Methods) (SplitODEProblem)\nStochastic ordinary differential equations (SODEs or SDEs) (SDEProblem)\nStochastic differential-algebraic equations (SDAEs) (SDEProblem with mass matrices)\nRandom differential equations (RODEs or RDEs) (RODEProblem)\nDifferential algebraic equations (DAEs) (DAEProblem and ODEProblem with mass matrices)\nDelay differential equations (DDEs) (DDEProblem)\nNeutral, retarded, and algebraic delay differential equations (NDDEs, RDDEs, and DDAEs)\nStochastic delay differential equations (SDDEs) (SDDEProblem)\nExperimental support for stochastic neutral, retarded, and algebraic delay differential equations (SNDDEs, SRDDEs, and SDDAEs)\nMixed discrete and continuous equations (Hybrid Equations, Jump Diffusions) (DEProblems with callbacks)\nOptimization (OptimizationProblem)\nNonlinear (constrained) optimization\n(Stochastic/Delay/Differential-Algebraic) Partial Differential Equations (PDESystem)\nFinite difference and finite volume methods\nInterfaces to finite element methods\nPhysics-Informed Neural Networks (PINNs)\nIntegro-Differential Equations\nFractional Differential Equations","category":"page"},{"location":"copies/DiffEqSensitivity/#SciMLSensitivity-and-Universal-Differential-Equations","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"SciMLSensitivity and Universal Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"SciMLSensitivity is for universal differential equations, where these can include delays, physical constraints, stochasticity, events, and all other kinds of interesting behavior that shows up in scientific simulations. Neural networks can be all or part of the model. They can be around the differential equation, in the cost function, or inside of the differential equation. Neural networks representing unknown portions of the model or functions can go anywhere you have uncertainty in the form of the scientific simulator. Forward sensitivity and adjoint equations are automatically generated with checkpointing and stabilization to ensure it works for large stiff equations, while specializations on static objects allows for high efficiency on small equations. For an overview of the topic with applications, consult the paper Universal Differential Equations for Scientific Machine Learning.","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"You can efficiently use the package for:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Parameter estimation of scientific models (ODEs, SDEs, DDEs, DAEs, etc.)\nNeural ODEs, Neural SDE, Neural DAEs, Neural DDEs, etc.\nNonlinear optimal control, including training neural controllers\n(Stiff) universal ordinary differential equations (universal ODEs)\nUniversal stochastic differential equations (universal SDEs)\nUniversal delay differential equations (universal DDEs)\nUniversal partial differential equations (universal PDEs)\nUniversal jump stochastic differential equations (universal jump diffusions)\nHybrid universal differential equations (universal DEs with event handling)","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"with high order, adaptive, implicit, GPU-accelerated, Newton-Krylov, etc. methods. For examples, please refer to the DiffEqFlux release blog post (which we try to keep updated for changes to the libraries). Additional demonstrations, like neural PDEs and neural jump SDEs, can be found at this blog post (among many others!). All of these features are only part of the advantage, as this library routinely benchmarks orders of magnitude faster than competing libraries like torchdiffeq. Use with GPUs is highly optimized by recompiling the solvers to GPUs to remove all CPU-GPU data transfers, while use with CPUs uses specialized kernels for accelerating differential equation solves.","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Many different training techniques are supported by this package, including:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Optimize-then-discretize (backsolve adjoints, checkpointed adjoints, quadrature adjoints)\nDiscretize-then-optimize (forward and reverse mode discrete sensitivity analysis)\nThis is a generalization of ANODE and ANODEv2 to all DifferentialEquations.jl ODE solvers\nHybrid approaches (adaptive time stepping + AD for adaptive discretize-then-optimize)\nO(1) memory backprop of ODEs via BacksolveAdjoint, and Virtual Brownian Trees for O(1) backprop of SDEs\nContinuous adjoints for integral loss functions\nProbabilistic programming and variational inference on ODEs/SDEs/DAEs/DDEs/hybrid equations etc. is provided by integration with Turing.jl and Gen.jl. Reproduce variational loss functions by plugging composible libraries together.","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"all while mixing forward mode and reverse mode approaches as appropriate for the most speed. For more details on the adjoint sensitivity analysis methods for computing fast gradients, see the adjoints details page.","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"With this package, you can explore various ways to integrate the two methodologies:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Neural networks can be defined where the “activations” are nonlinear functions described by differential equations\nNeural networks can be defined where some layers are ODE solves\nODEs can be defined where some terms are neural networks\nCost functions on ODEs can define neural networks","category":"page"},{"location":"copies/DiffEqSensitivity/#Note-on-Modularity-and-Composability-with-Solvers","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Note on Modularity and Composability with Solvers","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Note that DiffEqSensitivity.jl purely built on composable and modular infrastructure.  DiffEqSensitivity provides high level helper functions and documentation for the user, but the code generation stack is modular and composes in many different ways. For example, one can use and swap out the ODE solver between any common interface compatible library, like:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"Sundials.jl\nOrdinaryDiffEq.jl\nLSODA.jl\nIRKGaussLegendre.jl\nSciPyDiffEq.jl\n... etc. many other choices!","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"In addition, due to the composability of the system, none of the components are directly tied to the Flux.jl machine learning framework. For example, you can use DiffEqSensitivity.jl to generate TensorFlow graphs and train the neural network with TensorFlow.jl, use PyTorch arrays via Torch.jl, and more all with single line code changes by utilizing the underlying code generation. The tutorials shown here are thus mostly a guide on how to use the ecosystem as a whole, only showing a small snippet of the possible ways to compose the thousands of differentiable libraries together! Swap out ODEs for SDEs, DDEs, DAEs, etc., put quadrature libraries or  Tullio.jl in the loss function, the world is your  oyster!","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"As a proof of composability, note that the implementation of Bayesian neural ODEs required zero code changes to the library, and instead just relied on the composability with other Julia packages.","category":"page"},{"location":"copies/DiffEqSensitivity/#Citation","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"Citation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"If you use DiffEqSensitivity.jl or are influenced by its ideas, please cite:","category":"page"},{"location":"copies/DiffEqSensitivity/","page":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","title":"DiffEqSensitivity.jl: Automatic Differentiation and Adjoints for (Differential) Equation Solvers","text":"@article{rackauckas2020universal,\n  title={Universal differential equations for scientific machine learning},\n  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},\n  journal={arXiv preprint arXiv:2001.04385},\n  year={2020}\n}","category":"page"},{"location":"copies/Optimization/API/solve/#Common-Solver-Options-(Solve-Keyword-Arguments)","page":"solve","title":"Common Solver Options (Solve Keyword Arguments)","text":"","category":"section"},{"location":"copies/Optimization/API/solve/","page":"solve","title":"solve","text":"solve(::OptimizationProblem,::Any)","category":"page"},{"location":"copies/Optimization/API/solve/#CommonSolve.solve-Tuple{OptimizationProblem, Any}","page":"solve","title":"CommonSolve.solve","text":"solve(prob::OptimizationProblem, alg::AbstractOptimizationAlgorithm; kwargs...)\n\nKeyword Arguments\n\nThe arguments to solve are common across all of the optimizers. These common arguments are:\n\nmaxiters (the maximum number of iterations)\nmaxtime (the maximum of time the optimization runs for)\nabstol (absolute tolerance in changes of the objective value)\nreltol (relative tolerance  in changes of the objective value)\ncallback (a callback function)\n\nIf the chosen global optimzer employs a local optimization method a similiar set of common local optimizer arguments exists. The common local optimizer arguments are:\n\nlocal_method (optimiser used for local optimization in global method)\nlocal_maxiters (the maximum number of iterations)\nlocal_maxtime (the maximum of time the optimization runs for)\nlocal_abstol (absolute tolerance in changes of the objective value)\nlocal_reltol (relative tolerance  in changes of the objective value)\nlocal_options (NamedTuple of keyword arguments for local optimizer)\n\nSome optimizer algorithms have special keyword arguments documented in the solver portion of the documentation and their respective documentation. These arguments can be passed as kwargs... to solve. Similiarly, the special kewyword arguments for the local_method of a global optimizer are passed as a NamedTuple to local_options.\n\nOver time we hope to cover more of these keyword arguments under the common interface.\n\nIf a common argument is not implemented for a optimizer a warning will be shown.  \n\nCallback Functions\n\nThe callback function callback is a function which is called after every optimizer step. Its signature is:\n\ncallback = (x,other_args) -> false\n\nwhere other_args is are the extra return arguments of the optimization f. For example, if f(x,p) = 5x, then callback = (x) -> ... is used. If f(x,p) = 5x,55x, then = (x,extra) -> ... is used, where extra = 55x. This allows for saving values from the optimization and using them for plotting and display without recalculating. The callback should return a Boolean value, and the default  should be false, such that the optimization gets stopped if it returns true.\n\n\n\n\n\n","category":"method"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/#Bouncing-Ball-Hybrid-ODE-Optimization","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"The bouncing ball is a classic hybrid ODE which can be represented in the DifferentialEquations.jl event handling system. This can be applied to ODEs, SDEs, DAEs, DDEs, and more. Let's now add the DiffEqFlux machinery to this problem in order to optimize the friction that's required to match data. Assume we have data for the ball's height after 15 seconds. Let's first start by implementing the ODE:","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"using DiffEqFlux, DifferentialEquations\n\nfunction f(du,u,p,t)\n  du[1] = u[2]\n  du[2] = -p[1]\nend\n\nfunction condition(u,t,integrator) # Event when event_f(u,t) == 0\n  u[1]\nend\n\nfunction affect!(integrator)\n  integrator.u[2] = -integrator.p[2]*integrator.u[2]\nend\n\ncb = ContinuousCallback(condition,affect!)\nu0 = [50.0,0.0]\ntspan = (0.0,15.0)\np = [9.8, 0.8]\nprob = ODEProblem(f,u0,tspan,p)\nsol = solve(prob,Tsit5(),callback=cb)","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"Here we have a friction coefficient of 0.8. We want to refine this coefficient to find the value so that the predicted height of the ball at the endpoint is 20. We do this by minimizing a loss function against the value 20:","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"function loss(θ)\n  sol = solve(prob,Tsit5(),p=[9.8,θ[1]],callback=cb)\n  target = 20.0\n  abs2(sol[end][1] - target)\nend\n\nloss([0.8])\n@time res = DiffEqFlux.sciml_train(loss,[0.8])\n@show res.u # [0.866554105436901]","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"This runs in about 0.091215 seconds (533.45 k allocations: 80.717 MiB) and finds an optimal drag coefficient.","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/#Note-on-Sensitivity-Methods","page":"Bouncing Ball Hybrid ODE Optimization","title":"Note on Sensitivity Methods","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"The continuous adjoint sensitivities BacksolveAdjoint, InterpolatingAdjoint, and QuadratureAdjoint are compatible with events for ODEs. BacksolveAdjoint and InterpolatingAdjoint can also handle events for SDEs. Use BacksolveAdjoint if the event terminates the time evolution and several states are saved. Currently, the continuous adjoint sensitivities do not support multiple events per time point.","category":"page"},{"location":"copies/DiffEqSensitivity/hybrid_jump_fitting/bouncing_ball/","page":"Bouncing Ball Hybrid ODE Optimization","title":"Bouncing Ball Hybrid ODE Optimization","text":"All methods based on discrete sensitivity analysis via automatic differentiation, like ReverseDiffAdjoint, TrackerAdjoint, or ForwardDiffSensitivity are the methods to use (and ReverseDiffAdjoint is demonstrated above), are compatible with events. This applies to SDEs, DAEs, and DDEs as well.","category":"page"},{"location":"copies/LinearSolve/#LinearSolve.jl:-High-Performance-Unified-Linear-Solvers","page":"Home","title":"LinearSolve.jl: High-Performance Unified Linear Solvers","text":"","category":"section"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"LinearSolve.jl is a unified interface for the linear solving packages of Julia. It interfaces with other packages of the Julia ecosystem to make it easy to test alternative solver packages and pass small types to control algorithm swapping. It also interfaces with the ModelingToolkit.jl world of symbolic modeling to allow for automatically generating high-performance code.","category":"page"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"Performance is key: the current methods are made to be highly performant on scalar and statically sized small problems, with options for large-scale systems. If you run into any performance issues, please file an issue.","category":"page"},{"location":"copies/LinearSolve/#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"To install LinearSolve.jl, use the Julia package manager:","category":"page"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"LinearSolve\")","category":"page"},{"location":"copies/LinearSolve/#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to ModelingToolkit.\nThere are a few community forums:\nthe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\non the Julia Discourse forums\nsee also SciML Community page","category":"page"},{"location":"copies/LinearSolve/#Roadmap","page":"Home","title":"Roadmap","text":"","category":"section"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"Wrappers for every linear solver in the Julia language is on the roadmap. If there are any important ones that are missing that you would like to see added, please open an issue. The current algorithms should support automatic differentiation. Pre-defined preconditioners would be a welcome addition.","category":"page"},{"location":"copies/GlobalSensitivity/methods/rbdfast/#Random-Balance-Design-FAST-Method","page":"Random Balance Design FAST Method","title":"Random Balance Design FAST Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/rbdfast/","page":"Random Balance Design FAST Method","title":"Random Balance Design FAST Method","text":"struct RBDFAST <: GSAMethod  \n    num_harmonics::Int\nend","category":"page"},{"location":"copies/GlobalSensitivity/methods/rbdfast/","page":"Random Balance Design FAST Method","title":"Random Balance Design FAST Method","text":"RBDFAST has the following keyword arguments:","category":"page"},{"location":"copies/GlobalSensitivity/methods/rbdfast/","page":"Random Balance Design FAST Method","title":"Random Balance Design FAST Method","text":"num_harmonics: Number of harmonics to consider during power spectral density analysis.","category":"page"},{"location":"copies/GlobalSensitivity/methods/rbdfast/#Method-Details","page":"Random Balance Design FAST Method","title":"Method Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/rbdfast/","page":"Random Balance Design FAST Method","title":"Random Balance Design FAST Method","text":"In the Random Balance Designs (RBD) method, similar to eFAST,  N points are selected over a curve in the input space. A fixed frequency  equal to 1 is used for each factor. Then independent random  permutations are applied to the coordinates of the N points in order to  generate the design points. The input model for analysis is evaluated  at each design point and the outputs are reordered such that the design  points are in increasing order with respect to factor Xi. The Fourier  spectrum is calculated on the model output at the frequency 1 and at  its higher harmonics (2, 3, 4, 5, 6) and yields the estimate of the  sensitivity index of factor Xi.","category":"page"},{"location":"copies/GlobalSensitivity/methods/rbdfast/#API","page":"Random Balance Design FAST Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/rbdfast/","page":"Random Balance Design FAST Method","title":"Random Balance Design FAST Method","text":"function gsa(f, method::RBDFAST; num_params, N, rng::AbstractRNG = Random.default_rng(), batch = false, kwargs...)","category":"page"},{"location":"copies/GlobalSensitivity/methods/rbdfast/#Example","page":"Random Balance Design FAST Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/rbdfast/","page":"Random Balance Design FAST Method","title":"Random Balance Design FAST Method","text":"function linear_batch(X)\n    A= 7\n    B= 0.1\n    @. A*X[1,:]+B*X[2,:]\nend\nfunction linear(X)\n    A= 7\n    B= 0.1\n    A*X[1]+B*X[2]\nend\n\nlb = -ones(4)*π\nub = ones(4)*π\n\nrng = StableRNG(123)\nres1 = gsa(linear,GlobalSensitivity.RBDFAST(),num_params = 4, N=15000)\nres2 = gsa(linear_batch,GlobalSensitivity.RBDFAST(),num_params = 4, batch=true, N=15000)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/#Parameter-Identifiability-in-ODE-Models","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"Ordinary differential equations are commonly used for modeling real-world processes. The problem of parameter identifiability is one of the key design challenges for mathematical models. A parameter is said to be identifiable if one can recover its value from experimental data. Structural identifiability is a theoretical property of a model that answers this question. In this tutorial, we will show how to use StructuralIdentifiability.jl with ModelingToolkit.jl to assess identifiability of parameters in ODE models. The theory behind StructuralIdentifiability.jl is presented in paper [4].","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"We will start by illustrating local identifiability in which a parameter is known up to finitely many values, and then proceed to determining global identifiability, that is, which parameters can be identified uniquely.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"To install StructuralIdentifiability.jl, simply run","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"using Pkg\nPkg.add(\"StructuralIdentifiability\")","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"The package has a standalone data structure for ordinary differential equations but is also compatible with ODESystem type from ModelingToolkit.jl.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/#Local-Identifiability","page":"Parameter Identifiability in ODE Models","title":"Local Identifiability","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/#Input-System","page":"Parameter Identifiability in ODE Models","title":"Input System","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"We will consider the following model:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"begincases\nfracdx_4dt = - frack_5 x_4k_6 + x_4\nfracdx_5dt = frack_5 x_4k_6 + x_4 - frack_7 x_5(k_8 + x_5 + x_6)\nfracdx_6dt = frack_7 x_5(k_8 + x_5 + x_6) - frack_9  x_6  (k_10 - x_6) k_10\nfracdx_7dt = frack_9  x_6  (k_10 - x_6) k_10\ny_1 = x_4\ny_2 = x_5endcases","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"This model describes the biohydrogenation[1] process[2] with unknown initial conditions.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/#Using-the-ODESystem-object","page":"Parameter Identifiability in ODE Models","title":"Using the ODESystem object","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"To define the ode system in Julia, we use ModelingToolkit.jl.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"We first define the parameters, variables, differential equations and the output equations.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"using StructuralIdentifiability, ModelingToolkit\n\n# define parameters and variables\n@variables t x4(t) x5(t) x6(t) x7(t) y1(t) y2(t)\n@parameters k5 k6 k7 k8 k9 k10\nD = Differential(t)\n\n# define equations\neqs = [\n    D(x4) ~ - k5 * x4 / (k6 + x4),\n    D(x5) ~ k5 * x4 / (k6 + x4) - k7 * x5/(k8 + x5 + x6),\n    D(x6) ~ k7 * x5 / (k8 + x5 + x6) - k9 * x6 * (k10 - x6) / k10,\n    D(x7) ~ k9 * x6 * (k10 - x6) / k10\n]\n\n# define the output functions (quantities that can be measured)\nmeasured_quantities = [y1 ~ x4, y2 ~ x5]\n\n# define the system\nde = ODESystem(eqs, t, name=:Biohydrogenation)\n","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"After that we are ready to check the system for local identifiability:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"# query local identifiability\n# we pass the ode-system\nlocal_id_all = assess_local_identifiability(de, measured_quantities=measured_quantities, p=0.99)\n                # [ Info: Preproccessing `ModelingToolkit.ODESystem` object\n                # 6-element Vector{Bool}:\n                #  1\n                #  1\n                #  1\n                #  1\n                #  1\n                #  1","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"We can see that all states (except x_7) and all parameters are locally identifiable with probability 0.99. ","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"Let's try to check specific parameters and their combinations","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"to_check = [k5, k7, k10/k9, k5+k6]\nlocal_id_some = assess_local_identifiability(de, measured_quantities=measured_quantities, funcs_to_check=to_check, p=0.99)\n                # 4-element Vector{Bool}:\n                #  1\n                #  1\n                #  1\n                #  1","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"Notice that in this case, everything (except the state variable x_7) is locally identifiable, including combinations such as k_10k_9 k_5+k_6","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/#Global-Identifiability","page":"Parameter Identifiability in ODE Models","title":"Global Identifiability","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"In this part tutorial, let us cover an example problem of querying the ODE for globally identifiable parameters.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/#Input-System-2","page":"Parameter Identifiability in ODE Models","title":"Input System","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"Let us consider the following four-dimensional model with two outputs:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"begincases\n    x_1(t) = -b  x_1(t) + frac1  c + x_4(t)\n    x_2(t) = alpha  x_1(t) - beta  x_2(t)\n    x_3(t) = gamma  x_2(t) - delta  x_3(t)\n    x_4(t) = sigma  x_4(t)  frac(gamma x_2(t) - delta x_3(t)) x_3(t)\n    y(t) = x_1(t)\nendcases","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"We will run a global identifiability check on this enzyme dynamics[3] model. We will use the default settings: the probability of correctness will be p=0.99 and we are interested in identifiability of all possible parameters","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"Global identifiability needs information about local identifiability first, but the function we chose here will take care of that extra step for us.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"Note: as of writing this tutorial, UTF-symbols such as Greek characters are not supported by one of the project's dependencies, see this issue.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"using StructuralIdentifiability, ModelingToolkit\n@parameters b c a beta g delta sigma\n@variables t x1(t) x2(t) x3(t) x4(t) y(t) y2(t)\nD = Differential(t)\n\neqs = [\n    D(x1) ~ -b * x1 + 1/(c + x4),\n    D(x2) ~ a * x1 - beta * x2,\n    D(x3) ~ g * x2 - delta * x3,\n    D(x4) ~ sigma * x4 * (g * x2 - delta * x3)/x3\n]\n\nmeasured_quantities = [y~x1+x2, y2~x2]\n\n\node = ODESystem(eqs, t, name=:GoodwinOsc)\n\n@time global_id = assess_identifiability(ode, measured_quantities=measured_quantities)\n                    # 30.672594 seconds (100.97 M allocations: 6.219 GiB, 3.15% gc time, 0.01% compilation time)\n                    # Dict{Num, Symbol} with 7 entries:\n                    #   a     => :globally\n                    #   b     => :globally\n                    #   beta  => :globally\n                    #   c     => :globally\n                    #   sigma => :globally\n                    #   g     => :nonidentifiable\n                    #   delta => :globally","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"We can see that only parameters a, g are unidentifiable and everything else can be uniquely recovered.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"Let us consider the same system but with two inputs and we will try to find out identifiability with probability 0.9 for parameters c and b:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"using StructuralIdentifiability, ModelingToolkit\n@parameters b c a beta g delta sigma\n@variables t x1(t) x2(t) x3(t) x4(t) y(t) u1(t) [input=true] u2(t) [input=true]\nD = Differential(t)\n\neqs = [\n    D(x1) ~ -b * x1 + 1/(c + x4),\n    D(x2) ~ a * x1 - beta * x2 - u1,\n    D(x3) ~ g * x2 - delta * x3 + u2,\n    D(x4) ~ sigma * x4 * (g * x2 - delta * x3)/x3\n]\nmeasured_quantities = [y~x1+x2, y2~x2]\n\n# check only 2 parameters\nto_check = [b, c]\n\node = ODESystem(eqs, t, name=:GoodwinOsc)\n\nglobal_id = assess_identifiability(ode, measured_quantities=measured_quantities, funcs_to_check=to_check, p=0.9)\n            # Dict{Num, Symbol} with 2 entries:\n            #   b => :globally\n            #   c => :globally","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"Both parameters b, c are globally identifiable with probability 0.9 in this case.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"[1]: R. Munoz-Tamayo, L. Puillet, J.B. Daniel, D. Sauvant, O. Martin, M. Taghipoor, P. Blavy Review: To be or not to be an identifiable model. Is this a relevant question in animal science modelling?, Animal, Vol 12 (4), 701-712, 2018. The model is the ODE system (3) in Supplementary Material 2, initial conditions are assumed to be unknown.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"[2]: Moate P.J., Boston R.C., Jenkins T.C. and Lean I.J., Kinetics of Ruminal Lipolysis of Triacylglycerol and Biohydrogenationof Long-Chain Fatty Acids: New Insights from Old Data, Journal of Dairy Science 91, 731–742, 2008","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"[3]: Goodwin, B.C. Oscillatory behavior in enzymatic control processes, Advances in Enzyme Regulation, Vol 3 (C), 425-437, 1965","category":"page"},{"location":"copies/ModelingToolkit/tutorials/parameter_identifiability/","page":"Parameter Identifiability in ODE Models","title":"Parameter Identifiability in ODE Models","text":"[4]: Dong, R., Goodbrake, C., Harrington, H. A., & Pogudin, G. Computing input-output projections of dynamical models with applications to structural identifiability. arXiv preprint arXiv:2111.00991.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/#continuous_loss","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"The automatic differentiation tutorial demonstrated how to use AD packages like ForwardDiff.jl and Zygote.jl to compute derivatives of differential equation solutions with respect to initial conditions and parameters. The subsequent direct sensitivity analysis tutorial showed how to directly use the SciMLSensitivity.jl internals to define and solve the augmented differential equation systems which are used in the automatic differentiation process. ","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"While these internal functions give more flexibility, the previous demonstration focused on a case which was possible via automatic differentiation: discrete cost functionals. What is meant by discrete cost functionals is differentiation of a cost which uses a finite  number of time points. In the automatic differentiation case, these finite time points are the points returned by solve, i.e. those chosen by the saveat option in the solve call. In the direct adjoint sensitivity tooling, these were the time points chosen by the ts vector.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"However, there is an expanded set of cost functionals supported by SciMLSensitivity.jl, continuous cost functionals, which are not possible through automatic differentiation interfaces. In an abstract sense, a continuous cost functional is a total cost G defined as the integral of the instantanious cost g at all time points. In other words, the total cost is defined as:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"G(up)=G(u(cdotp))=int_t_0^Tg(u(tp)p)dt","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Notice that this cost function cannot accurately be computed using only estimates of u at discrete time points. The purpose of this tutorial is to demonstrate how such cost functionals can be easily evaluated using the direct sensitivity analysis interfaces.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/#Example:-Continuous-Functionals-with-Forward-Sensitivity-Analysis-via-Interpolation","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Example: Continuous Functionals with Forward Sensitivity Analysis via Interpolation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Evaluating continuous cost functionals with forward sensitivity analysis is rather straightforward since one can simply use the fact that the solution from ODEForwardSensitivityProblem is continuous when dense=true. For example,","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"function f(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + u[1]*u[2]\nend\n\np = [1.5,1.0,3.0]\nprob = ODEForwardSensitivityProblem(f,[1.0;1.0],(0.0,10.0),p)\nsol = solve(prob,DP8())","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"gives a continuous solution sol(t) with the derivative at each time point. This can then be used to define a continuous cost function via  Quadrature.jl, though the derivative would need to be defined by hand using the extra sensitivity terms.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/#Example:-Continuous-Adjoints-on-an-Energy-Functional","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Example: Continuous Adjoints on an Energy Functional","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Continuous adjoints on a continuous functional are more automatic than forward mode. In this case we'd like to calculate the adjoint sensitivity of the scalar energy functional:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"G(up)=int_0^Tfracsum_i=1^nu_i^2(t)2dt","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"which is:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"g(u,p,t) = (sum(u).^2) ./ 2","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Notice that the gradient of this function with respect to the state u is:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"function dg(out,u,p,t)\n  out[1]= u[1] + u[2]\n  out[2]= u[1] + u[2]\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"To get the adjoint sensitivities, we call:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"res = adjoint_sensitivities(sol,Vern9(),g,nothing,dg,abstol=1e-8,\n                                 reltol=1e-8,iabstol=1e-8,ireltol=1e-8)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"Notice that we can check this against autodifferentiation and numerical differentiation as follows:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/adjoint_continuous_functional/","page":"Adjoint Sensitivity Analysis of Continuous Functionals","title":"Adjoint Sensitivity Analysis of Continuous Functionals","text":"using QuadGK\nfunction G(p)\n  tmp_prob = remake(prob,p=p)\n  sol = solve(tmp_prob,Vern9(),abstol=1e-14,reltol=1e-14)\n  res,err = quadgk((t)-> (sum(sol(t)).^2)./2,0.0,10.0,atol=1e-14,rtol=1e-10)\n  res\nend\nres2 = ForwardDiff.gradient(G,[1.5,1.0,3.0])\nres3 = Calculus.gradient(G,[1.5,1.0,3.0])","category":"page"},{"location":"copies/DiffEqParamEstim/methods/collocation_loss/#Two-Stage-method-(Non-Parametric-Collocation)","page":"Two Stage method (Non-Parametric Collocation)","title":"Two Stage method (Non-Parametric Collocation)","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/collocation_loss/","page":"Two Stage method (Non-Parametric Collocation)","title":"Two Stage method (Non-Parametric Collocation)","text":"The two-stage method is a collocation method for estimating parameters without requiring repeated solving of the differential equation. It does so by determining a smoothed estimated trajectory of the data (local quadratic polynomial fit by least squares) and optimizing the derivative function and the data's timepoints to match the derivatives of the smoothed trajectory. This method has less accuracy than other methods but is much faster, and is a good method to try first to get in the general \"good parameter\" region, to then finish using one of the other methods.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/collocation_loss/","page":"Two Stage method (Non-Parametric Collocation)","title":"Two Stage method (Non-Parametric Collocation)","text":"function two_stage_method(prob::DEProblem,tpoints,data;kernel= :Epanechnikov,\n                          loss_func = L2DistLoss,mpg_autodiff = false,\n                          verbose = false,verbose_steps = 100)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/#Alternative-Objective-Functions","page":"Alternative Objective Functions","title":"Alternative Objective Functions","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/","page":"Alternative Objective Functions","title":"Alternative Objective Functions","text":"These are objective functions made to be used with special fitting packages.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/#LeastSquaresOptim.jl-objective","page":"Alternative Objective Functions","title":"LeastSquaresOptim.jl objective","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/","page":"Alternative Objective Functions","title":"Alternative Objective Functions","text":"build_lsoptim_objective builds an objective function to be used with LeastSquaresOptim.jl.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/","page":"Alternative Objective Functions","title":"Alternative Objective Functions","text":"build_lsoptim_objective(prob,tspan,t,data;\n                        prob_generator = (prob,p) -> remake(prob,u0=convert.(eltype(p),prob.u0),p=p),\n                        kwargs...)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/","page":"Alternative Objective Functions","title":"Alternative Objective Functions","text":"The arguments are the same as build_loss_objective.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/#lm_fit","page":"Alternative Objective Functions","title":"lm_fit","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/","page":"Alternative Objective Functions","title":"Alternative Objective Functions","text":"lm_fit is a function for fitting the parameters of an ODE using the Levenberg-Marquardt algorithm. This algorithm is really bad and thus not recommended since, for example, the Optim.jl algorithms on an L2 loss are more performant and robust. However, this is provided for completeness as most other differential equation libraries use an LM-based algorithm, so this allows one to test the increased effectiveness of not using LM.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/","page":"Alternative Objective Functions","title":"Alternative Objective Functions","text":"lm_fit(prob::DEProblem,tspan,t,data,p0;\n       prob_generator = (prob,p) -> remake(prob,u0=convert.(eltype(p),prob.u0),p=p),\n       kwargs...)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/alternative_objectives/","page":"Alternative Objective Functions","title":"Alternative Objective Functions","text":"The arguments are similar to before, but with p0 being the initial conditions for the parameters and the kwargs as the args passed to the LsqFit curve_fit function (which is used for the LM solver). This returns the fitted parameters.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Augmented-Neural-Ordinary-Differential-Equations","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Copy-Pasteable-Code","page":"Augmented Neural Ordinary Differential Equations","title":"Copy-Pasteable Code","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"using DiffEqFlux, DifferentialEquations\nusing Statistics, LinearAlgebra, Plots\nusing Flux.Data: DataLoader\n\nfunction random_point_in_sphere(dim, min_radius, max_radius)\n    distance = (max_radius - min_radius) .* (rand(1) .^ (1.0 / dim)) .+ min_radius\n    direction = randn(dim)\n    unit_direction = direction ./ norm(direction)\n    return distance .* unit_direction\nend\n\nfunction concentric_sphere(dim, inner_radius_range, outer_radius_range,\n                           num_samples_inner, num_samples_outer; batch_size = 64)\n    data = []\n    labels = []\n    for _ in 1:num_samples_inner\n        push!(data, reshape(random_point_in_sphere(dim, inner_radius_range...), :, 1))\n        push!(labels, ones(1, 1))\n    end\n    for _ in 1:num_samples_outer\n        push!(data, reshape(random_point_in_sphere(dim, outer_radius_range...), :, 1))\n        push!(labels, -ones(1, 1))\n    end\n    data = cat(data..., dims=2)\n    labels = cat(labels..., dims=2)\n    return DataLoader((data |> gpu, labels |> gpu); batchsize=batch_size, shuffle=true,\n                      partial=false)\nend\n\ndiffeqarray_to_array(x) = reshape(gpu(x), size(x)[1:2])\n\nfunction construct_model(out_dim, input_dim, hidden_dim, augment_dim)\n    input_dim = input_dim + augment_dim\n    node = NeuralODE(Chain(Dense(input_dim, hidden_dim, relu),\n                           Dense(hidden_dim, hidden_dim, relu),\n                           Dense(hidden_dim, input_dim)) |> gpu,\n                     (0.f0, 1.f0), Tsit5(), save_everystep = false,\n                     reltol = 1e-3, abstol = 1e-3, save_start = false) |> gpu\n    node = augment_dim == 0 ? node : AugmentedNDELayer(node, augment_dim)\n    return Chain((x, p=node.p) -> node(x, p),\n                 diffeqarray_to_array,\n                 Dense(input_dim, out_dim) |> gpu), node.p |> gpu\nend\n\nfunction plot_contour(model, npoints = 300)\n    grid_points = zeros(2, npoints ^ 2)\n    idx = 1\n    x = range(-4.0, 4.0, length = npoints)\n    y = range(-4.0, 4.0, length = npoints)\n    for x1 in x, x2 in y\n        grid_points[:, idx] .= [x1, x2]\n        idx += 1\n    end\n    sol = reshape(model(grid_points |> gpu), npoints, npoints) |> cpu\n\n    return contour(x, y, sol, fill = true, linewidth=0.0)\nend\n\nloss_node(x, y) = mean((model(x) .- y) .^ 2)\n\nprintln(\"Generating Dataset\")\n\ndataloader = concentric_sphere(2, (0.0, 2.0), (3.0, 4.0), 2000, 2000; batch_size = 256)\n\ncb = function()\n    global iter += 1\n    if iter % 10 == 0\n        println(\"Iteration $iter || Loss = $(loss_node(dataloader.data[1], dataloader.data[2]))\")\n    end\nend\n\nmodel, parameters = construct_model(1, 2, 64, 0)\nopt = ADAM(0.005)\niter = 0\n\nprintln(\"Training Neural ODE\")\n\nfor _ in 1:10\n    Flux.train!(loss_node, Flux.params([parameters, model]), dataloader, opt, cb = cb)\nend\n\nplt_node = plot_contour(model)\n\nmodel, parameters = construct_model(1, 2, 64, 1)\nopt = ADAM(0.005)\niter = 0\n\nprintln()\nprintln(\"Training Augmented Neural ODE\")\n\nfor _ in 1:10\n    Flux.train!(loss_node, Flux.params([parameters, model]), dataloader, opt, cb = cb)\nend\n\nplt_anode = plot_contour(model)","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Step-by-Step-Explanation","page":"Augmented Neural Ordinary Differential Equations","title":"Step-by-Step Explanation","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Loading-required-packages","page":"Augmented Neural Ordinary Differential Equations","title":"Loading required packages","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"using DiffEqFlux, DifferentialEquations\nusing Statistics, LinearAlgebra, Plots\nusing Flux.Data: DataLoader","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Generating-a-toy-dataset","page":"Augmented Neural Ordinary Differential Equations","title":"Generating a toy dataset","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"In this example, we will be using data sampled uniformly in two concentric circles and then train our Neural ODEs to do regression on that values. We assign 1 to any point which lies inside the inner circle, and -1 to any point which lies between the inner and outer circle. Our first function random_point_in_sphere samples points uniformly between 2 concentric circles/spheres of radii min_radius and max_radius respectively.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"function random_point_in_sphere(dim, min_radius, max_radius)\n    distance = (max_radius - min_radius) .* (rand(1) .^ (1.0 / dim)) .+ min_radius\n    direction = randn(dim)\n    unit_direction = direction ./ norm(direction)\n    return distance .* unit_direction\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"Next, we will construct a dataset of these points and use Flux's DataLoader to automatically minibatch and shuffle the data.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"function concentric_sphere(dim, inner_radius_range, outer_radius_range,\n                           num_samples_inner, num_samples_outer; batch_size = 64)\n    data = []\n    labels = []\n    for _ in 1:num_samples_inner\n        push!(data, reshape(random_point_in_sphere(dim, inner_radius_range...), :, 1))\n        push!(labels, ones(1, 1))\n    end\n    for _ in 1:num_samples_outer\n        push!(data, reshape(random_point_in_sphere(dim, outer_radius_range...), :, 1))\n        push!(labels, -ones(1, 1))\n    end\n    data = cat(data..., dims=2)\n    labels = cat(labels..., dims=2)\n    return DataLoader(data |> gpu, labels |> gpu; batchsize=batch_size, shuffle=true,\n                      partial=false)\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Models","page":"Augmented Neural Ordinary Differential Equations","title":"Models","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"We consider 2 models in this tutorial. The first is a simple Neural ODE which is described in detail in this tutorial. The other one is an Augmented Neural ODE [1]. The idea behind this layer is very simple. It augments the input to the Neural DE Layer by appending zeros. So in order to use any arbitrary DE Layer in combination with this layer, simply assume that the input to the DE Layer is of size size(x, 1) + augment_dim instead of size(x, 1) and construct that layer accordingly.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"In order to run the models on GPU, we need to manually transfer the models to GPU. First one is the network predicting the derivatives inside the Neural ODE and the other one is the last layer in the Chain.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"diffeqarray_to_array(x) = reshape(gpu(x), size(x)[1:2])\n\nfunction construct_model(out_dim, input_dim, hidden_dim, augment_dim)\n    input_dim = input_dim + augment_dim\n    node = NeuralODE(Chain(Dense(input_dim, hidden_dim, relu),\n                           Dense(hidden_dim, hidden_dim, relu),\n                           Dense(hidden_dim, input_dim)) |> gpu,\n                     (0.f0, 1.f0), Tsit5(), save_everystep = false,\n                     reltol = 1e-3, abstol = 1e-3, save_start = false) |> gpu\n    node = augment_dim == 0 ? node : (AugmentedNDELayer(node, augment_dim) |> gpu)\n    return Chain((x, p=node.p) -> node(x, p),\n                 diffeqarray_to_array,\n                 Dense(input_dim, out_dim) |> gpu), node.p |> gpu\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Plotting-the-Results","page":"Augmented Neural Ordinary Differential Equations","title":"Plotting the Results","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"Here, we define an utility to plot our model regression results as a heatmap.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"function plot_contour(model, npoints = 300)\n    grid_points = zeros(2, npoints ^ 2)\n    idx = 1\n    x = range(-4.0, 4.0, length = npoints)\n    y = range(-4.0, 4.0, length = npoints)\n    for x1 in x, x2 in y\n        grid_points[:, idx] .= [x1, x2]\n        idx += 1\n    end\n    sol = reshape(model(grid_points |> gpu), npoints, npoints) |> cpu\n\n    return contour(x, y, sol, fill = true, linewidth=0.0)\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Training-Parameters","page":"Augmented Neural Ordinary Differential Equations","title":"Training Parameters","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Loss-Functions","page":"Augmented Neural Ordinary Differential Equations","title":"Loss Functions","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"We use the L2 distance between the model prediction model(x) and the actual prediction y as the optimization objective.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"loss_node(x, y) = mean((model(x) .- y) .^ 2)","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Dataset","page":"Augmented Neural Ordinary Differential Equations","title":"Dataset","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"Next, we generate the dataset. We restrict ourselves to 2 dimensions as it is easy to visualize. We sample a total of 4000 data points.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"dataloader = concentric_sphere(2, (0.0, 2.0), (3.0, 4.0), 2000, 2000; batch_size = 256)","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Callback-Function","page":"Augmented Neural Ordinary Differential Equations","title":"Callback Function","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"Additionally we define a callback function which displays the total loss at specific intervals.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"cb = function()\n    global iter += 1\n    if iter % 10 == 1\n        println(\"Iteration $iter || Loss = $(loss_node(dataloader.data[1], dataloader.data[2]))\")\n    end\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Optimizer","page":"Augmented Neural Ordinary Differential Equations","title":"Optimizer","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"We use ADAM as the optimizer with a learning rate of 0.005","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"opt = ADAM(0.005)","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Training-the-Neural-ODE","page":"Augmented Neural Ordinary Differential Equations","title":"Training the Neural ODE","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"To train our neural ode model, we need to pass the appropriate learnable parameters, parameters which is returned by the construct_models function. It is simply the node.p vector. We then train our model for 20 epochs.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"model, parameters = construct_model(1, 2, 64, 0)\n\nfor _ in 1:10\n    Flux.train!(loss_node, Flux.params([model, parameters]), dataloader, opt, cb = cb)\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"Here is what the contour plot should look for Neural ODE. Notice that the regression is not perfect due to the thin artifact which connects the circles.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"(Image: node)","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Training-the-Augmented-Neural-ODE","page":"Augmented Neural Ordinary Differential Equations","title":"Training the Augmented Neural ODE","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"Our training configuration will be same as that of Neural ODE. Only in this case we have augmented the input with a single zero. This makes the problem 3 dimensional and as such it is possible to find a function which can be expressed by the neural ode. For more details and proofs please refer to [1].","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"model, parameters = construct_model(1, 2, 64, 1)\n\nfor _ in 1:10\n    Flux.train!(loss_node, Flux.params([model, parameters]), dataloader, opt, cb = cb)\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"For the augmented Neural ODE we notice that the artifact is gone.","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"(Image: anode)","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#Expected-Output","page":"Augmented Neural Ordinary Differential Equations","title":"Expected Output","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"Generating Dataset\nTraining Neural ODE\nIteration 10 || Loss = 0.9802582\nIteration 20 || Loss = 0.6727416\nIteration 30 || Loss = 0.5862373\nIteration 40 || Loss = 0.5278132\nIteration 50 || Loss = 0.4867624\nIteration 60 || Loss = 0.41630346\nIteration 70 || Loss = 0.3325938\nIteration 80 || Loss = 0.28235924\nIteration 90 || Loss = 0.24069068\nIteration 100 || Loss = 0.20503852\nIteration 110 || Loss = 0.17608969\nIteration 120 || Loss = 0.1491399\nIteration 130 || Loss = 0.12711425\nIteration 140 || Loss = 0.10686825\nIteration 150 || Loss = 0.089558244\n\nTraining Augmented Neural ODE\nIteration 10 || Loss = 1.3911372\nIteration 20 || Loss = 0.7694144\nIteration 30 || Loss = 0.5639633\nIteration 40 || Loss = 0.33187616\nIteration 50 || Loss = 0.14787851\nIteration 60 || Loss = 0.094676435\nIteration 70 || Loss = 0.07363529\nIteration 80 || Loss = 0.060333826\nIteration 90 || Loss = 0.04998395\nIteration 100 || Loss = 0.044843454\nIteration 110 || Loss = 0.042587914\nIteration 120 || Loss = 0.042706195\nIteration 130 || Loss = 0.040252227\nIteration 140 || Loss = 0.037686247\nIteration 150 || Loss = 0.036247417","category":"page"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/#References","page":"Augmented Neural Ordinary Differential Equations","title":"References","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/augmented_neural_ode/","page":"Augmented Neural Ordinary Differential Equations","title":"Augmented Neural Ordinary Differential Equations","text":"[1] Dupont, Emilien, Arnaud Doucet, and Yee Whye Teh. \"Augmented neural ODEs.\" In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 3140-3150. 2019.","category":"page"},{"location":"copies/DiffEqFlux/utilities/MultipleShooting/#Multiple-Shooting-Functionality","page":"Multiple Shooting Functionality","title":"Multiple Shooting Functionality","text":"","category":"section"},{"location":"copies/DiffEqFlux/utilities/MultipleShooting/","page":"Multiple Shooting Functionality","title":"Multiple Shooting Functionality","text":"multiple_shoot","category":"page"},{"location":"copies/DiffEqFlux/utilities/MultipleShooting/#DiffEqFlux.multiple_shoot","page":"Multiple Shooting Functionality","title":"DiffEqFlux.multiple_shoot","text":"Returns a total loss after trying a 'Direct multiple shooting' on ODE data and an array of predictions from each of the groups (smaller intervals). In Direct Multiple Shooting, the Neural Network divides the interval into smaller intervals and solves for them separately. The default continuity term is 100, implying any losses arising from the non-continuity of 2 different groups will be scaled by 100.\n\nmultiple_shoot(p, ode_data, tsteps, prob, loss_function, solver, group_size;\n               continuity_term=100, kwargs...)\nmultiple_shoot(p, ode_data, tsteps, prob, loss_function, continuity_loss, solver, group_size;\n               continuity_term=100, kwargs...)\n\nArguments:\n\np: The parameters of the Neural Network to be trained.\node_data: Original Data to be modelled.\ntsteps: Timesteps on which ode_data was calculated.\nprob: ODE problem that the Neural Network attempts to solve.\nloss_function: Any arbitrary function to calculate loss.\ncontinuity_loss: Function that takes states hatu_end of group k and\n\nu_0 of group k+1 as input and calculates prediction continuity loss   between them.   If no custom continuity_loss is specified, sum(abs, û_end - u_0) is used.\n\nsolver: ODE Solver algorithm.\ngroup_size: The group size achieved after splitting the ode_data into equal sizes.\ncontinuity_term: Weight term to ensure continuity of predictions throughout different groups.\nkwargs: Additional arguments splatted to the ODE solver. Refer to the\n\nLocal Sensitivity Analysis and   Common Solver Arguments   documentation for more details. Note: The parameter 'continuity_term' should be a relatively big number to enforce a large penalty whenever the last point of any group doesn't coincide with the first point of next group.\n\n\n\n\n\nReturns a total loss after trying a 'Direct multiple shooting' on ODE data and an array of predictions from each of the groups (smaller intervals). In Direct Multiple Shooting, the Neural Network divides the interval into smaller intervals and solves for them separately. The default continuity term is 100, implying any losses arising from the non-continuity of 2 different groups will be scaled by 100.\n\nmultiple_shoot(p, ode_data_ensemble, tsteps, ensemble_prob, ensemble_alg, loss_function, solver,\n                group_size; continuity_term=100, trajectories)\nmultiple_shoot(p, ode_data_ensemble, tsteps, ensemble_prob, ensemble_alg, loss_function,\n                continuity_loss, solver, group_size; continuity_term=100, trajectories)\n\nArguments:\n\np: The parameters of the Neural Network to be trained.\node_data_ensemble: Original Data to be modelled. Batches (or equivalently \"trajectories\") are located in the third dimension.\ntsteps: Timesteps on which ode_data_ensemble was calculated.\nensemble_prob: Ensemble problem that the Neural Network attempts to solve.\nensemble_alg: Ensemble algorithm, e.g. EnsembleThreads()\nloss_function: Any arbitrary function to calculate loss.\ncontinuity_loss: Function that takes states hatu_end of group k and\n\nu_0 of group k+1 as input and calculates prediction continuity loss   between them.   If no custom continuity_loss is specified, sum(abs, û_end - u_0) is used.\n\nsolver: ODE Solver algorithm.\ngroup_size: The group size achieved after splitting the ode_data into equal sizes.\ncontinuity_term: Weight term to ensure continuity of predictions throughout\n\ndifferent groups.\n\ntrajectories: number of trajectories for ensemble_prob.\nkwargs: Additional arguments splatted to the ODE solver. Refer to the\n\nLocal Sensitivity Analysis and   Common Solver Arguments   documentation for more details. Note: The parameter 'continuity_term' should be a relatively big number to enforce a large penalty whenever the last point of any group doesn't coincide with the first point of next group.\n\n\n\n\n\n","category":"function"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/#Global-Optimization-via-NLopt","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"The build_loss_objective function builds an objective function which is able to be used with MathOptInterface-associated solvers. This includes packages like IPOPT, NLopt, MOSEK, etc. Building off of the previous example, we can build a cost function for the single parameter optimization problem like:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"function f(du,u,p,t)\n  dx = p[1]*u[1] - u[1]*u[2]\n  dy = -3*u[2] + u[1]*u[2]\nend\n\nu0 = [1.0;1.0]\ntspan = (0.0,10.0)\np = [1.5]\nprob = ODEProblem(f,u0,tspan,p)\nsol = solve(prob,Tsit5())\n\nt = collect(range(0,stop=10,length=200))\nrandomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])\ndata = convert(Array,randomized)\n\nobj = build_loss_objective(prob,Tsit5(),L2Loss(t,data),maxiters=10000)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"We can now use this obj as the objective function with MathProgBase solvers. For our example, we will use NLopt. To use the local derivative-free Constrained Optimization BY Linear Approximations algorithm, we can simply do:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"using NLopt\nopt = Opt(:LN_COBYLA, 1)\nmin_objective!(opt, obj)\n(minf,minx,ret) = NLopt.optimize(opt,[1.3])","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"This finds a minimum at [1.49997]. For a modified evolutionary algorithm, we can use:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"opt = Opt(:GN_ESCH, 1)\nmin_objective!(opt, obj)\nlower_bounds!(opt,[0.0])\nupper_bounds!(opt,[5.0])\nxtol_rel!(opt,1e-3)\nmaxeval!(opt, 100000)\n(minf,minx,ret) = NLopt.optimize(opt,[1.3])","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"We can even use things like the Improved Stochastic Ranking Evolution Strategy (and add constraints if needed). This is done via:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"opt = Opt(:GN_ISRES, 1)\nmin_objective!(opt, obj.cost_function2)\nlower_bounds!(opt,[-1.0])\nupper_bounds!(opt,[5.0])\nxtol_rel!(opt,1e-3)\nmaxeval!(opt, 100000)\n(minf,minx,ret) = NLopt.optimize(opt,[0.2])","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"which is very robust to the initial condition. The fastest result comes from the following:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"using NLopt\nopt = Opt(:LN_BOBYQA, 1)\nmin_objective!(opt, obj)\n(minf,minx,ret) = NLopt.optimize(opt,[1.3])","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/global_optimization/","page":"Global Optimization via NLopt","title":"Global Optimization via NLopt","text":"For more information, see the NLopt documentation for more details. And give IPOPT or MOSEK a try!","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkit-Standard-Library:-Mechanical-Components","page":"Mechanical Components","title":"ModelingToolkit Standard Library: Mechanical Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#Rotational-Components","page":"Mechanical Components","title":"Rotational Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/","page":"Mechanical Components","title":"Mechanical Components","text":"CurrentModule = ModelingToolkitStandardLibrary.Mechanical.Rotational","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#Rotational-Utils","page":"Mechanical Components","title":"Rotational Utils","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/","page":"Mechanical Components","title":"Mechanical Components","text":"Flange\nSupport\nPartialCompliantWithRelativeStates\nPartialElementaryOneFlangeAndSupport2\nPartialElementaryTwoFlangesAndSupport2\nPartialCompliant","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.Flange","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.Flange","text":"Flange(;name)\n\n1-dim. rotational flange of a shaft.\n\nStates:\n\nphi: [rad] Absolute rotation angle of flange\ntau: [N.m] Cut torque in the flange\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.Support","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.Support","text":"Support(;name)\n\nSupport/housing of a 1-dim. rotational shaft\n\nStates:\n\nphi: [rad] Absolute rotation angle of the support/housing\ntau: [N.m] Cut torque in the support/housing\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.PartialCompliantWithRelativeStates","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.PartialCompliantWithRelativeStates","text":"PartialCompliantWithRelativeStates(;name, phi_rel_start=0.0, tau_start=0.0)\n\nPartial model for the compliant connection of two rotational 1-dim. shaft flanges where the relative angle and speed are used as preferred states\n\nParameters:\n\nphi_rel_start: [rad] Initial relative rotation angle\nw_rel_start: [rad/s] Initial relative angular velocity (= der(phi_rel))\na_rel_start: [rad/s²] Initial relative angular acceleration (= der(w_rel))\ntau_start: [N.m] Initial torque between flanges\n\nStates:\n\nphi_rel: [rad] Relative rotation angle (= flangeb.phi - flangea.phi)\nw_rel: [rad/s] Relative angular velocity (= der(phi_rel))\na_rel: [rad/s²] Relative angular acceleration (= der(w_rel))\ntau: [N.m] Torque between flanges (= flange_b.tau)\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.PartialElementaryOneFlangeAndSupport2","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.PartialElementaryOneFlangeAndSupport2","text":"PartialElementaryOneFlangeAndSupport2(;name, use_support=false)\n\nPartial model for a component with one rotational 1-dim. shaft flange and a support used for textual modeling, i.e., for elementary models\n\nParameters:\n\nuse_support: If support flange enabled, otherwise implicitly grounded\n\nStates:\n\nphi_support: [rad] Absolute angle of support flange\"\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.PartialElementaryTwoFlangesAndSupport2","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.PartialElementaryTwoFlangesAndSupport2","text":"PartialElementaryTwoFlangesAndSupport2(;name, use_support=false)\n\nPartial model for a component with two rotational 1-dim. shaft flanges and a support used for textual modeling, i.e., for elementary models\n\nParameters:\n\nuse_support: If support flange enabled, otherwise implicitly grounded\n\nStates:\n\nphi_support: [rad] Absolute angle of support flange\"\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.PartialCompliant","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.PartialCompliant","text":"PartialCompliant(;name, phi_rel_start=0.0, tau_start=0.0)\n\nPartial model for the compliant connection of two rotational 1-dim. shaft flanges.\n\nParameters:\n\nphi_rel_start: [rad] Initial relative rotation angle\ntau_start: [N.m] Initial torque between flanges\n\nStates:\n\nphi_rel: [rad] Relative rotation angle (= flangeb.phi - flangea.phi)\ntau: [N.m] Torque between flanges (= flange_b.tau)\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#Rotational-Core-Components","page":"Mechanical Components","title":"Rotational Core Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/","page":"Mechanical Components","title":"Mechanical Components","text":"Fixed\nInertia\nSpring\nDamper\nIdealGear","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.Fixed","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.Fixed","text":"Fixed(;name, phi0=0.0)\n\nFlange fixed in housing at a given angle.\n\nParameters:\n\nphi0: [rad] Fixed offset angle of housing\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.Inertia","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.Inertia","text":"Inertia(;name, J, phi_start=0.0, w_start=0.0, a_start=0.0)\n\n1D-rotational component with inertia.\n\nParameters:\n\nJ: [kg·m²] Moment of inertia \nphi_start: [rad] Initial value of absolute rotation angle of component \nw_start: [rad/s] Initial value of absolute angular velocity of component\na_start: [rad/s²] Initial value of absolute angular acceleration of component\n\nStates:\n\nphi: [rad] Absolute rotation angle of component \nw: [rad/s] Absolute angular velocity of component (= der(phi)) \na: [rad/s²] Absolute angular acceleration of component (= der(w)) \n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.Spring","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.Spring","text":"Spring(;name, c, phi_rel0=0.0)\n\nLinear 1D rotational spring\n\nParameters:\n\nc: [N.m/rad] Spring constant\nphi_rel0: Unstretched spring angle\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.Damper","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.Damper","text":"Damper(;name, d)\n\nLinear 1D rotational damper\n\nParameters:\n\nd: [N.m.s/rad] Damping constant\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.IdealGear","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.IdealGear","text":"IdealGear(;name, ratio, use_support=false)\n\nIdeal gear without inertia.\n\nThis element characterizes any type of gear box which is fixed in the ground and which has one driving shaft and one driven shaft.\n\nParameters:\n\nratio: Transmission ratio (flangea.phi/flangeb.phi)\nuse_support: If support flange enabled, otherwise implicitly grounded\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#Rotational-Sources","page":"Mechanical Components","title":"Rotational Sources","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/","page":"Mechanical Components","title":"Mechanical Components","text":"Torque","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/mechanical/#ModelingToolkitStandardLibrary.Mechanical.Rotational.Torque","page":"Mechanical Components","title":"ModelingToolkitStandardLibrary.Mechanical.Rotational.Torque","text":"Torque(;name)\n\nInput signal acting as external torque on a flange\n\n\n\n\n\n","category":"function"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/#Neural-Ordinary-Differential-Equations-with-GalacticOptim.jl","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"DiffEqFlux.jl defines sciml_train which is a high level utility that automates a lot of the choices, using heuristics to determine a potentially efficient method. However, in some cases you may want more control over the optimization process. The underlying optimization package behind sciml_train is GalacticOptim.jl. In this tutorial we will show how to more deeply interact with the optimization library to tweak its processes.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"We can use a neural ODE as our example. A neural ODE is an ODE where a neural network defines its derivative function. Thus for example, with the multilayer perceptron neural network FastChain(FastDense(2, 50, tanh), FastDense(50, 2)), we obtain  the following results.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/#Copy-Pasteable-Code","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Copy-Pasteable Code","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"Before getting to the explanation, here's some code to start with. We will follow a full explanation of the definition and training process:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"using DiffEqFlux, DifferentialEquations, Plots, GalacticOptim, GalacticFlux, GalacticOptimJL\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\n\nfunction predict_neuralode(p)\n  Array(prob_neuralode(u0, p))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, ode_data .- pred)\n    return loss, pred\nend\n\ncallback = function (p, l, pred; doplot = true)\n  display(l)\n  # plot current prediction against data\n  plt = scatter(tsteps, ode_data[1,:], label = \"data\")\n  scatter!(plt, tsteps, pred[1,:], label = \"prediction\")\n  if doplot\n    display(plot(plt))\n  end\n  return false\nend\n\n# use GalacticOptim.jl to solve the problem\nadtype = GalacticOptim.AutoZygote()\n\noptf = GalacticOptim.OptimizationFunction(loss_neuralode, adtype)\noptprob = GalacticOptim.OptimizationProblem(optfunc, prob_neuralode.p)\n\nresult_neuralode = GalacticOptim.solve(optprob,\n                                       ADAM(0.05),\n                                       cb = callback,\n                                       maxiters = 300)\n\noptprob2 = remake(optprob,u0 = result_neuralode.u)\n\nresult_neuralode2 = GalacticOptim.solve(optprob2,\n                                        LBFGS(),\n                                        cb = callback,\n                                        allow_f_increases = false)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"(Image: Neural ODE)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/#Explanation","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Explanation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"Let's get a time series array from the Lotka-Volterra equation as data:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"using DiffEqFlux, DifferentialEquations, Plots\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"Now let's define a neural network with a NeuralODE layer. First we define the layer. Here we're going to use FastChain, which is a faster neural network structure for NeuralODEs:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"dudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"Note that we can directly use Chains from Flux.jl as well, for example:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"dudt2 = Chain(x -> x.^3,\n              Dense(2, 50, tanh),\n              Dense(50, 2))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"In our model we used the x -> x.^3 assumption in the model. By incorporating structure into our equations, we can reduce the required size and training time for the neural network, but a good guess needs to be known!","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"From here we build a loss function around it. The NeuralODE has an optional second argument for new parameters which we will use to iteratively change the neural network in our training loop. We will use the L2 loss of the network's output against the time series data:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"function predict_neuralode(p)\n  Array(prob_neuralode(u0, p))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, ode_data .- pred)\n    return loss, pred\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"We define a callback function.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"# Callback function to observe training\ncallback = function (p, l, pred; doplot = false)\n  display(l)\n  # plot current prediction against data\n  plt = scatter(tsteps, ode_data[1,:], label = \"data\")\n  scatter!(plt, tsteps, pred[1,:], label = \"prediction\")\n  if doplot\n    display(plot(plt))\n  end\n  return false\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"We then train the neural network to learn the ODE.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"Here we showcase starting the optimization with ADAM to more quickly find a minimum, and then honing in on the minimum by using LBFGS. By using the two together, we are able to fit the neural ODE in 9 seconds! (Note, the timing commented out the plotting). You can easily incorporate the procedure below to set up custom optimization problems. For more information on the usage of GalacticOptim.jl, please consult this documentation.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"The x and p variables in the optimization function are different than x and p above. The optimization function runs over the space of parameters of the original problem, so x_optimization == p_original.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"# Train using the ADAM optimizer\nadtype = GalacticOptim.AutoZygote()\n\noptf = GalacticOptim.OptimizationFunction(loss_neuralode, adtype)\noptprob = GalacticOptim.OptimizationProblem(optfunc, prob_neuralode.p)\n\nresult_neuralode = GalacticOptim.solve(optprob,\n                                       ADAM(0.05),\n                                       cb = callback,\n                                       maxiters = 300)\n# output\n* Status: success\n\n* Candidate solution\n   u: [4.38e-01, -6.02e-01, 4.98e-01,  ...]\n   Minimum:   8.691715e-02\n\n* Found with\n   Algorithm:     ADAM\n   Initial Point: [-3.02e-02, -5.40e-02, 2.78e-01,  ...]","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"We then complete the training using a different optimizer starting from where ADAM stopped. We do allow_f_increases=false to make the optimization automatically halt when near the minimum.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_galacticoptim/","page":"Neural Ordinary Differential Equations with GalacticOptim.jl","title":"Neural Ordinary Differential Equations with GalacticOptim.jl","text":"# Retrain using the LBFGS optimizer\noptprob2 = remake(optprob,u0 = result_neuralode.u)\n\nresult_neuralode2 = GalacticOptim.solve(optprob2,\n                                        LBFGS(),\n                                        cb = callback,\n                                        allow_f_increases = false)\n# output\n* Status: success\n\n* Candidate solution\n   u: [4.23e-01, -6.24e-01, 4.41e-01,  ...]\n   Minimum:   1.429496e-02\n\n* Found with\n   Algorithm:     L-BFGS\n   Initial Point: [4.38e-01, -6.02e-01, 4.98e-01,  ...]\n\n* Convergence measures\n   |x - x'|               = 1.46e-11 ≰ 0.0e+00\n   |x - x'|/|x'|          = 1.26e-11 ≰ 0.0e+00\n   |f(x) - f(x')|         = 0.00e+00 ≤ 0.0e+00\n   |f(x) - f(x')|/|f(x')| = 0.00e+00 ≤ 0.0e+00\n   |g(x)|                 = 4.28e-02 ≰ 1.0e-08\n\n* Work counters\n   Seconds run:   4  (vs limit Inf)\n   Iterations:    35\n   f(x) calls:    336\n   ∇f(x) calls:   336","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear/#Modeling-Nonlinear-Systems","page":"Modeling Nonlinear Systems","title":"Modeling Nonlinear Systems","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/nonlinear/","page":"Modeling Nonlinear Systems","title":"Modeling Nonlinear Systems","text":"In this example we will go one step deeper and showcase the direct function generation capabilities in ModelingToolkit.jl to build nonlinear systems. Let's say we wanted to solve for the steady state of the previous ODE. This is the nonlinear system defined by where the derivatives are zero. We use (unknown) variables for our nonlinear system.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear/","page":"Modeling Nonlinear Systems","title":"Modeling Nonlinear Systems","text":"using ModelingToolkit, NonlinearSolve\r\n\r\n@variables x y z\r\n@parameters σ ρ β\r\n\r\n# Define a nonlinear system\r\neqs = [0 ~ σ*(y-x),\r\n       0 ~ x*(ρ-z)-y,\r\n       0 ~ x*y - β*z]\r\n@named ns = NonlinearSystem(eqs, [x,y,z], [σ,ρ,β])\r\n\r\nguess = [x => 1.0,\r\n         y => 0.0,\r\n         z => 0.0]\r\n\r\nps = [\r\n      σ => 10.0\r\n      ρ => 26.0\r\n      β => 8/3\r\n      ]\r\n\r\nprob = NonlinearProblem(ns,guess,ps)\r\nsol = solve(prob,NewtonRaphson())","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear/","page":"Modeling Nonlinear Systems","title":"Modeling Nonlinear Systems","text":"We can similarly ask to generate the NonlinearProblem with the analytical Jacobian function:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear/","page":"Modeling Nonlinear Systems","title":"Modeling Nonlinear Systems","text":"prob = NonlinearProblem(ns,guess,ps,jac=true)\r\nsol = solve(prob,NewtonRaphson())","category":"page"},{"location":"copies/ModelingToolkit/tutorials/optimization/#Modeling-Optimization-Problems","page":"Modeling Optimization Problems","title":"Modeling Optimization Problems","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/optimization/","page":"Modeling Optimization Problems","title":"Modeling Optimization Problems","text":"using ModelingToolkit, GalacticOptim, Optim\n\n@variables x y\n@parameters a b\nloss = (a - x)^2 + b * (y - x^2)^2\n@named sys = OptimizationSystem(loss,[x,y],[a,b])\n\nu0 = [\n    x=>1.0\n    y=>2.0\n]\np = [\n    a => 6.0\n    b => 7.0\n]\n\nprob = OptimizationProblem(sys,u0,p,grad=true,hess=true)\nsolve(prob,Newton())","category":"page"},{"location":"copies/ModelingToolkit/tutorials/optimization/","page":"Modeling Optimization Problems","title":"Modeling Optimization Problems","text":"Needs more text but it's super cool and auto-parallelizes and sparsifies too. Plus you can hierarchically nest systems to have it generate huge optimization problems.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/#Neural-Ordinary-Differential-Equations-with-Flux.train!","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"All of the tools of DiffEqSensitivity.jl can be used with Flux.jl. A lot of the examples have been written to use FastChain and sciml_train, but in all cases this can be changed to the Chain and Flux.train! workflow.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/#Using-Flux-Chain-neural-networks-with-Flux.train!","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Using Flux Chain neural networks with Flux.train!","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"This should work almost automatically by using solve. Here is an example of optimizing u0 and p.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"using DiffEqFlux, OrdinaryDiffEq, Flux, Optim, Plots\n\nu0 = Float32[2.; 0.]\ndatasize = 30\ntspan = (0.0f0,1.5f0)\n\nfunction trueODEfunc(du,u,p,t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\nt = range(tspan[1],tspan[2],length=datasize)\nprob = ODEProblem(trueODEfunc,u0,tspan)\node_data = Array(solve(prob,Tsit5(),saveat=t))\n\ndudt2 = Chain(x -> x.^3,\n             Dense(2,50,tanh),\n             Dense(50,2))\np,re = Flux.destructure(dudt2) # use this p as the initial condition!\ndudt(u,p,t) = re(p)(u) # need to restrcture for backprop!\nprob = ODEProblem(dudt,u0,tspan)\n\nfunction predict_n_ode()\n  Array(solve(prob,Tsit5(),u0=u0,p=p,saveat=t))\nend\n\nfunction loss_n_ode()\n    pred = predict_n_ode()\n    loss = sum(abs2,ode_data .- pred)\n    loss\nend\n\nloss_n_ode() # n_ode.p stores the initial parameters of the neural ODE\n\ncb = function (;doplot=false) #callback function to observe training\n  pred = predict_n_ode()\n  display(sum(abs2,ode_data .- pred))\n  # plot current prediction against data\n  pl = scatter(t,ode_data[1,:],label=\"data\")\n  scatter!(pl,t,pred[1,:],label=\"prediction\")\n  display(plot(pl))\n  return false\nend\n\n# Display the ODE with the initial parameter values.\ncb()\n\ndata = Iterators.repeated((), 1000)\nres1 = Flux.train!(loss_n_ode, Flux.params(u0,p), data, ADAM(0.05), cb = cb)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/#Using-Flux-Chain-neural-networks-with-GalacticOptim","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Using Flux Chain neural networks with GalacticOptim","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"Flux neural networks can be used with GalacitcOptim.jl by using the Flux.destructure function. In this case, if dudt is a Flux chain, then:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"p,re = Flux.destructure(chain)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"returns p which is the vector of parameters for the chain and re which is a function re(p) that reconstructs the neural network with new parameters p. Using this function we can thus build our neural differential equations in an explicit parameter style.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"Let's use this to build and train a neural ODE from scratch. In this example we will optimize both the neural network parameters p and the input initial condition u0. Notice that GalacticOptim.jl works on a vector input, so we have to concatenate u0 and p and then in the loss function split to the pieces.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"using DiffEqFlux, OrdinaryDiffEq, GalacticOptim, GalacticFlux, GalacticOptimJL, Plots\n\nu0 = Float32[2.; 0.]\ndatasize = 30\ntspan = (0.0f0,1.5f0)\n\nfunction trueODEfunc(du,u,p,t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\nt = range(tspan[1],tspan[2],length=datasize)\nprob = ODEProblem(trueODEfunc,u0,tspan)\node_data = Array(solve(prob,Tsit5(),saveat=t))\n\ndudt2 = Chain(x -> x.^3,\n             Dense(2,50,tanh),\n             Dense(50,2))\np,re = Flux.destructure(dudt2) # use this p as the initial condition!\ndudt(u,p,t) = re(p)(u) # need to restrcture for backprop!\nprob = ODEProblem(dudt,u0,tspan)\n\nθ = [u0;p] # the parameter vector to optimize\n\nfunction predict_n_ode(θ)\n  Array(solve(prob,Tsit5(),u0=θ[1:2],p=θ[3:end],saveat=t))\nend\n\nfunction loss_n_ode(θ)\n    pred = predict_n_ode(θ)\n    loss = sum(abs2,ode_data .- pred)\n    loss,pred\nend\n\nloss_n_ode(θ)\n\ncb = function (θ,l,pred;doplot=false) #callback function to observe training\n  display(l)\n  # plot current prediction against data\n  pl = scatter(t,ode_data[1,:],label=\"data\")\n  scatter!(pl,t,pred[1,:],label=\"prediction\")\n  display(plot(pl))\n  return false\nend\n\n# Display the ODE with the initial parameter values.\ncb(θ,loss_n_ode(θ)...)\n\n# use GalacticOptim.jl to solve the problem\nadtype = GalacticOptim.AutoZygote()\n\noptf = GalacticOptim.OptimizationFunction(loss_neuralode, adtype)\noptprob = GalacticOptim.OptimizationProblem(optfunc, prob_neuralode.p)\n\nresult_neuralode = GalacticOptim.solve(optprob,\n                                       ADAM(0.05),\n                                       cb = callback,\n                                       maxiters = 300)\n\noptprob2 = remake(optprob,u0 = result_neuralode.u)\n\nresult_neuralode2 = GalacticOptim.solve(optprob2,\n                                        LBFGS(),\n                                        cb = callback,\n                                        allow_f_increases = false)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"Notice that the advantage of this format is that we can use Optim's optimizers, like LBFGS with a full Chain object for all of Flux's neural networks, like convolutional neural networks.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_ode_flux/","page":"Neural Ordinary Differential Equations with Flux.train!","title":"Neural Ordinary Differential Equations with Flux.train!","text":"(Image: )","category":"page"},{"location":"copies/Surrogates/secondorderpoly/#Second-order-polynomial-tutorial","page":"SecondOrderPolynomial","title":"Second order polynomial tutorial","text":"","category":"section"},{"location":"copies/Surrogates/secondorderpoly/","page":"SecondOrderPolynomial","title":"SecondOrderPolynomial","text":"The square polynomial model can be expressed by: y = Xβ + ϵ Where X is the matrix of the linear model augmented by adding 2d columns, containing pair by pair product of variables and variables squared.","category":"page"},{"location":"copies/Surrogates/secondorderpoly/","page":"SecondOrderPolynomial","title":"SecondOrderPolynomial","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/secondorderpoly/#Sampling","page":"SecondOrderPolynomial","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/secondorderpoly/","page":"SecondOrderPolynomial","title":"SecondOrderPolynomial","text":"f = x -> 3*sin(x) + 10/x\nlb = 3.0\nub = 6.0\nn = 10\nx = sample(n,lb,ub,LowDiscrepancySample(2))\ny = f.(x)\nscatter(x, y, label=\"Sampled points\", xlims=(lb, ub))\nplot!(f, label=\"True function\", xlims=(lb, ub))","category":"page"},{"location":"copies/Surrogates/secondorderpoly/#Building-the-surrogate","page":"SecondOrderPolynomial","title":"Building the surrogate","text":"","category":"section"},{"location":"copies/Surrogates/secondorderpoly/","page":"SecondOrderPolynomial","title":"SecondOrderPolynomial","text":"sec = SecondOrderPolynomialSurrogate(x, y, lb, ub)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lb, ub))\nplot!(f, label=\"True function\",  xlims=(lb, ub))\nplot!(sec, label=\"Surrogate function\",  xlims=(lb, ub))","category":"page"},{"location":"copies/Surrogates/secondorderpoly/#Optimizing","page":"SecondOrderPolynomial","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/secondorderpoly/","page":"SecondOrderPolynomial","title":"SecondOrderPolynomial","text":"@show surrogate_optimize(f, SRBF(), lb, ub, sec, SobolSample())\nscatter(x, y, label=\"Sampled points\")\nplot!(f, label=\"True function\",  xlims=(lb, ub))\nplot!(sec, label=\"Surrogate function\",  xlims=(lb, ub))","category":"page"},{"location":"copies/Surrogates/secondorderpoly/","page":"SecondOrderPolynomial","title":"SecondOrderPolynomial","text":"The optimization method successfully found the minima.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/higher_order/#Automatic-Transformation-of-Nth-Order-ODEs-to-1st-Order-ODEs","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/higher_order/","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"ModelingToolkit has a system for transformations of mathematical systems. These transformations allow for symbolically changing the representation of the model to problems that are easier to numerically solve. One simple to demonstrate transformation is the ode_order_lowering transformation that sends an Nth order ODE to a 1st order ODE.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/higher_order/","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"To see this, let's define a second order riff on the Lorenz equations. We utilize the derivative operator twice here to define the second order:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/higher_order/","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"using ModelingToolkit, OrdinaryDiffEq\r\n\r\n@parameters σ ρ β\r\n@variables t x(t) y(t) z(t)\r\nD = Differential(t)\r\n\r\neqs = [D(D(x)) ~ σ*(y-x),\r\n       D(y) ~ x*(ρ-z)-y,\r\n       D(z) ~ x*y - β*z]\r\n\r\n@named sys = ODESystem(eqs)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/higher_order/","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"Note that we could've used an alternative syntax for 2nd order, i.e. D = Differential(t)^2 and then E(x) would be the second derivative, and this syntax extends to N-th order. Also, we can use * or ∘ to compose Differentials, like Differential(t) * Differential(x).","category":"page"},{"location":"copies/ModelingToolkit/tutorials/higher_order/","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"Now let's transform this into the ODESystem of first order components. We do this by simply calling ode_order_lowering:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/higher_order/","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"sys = ode_order_lowering(sys)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/higher_order/","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"Now we can directly numerically solve the lowered system. Note that, following the original problem, the solution requires knowing the initial condition for x', and thus we include that in our input specification:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/higher_order/","page":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","title":"Automatic Transformation of Nth Order ODEs to 1st Order ODEs","text":"u0 = [D(x) => 2.0,\r\n      x => 1.0,\r\n      y => 0.0,\r\n      z => 0.0]\r\n\r\np  = [σ => 28.0,\r\n      ρ => 10.0,\r\n      β => 8/3]\r\n\r\ntspan = (0.0,100.0)\r\nprob = ODEProblem(sys,u0,tspan,p,jac=true)\r\nsol = solve(prob,Tsit5())\r\nusing Plots; plot(sol,vars=(x,y))","category":"page"},{"location":"copies/Integrals/basics/IntegralProblem/#Integral-Problems","page":"Integral Problems","title":"Integral Problems","text":"","category":"section"},{"location":"copies/Integrals/basics/IntegralProblem/","page":"Integral Problems","title":"Integral Problems","text":"IntegralProblem","category":"page"},{"location":"copies/Integrals/basics/IntegralProblem/#SciMLBase.IntegralProblem","page":"Integral Problems","title":"SciMLBase.IntegralProblem","text":"Defines an integral problem. Documentation Page: https://github.com/SciML/Integrals.jl\n\nMathematical Specification of a Integral Problem\n\nIntegral problems are multi-dimensional integrals defined as:\n\nint_lb^ub f(up) du\n\nwhere p are parameters. u is a Number or AbstractArray whose geometry matches the space being integrated.\n\nProblem Type\n\nConstructors\n\nIntegralProblem{iip}(f,lb,ub,p=NullParameters();                   nout=1, batch = 0, kwargs...)\n\nf: the integrand, dx=f(x,p) for out-of-place or f(dx,x,p) for in-place.\nlb: Either a number or vector of lower bounds.\nub: Either a number or vector of upper bounds.\np: The parameters associated with the problem.\nnout: The output size of the function f. Defaults to 1, i.e., a scalar integral output.\nbatch: The preferred number of points to batch. This allows user-side parallelization  of the integrand. If batch != 0, then each x[:,i] is a different point of the integral  to calculate, and the output should be nout x batchsize. Note that batch is a suggestion  for the number of points, and it is not necessarily true that batch is the same as  batchsize in all algorithms.\nkwargs:: Keyword arguments copied to the solvers.\n\nAdditionally, we can supply iip like IntegralProblem{iip}(...) as true or false to declare at  compile time whether the integrator function is in-place.\n\nFields\n\nThe fields match the names of the constructor arguments.\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/TensorLayer/#Tensor-Product-Layer","page":"Tensor Product Layer","title":"Tensor Product Layer","text":"","category":"section"},{"location":"copies/DiffEqFlux/layers/TensorLayer/","page":"Tensor Product Layer","title":"Tensor Product Layer","text":"The following layer is a helper function for easily constructing a TensorLayer, which takes as input an array of n tensor product basis, B_1 B_2  B_n, a data point x, computes zi = Wi  B_1(x1)  B_2(x2)    B_n(xn), where W is the layer's weight, and returns [z[1], ..., z[out]].","category":"page"},{"location":"copies/DiffEqFlux/layers/TensorLayer/","page":"Tensor Product Layer","title":"Tensor Product Layer","text":"TensorLayer","category":"page"},{"location":"copies/DiffEqFlux/layers/TensorLayer/#DiffEqFlux.TensorLayer","page":"Tensor Product Layer","title":"DiffEqFlux.TensorLayer","text":"Constructs the Tensor Product Layer, which takes as input an array of n tensor product basis, [B1, B2, ..., Bn] a data point x, computes z[i] = W[i,:] ⨀ [B1(x[1]) ⨂ B2(x[2]) ⨂ ... ⨂ Bn(x[n])], where W is the layer's weight, and returns [z[1], ..., z[out]].\n\nTensorLayer(model,out,p=nothing)\n\nArguments:\n\nmodel: Array of TensorProductBasis [B1(n1), ..., Bk(nk)], where k corresponds to the dimension of the input.\nout: Dimension of the output.\np: Optional initialization of the layer's weight. Initialized to standard normal by default.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/SplineLayer/#Spline-Layer","page":"Spline Layer","title":"Spline Layer","text":"","category":"section"},{"location":"copies/DiffEqFlux/layers/SplineLayer/","page":"Spline Layer","title":"Spline Layer","text":"Constructs a Spline Layer. At a high-level, it performs the following:","category":"page"},{"location":"copies/DiffEqFlux/layers/SplineLayer/","page":"Spline Layer","title":"Spline Layer","text":"Takes as input a one-dimensional training dataset, a time span, a time step and an interpolation method.\nDuring training, adjusts the values of the function at multiples of the time-step such that the curve interpolated through these points has minimum loss on the corresponding one-dimensional dataset.","category":"page"},{"location":"copies/DiffEqFlux/layers/SplineLayer/","page":"Spline Layer","title":"Spline Layer","text":"SplineLayer","category":"page"},{"location":"copies/DiffEqFlux/layers/SplineLayer/#DiffEqFlux.SplineLayer","page":"Spline Layer","title":"DiffEqFlux.SplineLayer","text":"Constructs a Spline Layer. At a high-level, it performs the following:\n\nTakes as input a one-dimensional training dataset, a time span, a time step and\n\nan interpolation method.\n\nDuring training, adjusts the values of the function at multiples of the time-step\n\nsuch that the curve interpolated through these points has minimum loss on the corresponding one-dimensional dataset.\n\nSplineLayer(time_span,time_step,spline_basis,saved_points=nothing)\n\nArguments:\n\ntime_span: Tuple of real numbers corresponding to the time span.\ntime_step: Real number corresponding to the time step.\nspline_basis: Interpolation method to be used yb the basis (current supported interpolation methods: ConstantInterpolation, LinearInterpolation, QuadraticInterpolation, QuadraticSpline, CubicSpline).\n'saved_points': values of the function at multiples of the time step. Initialized by default\n\nto a random vector sampled from the unit normal.\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Composing-Ordinary-Differential-Equations","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"This is an introductory example for the usage of ModelingToolkit (MTK). It illustrates the basic user-facing functionality by means of some examples of Ordinary Differential Equations (ODE). Some references to more specific documentation are given at appropriate places.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Copy-Pastable-Simplified-Example","page":"Composing Ordinary Differential Equations","title":"Copy-Pastable Simplified Example","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"A much deeper tutorial with forcing functions and sparse Jacobians is all below. But if you want to just see some code and run, here's an example:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"using ModelingToolkit\r\n\r\n@variables t x(t) RHS(t)  # independent and dependent variables\r\n@parameters τ       # parameters\r\nD = Differential(t) # define an operator for the differentiation w.r.t. time\r\n\r\n# your first ODE, consisting of a single equation, indicated by ~\r\n@named fol = ODESystem([ D(x)  ~ (1 - x)/τ])\r\n\r\nusing DifferentialEquations: solve\r\nusing Plots: plot\r\n\r\nprob = ODEProblem(fol, [x => 0.0], (0.0,10.0), [τ => 3.0])\r\nsol = solve(prob)\r\nplot(sol)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"(Image: Simulation result of first-order lag element, with right-hand side) Now let's start digging into MTK!","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Your-very-first-ODE","page":"Composing Ordinary Differential Equations","title":"Your very first ODE","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Let us start with a minimal example. The system to be modelled is a","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"first-order lag element:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"dotx = fracf(t) - x(t)tau","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Here, t is the independent variable (time), x(t) is the (scalar) state variable, f(t) is an external forcing function, and tau is a constant parameter. In MTK, this system can be modelled as follows. For simplicity, we first set the forcing function to a constant value.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"using ModelingToolkit\r\n\r\n@variables t x(t)  # independent and dependent variables\r\n@parameters τ       # parameters\r\nD = Differential(t) # define an operator for the differentiation w.r.t. time\r\n\r\n# your first ODE, consisting of a single equation, indicated by ~\r\n@named fol_model = ODESystem(D(x) ~ (1 - x)/τ)\r\n      # Model fol_model with 1 equations\r\n      # States (1):\r\n      #   x(t)\r\n      # Parameters (1):\r\n      #   τ","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Note that equations in MTK use the tilde character (~) as equality sign. Also note that the @named macro simply ensures that the symbolic name matches the name in the REPL. If omitted, you can directly set the name keyword.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"After construction of the ODE, you can solve it using DifferentialEquations.jl:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"using DifferentialEquations\r\nusing Plots\r\n\r\nprob = ODEProblem(fol_model, [x => 0.0], (0.0,10.0), [τ => 3.0])\r\nplot(solve(prob))","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"(Image: Simulation result of first-order lag element)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"The initial state and the parameter values are specified using a mapping from the actual symbolic elements to their values, represented as an array of Pairs, which are constructed using the => operator.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Algebraic-relations-and-structural-simplification","page":"Composing Ordinary Differential Equations","title":"Algebraic relations and structural simplification","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"You could separate the calculation of the right-hand side, by introducing an intermediate variable RHS:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"@variables RHS(t)\r\n@named fol_separate = ODESystem([ RHS  ~ (1 - x)/τ,\r\n                                  D(x) ~ RHS ])\r\n      # Model fol_separate with 2 equations\r\n      # States (2):\r\n      #   x(t)\r\n      #   RHS(t)\r\n      # Parameters (1):\r\n      #   τ","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"To directly solve this system, you would have to create a Differential-Algebraic Equation (DAE) problem, since besides the differential equation, there is an additional algebraic equation now. However, this DAE system can obviously be transformed into the single ODE we used in the first example above. MTK achieves this by means of structural simplification:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"fol_simplified = structural_simplify(fol_separate)\r\n\r\nequations(fol_simplified)\r\n      # 1-element Array{Equation,1}:\r\n      #  Differential(t)(x(t)) ~ (τ^-1)*(1 - x(t))\r\n\r\nequations(fol_simplified) == equations(fol_model)\r\n      # true","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"You can extract the equations from a system using equations (and, in the same way, states and parameters). The simplified equation is exactly the same as the original one, so the simulation performance will also be the same. However, there is one difference. MTK does keep track of the eliminated algebraic variables as \"observables\" (see Observables and Variable Elimination). That means, MTK still knows how to calculate them out of the information available in a simulation result. The intermediate variable RHS therefore can be plotted along with the state variable. Note that this has to be requested explicitly, though:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"prob = ODEProblem(fol_simplified, [x => 0.0], (0.0,10.0), [τ => 3.0])\r\nsol = solve(prob)\r\nplot(sol, vars=[x, RHS])","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"(Image: Simulation result of first-order lag element, with right-hand side)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Note that similarly the indexing of the solution works via the names, and so sol[x] gives the timeseries for x, sol[x,2:10] gives the 2nd through 10th values of x matching sol.t, etc. Note that this works even for variables which have been eliminated, and thus sol[RHS] retrieves the values of RHS.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Specifying-a-time-variable-forcing-function","page":"Composing Ordinary Differential Equations","title":"Specifying a time-variable forcing function","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"What if the forcing function (the \"external input\") f(t) is not constant? Obviously, one could use an explicit, symbolic function of time:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"@variables f(t)\r\n@named fol_variable_f = ODESystem([f ~ sin(t), D(x) ~ (f - x)/τ])","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"But often there is time-series data, such as measurement data from an experiment, we want to embed as data in the simulation of a PDE, or as a forcing function on the right-hand side of an ODE – is it is the case here. For this, MTK allows to \"register\" arbitrary Julia functions, which are excluded from symbolic transformations but are just used as-is. So, you could, for example, interpolate a given time series using DataInterpolations.jl. Here, we illustrate this option by a simple lookup (\"zero-order hold\") of a vector of random values:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"value_vector = randn(10)\r\nf_fun(t) = t >= 10 ? value_vector[end] : value_vector[Int(floor(t))+1]\r\n@register_symbolic f_fun(t)\r\n\r\n@named fol_external_f = ODESystem([f ~ f_fun(t), D(x) ~ (f - x)/τ])\r\nprob = ODEProblem(structural_simplify(fol_external_f), [x => 0.0], (0.0,10.0), [τ => 0.75])\r\n\r\nsol = solve(prob)\r\nplot(sol, vars=[x,f])","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"(Image: Simulation result of first-order lag element, step-wise forcing function)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Building-component-based,-hierarchical-models","page":"Composing Ordinary Differential Equations","title":"Building component-based, hierarchical models","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Working with simple one-equation systems is already fun, but composing more complex systems from simple ones is even more fun. Best practice for such a \"modeling framework\" could be to use factory functions for model components:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"function fol_factory(separate=false;name)\r\n    @parameters τ\r\n    @variables t x(t) f(t) RHS(t)\r\n\r\n    eqs = separate ? [RHS ~ (f - x)/τ,\r\n                      D(x) ~ RHS] :\r\n                      D(x) ~(f - x)/τ\r\n\r\n    ODESystem(eqs;name)\r\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Such a factory can then used to instantiate the same component multiple times, but allows for customization:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"@named fol_1 = fol_factory()\r\n@named fol_2 = fol_factory(true) # has observable RHS","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"The @named macro rewrites fol_2 = fol_factory(true) into fol_2 = fol_factory(true,:fol_2). Now, these two components can be used as subsystems of a parent system, i.e. one level higher in the model hierarchy. The connections between the components again are just algebraic relations:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"connections = [ fol_1.f ~ 1.5,\r\n                fol_2.f ~ fol_1.x ]\r\n\r\nconnected = compose(ODESystem(connections,name=:connected), fol_1, fol_2)\r\n      # Model connected with 5 equations\r\n      # States (5):\r\n      #   fol_1₊f(t)\r\n      #   fol_2₊f(t)\r\n      #   fol_1₊x(t)\r\n      #   fol_2₊x(t)\r\n      #   fol_2₊RHS(t)\r\n      # Parameters (2):\r\n      #   fol_1₊τ\r\n      #   fol_2₊τ","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"All equations, variables and parameters are collected, but the structure of the hierarchical model is still preserved. That is, you can still get information about fol_1 by addressing it by connected.fol_1, or its parameter by connected.fol_1.τ. Before simulation, we again eliminate the algebraic variables and connection equations from the system using structural simplification:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"connected_simp = structural_simplify(connected)\r\n      # Model connected with 2 equations\r\n      # States (2):\r\n      #   fol_1₊x(t)\r\n      #   fol_2₊x(t)\r\n      # Parameters (2):\r\n      #   fol_1₊τ\r\n      #   fol_2₊τ\r\n      # Incidence matrix:\r\n      #   [1, 1]  =  ×\r\n      #   [2, 1]  =  ×\r\n      #   [2, 2]  =  ×\r\n      #   [1, 3]  =  ×\r\n      #   [2, 4]  =  ×\r\n\r\nfull_equations(connected_simp)\r\n      # 2-element Array{Equation,1}:\r\n      #  Differential(t)(fol_1₊x(t)) ~ (fol_1₊τ^-1)*(1.5 - fol_1₊x(t))\r\n      #  Differential(t)(fol_2₊x(t)) ~ (fol_2₊τ^-1)*(fol_1₊x(t) - fol_2₊x(t))","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"As expected, only the two state-derivative equations remain, as if you had manually eliminated as many variables as possible from the equations. Some observed variables are not expanded unless full_equations is used. As mentioned above, the hierarchical structure is preserved though. So the initial state and the parameter values can be specified accordingly when building the ODEProblem:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"u0 = [ fol_1.x => -0.5,\r\n       fol_2.x => 1.0 ]\r\n\r\np = [ fol_1.τ => 2.0,\r\n      fol_2.τ => 4.0 ]\r\n\r\nprob = ODEProblem(connected_simp, u0, (0.0,10.0), p)\r\nplot(solve(prob))","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"(Image: Simulation of connected system (two first-order lag elements in series))","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"More on this topic may be found in Composing Models and Building Reusable Components.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Defaults","page":"Composing Ordinary Differential Equations","title":"Defaults","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Often it is a good idea to specify reasonable values for the initial state and the parameters of a model component. Then, these do not have to be explicitly specified when constructing the ODEProblem.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"function unitstep_fol_factory(;name)\r\n    @parameters τ\r\n    @variables t x(t)\r\n    ODESystem(D(x) ~ (1 - x)/τ; name, defaults=Dict(x=>0.0, τ=>1.0))\r\nend\r\n\r\nODEProblem(unitstep_fol_factory(name=:fol),[],(0.0,5.0),[]) |> solve","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Note that the defaults can be functions of the other variables, which is then resolved at the time of the problem construction. Of course, the factory function could accept additional arguments to optionally specify the initial state or parameter values, etc.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Symbolic-and-sparse-derivatives","page":"Composing Ordinary Differential Equations","title":"Symbolic and sparse derivatives","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"One advantage of a symbolic toolkit is that derivatives can be calculated explicitly, and that the incidence matrix of partial derivatives (the \"sparsity pattern\") can also be explicitly derived. These two facts lead to a substantial speedup of all model calculations, e.g. when simulating a model over time using an ODE solver.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"By default, analytical derivatives and sparse matrices, e.g. for the Jacobian, the matrix of first partial derivatives, are not used. Let's benchmark this (prob still is the problem using the connected_simp system above):","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"using BenchmarkTools\r\n\r\n@btime solve($prob, Rodas4());\r\n      # 251.300 μs (873 allocations: 31.18 KiB)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Now have MTK provide sparse, analytical derivatives to the solver. This has to be specified during the construction of the ODEProblem:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"prob_an = ODEProblem(connected_simp, u0, (0.0,10.0), p; jac=true, sparse=true)\r\n\r\n@btime solve($prob_an, Rodas4());\r\n      # 142.899 μs (1297 allocations: 83.96 KiB)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"The speedup is significant. For this small dense model (3 of 4 entries are populated), using sparse matrices is counterproductive in terms of required memory allocations. For large, hierarchically built models, which tend to be sparse, speedup and the reduction of memory allocation can be expected to be substantial. In addition, these problem builders allow for automatic parallelism using the structural information. For more information, see the ODESystem page.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/#Notes-and-pointers-how-to-go-on","page":"Composing Ordinary Differential Equations","title":"Notes and pointers how to go on","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Here are some notes that may be helpful during your initial steps with MTK:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Sometimes, the symbolic engine within MTK is not able to correctly identify the independent variable (e.g. time) out of all variables. In such a case, you usually get an error that some variable(s) is \"missing from variable map\". In most cases, it is then sufficient to specify the independent variable as second argument to ODESystem, e.g. ODESystem(eqs, t).\nA completely macro-free usage of MTK is possible and is discussed in a separate tutorial. This is for package developers, since the macros are only essential for automatic symbolic naming for modelers.\nVector-valued parameters and variables are possible. A cleaner, more consistent treatment of these is work in progress, though. Once finished, this introductory tutorial will also cover this feature.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Where to go next?","category":"page"},{"location":"copies/ModelingToolkit/tutorials/ode_modeling/","page":"Composing Ordinary Differential Equations","title":"Composing Ordinary Differential Equations","text":"Not sure how MTK relates to similar tools and packages? Read Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages.\nDepending on what you want to do with MTK, have a look at some of the other Symbolic Modeling Tutorials.\nIf you want to automatically convert an existing function to a symbolic representation, you might go through the ModelingToolkitize Tutorials.\nTo learn more about the inner workings of MTK, consider the sections under Basics and System Types.","category":"page"},{"location":"copies/Integrals/tutorials/differentiating_integrals/#Differentiating-Integrals","page":"Differentiating Integrals","title":"Differentiating Integrals","text":"","category":"section"},{"location":"copies/Integrals/tutorials/differentiating_integrals/","page":"Differentiating Integrals","title":"Differentiating Integrals","text":"Integrals.jl is a fully differentiable quadrature library. Thus, it adds the ability to perform automatic differentiation over any of the libraries that it calls. It integrates with ForwardDiff.jl for forward-mode automatic differentiation and Zygote.jl for reverse-mode automatic differentiation. For example:","category":"page"},{"location":"copies/Integrals/tutorials/differentiating_integrals/","page":"Differentiating Integrals","title":"Differentiating Integrals","text":"using Integrals, ForwardDiff, FiniteDiff, Zygote, Cuba\nf(x,p) = sum(sin.(x .* p))\nlb = ones(2)\nub = 3ones(2)\np = [1.5,2.0]\n\nfunction testf(p)\n    prob = IntegralProblem(f,lb,ub,p)\n    sin(solve(prob,CubaCuhre(),reltol=1e-6,abstol=1e-6)[1])\nend\ndp1 = Zygote.gradient(testf,p)\ndp2 = FiniteDiff.finite_difference_gradient(testf,p)\ndp3 = ForwardDiff.gradient(testf,p)\ndp1[1] ≈ dp2 ≈ dp3","category":"page"},{"location":"copies/GlobalSensitivity/methods/fractional/#Fractional-Factorial-Method","page":"Fractional Factorial Method","title":"Fractional Factorial Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/fractional/","page":"Fractional Factorial Method","title":"Fractional Factorial Method","text":"FractionalFactorial does not have any keyword arguments.","category":"page"},{"location":"copies/GlobalSensitivity/methods/fractional/#Method-Details","page":"Fractional Factorial Method","title":"Method Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/fractional/","page":"Fractional Factorial Method","title":"Fractional Factorial Method","text":"Fractional Factorial method creates a design matrix by utilising Hadamard Matrix and uses it run simulations of the input model. The main effects are then evaluated by dot product between the contrast  for the parameter and the vector of simulation results. The  corresponding main effects and variance, i.e. square of the main effects are returned as results for Fractional Factorial method.","category":"page"},{"location":"copies/GlobalSensitivity/methods/fractional/#API","page":"Fractional Factorial Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/fractional/","page":"Fractional Factorial Method","title":"Fractional Factorial Method","text":"function gsa(f, method::FractionalFactorial; num_params, p_range = nothing, kwargs...)","category":"page"},{"location":"copies/GlobalSensitivity/methods/fractional/#Example","page":"Fractional Factorial Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/fractional/","page":"Fractional Factorial Method","title":"Fractional Factorial Method","text":"using GlobalSensitivity, Test\n\nf = X -> X[1] + 2 * X[2] + 3 * X[3] + 4 * X[7] * X[12]\nres1 = gsa(f,FractionalFactorial(),num_params = 12,N=10)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#scimlfunctions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The SciML ecosystem provides an extensive interface for declaring extra functions associated with the differential equation's data. In traditional libraries there is usually only one option: the Jacobian. However, we allow for a large array of pre-computed functions to speed up the calculations. This is offered via the SciMLFunction types which can be passed to the problems.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Definition-of-the-AbstractSciMLFunction-Interface","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Definition of the AbstractSciMLFunction Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The following standard principles should be adhered to across all  AbstractSciMLFunction instantiations.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Common-Function-Choice-Definitions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Common Function Choice Definitions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The full interface available to the solvers is as follows:","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"jac: The Jacobian of the differential equation with respect to the state variable u at a time t with parameters p.\nparamjac: The Jacobian of the differential equation with respect to p at state u at time t.\nanalytic: Defines an analytical solution using u0 at time t with p which will cause the solvers to return errors. Used for testing.\nsyms: Allows you to name your variables for automatic names in plots and other output.\njac_prototype: Defines the type to be used for any internal Jacobians within the solvers.\nsparsity: Defines the sparsity pattern to be used for the sparse differentiation schemes. By default this is equal to jac_prototype. See the sparsity handling portion of this page for more information.\ncolorvec: The coloring pattern used by the sparse differentiator. See the sparsity handling portion of this page for more information.\nobserved: A function which allows for generating other observables from a solution.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"Each function type additionally has some specific arguments, refer to their documentation for details.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#In-place-Specification-and-No-Recompile-Mode","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"In-place Specification and No-Recompile Mode","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"Each SciMLFunction type can be called with an \"is inplace\" (iip) choice.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"ODEFunction(f)\nODEFunction{iip}(f)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"which is a boolean for whether the function is in the inplace form (mutating to change the first value). This is automatically determined using the methods table but note that for full type-inferrability of the SciMLProblem this iip-ness should be specified.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"Additionally, the functions are fully specialized to reduce the runtimes. If one would instead like to not specialize on the functions to reduce compile time, then one can set recompile to false.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"ODEFunction{iip,false}(f)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"This makes the ODE solver compilation independent of the function and so changing the function will not cause recompilation. One can change the default value by changing the const RECOMPILE_BY_DEFAULT = true to false in the SciMLBase.jl source code.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Specifying-Jacobian-Types","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Specifying Jacobian Types","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The jac field of an inplace style SciMLFunction has the signature jac(J,u,p,t), which updates the jacobian J in-place. The intended type for J can sometimes be inferred (e.g. when it is just a dense Matrix), but not in general. To supply the type information, you can provide a jac_prototype in the function's constructor.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The following example creates an inplace ODEFunction whose jacobian is a Diagonal:","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"using LinearAlgebra\nf = (du,u,p,t) -> du .= t .* u\njac = (J,u,p,t) -> (J[1,1] = t; J[2,2] = t; J)\njp = Diagonal(zeros(2))\nfun = ODEFunction(f; jac=jac, jac_prototype=jp)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"Note that the integrators will always make a deep copy of fun.jac_prototype, so there's no worry of aliasing.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"In general the jacobian prototype can be anything that has mul! defined, in particular sparse matrices or custom lazy types that support mul!. A special case is when the jac_prototype is a AbstractDiffEqLinearOperator, in which case you do not need to supply jac as it is automatically set to update_coefficients!. Refer to the DiffEqOperators section for more information on setting up time/parameter dependent operators.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Sparsity-Handling","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Sparsity Handling","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The solver libraries internally use packages such as FiniteDiff.jl and SparseDiffTools.jl for high performance calculation of sparse Jacobians and Hessians, along with matrix-free calculations of Jacobian-Vector products (Jv), vector-Jacobian products (v'J), and Hessian-vector products (H*v). The SciML interface gives users the ability to control these connections in order to allow for top notch performance.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The key arguments in the SciMLFunction is the prototype, which is an object that will be used as the underlying Jacobian/Hessian. Thus if one wants to use a sparse Jacobian, one should specify jac_prototype to be a sparse matrix. The sparsity pattern used in the differentiation scheme is defined by sparsity. By default, sparsity=jac_prototype, meaning that the sparse automatic differentiation scheme should specialize on the sparsity pattern given by the actual sparsity pattern. This can be overridden to say perform partial matrix coloring approximations. Additionally, the color vector for the sparse differentiation directions can be specified directly via colorvec. For more information on how these arguments control the differentiation process, see the aforementioned differentiation library documentations.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Traits","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Traits","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"SciMLBase.isinplace(f::SciMLBase.AbstractSciMLFunction)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#AbstractSciMLFunction-API","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"AbstractSciMLFunction API","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Abstract-SciML-Functions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Abstract SciML Functions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"SciMLBase.AbstractDiffEqFunction\nSciMLBase.AbstractODEFunction\nSciMLBase.AbstractSDEFunction\nSciMLBase.AbstractDDEFunction\nSciMLBase.AbstractDAEFunction\nSciMLBase.AbstractRODEFunction\nSciMLBase.AbstractDiscreteFunction\nSciMLBase.AbstractSDDEFunction\nSciMLBase.AbstractNonlinearFunction","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractDiffEqFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDiffEqFunction","text":"abstract type AbstractDiffEqFunction{iip} <: SciMLBase.AbstractSciMLFunction{iip}\n\nBase for types defining differential equation functions.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractODEFunction","text":"abstract type AbstractODEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractSDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractSDEFunction","text":"abstract type AbstractSDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDDEFunction","text":"abstract type AbstractDDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractDAEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDAEFunction","text":"abstract type AbstractDAEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractRODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractRODEFunction","text":"abstract type AbstractRODEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractDiscreteFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDiscreteFunction","text":"abstract type AbstractDiscreteFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractSDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractSDDEFunction","text":"abstract type AbstractSDDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractNonlinearFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractNonlinearFunction","text":"abstract type AbstractNonlinearFunction{iip} <: SciMLBase.AbstractSciMLFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Concrete-SciML-Functions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Concrete SciML Functions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"ODEFunction\nSplitFunction\nDynamicalODEFunction\nDDEFunction\nDynamicalDDEFunction\nDiscreteFunction\nSDEFunction\nSplitSDEFunction\nDynamicalSDEFunction\nRODEFunction\nDAEFunction\nSDDEFunction\nNonlinearFunction\nOptimizationFunction","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.SplitFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.SplitFunction","text":"SplitFunction{iip,F1,F2,TMM,C,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractODEFunction{iip}\n\nA representation of a split ODE function f, defined by:\n\nM fracdudt = f_1(upt) + f_2(upt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nGenerally, for ODE integrators the f_1 portion should be considered the \"stiff portion of the model\" with larger time scale separation, while the f_2 portion should be considered the \"non-stiff portion\". This interpretation is directly used in integrators like IMEX (implicit-explicit integrators) and exponential integrators.\n\nConstructor\n\nSplitFunction{iip,recompile}(f1,f2;\n                             mass_matrix=I,\n                             analytic=nothing,\n                             tgrad=nothing,\n                             jac=nothing,\n                             jvp=nothing,\n                             vjp=nothing,\n                             jac_prototype=nothing,\n                             sparsity=jac_prototype,\n                             paramjac = nothing,\n                             syms = nothing,\n                             indepsym = nothing,\n                             colorvec = nothing)\n\nNote that only the functions f_i themselves are required. These functions should be given as f_i!(du,u,p,t) or du = f_i(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f_1(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdf_1du\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdf_1du v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdf_1du^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdf_1dp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\nNote on the Derivative Definition\n\nThe derivatives, such as the Jacobian, are only defined on the f1 portion of the split ODE. This is used to treat the f1 implicit while keeping the f2 portion explicit.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the SplitFunction type directly match the names of the inputs.\n\nSymbolically Generating the Functions\n\nSee the modelingtoolkitize function from ModelingToolkit.jl for automatically symbolically generating the Jacobian and more from the  numerically-defined functions. See ModelingToolkit.SplitODEProblem for information on generating the SplitFunction from this symbolic engine.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DynamicalODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DynamicalODEFunction","text":"DynamicalODEFunction{iip,F1,F2,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractODEFunction{iip}\n\nA representation of an ODE function f, defined by:\n\nM fracdudt = f(upt)\n\nas a partitioned ODE:\n\nM_1 fracdudt = f_1(upt)\nM_2 fracdudt = f_2(upt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDynamicalODEFunction{iip,recompile}(f1,f2;\n                                    mass_matrix=I,\n                                    analytic=nothing,\n                                    tgrad=nothing,\n                                    jac=nothing,\n                                    jvp=nothing,\n                                    vjp=nothing,\n                                    jac_prototype=nothing,\n                                    sparsity=jac_prototype,\n                                    paramjac = nothing,\n                                    syms = nothing,\n                                    indepsym = nothing,\n                                    colorvec = nothing)\n\nNote that only the functions f_i themselves are required. These functions should be given as f_i!(du,u,p,t) or du = f_i(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M_i represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/daesolve/. Must be an AbstractArray or an AbstractSciMLOperator. Should be given as a tuple of mass matrices, i.e. `(M1, M_2)` for the mass matrices of equations 1 and 2 respectively.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DynamicalODEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DDEFunction","text":"DDEFunction{iip,F,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractDDEFunction{iip}\n\nA representation of a DDE function f, defined by:\n\nM fracdudt = f(uhpt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDDEFunction{iip,recompile}(f;\n                 mass_matrix=I,\n                 analytic=nothing,\n                 tgrad=nothing,\n                 jac=nothing,\n                 jvp=nothing,\n                 vjp=nothing,\n                 jac_prototype=nothing,\n                 sparsity=jac_prototype,\n                 paramjac = nothing,\n                 syms = nothing,\n                 indepsym = nothing,\n                 colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,h,p,t) or du = f(u,h,p,t). See the section on iip for more details on in-place vs out-of-place handling. The histroy function h acts as an interpolator over time, i.e. h(t) with options matching the solution interface, i.e. h(t; save_idxs = 2).\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,h,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,h,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,h,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,h,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,h,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DynamicalDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DynamicalDDEFunction","text":"DynamicalDDEFunction{iip,F1,F2,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractDDEFunction{iip}\n\nA representation of a DDE function f, defined by:\n\nM fracdudt = f(uhpt)\n\nas a partitioned ODE:\n\nM_1 fracdudt = f_1(uhpt)\nM_2 fracdudt = f_2(uhpt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDynamicalDDEFunction{iip,recompile}(f1,f2;\n                                    mass_matrix=I,\n                                    analytic=nothing,\n                                    tgrad=nothing,\n                                    jac=nothing,\n                                    jvp=nothing,\n                                    vjp=nothing,\n                                    jac_prototype=nothing,\n                                    sparsity=jac_prototype,\n                                    paramjac = nothing,\n                                    syms = nothing,\n                                    indepsym = nothing,\n                                    colorvec = nothing)\n\nNote that only the functions f_i themselves are required. These functions should be given as f_i!(du,u,h,p,t) or du = f_i(u,h,p,t). See the section on iip for more details on in-place vs out-of-place handling. The histroy function h acts as an interpolator over time, i.e. h(t) with options matching the solution interface, i.e. h(t; save_idxs = 2).\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M_i represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/daesolve/. Must be an AbstractArray or an AbstractSciMLOperator. Should be given as a tuple of mass matrices, i.e. `(M1, M_2)` for the mass matrices of equations 1 and 2 respectively.\nanalytic(u0,h,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,h,p,t) or dT=tgrad(u,h,p,t): returns fracpartial f(upt)partial t\njac(J,u,h,p,t) or J=jac(u,h,p,t): returns fracdfdu\njvp(Jv,v,u,h,p,t) or Jv=jvp(v,u,h,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,h,p,t) or Jv=vjp(v,u,h,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,h,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DynamicalDDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DiscreteFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DiscreteFunction","text":"DiscreteFunction{iip,F,Ta,S,O} <: AbstractDiscreteFunction{iip}\n\nA representation of an discrete dynamical system f, defined by:\n\nu_n+1 = f(upt_n+1)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDiscreteFunction{iip,recompile}(f;\n                                analytic=nothing, \n                                syms=nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p,t) or du = f(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DiscreteFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.SplitSDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.SplitSDEFunction","text":"SplitSDEFunction{iip,F1,F2,G,TMM,C,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractSDEFunction{iip}\n\nA representation of a split SDE function f, defined by:\n\nM fracdudt = f_1(upt) + f_2(upt) + g(upt) dW\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nGenerally, for SDE integrators the f_1 portion should be considered the \"stiff portion of the model\" with larger time scale separation, while the f_2 portion should be considered the \"non-stiff portion\". This interpretation is directly used in integrators like IMEX (implicit-explicit integrators) and exponential integrators.\n\nConstructor\n\nSplitSDEFunction{iip,recompile}(f1,f2,g;\n                 mass_matrix=I,\n                 analytic=nothing,\n                 tgrad=nothing,\n                 jac=nothing,\n                 jvp=nothing,\n                 vjp=nothing,\n                 ggprime = nothing,\n                 jac_prototype=nothing,\n                 sparsity=jac_prototype,\n                 paramjac = nothing,\n                 syms = nothing,\n                 indepsym = nothing,\n                 colorvec = nothing)\n\nNote that only the function f itself is required. All of the remaining functions are optional for improving or accelerating the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the SDE function. Can be used to determine that the equation is actually a stochastic differential-algebraic equation (SDAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/sdae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f_1(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdf_1du\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdf_1du v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdf_1du^ast v\nggprime(J,u,p,t) or J = ggprime(u,p,t): returns the Milstein derivative  fracdg(upt)du g(upt)\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdf_1dp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\nNote on the Derivative Definition\n\nThe derivatives, such as the Jacobian, are only defined on the f1 portion of the split ODE. This is used to treat the f1 implicit while keeping the f2 portion explicit.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the SplitSDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DynamicalSDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DynamicalSDEFunction","text":"DynamicalSDEFunction{iip,F1,F2,G,TMM,C,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractSDEFunction{iip}\n\nA representation of an SDE function f and g, defined by:\n\nM du = f(upt) dt + g(upt) dW_t\n\nas a partitioned ODE:\n\nM_1 du = f_1(upt) dt + g(upt) dW_t\nM_2 du = f_2(upt) dt + g(upt) dW_t\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDynamicalSDEFunction{iip,recompile}(f1,f2;\n                                    mass_matrix=I,\n                                    analytic=nothing,\n                                    tgrad=nothing,\n                                    jac=nothing,\n                                    jvp=nothing,\n                                    vjp=nothing,\n                                    ggprime=nothing,\n                                    jac_prototype=nothing,\n                                    sparsity=jac_prototype,\n                                    paramjac = nothing,\n                                    syms = nothing,\n                                    indepsym = nothing,\n                                    colorvec = nothing)\n\nNote that only the functions f_i themselves are required. These functions should be given as f_i!(du,u,p,t) or du = f_i(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M_i represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/daesolve/. Must be an AbstractArray or an AbstractSciMLOperator. Should be given as a tuple of mass matrices, i.e. `(M1, M_2)` for the mass matrices of equations 1 and 2 respectively.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\nggprime(J,u,p,t) or J = ggprime(u,p,t): returns the Milstein derivative  fracdg(upt)du g(upt)\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DynamicalSDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.RODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.RODEFunction","text":"RODEFunction{iip,F,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractRODEFunction{iip}\n\nA representation of an RODE function f, defined by:\n\nM fracdudt = f(uptW)dt\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nRODEFunction{iip,recompile}(f;\n                           mass_matrix=I,\n                           analytic=nothing,\n                           tgrad=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           paramjac = nothing,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p,t) or du = f(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the RODEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DAEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DAEFunction","text":"DAEFunction{iip,F,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractDAEFunction{iip}\n\nA representation of an implicit DAE function f, defined by:\n\n0 = f(fracdudtupt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDAEFunction{iip,recompile}(f;\n                           analytic=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(out,du,u,p,t) or out = f(du,u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\njac(J,du,u,p,gamma,t) or J=jac(du,u,p,gamma,t): returns the implicit DAE Jacobian defined as gamma fracdGd(du) + fracdGdu\njvp(Jv,v,du,u,p,gamma,t) or Jv=jvp(v,du,u,p,gamma,t): returns the directional  derivativefracdfdu v\nvjp(Jv,v,du,u,p,gamma,t) or Jv=vjp(v,du,u,p,gamma,t): returns the adjoint  derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DAEFunction type directly match the names of the inputs.\n\nExamples\n\nDeclaring Explicit Jacobians for DAEs\n\nFor fully implicit ODEs (DAEProblems), a slightly different Jacobian function is necessary. For the DAE\n\nG(duupt) = res\n\nThe Jacobian should be given in the form gamma*dG/d(du) + dG/du where gamma is given by the solver. This means that the signature is:\n\nf(J,du,u,p,gamma,t)\n\nFor example, for the equation\n\nfunction testjac(res,du,u,p,t)\n  res[1] = du[1] - 2.0 * u[1] + 1.2 * u[1]*u[2]\n  res[2] = du[2] -3 * u[2] - u[1]*u[2]\nend\n\nwe would define the Jacobian as:\n\nfunction testjac(J,du,u,p,gamma,t)\n  J[1,1] = gamma - 2.0 + 1.2 * u[2]\n  J[1,2] = 1.2 * u[1]\n  J[2,1] = - 1 * u[2]\n  J[2,2] = gamma - 3 - u[1]\n  nothing\nend\n\nSymbolically Generating the Functions\n\nSee the modelingtoolkitize function from ModelingToolkit.jl for automatically symbolically generating the Jacobian and more from the  numerically-defined functions.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.SDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.SDDEFunction","text":"SDDEFunction{iip,F,G,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,GG,S,O,TCV} <: AbstractSDDEFunction{iip}\n\nA representation of a SDDE function f, defined by:\n\nM du = f(uhpt) dt + g(uhpt) dW_t\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nSDDEFunction{iip,recompile}(f,g;\n                 mass_matrix=I,\n                 analytic=nothing,\n                 tgrad=nothing,\n                 jac=nothing,\n                 jvp=nothing,\n                 vjp=nothing,\n                 jac_prototype=nothing,\n                 sparsity=jac_prototype,\n                 paramjac = nothing,\n                 syms = nothing,\n                 indepsym = nothing,\n                 colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,h,p,t) or du = f(u,h,p,t). See the section on iip for more details on in-place vs out-of-place handling. The histroy function h acts as an interpolator over time, i.e. h(t) with options matching the solution interface, i.e. h(t; save_idxs = 2).\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,h,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,h,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,h,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,h,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,h,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/Surrogates/ackley/#Ackley-function","page":"Ackley function","title":"Ackley function","text":"","category":"section"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"The Ackley function is defined as: f(x) = -a*exp(-bsqrtfrac1dsum_i=1^d x_i^2) - exp(frac1d sum_i=1^d cos(cx_i)) + a + exp(1) Usually the recommended values are: a =  20, b = 02 and c =  2pi","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"Let's see the 1D case.","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"Now, let's define the Ackley function:","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"function ackley(x)\n    a, b, c = 20.0, -0.2, 2.0*π\n    len_recip = inv(length(x))\n    sum_sqrs = zero(eltype(x))\n    sum_cos = sum_sqrs\n    for i in x\n        sum_cos += cos(c*i)\n        sum_sqrs += i^2\n    end\n    return (-a * exp(b * sqrt(len_recip*sum_sqrs)) -\n            exp(len_recip*sum_cos) + a + 2.71)\nend","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"n = 100\nlb = -32.768\nub = 32.768\nx = sample(n, lb, ub, SobolSample())\ny = ackley.(x)\nxs = lb:0.001:ub\nscatter(x, y, label=\"Sampled points\", xlims=(lb, ub), ylims=(0,30), legend=:top)\nplot!(xs, ackley.(xs), label=\"True function\", legend=:top)","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"my_rad = RadialBasis(x, y, lb, ub)\nmy_krig = Kriging(x, y, lb, ub)\nmy_loba = LobachevskySurrogate(x, y, lb, ub)","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"scatter(x, y, label=\"Sampled points\", xlims=(lb, ub), ylims=(0, 30), legend=:top)\nplot!(xs, ackley.(xs), label=\"True function\", legend=:top)\nplot!(xs, my_rad.(xs), label=\"Polynomial expansion\", legend=:top)\nplot!(xs, my_krig.(xs), label=\"Lobachevsky\", legend=:top)\nplot!(xs, my_loba.(xs), label=\"Kriging\", legend=:top)","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"The fit looks good. Let's now see if we are able to find the minimum value using optimization methods:","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"surrogate_optimize(ackley,DYCORS(),lb,ub,my_rad,UniformSample())\nscatter(x, y, label=\"Sampled points\", xlims=(lb, ub), ylims=(0, 30), legend=:top)\nplot!(xs, ackley.(xs), label=\"True function\", legend=:top)\nplot!(xs, my_rad.(xs), label=\"Radial basis optimized\", legend=:top)","category":"page"},{"location":"copies/Surrogates/ackley/","page":"Ackley function","title":"Ackley function","text":"The DYCORS methods successfully finds the minimum.","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/#Optimization-of-Stochastic-Differential-Equations","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Here we demonstrate sensealg = ForwardDiffSensitivity() (provided by DiffEqSensitivity.jl) for forward-mode automatic differentiation of a small stochastic differential equation. For large parameter equations, like neural stochastic differential equations, you should use reverse-mode automatic differentiation. However, forward-mode can be more efficient for low numbers of parameters (<100). (Note: the default is reverse-mode AD which is more suitable for things like neural SDEs!)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/#Example-1:-Fitting-Data-with-SDEs-via-Method-of-Moments-and-Parallelism","page":"Optimization of Stochastic Differential Equations","title":"Example 1: Fitting Data with SDEs via Method of Moments and Parallelism","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Let's do the most common scenario: fitting data. Let's say our ecological system is a stochastic process. Each time we solve this equation we get a different solution, so we need a sensible data source.","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"using DiffEqFlux, DifferentialEquations, Plots\nfunction lotka_volterra!(du,u,p,t)\n  x,y = u\n  α,β,γ,δ = p\n  du[1] = dx = α*x - β*x*y\n  du[2] = dy = δ*x*y - γ*y\nend\nu0 = [1.0,1.0]\ntspan = (0.0,10.0)\n\nfunction multiplicative_noise!(du,u,p,t)\n  x,y = u\n  du[1] = p[5]*x\n  du[2] = p[6]*y\nend\np = [1.5,1.0,3.0,1.0,0.3,0.3]\n\nprob = SDEProblem(lotka_volterra!,multiplicative_noise!,u0,tspan,p)\nsol = solve(prob)\nplot(sol)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Let's assume that we are observing the seasonal behavior of this system and have 10,000 years of data, corresponding to 10,000 observations of this timeseries. We can utilize this to get the seasonal means and variances. To simulate that scenario, we will generate 10,000 trajectories from the SDE to build our dataset:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"using Statistics\nensembleprob = EnsembleProblem(prob)\n@time sol = solve(ensembleprob,SOSRI(),saveat=0.1,trajectories=10_000)\ntruemean = mean(sol,dims=3)[:,:]\ntruevar  = var(sol,dims=3)[:,:]","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"From here, we wish to utilize the method of moments to fit the SDE's parameters. Thus our loss function will be to solve the SDE a bunch of times and compute moment equations and use these as our loss against the original series. We then plot the evolution of the means and variances to verify the fit. For example:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"function loss(p)\n  tmp_prob = remake(prob,p=p)\n  ensembleprob = EnsembleProblem(tmp_prob)\n  tmp_sol = solve(ensembleprob,SOSRI(),saveat=0.1,trajectories=1000)\n  arrsol = Array(tmp_sol)\n  sum(abs2,truemean - mean(arrsol,dims=3)) + 0.1sum(abs2,truevar - var(arrsol,dims=3)),arrsol\nend\n\nfunction cb2(p,l,arrsol)\n  @show p,l\n  means = mean(arrsol,dims=3)[:,:]\n  vars = var(arrsol,dims=3)[:,:]\n  p1 = plot(sol[1].t,means',lw=5)\n  scatter!(p1,sol[1].t,truemean')\n  p2 = plot(sol[1].t,vars',lw=5)\n  scatter!(p2,sol[1].t,truevar')\n  p = plot(p1,p2,layout = (2,1))\n  display(p)\n  false\nend","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"We can then use sciml_train to fit the SDE:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"pinit = [1.2,0.8,2.5,0.8,0.1,0.1]\n@time res = DiffEqFlux.sciml_train(loss,pinit,ADAM(0.05),cb=cb2,maxiters = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"The final print out was:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"(p, l) = ([1.5242134195974462, 1.019859938499017, 2.9120928257869227, 0.9840408090733335, 0.29427123791721765, 0.3334393815923646], 1.7046719990657184)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Notice that both the parameters of the deterministic drift equations and the stochastic portion (the diffusion equation) are fit through this process! Also notice that the final fit of the moment equations is close:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"The time for the full fitting process was:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"250.654845 seconds (4.69 G allocations: 104.868 GiB, 11.87% gc time)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"approximately 4 minutes.","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/#Example-2:-Fitting-SDEs-via-Bayesian-Quasi-Likelihood-Approaches","page":"Optimization of Stochastic Differential Equations","title":"Example 2: Fitting SDEs via Bayesian Quasi-Likelihood Approaches","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"An inference method which can be much more efficient in many cases is the quasi-likelihood approach. This approach matches the random likelihood of the SDE output with the random sampling of a Bayesian inference problem to more efficiently directly estimate the posterior distribution. For more information, please see the Turing.jl Bayesian Differential Equations tutorial","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/#Example-3:-Controlling-SDEs-to-an-objective","page":"Optimization of Stochastic Differential Equations","title":"Example 3: Controlling SDEs to an objective","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"In this example, we will find the parameters of the SDE that force the solution to be close to the constant 1.","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"using DifferentialEquations, DiffEqFlux, Plots\n\nfunction lotka_volterra!(du, u, p, t)\n  x, y = u\n  α, β, δ, γ = p\n  du[1] = dx = α*x - β*x*y\n  du[2] = dy = -δ*y + γ*x*y\nend\n\nfunction lotka_volterra_noise!(du, u, p, t)\n  du[1] = 0.1u[1]\n  du[2] = 0.1u[2]\nend\n\nu0 = [1.0,1.0]\ntspan = (0.0, 10.0)\np = [2.2, 1.0, 2.0, 0.4]\nprob_sde = SDEProblem(lotka_volterra!, lotka_volterra_noise!, u0, tspan)\n\n\nfunction predict_sde(p)\n  return Array(solve(prob_sde, SOSRI(), p=p,\n               sensealg = ForwardDiffSensitivity(), saveat = 0.1))\nend\n\nloss_sde(p) = sum(abs2, x-1 for x in predict_sde(p))","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"For this training process, because the loss function is stochastic, we will use the ADAM optimizer from Flux.jl. The sciml_train function is the same as before. However, to speed up the training process, we will use a global counter so that way we only plot the current results every 10 iterations. This looks like:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"callback = function (p, l)\n  display(l)\n  remade_solution = solve(remake(prob_sde, p = p), SOSRI(), saveat = 0.1)\n  plt = plot(remade_solution, ylim = (0, 6))\n  display(plt)\n  return false\nend","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"Let's optimize","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"result_sde = DiffEqFlux.sciml_train(loss_sde, p, ADAM(0.1),\n                                    cb = callback, maxiters = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/optimization_sde/","page":"Optimization of Stochastic Differential Equations","title":"Optimization of Stochastic Differential Equations","text":"(Image: )","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#linearsystemsolvers","page":"Linear System Solvers","title":"Linear System Solvers","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"solve(prob::LinearProlem,alg;kwargs)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Solves for Au=b in the problem defined by prob using the algorithm alg. If no algorithm is given, a default algorithm will be chosen.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Recommended-Methods","page":"Linear System Solvers","title":"Recommended Methods","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The default algorithm nothing is good for choosing an algorithm that will work, but one may need to change this to receive more performance or precision. If more precision is necessary, QRFactorization() and SVDFactorization() are the best choices, with SVD being the slowest but most precise.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"For efficiency, RFLUFactorization is the fastest for dense LU-factorizations. For sparse LU-factorizations, KLUFactorization if there is less structure to the sparsity pattern and UMFPACKFactorization if there is more structure. Pardiso.jl's methods are also known to be very efficient sparse linear solvers.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"As sparse matrices get larger, iterative solvers tend to get more efficient than factorization methods if a lower tolerance of the solution is required.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"IterativeSolvers.jl uses a low-rank Q update in its GMRES so it tends to be faster than Krylov.jl for CPU-based arrays, but it's only compatible with CPU-based arrays while Krylov.jl is more general and will support accelerators like CUDA. Krylov.jl works with CPUs and GPUs and tends to be more efficient than other Krylov-based methods.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Finally, a user can pass a custom function for handling the linear solve using LinearSolveFunction() if existing solvers are not optimally suited for their application. The interface is detailed here","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Full-List-of-Methods","page":"Linear System Solvers","title":"Full List of Methods","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/#RecursiveFactorization.jl","page":"Linear System Solvers","title":"RecursiveFactorization.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"RFLUFactorization(): a fast pure Julia LU-factorization implementation using RecursiveFactorization.jl. This is by far the fastest LU-factorization implementation, usually outperforming OpenBLAS and MKL, but generally optimized only for Base Array with Float32, Float64, ComplexF32, and ComplexF64.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Base.LinearAlgebra","page":"Linear System Solvers","title":"Base.LinearAlgebra","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"These overloads tend to work for many array types, such as CuArrays for GPU-accelerated solving, using the overloads provided by the respective packages. Given that this can be customized per-package, details given below describe a subset of important arrays (Matrix, SparseMatrixCSC, CuMatrix, etc.)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"LUFactorization(pivot=LinearAlgebra.RowMaximum()): Julia's built in lu.\nOn dense matrices this uses the current BLAS implementation of the user's computer which by default is OpenBLAS but will use MKL if the user does using MKL in their system.\nOn sparse matrices this will use UMFPACK from SuiteSparse. Note that this will not cache the symbolic factorization.\nOn CuMatrix it will use a CUDA-accelerated LU from CuSolver.\nOn BandedMatrix and BlockBandedMatrix it will use a banded LU.\nQRFactorization(pivot=LinearAlgebra.NoPivot(),blocksize=16): Julia's built in qr.\nOn dense matrices this uses the current BLAS implementation of the user's computer which by default is OpenBLAS but will use MKL if the user does using MKL in their system.\nOn sparse matrices this will use SPQR from SuiteSparse\nOn CuMatrix it will use a CUDA-accelerated QR from CuSolver.\nOn BandedMatrix and BlockBandedMatrix it will use a banded QR.\nSVDFactorization(full=false,alg=LinearAlgebra.DivideAndConquer()): Julia's built in svd.\nOn dense matrices this uses the current BLAS implementation of the user's computer which by default is OpenBLAS but will use MKL if the user does using MKL in their system.\nGenericFactorization(fact_alg): Constructs a linear solver from a generic factorization algorithm fact_alg which complies with the Base.LinearAlgebra factorization API. Quoting from Base:\nIf A is upper or lower triangular (or diagonal), no factorization of A is required and the system is solved with either forward or backward substitution. For non-triangular square matrices, an LU factorization is used. For rectangular A the result is the minimum-norm least squares solution computed by a pivoted QR factorization of A and a rank estimate of A based on the R factor. When A is sparse, a similar polyalgorithm is used. For indefinite matrices, the LDLt factorization does not use pivoting during the numerical factorization and therefore the procedure can fail even for invertible matrices.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#LinearSolve.jl","page":"Linear System Solvers","title":"LinearSolve.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"LinearSolve.jl contains some linear solvers built in.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"SimpleLUFactorization: a simple LU-factorization implementation without BLAS. Fast for small matrices.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#SuiteSparse.jl","page":"Linear System Solvers","title":"SuiteSparse.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"By default, the SuiteSparse.jl are implemented for efficiency by caching the symbolic factorization. I.e. if set_A is used, it is expected that the new A has the same sparsity pattern as the previous A. If this algorithm is to be used in a context where that assumption does not hold, set reuse_symbolic=false.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"KLUFactorization(;reuse_symbolic=true): A fast sparse LU-factorization which specializes on sparsity patterns with \"less structure\".\nUMFPACKFactorization(;reuse_symbolic=true): A fast sparse multithreaded LU-factorization which specializes on sparsity patterns that are more structured.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Pardiso.jl","page":"Linear System Solvers","title":"Pardiso.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"note: Note\nUsing this solver requires adding the package LinearSolvePardiso.jl","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The following algorithms are pre-specified:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"MKLPardisoFactorize(;kwargs...): A sparse factorization method.\nMKLPardisoIterate(;kwargs...): A mixed factorization+iterative method.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Those algorithms are defined via:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"MKLPardisoFactorize(;kwargs...) = PardisoJL(;fact_phase=Pardiso.NUM_FACT,\n                                             solve_phase=Pardiso.SOLVE_ITERATIVE_REFINE,\n                                             kwargs...)\nMKLPardisoIterate(;kwargs...) = PardisoJL(;solve_phase=Pardiso.NUM_FACT_SOLVE_REFINE,\n                                           kwargs...)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The full set of keyword arguments for PardisoJL are:                         ","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Base.@kwdef struct PardisoJL <: SciMLLinearSolveAlgorithm\n    nprocs::Union{Int, Nothing} = nothing\n    solver_type::Union{Int, Pardiso.Solver, Nothing} = nothing\n    matrix_type::Union{Int, Pardiso.MatrixType, Nothing} = nothing\n    fact_phase::Union{Int, Pardiso.Phase, Nothing} = nothing\n    solve_phase::Union{Int, Pardiso.Phase, Nothing} = nothing\n    release_phase::Union{Int, Nothing} = nothing\n    iparm::Union{Vector{Tuple{Int,Int}}, Nothing} = nothing\n    dparm::Union{Vector{Tuple{Int,Int}}, Nothing} = nothing\nend","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#CUDA.jl","page":"Linear System Solvers","title":"CUDA.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Note that CuArrays are supported by GenericFactorization in the \"normal\" way. The following are non-standard GPU factorization routines.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"note: Note\nUsing this solver requires adding the package LinearSolveCUDA.jl","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"CudaOffloadFactorization(): An offloading technique used to GPU-accelerate CPU-based computations. Requires a sufficiently large A to overcome the data transfer costs.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#IterativeSolvers.jl","page":"Linear System Solvers","title":"IterativeSolvers.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"IterativeSolversJL_CG(args...;kwargs...): A generic CG implementation\nIterativeSolversJL_GMRES(args...;kwargs...): A generic GMRES implementation\nIterativeSolversJL_BICGSTAB(args...;kwargs...): A generic BICGSTAB implementation\nIterativeSolversJL_MINRES(args...;kwargs...): A generic MINRES implementation","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The general algorithm is:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"IterativeSolversJL(args...;\n                   generate_iterator = IterativeSolvers.gmres_iterable!,\n                   Pl=nothing, Pr=nothing,\n                   gmres_restart=0, kwargs...)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Krylov.jl","page":"Linear System Solvers","title":"Krylov.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"KrylovJL_CG(args...;kwargs...): A generic CG implementation\nKrylovJL_GMRES(args...;kwargs...): A generic GMRES implementation\nKrylovJL_BICGSTAB(args...;kwargs...): A generic BICGSTAB implementation\nKrylovJL_MINRES(args...;kwargs...): A generic MINRES implementation","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The general algorithm is:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"KrylovJL(args...; KrylovAlg = Krylov.gmres!,\n                  Pl=nothing, Pr=nothing,\n                  gmres_restart=0, window=0,\n                  kwargs...)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#KrylovKit.jl","page":"Linear System Solvers","title":"KrylovKit.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"KrylovKitJL_CG(args...;kwargs...): A generic CG implementation\nKrylovKitJL_GMRES(args...;kwargs...): A generic GMRES implementation","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The general algorithm is:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"function KrylovKitJL(args...;\n                     KrylovAlg = KrylovKit.GMRES, gmres_restart = 0,\n                     kwargs...)","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#units","page":"Model Validation and Units","title":"Model Validation and Units","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"ModelingToolkit.jl provides extensive functionality for model validation and unit checking. This is done by providing metadata to the variable types and then running the validation functions which identify malformed systems and non-physical equations. This approach provides high performance and compatibility with numerical solvers.","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#Assigning-Units","page":"Model Validation and Units","title":"Assigning Units","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Units may assigned with the following syntax. ","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"using ModelingToolkit, Unitful\r\n@variables t [unit = u\"s\"] x(t) [unit = u\"m\"] g(t) w(t) [unit = \"Hz\"]\r\n\r\n@variables(t, [unit = u\"s\"], x(t), [unit = u\"m\"], g(t), w(t), [unit = \"Hz\"])\r\n\r\n@variables(begin\r\nt, [unit = u\"s\"],\r\nx(t), [unit = u\"m\"],\r\ng(t),\r\nw(t), [unit = \"Hz\"]\r\nend)\r\n\r\n# Simultaneously set default value (use plain numbers, not quantities)\r\n@variable x=10 [unit = u\"m\"]\r\n\r\n# Symbolic array: unit applies to all elements\r\n@variable x[1:3] [unit = u\"m\"]","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Do not use quantities such as  1u\"s\", 1/u\"s\" or u\"1/s\" as these will result in errors; instead use u\"s\", u\"s^-1\", or u\"s\"^-1. ","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#Unit-Validation-and-Inspection","page":"Model Validation and Units","title":"Unit Validation & Inspection","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Unit validation of equations happens automatically when creating a system. However, for debugging purposes one may wish to validate the equations directly using validate.","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"ModelingToolkit.validate","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#ModelingToolkit.validate","page":"Model Validation and Units","title":"ModelingToolkit.validate","text":"Returns true iff units of equations are valid.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Inside, validate uses get_unit, which may be directly applied to any term. Note that validate will not throw an error in the event of incompatible units, but get_unit will. If you would rather receive a warning instead of an error, use safe_get_unit which will yield nothing in the event of an error. Unit agreement is tested with ModelingToolkit.equivalent(u1,u2). ","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"ModelingToolkit.get_unit","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#ModelingToolkit.get_unit","page":"Model Validation and Units","title":"ModelingToolkit.get_unit","text":"Find the unit of a symbolic item.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Example usage below. Note that ModelingToolkit does not force unit conversions to preferred units in the event of nonstandard combinations – it merely checks that the equations are consistent. ","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"using ModelingToolkit, Unitful\r\n@parameters τ [unit = u\"ms\"]\r\n@variables t [unit = u\"ms\"] E(t) [unit = u\"kJ\"] P(t) [unit = u\"MW\"]\r\nD = Differential(t)\r\neqs = eqs = [D(E) ~ P - E/τ,\r\n                0 ~ P       ]\r\nModelingToolkit.validate(eqs) #Returns true\r\nModelingToolkit.validate(eqs[1]) #Returns true\r\nModelingToolkit.get_unit(eqs[1].rhs) #Returns u\"kJ ms^-1\"","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"An example of an inconsistent system: at present, ModelingToolkit requires that the units of all terms in an equation or sum to be equal-valued (ModelingToolkit.equivalent(u1,u2)), rather that simply dimensionally consistent. In the future, the validation stage may be upgraded to support the insertion of conversion factors into the equations. ","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"using ModelingToolkit, Unitful\r\n@parameters τ [unit = u\"ms\"]\r\n@variables t [unit = u\"ms\"] E(t) [unit = u\"J\"] P(t) [unit = u\"MW\"]\r\nD = Differential(t)\r\neqs = eqs = [D(E) ~ P - E/τ,\r\n                0 ~ P       ]\r\nModelingToolkit.validate(eqs) #Returns false while displaying a warning message","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#User-Defined-Registered-Functions-and-Types","page":"Model Validation and Units","title":"User-Defined Registered Functions and Types","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"In order to validate user-defined types and registered functions, specialize get_unit.  Single-parameter calls to get_unit expect an object type, while two-parameter calls expect a function type as the first argument, and a vector of arguments as the  second argument.","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"using ModelingToolkit\r\n# Composite type parameter in registered function\r\n@parameters t\r\nD = Differential(t)\r\nstruct NewType\r\n    f\r\nend\r\n@register_symbolic dummycomplex(complex::Num, scalar)\r\ndummycomplex(complex, scalar) = complex.f - scalar\r\n\r\nc = NewType(1)\r\nMT.get_unit(x::NewType) = MT.get_unit(x.f)\r\nfunction MT.get_unit(op::typeof(dummycomplex),args)\r\n    argunits = MT.get_unit.(args)\r\n    MT.get_unit(-,args)\r\nend\r\n\r\nsts = @variables a(t)=0 [unit = u\"cm\"]\r\nps = @parameters s=-1 [unit = u\"cm\"] c=c [unit = u\"cm\"]\r\neqs = [D(a) ~ dummycomplex(c, s);]\r\nsys = ODESystem(eqs, t, [sts...;], [ps...;], name=:sys)\r\nsys_simple = structural_simplify(sys)","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#Unitful-Literals","page":"Model Validation and Units","title":"Unitful Literals","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"In order for a function to work correctly during both validation & execution, the function must be unit-agnostic. That is, no unitful literals may be used. Any unitful quantity must either be a parameter or variable. For example, these equations will not validate successfully. ","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"using ModelingToolkit, Unitful\r\n@variables t [unit = u\"ms\"] E(t) [unit = u\"J\"] P(t) [unit = u\"MW\"]\r\nD = Differential(t)\r\neqs = [D(E) ~ P - E/1u\"ms\"   ]\r\nModelingToolkit.validate(eqs) #Returns false while displaying a warning message\r\n\r\nmyfunc(E) = E/1u\"ms\"\r\neqs = [D(E) ~ P - myfunc(E) ]\r\nModelingToolkit.validate(eqs) #Returns false while displaying a warning message","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Instead, they should be parameterized:","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"using ModelingToolkit, Unitful\r\n@parameters τ [unit = u\"ms\"]\r\n@variables t [unit = u\"ms\"] E(t) [unit = u\"kJ\"] P(t) [unit = u\"MW\"]\r\nD = Differential(t)\r\neqs = [D(E) ~ P - E/τ]\r\nModelingToolkit.validate(eqs) #Returns true\r\n\r\nmyfunc(E,τ) = E/τ \r\neqs = [D(E) ~ P - myfunc(E,τ)]\r\nModelingToolkit.validate(eqs) #Returns true","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"It is recommended not to circumvent unit validation by specializing user-defined functions on Unitful arguments vs. Numbers. This both fails to take advantage of validate for ensuring correctness, and may cause in errors in the future when ModelingToolkit is extended to support eliminating Unitful literals from functions.","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#Other-Restrictions","page":"Model Validation and Units","title":"Other Restrictions","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Unitful provides non-scalar units such as dBm, °C, etc. At this time, ModelingToolkit only supports scalar quantities. Additionally, angular degrees (°) are not supported because trigonometric functions will treat plain numerical values as radians, which would lead systems validated using degrees to behave erroneously when being solved. ","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#Troubleshooting-and-Gotchas","page":"Model Validation and Units","title":"Troubleshooting & Gotchas","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"If a system fails to validate due to unit issues, at least one warning message will appear, including a line number as well as the unit types and expressions that were in conflict. Some system constructors re-order equations before the unit checking can be done, in which case the equation numbers may be inaccurate. The printed expression that the problem resides in is always correctly shown.","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Symbolic exponents for unitful variables are supported (ex: P^γ in thermodynamics). However, this means that ModelingToolkit cannot reduce such expressions to Unitful.Unitlike subtypes at validation time because the exponent value is not available. In this case ModelingToolkit.get_unit is type-unstable, yielding a symbolic result, which can still be checked for symbolic equality with ModelingToolkit.equivalent. ","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/#Parameter-and-Initial-Condition-Values","page":"Model Validation and Units","title":"Parameter & Initial Condition Values","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Parameter and initial condition values are supplied to problem constructors as plain numbers, with the understanding that they have been converted to the appropriate units. This is done for simplicity of interfacing with optimization solvers. Some helper function for dealing with value maps:","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"remove_units(p::Dict) = Dict(k => Unitful.ustrip(ModelingToolkit.get_unit(k),v) for (k,v) in p)\r\nadd_units(p::Dict) = Dict(k => v*ModelingToolkit.get_unit(k) for (k,v) in p)","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"Recommended usage:","category":"page"},{"location":"copies/ModelingToolkit/basics/Validation/","page":"Model Validation and Units","title":"Model Validation and Units","text":"pars = @parameters τ [unit = u\"ms\"]\r\np = Dict(τ => 1u\"ms\")\r\nODEProblem(sys,remove_units(u0),tspan,remove_units(p))","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/#Component-Based-Modeling-a-Spring-Mass-System","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"In this tutorial we will build a simple component-based model of a spring-mass system. A spring-mass system consists of one or more masses connected by springs. Hooke's law gives the force exerted by a spring when it is extended or compressed by a given distance. This specifies a differential-equation system where the acceleration of the masses is specified using the forces acting on them.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/#Copy-Paste-Example","page":"Component-Based Modeling a Spring-Mass System","title":"Copy-Paste Example","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"using ModelingToolkit, Plots, DifferentialEquations, LinearAlgebra\nusing Symbolics: scalarize\n\n@variables t\nD = Differential(t)\n\nfunction Mass(; name, m = 1.0, xy = [0., 0.], u = [0., 0.])\n    ps = @parameters m=m\n    sts = @variables pos[1:2](t)=xy v[1:2](t)=u\n    eqs = scalarize(D.(pos) .~ v)\n    ODESystem(eqs, t, [pos..., v...], ps; name)\nend\n\nfunction Spring(; name, k = 1e4, l = 1.)\n    ps = @parameters k=k l=l\n    @variables x(t), dir[1:2](t)\n    ODESystem(Equation[], t, [x, dir...], ps; name)\nend\n\nfunction connect_spring(spring, a, b)\n    [\n        spring.x ~ norm(scalarize(a .- b))\n        scalarize(spring.dir .~ scalarize(a .- b))\n    ]\nend\n\nspring_force(spring) = -spring.k .* scalarize(spring.dir) .* (spring.x - spring.l)  ./ spring.x\n\nm = 1.0\nxy = [1., -1.]\nk = 1e4\nl = 1.\ncenter = [0., 0.]\ng = [0., -9.81]\n@named mass = Mass(m=m, xy=xy)\n@named spring = Spring(k=k, l=l)\n\neqs = [\n    connect_spring(spring, mass.pos, center)\n    scalarize(D.(mass.v) .~ spring_force(spring) / mass.m .+ g)\n]\n\n@named _model = ODESystem(eqs, t, [spring.x; spring.dir; mass.pos], [])\n@named model = compose(_model, mass, spring)\nsys = structural_simplify(model)\n\nprob = ODEProblem(sys, [], (0., 3.))\nsol = solve(prob, Rosenbrock23())\nplot(sol)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/#Explanation","page":"Component-Based Modeling a Spring-Mass System","title":"Explanation","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/#Building-the-components","page":"Component-Based Modeling a Spring-Mass System","title":"Building the components","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"For each component we use a Julia function that returns an ODESystem. At the top, we define the fundamental properties of a Mass: it has a mass m, a position pos and a velocity v. We also define that the velocity is the rate of change of position with respect to time.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"function Mass(; name, m = 1.0, xy = [0., 0.], u = [0., 0.])\n    ps = @parameters m=m\n    sts = @variables pos[1:2](t)=xy v[1:2](t)=u\n    eqs = scalarize(D.(pos) .~ v)\n    ODESystem(eqs, t, [pos..., v...], ps; name)\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"Note that this is an incompletely specified ODESystem. It cannot be simulated on its own since the equations for the velocity v[1:2](t) are unknown. Notice the addition of a name keyword. This allows us to generate different masses with different names. A Mass can now be constructed as:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"Mass(name = :mass1)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"Or using the @named helper macro","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"@named mass1 = Mass()","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"Next we build the spring component. It is characterised by the spring constant k and the length l of the spring when no force is applied to it. The state of a spring is defined by its current length and direction.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"function Spring(; name, k = 1e4, l = 1.)\n    ps = @parameters k=k l=l\n    @variables x(t), dir[1:2](t)\n    ODESystem(Equation[], t, [x, dir...], ps; name)\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"We now define functions that help construct the equations for a mass-spring system. First, the connect_spring function connects a spring between two positions a and b. Note that a and b can be the pos of a Mass, or just a fixed position such as [0., 0.]. In that sense, the length of the spring x is given by the length of the vector dir joining a and b.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"function connect_spring(spring, a, b)\n    [\n        spring.x ~ norm(scalarize(a .- b))\n        scalarize(spring.dir .~ scalarize(a .- b))\n    ]\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"Lastly, we define the spring_force function that takes a spring and returns the force exerted by this spring.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"spring_force(spring) = -spring.k .* scalarize(spring.dir) .* (spring.x - spring.l)  ./ spring.x","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"To create our system, we will first create the components: a mass and a spring. This is done as follows:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"m = 1.0\nxy = [1., -1.]\nk = 1e4\nl = 1.\ncenter = [0., 0.]\ng = [0., -9.81]\n@named mass = Mass(m=m, xy=xy)\n@named spring = Spring(k=k, l=l)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"We can now create the equations describing this system, by connecting spring to mass and a fixed point.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"eqs = [\n    connect_spring(spring, mass.pos, center)\n    scalarize(D.(mass.v) .~ spring_force(spring) / mass.m .+ g)\n]","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"Finally, we can build the model using these equations and components.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"@named _model = ODESystem(eqs, t, [spring.x; spring.dir; mass.pos], [])\n@named model = compose(_model, mass, spring)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"We can take a look at the equations in the model using the equations function.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"equations(model)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"The states of this model are:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"states(model)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"And the parameters of this model are:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"parameters(model)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/#Simplifying-and-solving-this-system","page":"Component-Based Modeling a Spring-Mass System","title":"Simplifying and solving this system","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"This system can be solved directly as a DAE using one of the DAE solvers from DifferentialEquations.jl. However, we can symbolically simplify the system first beforehand. Running structural_simplify eliminates unnecessary variables from the model to give the leanest numerical representation of the system.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"sys = structural_simplify(model)\nequations(sys)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"We are left with only 4 equations involving 4 state variables (mass.pos[1], mass.pos[2], mass.v[1], mass.v[2]). We can solve the system by converting it to an ODEProblem. Some observed variables are not expanded by default. To view the complete equations, one can do","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"full_equations(sys)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"This is done as follows:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"prob = ODEProblem(sys, [], (0., 3.))\nsol = solve(prob, Rosenbrock23())\nplot(sol)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"What if we want the timeseries of a different variable? That information is not lost! Instead, structural_simplify simply changes state variables into observed variables.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"observed(sys)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"These are explicit algebraic equations which can be used to reconstruct the required variables on the fly. This leads to dramatic computational savings since implicitly solving an ODE scales as O(n^3), so fewer states are significantly better!","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"We can access these variables using the solution object. For example, let's retrieve the x-position of the mass over time:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"sol[mass.pos[1]]","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"We can also plot the path of the mass:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/spring_mass/","page":"Component-Based Modeling a Spring-Mass System","title":"Component-Based Modeling a Spring-Mass System","text":"plot(sol, vars = (mass.pos[1], mass.pos[2]))","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/#Evolutionary.jl","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary is a Julia package implementing various evolutionary and genetic algorithm.","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/#Installation:-OptimizationCMAEvolutionStrategy.jl","page":"Evolutionary.jl","title":"Installation: OptimizationCMAEvolutionStrategy.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"To use this package, install the OptimizationCMAEvolutionStrategy package:","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"import Pkg; Pkg.add(\"OptimizationCMAEvolutionStrategy\")","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/#Global-Optimizer","page":"Evolutionary.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/evolutionary/#Without-Constraint-Equations","page":"Evolutionary.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"The methods in Evolutionary are performing global optimization on problems without constraint equations. These methods work both with and without lower and upper constraints set by lb and ub in the OptimizationProblem.","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"A Evolutionary algorithm is called by one of the following:","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Evolutionary.GA(): Genetic Algorithm optimizer\nEvolutionary.DE(): Differential Evolution optimizer\nEvolutionary.ES(): Evolution Strategy algorithm\nEvolutionary.CMAES(): Covariance Matrix Adaptation Evolution Strategy algorithm","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"Algorithm specific options are defined as kwargs. See the respective documentation for more detail.","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/#Example","page":"Evolutionary.jl","title":"Example","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"The Rosenbrock function can optimized using the Evolutionary.CMAES() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/evolutionary/","page":"Evolutionary.jl","title":"Evolutionary.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, Evolutionary.CMAES(μ =40 , λ = 100))","category":"page"},{"location":"copies/GlobalSensitivity/#Global-Sensitivity-Analysis","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"Global Sensitivity Analysis","text":"","category":"section"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"Global Sensitivity Analysis (GSA) methods are used to quantify the uncertainty in output of a model w.r.t. the parameters. These methods allow practitioners to  measure both parameter's individual contributions and the contribution of their interactions to the output uncertainity. ","category":"page"},{"location":"copies/GlobalSensitivity/#Installation","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"Installation","text":"","category":"section"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"To use this functionality, you must install GlobalSensitivity.jl:","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"]add GlobalSensitivity\nusing GlobalSensitivity","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"Note: GlobalSensitivity.jl is unrelated to the GlobalSensitivityAnalysis.jl package.","category":"page"},{"location":"copies/GlobalSensitivity/#General-Interface","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"General Interface","text":"","category":"section"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"The general interface for calling a global sensitivity analysis is either:","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"effects = gsa(f, method, param_range; N, batch=false)","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"where:","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"y=f(x) is a function that takes in a single vector and spits out a single vector or scalar. If batch=true, then f takes in a matrix where each row is a set of parameters, and returns a matrix where each row is a the output for the corresponding row of parameters.\nmethod is one of the GSA methods below.\nparam_range is a vector of tuples for the upper and lower bound for the given parameter i.\nN is a required keyword argument for the number of samples to take in the trajectories/design.","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"Note that for some methods there is a second interface where one can directly pass the design matrices:","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"effects = gsa(f, method, A, B; batch=false)","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"where A and B are design matrices with each row being a set of parameters. Note that generate_design_matrices from QuasiMonteCarlo.jl can be used to generate the design matrices.","category":"page"},{"location":"copies/GlobalSensitivity/","page":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","title":"GlobalSensitivity.jl: Global Sensitivity Analysis (GSA)","text":"The descriptions of the available methods can be found in the Methods section. The GSA interface allows for utilizing batched functions with the batch kwarg discussed above for parallel  computation of GSA results.","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/divergence/#Handling-Divergent-and-Unstable-Trajectories","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"It is not uncommon for a set of parameters in an ODE model to simply give a divergent trajectory. If the rate of growth compounds and outpaces the rate of decay, you will end up at infinity in finite time. This it is not uncommon to see divergent trajectories in the optimization of parameters, as many times an optimizer can take an excursion into a parameter regime which simply gives a model with an infinite solution.","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"This can be addressed by using the retcode system. In DifferentialEquations.jl, RetCodes detail the status of the returned solution. Thus if the retcode corresponds to a failure, we can use this to give an infinite loss and effectively discard the parameters. This is shown in the loss function:","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"function loss(p)\n  tmp_prob = remake(prob, p=p)\n  tmp_sol = solve(tmp_prob,Tsit5(),saveat=0.1)\n  if tmp_sol.retcode == :Success\n    return sum(abs2,Array(tmp_sol) - dataset)\n  else\n    return Inf\n  end\nend","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"A full example making use of this trick is:","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"using DifferentialEquations, Plots\n\nfunction lotka_volterra!(du,u,p,t)\n    rab, wol = u\n    α,β,γ,δ=p\n    du[1] = drab = α*rab - β*rab*wol\n    du[2] = dwol = γ*rab*wol - δ*wol\n    nothing\nend\n\nu0 = [1.0,1.0]\ntspan = (0.0,10.0)\np = [1.5,1.0,3.0,1.0]\nprob = ODEProblem(lotka_volterra!,u0,tspan,p)\nsol = solve(prob,saveat=0.1)\nplot(sol)\n\ndataset = Array(sol)\nscatter!(sol.t,dataset')\n\ntmp_prob = remake(prob, p=[1.2,0.8,2.5,0.8])\ntmp_sol = solve(tmp_prob)\nplot(tmp_sol)\nscatter!(sol.t,dataset')\n\nfunction loss(p)\n  tmp_prob = remake(prob, p=p)\n  tmp_sol = solve(tmp_prob,Tsit5(),saveat=0.1)\n  if tmp_sol.retcode == :Success\n    return sum(abs2,Array(tmp_sol) - dataset)\n  else\n    return Inf\n  end\nend\n\nusing DiffEqFlux\n\npinit = [1.2,0.8,2.5,0.8]\nres = DiffEqFlux.sciml_train(loss,pinit,ADAM(), maxiters = 1000)\n\n# res = DiffEqFlux.sciml_train(loss,pinit,BFGS(), maxiters = 1000) ### errors!\n\n#try Newton method of optimization\nres = DiffEqFlux.sciml_train(loss,pinit,Newton(), GalacticOptim.AutoForwardDiff())","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"You might notice that AutoZygote (default) fails for the above sciml_train call with Optim's optimizers which happens because of Zygote's behaviour for zero gradients in which case it returns nothing. To avoid such issue you can just use a different version of the same check which compares the size of the obtained  solution and the data we have, shown below, which is easier to AD.","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/divergence/","page":"Handling Divergent and Unstable Trajectories","title":"Handling Divergent and Unstable Trajectories","text":"function loss(p)\n  tmp_prob = remake(prob, p=p)\n  tmp_sol = solve(tmp_prob,Tsit5(),saveat=0.1)\n  if size(tmp_sol) == size(dataset)\n    return sum(abs2,Array(tmp_sol) .- dataset)\n  else\n    return Inf\n  end\nend","category":"page"},{"location":"copies/NonlinearSolve/basics/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Ask more questions.","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/#Nonconvex.jl","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Nonconvex is a is a Julia package implementing and wrapping nonconvex constrained optimization algorithms.","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/#Installation:-OptimizationNonconvex.jl","page":"Nonconvex.jl","title":"Installation: OptimizationNonconvex.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"To use this package, install the OptimizationNonconvex package:","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"import Pkg; Pkg.add(\"OptimizationNonconvex\")","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/#Global-Optimizer","page":"Nonconvex.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nonconvex/#Without-Constraint-Equations","page":"Nonconvex.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"A Nonconvex algorithm is called using one of the following:","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Method of moving asymptotes (MMA):\nMMA87()\nMMA02()\nIpopt:\nIpoptAlg()\nNLopt:\nNLoptAlg(solver) where solver can be any of the NLopt algorithms\nAugmented Lagrangian algorithm:\nAugLag()\nonly works with constraints\nMixed integer nonlinear programming (MINLP):\nJuniper + Ipopt: JuniperIpoptAlg()\nPavito + Ipopt + Cbc: PavitoIpoptCbcAlg()\nMulti-start optimization:\nHyperoptAlg(subsolver) where subalg can be any of the described Nonconvex algorithm\nSurrogate-assisted Bayesian optimization\nBayesOptAlg(subsolver) where subalg can be any of the described Nonconvex algorithm\nMultiple Trajectory Search\nMTSAlg()","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"When performing optimizing a combination of integer and floating-point parameters the integer keyword has to be set. It takes a boolean vector indicating which parameter is an integer.","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/#Notes","page":"Nonconvex.jl","title":"Notes","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"Some optimizer may require further options to be defined in order to work.","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The currently available algorithms are listed here","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The algorithms in Nonconvex are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/#Examples","page":"Nonconvex.jl","title":"Examples","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The Rosenbrock function can optimized using the Method of moving asymptotes algorithm MMA02() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, MMA02(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"The options of for a sub-algorithm are passed simply as a NamedTuple and GalactcOptim infers the correct Nonconvex options struct:","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, HyperoptAlg(IpoptAlg()), sub_options=(;max_iter=100))","category":"page"},{"location":"copies/Optimization/optimization_packages/nonconvex/#With-Constraint-Equations","page":"Nonconvex.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/nonconvex/","page":"Nonconvex.jl","title":"Nonconvex.jl","text":"While Nonconvex.jl supports such constraints, Optimization.jl currently does not relay these constraints.","category":"page"},{"location":"copies/DiffEqParamEstim/#DiffEqParamEstim.jl","page":"DiffEqParamEstim.jl: Parameter Estimation for Differential Equations","title":"DiffEqParamEstim.jl","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/","page":"DiffEqParamEstim.jl: Parameter Estimation for Differential Equations","title":"DiffEqParamEstim.jl: Parameter Estimation for Differential Equations","text":"DiffEqParamEstim.jl is a component package in the DifferentialEquations ecosystem. It holds the parameter estimation tools. While completely independent and usable on its own, users interested in using this functionality should check out DifferentialEquations.jl.","category":"page"},{"location":"copies/DiffEqParamEstim/#Installation","page":"DiffEqParamEstim.jl: Parameter Estimation for Differential Equations","title":"Installation","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/","page":"DiffEqParamEstim.jl: Parameter Estimation for Differential Equations","title":"DiffEqParamEstim.jl: Parameter Estimation for Differential Equations","text":"This functionality does not come standard with DifferentialEquations.jl. To use this functionality, you must install DiffEqParamEstim.jl:","category":"page"},{"location":"copies/DiffEqParamEstim/","page":"DiffEqParamEstim.jl: Parameter Estimation for Differential Equations","title":"DiffEqParamEstim.jl: Parameter Estimation for Differential Equations","text":"]add DiffEqParamEstim\nusing DiffEqParamEstim","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/#QuadDIRECT.jl","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"QuadDIRECT is a Julia package implementing QuadDIRECT algorithm (inspired by DIRECT and MCS). ","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The QuadDIRECT algorithm is called using QuadDirect(). ","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/#Installation:-OptimizationQuadDIRECT.jl","page":"QuadDIRECT.jl","title":"Installation: OptimizationQuadDIRECT.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"To use this package, install the OptimizationQuadDIRECT package:","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"import Pkg; Pkg.add(\"OptimizationQuadDIRECT\")","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Also note that QuadDIRECT should (for now) be installed by doing:","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"] add https://github.com/timholy/QuadDIRECT.jl.git","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/#Global-Optimizer","page":"QuadDIRECT.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/quaddirect/#Without-Constraint-Equations","page":"QuadDIRECT.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The algorithm in QuadDIRECT is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"Furthermore, QuadDirect requires splits which is a list of 3-vectors with initial locations at which to evaluate the function (the values must be in strictly increasing order and lie within the specified bounds) such that solve(problem, QuadDirect(), splits).","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/#Example","page":"QuadDIRECT.jl","title":"Example","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"The Rosenbrock function can optimized using the QuadDirect() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/quaddirect/","page":"QuadDIRECT.jl","title":"QuadDIRECT.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsolve(prob, QuadDirect(), splits = ([-0.9, 0, 0.9], [-0.8, 0, 0.8]))","category":"page"},{"location":"copies/Surrogates/Salustowicz/#Salustowicz-Benchmark-Function","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark Function","text":"","category":"section"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"The true underlying function HyGP had to approximate is the 1D Salustowicz function. The function can be evaluated in the given domain: x in 0 10.","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"The Salustowicz benchmark function is as follows:","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"f(x) = e^(-x) x^3 cos(x) sin(x) (cos(x) sin^2(x) - 1)","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"Let's import these two packages  Surrogates and Plots:","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"using Surrogates\r\nusing Plots\r\ndefault()","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"Now, let's define our objective function:","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"function salustowicz(x)\r\n    term1 = 2.72^(-x) * x^3 * cos(x) * sin(x);\r\n    term2 = (cos(x) * sin(x)*sin(x) - 1);\r\n    y = term1 * term2;\r\nend","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"Let's sample f in 30 points between 0 and 10 using the sample function. The sampling points are chosen using a Sobol Sample, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"n_samples = 30\r\nlower_bound = 0\r\nupper_bound = 10\r\nnum_round = 2\r\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\ny = salustowicz.(x)\r\nxs = lower_bound:0.001:upper_bound\r\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(xs, salustowicz.(xs), label=\"True function\", legend=:top)","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"Now, let's fit Salustowicz Function with different Surrogates:","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"InverseDistance = InverseDistanceSurrogate(x, y, lower_bound, upper_bound)\r\nlobachevsky_surrogate = LobachevskySurrogate(x, y, lower_bound, upper_bound, alpha = 2.0, n = 6)\r\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:topright)\r\nplot!(xs, salustowicz.(xs), label=\"True function\", legend=:topright)\r\nplot!(xs, InverseDistance.(xs), label=\"InverseDistanceSurrogate\", legend=:topright)\r\nplot!(xs, lobachevsky_surrogate.(xs), label=\"Lobachevsky\", legend=:topright)","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"Not's let's see Kriging Surrogate with different hyper parameter:","category":"page"},{"location":"copies/Surrogates/Salustowicz/","page":"Salustowicz Benchmark","title":"Salustowicz Benchmark","text":"kriging_surrogate1 = Kriging(x, y, lower_bound, upper_bound, p=0.9);\r\nkriging_surrogate2 = Kriging(x, y, lower_bound, upper_bound, p=1.5);\r\nkriging_surrogate3 = Kriging(x, y, lower_bound, upper_bound, p=1.9);\r\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:topright)\r\nplot!(xs, salustowicz.(xs), label=\"True function\", legend=:topright)\r\nplot!(xs, kriging_surrogate1.(xs), label=\"kriging_surrogate1\", ribbon=p->std_error_at_point(kriging_surrogate1, p), legend=:topright)\r\nplot!(xs, kriging_surrogate2.(xs), label=\"kriging_surrogate2\", ribbon=p->std_error_at_point(kriging_surrogate2, p), legend=:topright)\r\nplot!(xs, kriging_surrogate3.(xs), label=\"kriging_surrogate3\", ribbon=p->std_error_at_point(kriging_surrogate3, p), legend=:topright)","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/#Automated-Sparse-Analytical-Jacobians","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"","category":"section"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"In many cases where you have large stiff differential equations, getting a sparse Jacobian can be essential for performance. In this tutorial we will show how to use modelingtoolkitize to regenerate an ODEProblem code with the analytical solution to the sparse Jacobian, along with the sparsity pattern required by DifferentialEquations.jl's solvers to specialize the solving process.","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"First let's start out with an implementation of the 2-dimensional Brusselator partial differential equation discretized using finite differences:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"using DifferentialEquations, ModelingToolkit\n\nconst N = 32\nconst xyd_brusselator = range(0,stop=1,length=N)\nbrusselator_f(x, y, t) = (((x-0.3)^2 + (y-0.6)^2) <= 0.1^2) * (t >= 1.1) * 5.\nlimit(a, N) = a == N+1 ? 1 : a == 0 ? N : a\nfunction brusselator_2d_loop(du, u, p, t)\n  A, B, alpha, dx = p\n  alpha = alpha/dx^2\n  @inbounds for I in CartesianIndices((N, N))\n    i, j = Tuple(I)\n    x, y = xyd_brusselator[I[1]], xyd_brusselator[I[2]]\n    ip1, im1, jp1, jm1 = limit(i+1, N), limit(i-1, N), limit(j+1, N), limit(j-1, N)\n    du[i,j,1] = alpha*(u[im1,j,1] + u[ip1,j,1] + u[i,jp1,1] + u[i,jm1,1] - 4u[i,j,1]) +\n                B + u[i,j,1]^2*u[i,j,2] - (A + 1)*u[i,j,1] + brusselator_f(x, y, t)\n    du[i,j,2] = alpha*(u[im1,j,2] + u[ip1,j,2] + u[i,jp1,2] + u[i,jm1,2] - 4u[i,j,2]) +\n                A*u[i,j,1] - u[i,j,1]^2*u[i,j,2]\n    end\nend\np = (3.4, 1., 10., step(xyd_brusselator))\n\nfunction init_brusselator_2d(xyd)\n  N = length(xyd)\n  u = zeros(N, N, 2)\n  for I in CartesianIndices((N, N))\n    x = xyd[I[1]]\n    y = xyd[I[2]]\n    u[I,1] = 22*(y*(1-y))^(3/2)\n    u[I,2] = 27*(x*(1-x))^(3/2)\n  end\n  u\nend\nu0 = init_brusselator_2d(xyd_brusselator)\nprob = ODEProblem(brusselator_2d_loop,u0,(0.,11.5),p)","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"Now let's use modelingtoolkitize to generate the symbolic version:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"sys = modelingtoolkitize(prob)","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"Now we regenerate the problem using jac=true for the analytical Jacobian and sparse=true to make it sparse:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"sparseprob = ODEProblem(sys,Pair[],(0.,11.5),jac=true,sparse=true)","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"Hard? No! How much did that help?","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"using BenchmarkTools\n@btime solve(prob,save_everystep=false) # 51.714 s (7317 allocations: 70.12 MiB)\n@btime solve(sparseprob,save_everystep=false) # 2.880 s (55533 allocations: 885.09 MiB)","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"Notice though that the analytical solution to the Jacobian can be quite expensive. Thus in some cases we may only want to get the sparsity pattern. In this case, we can simply do:","category":"page"},{"location":"copies/ModelingToolkit/mtkitize_tutorials/sparse_jacobians/","page":"Automated Sparse Analytical Jacobians","title":"Automated Sparse Analytical Jacobians","text":"sparsepatternprob = ODEProblem(sys,Pair[],(0.,11.5),sparse=true)\n@btime solve(sparsepatternprob,save_everystep=false) # 2.880 s (55533 allocations: 885.09 MiB)","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLSolutions","page":"SciMLSolutions","title":"SciMLSolutions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/#Definition-of-the-SciMLSolution-Interface","page":"SciMLSolutions","title":"Definition of the SciMLSolution Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"All SciMLSolution types are a subset of some AbstractArray. Types with time series (like ODESolution) are subtypes of RecursiveArrayTools.AbstractVectorOfArray and  RecursiveArrayTools.AbstractDiffEqArray where appropriate. Types without a time series (like OptimizationSolution) are directly subsets of AbstractArray. ","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#Array-Interface","page":"SciMLSolutions","title":"Array Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"Instead of working on the Vector{uType} directly, we can use the provided array interface.","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol[j]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"to access the value at timestep j (if the timeseries was saved), and","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol.t[j]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"to access the value of t at timestep j. For multi-dimensional systems, this will address first by component and lastly by time, and thus","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol[i,j]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"will be the ith component at timestep j. Hence, sol[j][i] == sol[i, j]. This is done because Julia is column-major, so the leading dimension should be contiguous in memory. If the independent variables had shape (for example, was a matrix), then i is the linear index. We can also access solutions with shape:","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol[i,k,j]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"gives the [i,k] component of the system at timestep j. The colon operator is supported, meaning that","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol[i,:]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"gives the timeseries for the ith component.","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#Common-Field-Names","page":"SciMLSolutions","title":"Common Field Names","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"u: the solution values\nt: the independent variable values, matching the length of the solution, if applicable\nresid: the residual of the solution, if applicable\noriginal: the solution object from the original solver, if it's a wrapper algorithm\nretcode: see the documentation section on return codes\nprob: the problem that was solved\nalg: the algorithm used to solve the problem","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#retcodes","page":"SciMLSolutions","title":"Return Codes (RetCodes)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"The solution types have a retcode field which returns a symbol signifying the error state of the solution. The retcodes are as follows:","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":":Default: The solver did not set retcodes.\n:Success: The integration completed without erroring or the steady state solver from SteadyStateDiffEq found the steady state.\n:Terminated: The integration is terminated with terminate!(integrator). Note that this may occur by using TerminateSteadyState from the callback library DiffEqCallbacks.\n:MaxIters: The integration exited early because it reached its maximum number of iterations.\n:DtLessThanMin: The timestep method chose a stepsize which is smaller than the allowed minimum timestep, and exited early.\n:Unstable: The solver detected that the solution was unstable and exited early.\n:InitialFailure: The DAE solver could not find consistent initial conditions.\n:ConvergenceFailure: The internal implicit solvers failed to converge.\n:Failure: General uncategorized failures or errors.","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#Traits","page":"SciMLSolutions","title":"Traits","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLSolution-API","page":"SciMLSolutions","title":"SciMLSolution API","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/#Abstract-SciML-Solutions","page":"SciMLSolutions","title":"Abstract SciML Solutions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"SciMLBase.SciMLSolution\nSciMLBase.AbstractNoTimeSolution\nSciMLBase.AbstractTimeseriesSolution\nSciMLBase.AbstractNoiseProcess\nSciMLBase.AbstractEnsembleSolution\nSciMLBase.AbstractLinearSolution\nSciMLBase.AbstractNonlinearSolution\nSciMLBase.AbstractQuadratureSolution\nSciMLBase.AbstractSteadyStateSolution\nSciMLBase.AbstractAnalyticalSolution\nSciMLBase.AbstractODESolution\nSciMLBase.AbstractDDESolution\nSciMLBase.AbstractRODESolution\nSciMLBase.AbstractDAESolution","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.SciMLSolution","page":"SciMLSolutions","title":"SciMLBase.SciMLSolution","text":"Union of all base solution types.\n\nUses a Union so that solution types can be <: AbstractArray\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractNoTimeSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractNoTimeSolution","text":"abstract type AbstractNoTimeSolution{T, N} <: AbstractArray{T, N}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractTimeseriesSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractTimeseriesSolution","text":"abstract type AbstractTimeseriesSolution{T, N, A} <: RecursiveArrayTools.AbstractDiffEqArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractNoiseProcess","page":"SciMLSolutions","title":"SciMLBase.AbstractNoiseProcess","text":"abstract type AbstractNoiseProcess{T, N, A, isinplace} <: RecursiveArrayTools.AbstractDiffEqArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractEnsembleSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractEnsembleSolution","text":"abstract type AbstractEnsembleSolution{T, N, A} <: RecursiveArrayTools.AbstractVectorOfArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractLinearSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractLinearSolution","text":"abstract type AbstractLinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractNonlinearSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractNonlinearSolution","text":"abstract type AbstractNonlinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractSteadyStateSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractSteadyStateSolution","text":"abstract type AbstractNonlinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractAnalyticalSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractAnalyticalSolution","text":"abstract type AbstractAnalyticalSolution{T, N, S} <: SciMLBase.AbstractTimeseriesSolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractODESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractODESolution","text":"abstract type AbstractODESolution{T, N, S} <: SciMLBase.AbstractTimeseriesSolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractDDESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractDDESolution","text":"abstract type AbstractDDESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractRODESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractRODESolution","text":"abstract type AbstractRODESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractDAESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractDAESolution","text":"abstract type AbstractDAESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#Concrete-SciML-Solutions","page":"SciMLSolutions","title":"Concrete SciML Solutions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"SciMLBase.LinearSolution\nSciMLBase.QuadratureSolution\nSciMLBase.DAESolution\nSciMLBase.NonlinearSolution\nSciMLBase.ODESolution\nSciMLBase.OptimizationSolution\nSciMLBase.RODESolution","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.LinearSolution","page":"SciMLSolutions","title":"SciMLBase.LinearSolution","text":"struct LinearSolution{T, N, uType, R, A, C} <: SciMLBase.AbstractLinearSolution{T, N}\n\nRepresentation of the solution to an linear system Ax=b defined by a LinearProblem\n\nFields\n\nu: the representation of the optimization's solution.\nresid: the residual of the solver, if the method is an iterative method.\nalg: the algorithm type used by the solver.\niters: the number of iterations used to solve the equation, if the method is an iterative method.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\ncache: the LinearCache object containing the solver's internal cached variables. This is given to allow continuation of solver usage, for example, solving Ax=b with the same A and a new b without refactorizing A. See the caching interface tutorial for details on how to use the cache effectively: http://linearsolve.sciml.ai/dev/tutorials/caching_interface/ \n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.DAESolution","page":"SciMLSolutions","title":"SciMLBase.DAESolution","text":"struct DAESolution{T, N, uType, duType, uType2, DType, tType, P, A, ID, DE} <: SciMLBase.AbstractDAESolution{T, N, uType}\n\nRepresentation of the solution to an differential-algebraic equation defined by an DAEProblem.\n\nDESolution Interface\n\nFor more information on interacting with DESolution types, check out the Solution Handling page of the DifferentialEquations.jl documentation.\n\nhttps://diffeq.sciml.ai/stable/basics/solution/\n\nFields\n\nu: the representation of the DAE solution. Given as an array of solutions, where u[i] corresponds to the solution at time t[i]. It is recommended in most cases one does not access sol.u directly and instead use the array interface described in the Solution  Handling page of the DifferentialEquations.jl documentation.\ndu: the representation fo the derivatives of the DAE solution.\nt: the time points corresponding to the saved values of the DAE solution.\nprob: the original DAEProblem that was solved.\nalg: the algorithm type used by the solver.\ndestats: statistics of the solver, such as the number of function evaluations required, number of Jacobians computed, and more.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.NonlinearSolution","page":"SciMLSolutions","title":"SciMLBase.NonlinearSolution","text":"struct NonlinearSolution{T, N, uType, R, P, A, O, uType2} <: SciMLBase.AbstractNonlinearSolution{T, N}\n\nRepresentation of the solution to an nonlinear equation defined by an NonlinearProblem, or the steady state solution to a differential equation defined by a SteadyStateProblem.\n\nFields\n\nu: the representation of the nonlinear equation's solution.\nresid: the residual of the solution.\nprob: the original NonlinearProblem/SteadyStateProblem that was solved.\nalg: the algorithm type used by the solver.\noriginal: if the solver is wrapped from an alternative solver ecosystem, such as NLsolve.jl, then this is the original return from said solver library.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\nleft: if the solver is bracketing method, this is the final left bracket value.\nright: if the solver is bracketing method, this is the final right bracket value.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.ODESolution","page":"SciMLSolutions","title":"SciMLBase.ODESolution","text":"struct ODESolution{T, N, uType, uType2, DType, tType, rateType, P, A, IType, DE} <: SciMLBase.AbstractODESolution{T, N, uType}\n\nRepresentation of the solution to an ordinary differential equation defined by an ODEProblem.\n\nDESolution Interface\n\nFor more information on interacting with DESolution types, check out the Solution Handling page of the DifferentialEquations.jl documentation.\n\nhttps://diffeq.sciml.ai/stable/basics/solution/\n\nFields\n\nu: the representation of the ODE solution. Given as an array of solutions, where u[i] corresponds to the solution at time t[i]. It is recommended in most cases one does not access sol.u directly and instead use the array interface described in the Solution  Handling page of the DifferentialEquations.jl documentation.\nt: the time points corresponding to the saved values of the ODE solution.\nprob: the original ODEProblem that was solved.\nalg: the algorithm type used by the solver.\ndestats: statistics of the solver, such as the number of function evaluations required, number of Jacobians computed, and more.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.OptimizationSolution","page":"SciMLSolutions","title":"SciMLBase.OptimizationSolution","text":"struct OptimizationSolution{T, N, uType, P, A, Tf, O} <: SciMLBase.AbstractOptimizationSolution{T, N}\n\nRepresentation of the solution to an nonlinear optimization defined by an OptimizationProblem\n\nFields\n\nu: the representation of the optimization's solution.\nprob: the original NonlinearProblem/SteadyStateProblem that was solved.\nalg: the algorithm type used by the solver.\noriginal: if the solver is wrapped from an alternative solver ecosystem, such as Optim.jl, then this is the original return from said solver library.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.RODESolution","page":"SciMLSolutions","title":"SciMLBase.RODESolution","text":"struct RODESolution{T, N, uType, uType2, DType, tType, randType, P, A, IType, DE} <: SciMLBase.AbstractRODESolution{T, N, uType}\n\nRepresentation of the solution to an stochastic differential equation defined by an SDEProblem, or of a random ordinary differential equation defined by an RODEProblem.\n\nDESolution Interface\n\nFor more information on interacting with DESolution types, check out the Solution Handling page of the DifferentialEquations.jl documentation.\n\nhttps://diffeq.sciml.ai/stable/basics/solution/\n\nFields\n\nu: the representation of the SDE or RODE solution. Given as an array of solutions, where u[i] corresponds to the solution at time t[i]. It is recommended in most cases one does not access sol.u directly and instead use the array interface described in the Solution  Handling page of the DifferentialEquations.jl documentation.\nt: the time points corresponding to the saved values of the ODE solution.\nW: the representation of the saved noise process from the solution. See the Noise Processes page of the DifferentialEquations.jl documentation for more details:  https://diffeq.sciml.ai/stable/features/noiseprocess/ . Note that this noise is only saved in full if `savenoise=true` in the solver.\nprob: the original SDEProblem/RODEProblem that was solved.\nalg: the algorithm type used by the solver.\ndestats: statistics of the solver, such as the number of function evaluations required, number of Jacobians computed, and more.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"copies/GlobalSensitivity/methods/efast/#eFAST-Method","page":"eFAST Method","title":"eFAST Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/efast/","page":"eFAST Method","title":"eFAST Method","text":"struct eFAST <: GSAMethod\n    num_harmonics::Int\nend","category":"page"},{"location":"copies/GlobalSensitivity/methods/efast/","page":"eFAST Method","title":"eFAST Method","text":"The eFAST object has num_harmonics as the only field, which is the number of harmonics to sum in the Fourier series decomposition, this defaults to 4.","category":"page"},{"location":"copies/GlobalSensitivity/methods/efast/#eFAST-Method-Details","page":"eFAST Method","title":"eFAST Method Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/efast/","page":"eFAST Method","title":"eFAST Method","text":"eFAST offers a robust, especially at low sample size, and computationally efficient procedure to get the first and total order indices as discussed in Sobol. It utilizes monodimensional Fourier decomposition along a curve exploring the parameter space. The curve is defined by a set of parametric equations,","category":"page"},{"location":"copies/GlobalSensitivity/methods/efast/","page":"eFAST Method","title":"eFAST Method","text":"x_i(s) = G_i(sin ω_is)  i=12  n","category":"page"},{"location":"copies/GlobalSensitivity/methods/efast/","page":"eFAST Method","title":"eFAST Method","text":"where s is a scalar variable varying over the range -  s  +, G_i are transformation functions and ω_i  i=12n is a set of different (angular) frequencies, to be properly selected, associated with each factor. For more details on the transformation used and other implementation details you can go through  A. Saltelli et al..","category":"page"},{"location":"copies/GlobalSensitivity/methods/efast/#API","page":"eFAST Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/efast/","page":"eFAST Method","title":"eFAST Method","text":"function gsa(f, method::eFAST, p_range::AbstractVector; n::Int=1000, batch=false, distributed::Val{SHARED_ARRAY} = Val(false), kwargs...) where {SHARED_ARRAY}","category":"page"},{"location":"copies/GlobalSensitivity/methods/efast/#Example","page":"eFAST Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/efast/","page":"eFAST Method","title":"eFAST Method","text":"Below we show use of eFAST on the Ishigami function.","category":"page"},{"location":"copies/GlobalSensitivity/methods/efast/","page":"eFAST Method","title":"eFAST Method","text":"using GlobalSensitivity, QuasiMonteCarlo\n\nfunction ishi(X)\n    A= 7\n    B= 0.1\n    sin(X[1]) + A*sin(X[2])^2+ B*X[3]^4 *sin(X[1])\nend\n\nlb = -ones(4)*π\nub = ones(4)*π\n\nres1 = gsa(ishi,eFAST(),[[lb[i],ub[i]] for i in 1:4],n=15000)\n\n##with batching\nfunction ishi_batch(X)\n    A= 7\n    B= 0.1\n    @. sin(X[1,:]) + A*sin(X[2,:])^2+ B*X[3,:]^4 *sin(X[1,:])\nend\n\nres2 = gsa(ishi_batch,eFAST(),[[lb[i],ub[i]] for i in 1:4],n=15000,batch=true)\n","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/#Optimization-Based-ODE-Parameter-Estimation","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"We choose to optimize the parameters on the Lotka-Volterra equation. We do so by defining the function as a function with parameters:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"function f(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - u[1]*u[2]\n  du[2] = dy = -3*u[2] + u[1]*u[2]\nend\n\nu0 = [1.0;1.0]\ntspan = (0.0,10.0)\np = [1.5]\nprob = ODEProblem(f,u0,tspan,p)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"We create data using the numerical result with a=1.5:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"sol = solve(prob,Tsit5())\nt = collect(range(0,stop=10,length=200))\nusing RecursiveArrayTools # for VectorOfArray\nrandomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])\ndata = convert(Array,randomized)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Here we used VectorOfArray from RecursiveArrayTools.jl to turn the result of an ODE into a matrix.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"If we plot the solution with the parameter at a=1.42, we get the following:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"(Image: Parameter Estimation Not Fit)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Notice that after one period this solution begins to drift very far off: this problem is sensitive to the choice of a.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"To build the objective function for Optim.jl, we simply call the build_loss_objective function:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"cost_function = build_loss_objective(prob,Tsit5(),L2Loss(t,data),\n                                     maxiters=10000,verbose=false)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"This objective function internally is calling the ODE solver to get solutions to test against the data. The keyword arguments are passed directly to the solver. Note that we set maxiters in a way that causes the differential equation solvers to error more quickly when in bad regions of the parameter space, speeding up the process. If the integrator stops early (due to divergence), then those parameters are given an infinite loss, and thus this is a quick way to avoid bad parameters. We set verbose=false because this divergence can get noisy.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Before optimizing, let's visualize our cost function by plotting it for a range of parameter values:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"vals = 0.0:0.1:10.0\nusing Plots; plotly()\nplot(vals,[cost_function(i) for i in vals],yscale=:log10,\n     xaxis = \"Parameter\", yaxis = \"Cost\", title = \"1-Parameter Cost Function\",\n     lw = 3)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"(Image: 1 Parameter Likelihood)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Here we see that there is a very well-defined minimum in our cost function at the real parameter (because this is where the solution almost exactly fits the dataset).","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Now this cost function can be used with Optim.jl in order to get the parameters. For example, we can use Brent's algorithm to search for the best solution on the interval [0,10] by:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"using Optim\nresult = optimize(cost_function, 0.0, 10.0)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"This returns result.minimizer[1]==1.5 as the best parameter to match the data. When we plot the fitted equation on the data, we receive the following:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"(Image: Parameter Estimation Fit)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Thus we see that after fitting, the lines match up with the generated data and receive the right parameter value.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"We can also use the multivariate optimization functions. For example, we can use the BFGS algorithm to optimize the parameter starting at a=1.42 using:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"result = optimize(cost_function, [1.42], BFGS())","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Note that some of the algorithms may be sensitive to the initial condition. For more details on using Optim.jl, see the documentation for Optim.jl. We can improve our solution by noting that the Lotka-Volterra equation requires that the parameters are positive. Thus following the Optim.jl documentation we can add box constraints to ensure the optimizer only checks between 0.0 and 3.0 which improves the efficiency of our algorithm:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"lower = [0.0]\nupper = [3.0]\nresult = optimize(cost_function, lower, upper, [1.42], Fminbox(BFGS()))","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Lastly, we can use the same tools to estimate multiple parameters simultaneously. Let's use the Lotka-Volterra equation with all parameters free:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"function f2(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\n\nu0 = [1.0;1.0]\ntspan = (0.0,10.0)\np = [1.5,1.0,3.0,1.0]\nprob = ODEProblem(f2,u0,tspan,p)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"We can build an objective function and solve the multiple parameter version just as before:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"cost_function = build_loss_objective(prob,Tsit5(),L2Loss(t,data),\n                                      maxiters=10000,verbose=false)\nresult_bfgs = Optim.optimize(cost_function, [1.3,0.8,2.8,1.2], Optim.BFGS())","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"We can also use First-Differences in L2Loss by passing the kwarg differ_weight which decides the contribution of the differencing loss to the total loss.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"cost_function = build_loss_objective(prob,Tsit5(),L2Loss(t,data,differ_weight=0.3,data_weight=0.7),\n                                      maxiters=10000,verbose=false)\nresult_bfgs = Optim.optimize(cost_function, [1.3,0.8,2.8,1.2], Optim.BFGS())","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"To solve it using LeastSquaresOptim.jl, we use the build_lsoptim_objective function:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"cost_function = build_lsoptim_objective(prob1,t,data,Tsit5())","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"The result is a cost function which can be used with LeastSquaresOptim. For more details, consult the documentation for LeastSquaresOptim.jl:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"using LeastSquaresOptim # for LeastSquaresProblem\nx = [1.3,0.8,2.8,1.2]\nres = optimize!(LeastSquaresProblem(x = x, f! = cost_function,\n                output_length = length(t)*length(prob.u0)),\n                LeastSquaresOptim.Dogleg(LeastSquaresOptim.LSMR()))","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"We can see the results are:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"println(res.minimizer)\n\nResults of Optimization Algorithm\n * Algorithm: Dogleg\n * Minimizer: [1.4995074428834114,0.9996531871795851,3.001556360700904,1.0006272074128821]\n * Sum of squares at Minimum: 0.035730\n * Iterations: 63\n * Convergence: true\n * |x - x'| < 1.0e-15: true\n * |f(x) - f(x')| / |f(x)| < 1.0e-14: false\n * |g(x)| < 1.0e-14: false\n * Function Calls: 64\n * Gradient Calls: 9\n * Multiplication Calls: 135","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"and thus this algorithm was able to correctly identify all four parameters.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"We can also use Multiple Shooting method by creating a multiple_shooting_objective","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"function ms_f(du,u,p,t)\n  dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  dy = -3*u[2] + u[1]*u[2]\nend\nms_u0 = [1.0;1.0]\ntspan = (0.0,10.0)\nms_p = [1.5,1.0]\nms_prob = ODEProblem(ms_f,ms_u0,tspan,ms_p)\nt = collect(range(0,stop=10,length=200))\ndata = Array(solve(ms_prob,Tsit5(),saveat=t,abstol=1e-12,reltol=1e-12))\nbound = Tuple{Float64, Float64}[(0, 10),(0, 10),(0, 10),(0, 10),\n                                (0, 10),(0, 10),(0, 10),(0, 10),\n                                (0, 10),(0, 10),(0, 10),(0, 10),\n                                (0, 10),(0, 10),(0, 10),(0, 10),(0, 10),(0, 10)]\n\n\nms_obj = multiple_shooting_objective(ms_prob,Tsit5(),L2Loss(t,data);discontinuity_weight=1.0,abstol=1e-12,reltol=1e-12)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"This creates the objective function that can be passed to an optimizer from which we can then get the parameter values and the initial values of the short time periods keeping in mind the indexing.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"# ]add BlackBoxOptim\nusing BlackBoxOptim\n\nresult = bboptimize(ms_obj;SearchRange = bound, MaxSteps = 21e3)\nresult.archive_output.best_candidate[end-1:end]","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Giving us the results as","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Starting optimization with optimizer BlackBoxOptim.DiffEvoOpt{BlackBoxOptim.FitPopulation{Float64},BlackBoxOptim.RadiusLimitedSelector,BlackBoxOptim.AdaptiveDiffEvoRandBin{3},BlackBoxOptim.RandomBound{BlackBoxOptim.RangePerDimSearchSpace}}\n\nOptimization stopped after 21001 steps and 136.60030698776245 seconds\nTermination reason: Max number of steps (21000) reached\nSteps per second = 153.7405036862868\nFunction evals per second = 154.43596332393247\nImprovements/step = 0.17552380952380953\nTotal function evaluations = 21096\n\n\nBest candidate found: [0.997396, 1.04664, 3.77834, 0.275823, 2.14966, 4.33106, 1.43777, 0.468442, 6.22221, 0.673358, 0.970036, 2.05182, 2.4216, 0.274394, 5.64131, 3.38132, 1.52826, 1.01721]\n\nFitness: 0.126884213\n\nOut[4]:2-element Array{Float64,1}:\n        1.52826\n        1.01721","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"Here as our model had 2 parameters, we look at the last two indexes of result to get our parameter values and the rest of the values are the initial values of the shorter timespans as described in the reference section.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"The objective function for Two Stage method can be created and passed to an optimizer as","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"two_stage_obj = two_stage_method(ms_prob,t,data)\nresult = Optim.optimize(two_stage_obj, [1.3,0.8,2.8,1.2], Optim.BFGS()\n)\nResults of Optimization Algorithm\n * Algorithm: BFGS\n * Starting Point: [1.3,0.8,2.8,1.2]\n * Minimizer: [1.5035938533664717,0.9925731153746833, ...]\n * Minimum: 1.513400e+00\n * Iterations: 9\n * Convergence: true\n   * |x - x'| ≤ 0.0e+00: false\n     |x - x'| = 4.58e-10\n   * |f(x) - f(x')| ≤ 0.0e+00 |f(x)|: false\n     |f(x) - f(x')| = 5.87e-16 |f(x)|\n   * |g(x)| ≤ 1.0e-08: true\n     |g(x)| = 7.32e-11\n   * Stopped by an increasing objective: false\n   * Reached Maximum Number of Iterations: false\n * Objective Calls: 31\n * Gradient Calls: 31","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/ODE_inference/","page":"Optimization-Based ODE Parameter Estimation","title":"Optimization-Based ODE Parameter Estimation","text":"The default kernel used in the method is Epanechnikov others that are available are Uniform,  Triangular, Quartic, Triweight, Tricube, Gaussian, Cosine, Logistic and Sigmoid, this can be passed by the kernel keyword argument. loss_func keyword argument can be used to pass the loss function (cost function) you want  to use and mpg_autodiff enables Auto Differentiation.","category":"page"},{"location":"copies/LinearSolve/advanced/custom/#Passing-in-a-Custom-Linear-Solver","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"","category":"section"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"Julia users are building a wide variety of applications in the SciML ecosystem, often requiring problem-specific handling of their linear solves. As existing solvers in LinearSolve.jl may not be optimally suited for novel applications, it is essential for the linear solve interface to be easily extendable by users. To that end, the linear solve algorithm LinearSolveFunction() accepts a user-defined function for handling the solve. A user can pass in their custom linear solve function, say my_linsolve, to LinearSolveFunction(). A contrived example of solving a linear system with a custom solver is below.","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"using LinearSolve, LinearAlgebra\n\nfunction my_linsolve(A,b,u,p,newA,Pl,Pr,solverdata;verbose=true, kwargs...)\n    if verbose == true\n        println(\"solving Ax=b\")\n    end\n    u = A \\ b\n    return u\nend\n\nprob = LinearProblem(Diagonal(rand(4)), rand(4))\nalg  = LinearSolveFunction(my_linsolve)\nsol  = solve(prob, alg)","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"The inputs to the function are as follows:","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"A, the linear operator\nb, the right-hand-side\nu, the solution initialized as zero(b),\np, a set of parameters\nnewA, a Bool which is true if A has been modified since last solve\nPl, left-preconditioner\nPr, right-preconditioner\nsolverdata, solver cache set to nothing if solver hasn't been initialized\nkwargs, standard SciML keyword arguments such as verbose, maxiters, abstol, reltol","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"The function my_linsolve must accept the above specified arguments, and return the solution, u. As memory for u is already allocated, the user may choose to modify u in place as follows:","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"function my_linsolve!(A,b,u,p,newA,Pl,Pr,solverdata;verbose=true, kwargs...)\n    if verbose == true\n        println(\"solving Ax=b\")\n    end\n    u .= A \\ b # in place\n    return u\nend\n\nalg  = LinearSolveFunction(my_linsolve!)\nsol  = solve(prob, alg)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/#Training-a-Neural-Ordinary-Differential-Equation-with-Mini-Batching","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"using DifferentialEquations, DiffEqFlux, Plots\nusing IterTools: ncycle \n\n\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k*(temp-temp_m) \n  end\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2)/8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend\n\n\nann = FastChain(FastDense(1,8,tanh), FastDense(8,1,tanh))\nθ = initial_params(ann)\n\nfunction dudt_(u,p,t)           \n    ann(u, p).* u\nend\n\nfunction predict_adjoint(time_batch)\n    _prob = remake(prob,u0=u0,p=θ)\n    Array(solve(_prob, Tsit5(), saveat = time_batch)) \nend\n\nfunction loss_adjoint(batch, time_batch)\n    pred = predict_adjoint(time_batch)\n    sum(abs2, batch - pred)#, pred\nend\n\n\nu0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 3.0f0)\n\nt = range(tspan[1], tspan[2], length=datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat=t))\n\nprob = ODEProblem{false}(dudt_, u0, tspan, θ)\n\nk = 10\ntrain_loader = Flux.Data.DataLoader((ode_data, t), batchsize = k)\n\nfor (x, y) in train_loader\n    @show x\n    @show y\nend\n\nnumEpochs = 300\nlosses=[]\ncb() = begin\n    l=loss_adjoint(ode_data, t)\n    push!(losses, l)\n    @show l\n    pred=predict_adjoint(t)\n    pl = scatter(t,ode_data[1,:],label=\"data\", color=:black, ylim=(150,200))\n    scatter!(pl,t,pred[1,:],label=\"prediction\", color=:darkgreen)\n    display(plot(pl))\n    false\nend \n\nopt=ADAM(0.05)\nFlux.train!(loss_adjoint, Flux.params(θ), ncycle(train_loader,numEpochs), opt, cb=Flux.throttle(cb, 10))\n\n#Now lets see how well it generalizes to new initial conditions \n\nstarting_temp=collect(10:30:250)\ntrue_prob_func(u0)=ODEProblem(true_sol, [u0], tspan)\ncolor_cycle=palette(:tab10)\npl=plot()\nfor (j,temp) in enumerate(starting_temp)\n    ode_test_sol = solve(ODEProblem(true_sol, [temp], (0.0f0,10.0f0)), Tsit5(), saveat=0.0:0.5:10.0)\n    ode_nn_sol = solve(ODEProblem{false}(dudt_, [temp], (0.0f0,10.0f0), θ))\n    scatter!(pl, ode_test_sol, var=(0,1), label=\"\", color=color_cycle[j])\n    plot!(pl, ode_nn_sol, var=(0,1), label=\"\", color=color_cycle[j], lw=2.0)\nend\ndisplay(pl) \ntitle!(\"Neural ODE for Newton's Law of Cooling: Test Data\")\nxlabel!(\"Time\")\nylabel!(\"Temp\") \n\n\n# How to use MLDataUtils \nusing MLDataUtils\ntrain_loader, _, _ = kfolds((ode_data, t))\n\n@info \"Now training using the MLDataUtils format\"\nFlux.train!(loss_adjoint, Flux.params(θ), ncycle(eachbatch(train_loader[1], k), numEpochs), opt, cb=Flux.throttle(cb, 10))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"When training a neural network we need to find the gradient with respect to our data set. There are three main ways to partition our data when using a training algorithm like gradient descent: stochastic, batching and mini-batching. Stochastic gradient descent trains on a single random data point each epoch. This allows for the neural network to better converge to the global minimum even on noisy data but is computationally inefficient. Batch gradient descent trains on the whole data set each epoch and while computationally efficient is prone to converging to local minima. Mini-batching combines both of these advantages and by training on a small random \"mini-batch\" of the data each epoch can converge to the global minimum while remaining more computationally efficient than stochastic descent. Typically we do this by randomly selecting subsets of the data each epoch and use this subset to train on. We can also pre-batch the data by creating an iterator holding these randomly selected batches before beginning to train. The proper size for the batch can be determined experimentally. Let us see how to do this with Julia. ","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"For this example we will use a very simple ordinary differential equation, newtons law of cooling. We can represent this in Julia like so. ","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"using DifferentialEquations, DiffEqFlux, Plots\nusing IterTools: ncycle \n\n\nfunction newtons_cooling(du, u, p, t)\n    temp = u[1]\n    k, temp_m = p\n    du[1] = dT = -k*(temp-temp_m) \n  end\n\nfunction true_sol(du, u, p, t)\n    true_p = [log(2)/8.0, 100.0]\n    newtons_cooling(du, u, true_p, t)\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"Now we define a neural-network using a linear approximation with 1 hidden layer of 8 neurons.  ","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"ann = FastChain(FastDense(1,8,tanh), FastDense(8,1,tanh))\nθ = initial_params(ann)\n\nfunction dudt_(u,p,t)           \n    ann(u, p).* u\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"From here we build a loss function around it. ","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"function predict_adjoint(time_batch)\n    _prob = remake(prob, u0=u0, p=θ)\n    Array(solve(_prob, Tsit5(), saveat = time_batch)) \nend\n\nfunction loss_adjoint(batch, time_batch)\n    pred = predict_adjoint(time_batch)\n    sum(abs2, batch - pred)#, pred\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"To add support for batches of size k we use Flux.Data.DataLoader. To use this we pass in the ode_data and t as the 'x' and 'y' data to batch respectively. The parameter batchsize controls the size of our batches. We check our implementation by iterating over the batched data. ","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"u0 = Float32[200.0]\ndatasize = 30\ntspan = (0.0f0, 3.0f0)\n\nt = range(tspan[1], tspan[2], length=datasize)\ntrue_prob = ODEProblem(true_sol, u0, tspan)\node_data = Array(solve(true_prob, Tsit5(), saveat=t))\nprob = ODEProblem{false}(dudt_, u0, tspan, θ)\n\nk = 10\ntrain_loader = Flux.Data.DataLoader((ode_data, t), batchsize = k)\nfor (x, y) in train_loader\n    @show x\n    @show y\nend\n\n\n#x = Float32[200.0 199.55284 199.1077 198.66454 198.22334 197.78413 197.3469 196.9116 196.47826 196.04686]\n#y = Float32[0.0, 0.05172414, 0.10344828, 0.15517241, 0.20689656, 0.25862068, 0.31034482, 0.36206895, 0.41379312, 0.46551725]\n#x = Float32[195.61739 195.18983 194.76418 194.34044 193.9186 193.49864 193.08057 192.66435 192.25 191.8375]\n#y = Float32[0.51724136, 0.5689655, 0.62068963, 0.67241377, 0.7241379, 0.7758621, 0.82758623, 0.87931037, 0.9310345, 0.98275864]\n#x = Float32[191.42683 191.01802 190.61102 190.20586 189.8025 189.40094 189.00119 188.60321 188.20702 187.8126]\n#y = Float32[1.0344827, 1.0862069, 1.137931, 1.1896552, 1.2413793, 1.2931035, 1.3448275, 1.3965517, 1.4482758, 1.5]","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"Now we train the neural network with a user defined call back function to display loss and the graphs with a maximum of 300 epochs. ","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"numEpochs = 300\nlosses=[]\ncb() = begin\n    l=loss_adjoint(ode_data, t)\n    push!(losses, l)\n    @show l\n    pred=predict_adjoint(t)\n    pl = scatter(t,ode_data[1,:],label=\"data\", color=:black, ylim=(150,200))\n    scatter!(pl,t,pred[1,:],label=\"prediction\", color=:darkgreen)\n    display(plot(pl))\n    false\nend \n\nopt=ADAM(0.05)\nFlux.train!(loss_adjoint, Flux.params(θ), ncycle(train_loader,numEpochs), opt, cb=Flux.throttle(cb, 10))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"Finally we can see how well our trained network will generalize to new initial conditions. ","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"starting_temp=collect(10:30:250)\ntrue_prob_func(u0)=ODEProblem(true_sol, [u0], tspan)\ncolor_cycle=palette(:tab10)\npl=plot()\nfor (j,temp) in enumerate(starting_temp)\n    ode_test_sol = solve(ODEProblem(true_sol, [temp], (0.0f0,10.0f0)), Tsit5(), saveat=0.0:0.5:10.0)\n    ode_nn_sol = solve(ODEProblem{false}(dudt_, [temp], (0.0f0,10.0f0), θ))\n    scatter!(pl, ode_test_sol, var=(0,1), label=\"\", color=color_cycle[j])\n    plot!(pl, ode_nn_sol, var=(0,1), label=\"\", color=color_cycle[j], lw=2.0)\nend\ndisplay(pl) \ntitle!(\"Neural ODE for Newton's Law of Cooling: Test Data\")\nxlabel!(\"Time\")\nylabel!(\"Temp\")","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"We can also minibatch using tools from MLDataUtils. To do this we need to slightly change our implementation and is shown below again with a batch size of k and the same number of epochs.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/minibatch/","page":"Training a Neural Ordinary Differential Equation with Mini-Batching","title":"Training a Neural Ordinary Differential Equation with Mini-Batching","text":"using MLDataUtils\ntrain_loader, _, _ = kfolds((ode_data, t))\n\n@info \"Now training using the MLDataUtils format\"\nFlux.train!(loss_adjoint, Flux.params(θ), ncycle(eachbatch(train_loader[1], k), numEpochs), opt, cb=Flux.throttle(cb, 10))","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/#Nonlinear-Optimal-Control","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/#Note:-this-is-still-a-work-in-progress!","page":"Nonlinear Optimal Control","title":"Note: this is still a work in progress!","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"The ControlSystem type is an interesting system because, unlike other system types, it cannot be numerically solved on its own. Instead, it must be transformed into another system before solving. Standard methods such as the \"direct method\", \"multiple shooting\", or \"discretize-then-optimize\" can all be phrased as symbolic transformations to a ControlSystem: this is the strategy of this methodology.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/#Defining-a-Nonlinear-Optimal-Control-Problem","page":"Nonlinear Optimal Control","title":"Defining a Nonlinear Optimal Control Problem","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"Here we will start by defining a classic optimal control problem. Let:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"x^ = u^3(t)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"where we want to optimize our controller u(t) such that the following is minimized:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"L(theta) = sum_i Vert 4 - x(t_i) Vert + 2 Vert x^prime(t_i) Vert + Vert u(t_i) Vert","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"where i is measured on (0,8) at 0.01 intervals. To do this, we rewrite the ODE in first order form:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"beginaligned\nx^prime = v \nv^ = u^3(t) \nendaligned","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"and thus","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"L(theta) = sum_i Vert 4 - x(t_i) Vert + 2 Vert v(t_i) Vert + Vert u(t_i) Vert","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"is our loss function on the first order system.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"Defining such a control system is similar to an ODESystem, except we must also specify a control variable u(t) and a loss function. Together, this problem looks as follows:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"using ModelingToolkit\n\n@variables t x(t) v(t) u(t)\n@parameters p[1:2]\nD = Differential(t)\n\nloss = (4-x)^2 + 2v^2 + u^2\neqs = [\n    D(x) ~ v - p[2]*x\n    D(v) ~ p[1]*u^3 + v\n]\n\n@named sys = ControlSystem(loss,eqs,t,[x,v],[u],p)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/#Solving-a-Control-Problem-via-Discretize-Then-Optimize","page":"Nonlinear Optimal Control","title":"Solving a Control Problem via Discretize-Then-Optimize","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"One common way to solve nonlinear optimal control problems is by transforming them into an optimization problem by performing a Runge-Kutta discretization of the differential equation system and imposing equalities between variables in the same steps. This can be done via the runge_kutta_discretize transformation on the ControlSystem. While a tableau tab can be specified, it defaults to a 5th order RadauIIA collocation, which is a common method in the field. To perform this discretization, we simply need to give a dt and a timespan on which to discretize:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"dt = 0.1\ntspan = (0.0,1.0)\nsys = runge_kutta_discretize(sys,dt,tspan)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"Now sys is an OptimizationSystem which, when solved, gives the values of x(t), v(t), and u(t). Thus we solve the OptimizationSystem using GalacticOptim.jl:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"u0 = rand(length(states(sys))) # guess for the state values\nprob = OptimizationProblem(sys,u0,[0.1,0.1],grad=true)\n\nusing GalacticOptim, Optim\nsol = solve(prob,BFGS())","category":"page"},{"location":"copies/ModelingToolkit/tutorials/nonlinear_optimal_control/","page":"Nonlinear Optimal Control","title":"Nonlinear Optimal Control","text":"And this is missing some nice interfaces and ignores the equality constraints right now so the tutorial is not complete.","category":"page"},{"location":"copies/GlobalSensitivity/methods/easi/#EASI-Method","page":"EASI Method","title":"EASI Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/easi/","page":"EASI Method","title":"EASI Method","text":"struct EASI <: GSAMethod \n    max_harmonic::Int\nend","category":"page"},{"location":"copies/GlobalSensitivity/methods/easi/","page":"EASI Method","title":"EASI Method","text":"EASI has the following keyword arguments:","category":"page"},{"location":"copies/GlobalSensitivity/methods/easi/","page":"EASI Method","title":"EASI Method","text":"max_harmonic: Maximum harmonic of the input frequency for which the output power spectrum is analyzed for. Defaults to 10.","category":"page"},{"location":"copies/GlobalSensitivity/methods/easi/#Method-Details","page":"EASI Method","title":"Method Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/easi/","page":"EASI Method","title":"EASI Method","text":"The EASI method is a Fourier-based technique for performing  variance-based methods of global sensitivity analysis for the  computation of first order effects (Sobol’ indices), hence belonging  into the same class of algorithms as FAST and RBD. It is a  computationally cheap method for which existing data can be used.  Unlike the FAST and RBD methods which use a specially generated sample  set that contains suitable frequency data for the input factors, in  EASI these frequencies are introduced by sorting and shuffling the  available input samples.","category":"page"},{"location":"copies/GlobalSensitivity/methods/easi/#API","page":"EASI Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/easi/","page":"EASI Method","title":"EASI Method","text":"function gsa(f, method::EASI, p_range; N, batch = false, rng::AbstractRNG = Random.default_rng(), kwargs...)","category":"page"},{"location":"copies/GlobalSensitivity/methods/easi/#Example","page":"EASI Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/easi/","page":"EASI Method","title":"EASI Method","text":"using GlobalSensitivity, Test\n\nfunction ishi_batch(X)\n    A= 7\n    B= 0.1\n    @. sin(X[1,:]) + A*sin(X[2,:])^2+ B*X[3,:]^4 *sin(X[1,:])\nend\nfunction ishi(X)\n    A= 7\n    B= 0.1\n    sin(X[1]) + A*sin(X[2])^2+ B*X[3]^4 *sin(X[1])\nend\n\nlb = -ones(4)*π\nub = ones(4)*π\n\nres1 = gsa(ishi,EASI(),[[lb[i],ub[i]] for i in 1:4],N=15000)\nres2 = gsa(ishi_batch,EASI(),[[lb[i],ub[i]] for i in 1:4],N=15000,batch=true)\n","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#optim","page":"Optim.jl","title":"Optim.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim is Julia package implementing various algorithm to perform univariate and multivariate optimization.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#Installation:-OptimizationOptimJL.jl","page":"Optim.jl","title":"Installation: OptimizationOptimJL.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"To use this package, install the OptimizationOptimJL package:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"import Pkg; Pkg.add(\"OptimizationOptimJL\")","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#Methods","page":"Optim.jl","title":"Methods","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl algorithms can be one of the following:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NelderMead()\nOptim.SimulatedAnnealing()\nOptim.ParticleSwarm()\nOptim.ConjugateGradient()\nOptim.GradientDescent()\nOptim.BFGS()\nOptim.LBFGS()\nOptim.NGMRES()\nOptim.OACCEL()\nOptim.NewtonTrustRegion()\nOptim.Newton()\nOptim.KrylovTrustRegion()\nOptim.ParticleSwarm()\nOptim.SAMIN()","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Each optimizer also takes special arguments which are outlined in the sections below.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following special keyword arguments which are not covered by the common solve arguments can be used with Optim.jl optimizers:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"x_tol: Absolute tolerance in changes of the input vector x, in infinity norm. Defaults to 0.0.\ng_tol: Absolute tolerance in the gradient, in infinity norm. Defaults to 1e-8. For gradient free methods, this will control the main convergence tolerance, which is solver specific.\nf_calls_limit: A soft upper limit on the number of objective calls. Defaults to 0 (unlimited).\ng_calls_limit: A soft upper limit on the number of gradient calls. Defaults to 0 (unlimited).\nh_calls_limit: A soft upper limit on the number of Hessian calls. Defaults to 0 (unlimited).\nallow_f_increases: Allow steps that increase the objective value. Defaults to false. Note that, when setting this to true, the last iterate will be returned as the minimizer even if the objective increased.\nstore_trace: Should a trace of the optimization algorithm's state be stored? Defaults to false.\nshow_trace: Should a trace of the optimization algorithm's state be shown on stdout? Defaults to false.\nextended_trace: Save additional information. Solver dependent. Defaults to false.\ntrace_simplex: Include the full simplex in the trace for NelderMead. Defaults to false.\nshow_every: Trace output is printed every show_everyth iteration.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"For a more extensive documentation of all the algorithms and options please consult the  Documentation","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#Local-Optimizer","page":"Optim.jl","title":"Local Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/#Local-Constraint","page":"Optim.jl","title":"Local Constraint","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following local constraint algorithms:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.IPNewton()\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nμ0 specifies the initial barrier penalty coefficient as either a number or :auto\nshow_linesearch is an option to turn on linesearch verbosity.\nDefaults:\nlinesearch::Function = Optim.backtrack_constrained_grad\nμ0::Union{Symbol,Number} = :auto\nshow_linesearch::Bool = false","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.IPNewton() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\ncons= (x,p) -> [x[1]^2 + x[2]^2]\nx0 = zeros(2)\np  = [1.0,100.0]\nprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= cons)\nprob = Optimization.OptimizationProblem(prob, x0, p, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton())","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#Derivative-Free","page":"Optim.jl","title":"Derivative-Free","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Derivative-free optimizers are optimizers that can be used even in cases where no derivatives or automatic differentiation is specified. While they tend to be less efficient than derivative-based optimizers, they can be easily applied to cases where defining derivatives is difficult. Note that while these methods do not support general constraints, all support bounds constraints via lb and ub in the Optimization.OptimizationProblem.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following derivative-free algorithms:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NelderMead(): Nelder-Mead optimizer\nsolve(problem, NelderMead(parameters, initial_simplex))\nparameters = AdaptiveParameters() or parameters = FixedParameters()\ninitial_simplex = AffineSimplexer()\nDefaults:\nparameters = AdaptiveParameters()\ninitial_simplex = AffineSimplexer()\nOptim.SimulatedAnnealing(): Simulated Annealing\nsolve(problem, SimulatedAnnealing(neighbor, T, p))\nneighbor is a mutating function of the current and proposed x\nT is a function of the current iteration that returns a temperature\np is a function of the current temperature\nDefaults:\nneighbor = default_neighbor!\nT = default_temperature\np = kirkpatrick\nOptim.ParticleSwarm()","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.NelderMead() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nprob = Optimization.OptimizationProblem(rosenbrock, x0, p)\nsol = solve(prob, Optim.NelderMead())","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#Gradient-Based","page":"Optim.jl","title":"Gradient-Based","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Gradient-based optimizers are optimizers which utilise the gradient information based on derivatives defined or automatic differentiation.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following gradient-based algorithms:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.ConjugateGradient(): Conjugate Gradient Descent\nsolve(problem, ConjugateGradient(alphaguess, linesearch, eta, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\neta determines the next step direction\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialHagerZhang()\nlinesearch = LineSearches.HagerZhang()\neta = 0.4\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.GradientDescent(): Gradient Descent (a quasi-Newton solver)\nsolve(problem, GradientDescent(alphaguess, linesearch, P, precondprep))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nDefaults:\nalphaguess = LineSearches.InitialPrevious()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nOptim.BFGS(): Broyden-Fletcher-Goldfarb-Shanno algorithm\nsolve(problem, BFGS(alpaguess, linesearch, initial_invH, initial_stepnorm, manifold))\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\ninitial_invH specifies an optional initial matrix\ninitial_stepnorm determines that initial_invH is an identity matrix scaled by the value of initial_stepnorm multiplied by the sup-norm of the gradient at the initial point\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\ninitial_invH = nothing\ninitial_stepnorm = nothing\nmanifold = Flat()\nOptim.LBFGS(): Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm\nm is the number of history points\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nP is an optional preconditioner (for more information, see this source)\nprecondpred is used to update P as the state variable x changes\nmanifold specifies a (Riemannian) manifold on which the function is to be minimized (for more information, consult this source)\navailable manifolds:\nFlat\nSphere\nStiefel\nmeta-manifolds:\nPowerManifold\nProductManifold\ncustom manifolds\nscaleinvH0: whether to scale the initial Hessian approximation\nDefaults:\nm = 10\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()\nP = nothing\nprecondprep = (P, x) -> nothing\nmanifold = Flat()\nscaleinvH0::Bool = true && (typeof(P) <: Nothing)\nOptim.NGMRES()\nOptim.OACCEL()","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.LD_LBFGS() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(optprob, x0, p, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, NLopt.LD_LBFGS())","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#Hessian-Based-Second-Order","page":"Optim.jl","title":"Hessian-Based Second Order","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Hessian-based optimization methods are second order optimization methods which use the direct computation of the Hessian. These can converge faster but require fast and accurate methods for calulating the Hessian in order to be appropriate.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following hessian-based algorithms:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.NewtonTrustRegion(): Newton Trust Region method\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75\nOptim.Newton(): Newton's method with line search\nalphaguess computes the initial step length (for more information, consult this source and this example)\navailable initial step length procedures:\nInitialPrevious\nInitialStatic\nInitialHagerZhang\nInitialQuadratic\nInitialConstantChange\nlinesearch specifies the line search algorithm (for more information, consult this source and this example)\navailable line search algorithms:\nHaegerZhang\nMoreThuente\nBackTracking\nStrongWolfe\nStatic\nDefaults:\nalphaguess = LineSearches.InitialStatic()\nlinesearch = LineSearches.HagerZhang()","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.Newton() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock,ModelingToolkit.AutoModelingToolkit(),x0,p,grad=true,hess=true)\nprob = Optimization.OptimizationProblem(f,x0,p)\nsol = solve(prob,Optim.Newton())","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#Hessian-Free-Second-Order","page":"Optim.jl","title":"Hessian-Free Second Order","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Hessian-free methods are methods which perform second order optimization by direct computation of Hessian-vector products (Hv) without requiring the construction of the full Hessian. As such, these methods can perform well for large second order optimization problems, but can require special case when considering conditioning of the Hessian.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.jl implements the following hessian-free algorithms:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.KrylovTrustRegion(): A Newton-Krylov method with Trust Regions\ninitial_delta: The starting trust region radius\ndelta_hat: The largest allowable trust region radius\neta: When rho is at least eta, accept the step.\nrho_lower: When rho is less than rho_lower, shrink the trust region.\nrho_upper: When rho is greater than rhoupper, grow the trust region (though no greater than deltahat).\nDefaults:\ninitial_delta = 1.0\ndelta_hat = 100.0\neta = 0.1\nrho_lower = 0.25\nrho_upper = 0.75","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.KrylovTrustRegion() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\ncons= (x,p) -> [x[1]^2 + x[2]^2]\nx0 = zeros(2)\np  = [1.0,100.0]\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= cons)\nprob = Optimization.OptimizationProblem(optprob, x0, p)\nsol = solve(prob, Optim.KrylovTrustRegion())","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#Global-Optimizer","page":"Optim.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/#Without-Constraint-Equations","page":"Optim.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following method in Optim is performing global optimization on problems without constraint equations. It works both with and without lower and upper constraints set by lb and ub in the Optimization.OptimizationProblem.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.ParticleSwarm(): Particle Swarm Optimization\nsolve(problem, ParticleSwarm(lower, upper, n_particles))\nlower/upper are vectors of lower/upper bounds respectively\nn_particles is the number of particles in the swarm\ndefaults to: lower = [], upper = [], n_particles = 0","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.ParticleSwarm() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb=[-1.0, -1.0], ub=[1.0, 1.0])\nsol = solve(prob, Optim.ParticleSwarm(lower=prob.lb, upper= prob.ub, n_particles=100))","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/#With-Constraint-Equations","page":"Optim.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The following method in Optim is performing global optimization on problems with constraint equations.","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"Optim.SAMIN(): Simulated Annealing with bounds\nsolve(problem, SAMIN(nt, ns, rt, neps, f_tol, x_tol, coverage_ok, verbosity))\nDefaults:\nnt = 5\nns = 5\nrt = 0.9\nneps = 5\nf_tol = 1e-12\nx_tol = 1e-6\ncoverage_ok = false\nverbosity = 0","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"The Rosenbrock function can optimized using the Optim.SAMIN() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/optim/","page":"Optim.jl","title":"Optim.jl","text":"rosenbrock(x, p) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = Optimization.OptimizationProblem(f, x0, p, lb=[-1.0, -1.0], ub=[1.0, 1.0])\nsol = solve(prob, Optim.SAMIN())","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#The-AbstractSystem-Interface","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Overview","page":"The AbstractSystem Interface","title":"Overview","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"The AbstractSystem interface is the core of the system level of ModelingToolkit.jl. It establishes a common set of functionality that is used between systems representing ODEs, PDEs, SDEs and more, allowing users to have a common framework for model manipulation and compilation.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Subtypes","page":"The AbstractSystem Interface","title":"Subtypes","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"There are three immediate subtypes of AbstractSystem, classified by how many independent variables each type has:","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"AbstractTimeIndependentSystem: has no independent variable (eg: NonlinearSystem)\nAbstractTimeDependentSystem: has a single independent variable (eg: ODESystem)\nAbstractMultivariateSystem: may have multiple independent variables (eg: PDESystem)","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Constructors-and-Naming","page":"The AbstractSystem Interface","title":"Constructors and Naming","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"The AbstractSystem interface has a consistent method for constructing systems. Generally it follows the order of:","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"Equations\nIndependent Variables\nDependent Variables (or States)\nParameters","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"All other pieces are handled via keyword arguments. AbstractSystems share the same keyword arguments, which are:","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"system: This is used for specifying subsystems for hierarchical modeling with reusable components. For more information, see the components page\nDefaults: Keyword arguments like defaults are used for specifying default values which are used. If a value is not given at the SciMLProblem construction time, its numerical value will be the default.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Composition-and-Accessor-Functions","page":"The AbstractSystem Interface","title":"Composition and Accessor Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"Each AbstractSystem has lists of variables in context, such as distinguishing parameters vs states. In addition, an AbstractSystem also can hold other AbstractSystem types. Direct accessing of the values, such as sys.states, gives the immediate list, while the accessor functions states(sys) gives the total set, which includes that of all systems held inside.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"The values which are common to all AbstractSystems are:","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"equations(sys): All equations that define the system and its subsystems.\nstates(sys): All the states in the system and its subsystems.\nparameters(sys): All parameters of the system and its subsystems.\nnameof(sys): The name of the current-level system.\nget_eqs(sys): Equations that define the current-level system.\nget_states(sys): States that are in the current-level system.\nget_ps(sys): Parameters that are in the current-level system.\nget_systems(sys): Subsystems of the current-level system.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"Optionally, a system could have:","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"observed(sys): All observed equations of the system and its subsystems.\nget_observed(sys): Observed equations of the current-level system.\nget_continuous_events(sys): SymbolicContinuousCallbacks of the current-level system.\nget_defaults(sys): A Dict that maps variables into their default values.\nindependent_variables(sys): The independent variables of a system.\nget_noiseeqs(sys): Noise equations of the current-level system.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"Note that if you know a system is an AbstractTimeDependentSystem you could use get_iv to get the  unique independent variable directly, rather than using independent_variables(sys)[1], which is clunky and may cause problems if sys is an AbstractMultivariateSystem because there may be more than one independent variable. AbstractTimeIndependentSystems do not have a method get_iv, and independent_variables(sys) will return a size-zero result for such. For an AbstractMultivariateSystem, get_ivs is equivalent.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"A system could also have caches:","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"get_jac(sys): The Jacobian of a system.\nget_tgrad(sys): The gradient with respect to time of a system.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Transformations","page":"The AbstractSystem Interface","title":"Transformations","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"Transformations are functions which send a valid AbstractSystem definition to another AbstractSystem. These are passes, like optimizations (e.g., Block-Lower Triangle transformations), or changes to the representation, which allow for alternative numerical methods to be utilized on the model (e.g., DAE index reduction).","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Analyses","page":"The AbstractSystem Interface","title":"Analyses","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"Analyses are functions on a system which return information about the corresponding properties, like whether its parameters are structurally identifiable, or whether it's linear.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Function-Calculation-and-Generation","page":"The AbstractSystem Interface","title":"Function Calculation and Generation","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"The calculation and generation functions allow for calculating additional quantities to enhance the numerical methods applied to the resulting system. The calculations, like calculate_jacobian, generate ModelingToolkit IR for the Jacobian of the system, while the generations, like generate_jacobian, generate compiled output for the numerical solvers by applying build_function to the generated code. Additionally, many systems have function-type outputs, which cobble together the generation functionality for a system, for example, ODEFunction can be used to generate a DifferentialEquations-based ODEFunction with compiled version of the ODE itself, the Jacobian, the mass matrix, etc.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"Below are the possible calculation and generation functions:","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"calculate_tgrad\ncalculate_gradient\ncalculate_jacobian\ncalculate_factorized_W\ncalculate_hessian\ngenerate_tgrad\ngenerate_gradient\ngenerate_jacobian\ngenerate_factorized_W\ngenerate_hessian","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.calculate_tgrad","page":"The AbstractSystem Interface","title":"ModelingToolkit.calculate_tgrad","text":"calculate_tgrad(sys::AbstractTimeDependentSystem)\n\nCalculate the time gradient of a system.\n\nReturns a vector of Num instances. The result from the first call will be cached in the system object.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.calculate_gradient","page":"The AbstractSystem Interface","title":"ModelingToolkit.calculate_gradient","text":"calculate_gradient(sys::AbstractSystem)\n\nCalculate the gradient of a scalar system.\n\nReturns a vector of Num instances. The result from the first call will be cached in the system object.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.calculate_jacobian","page":"The AbstractSystem Interface","title":"ModelingToolkit.calculate_jacobian","text":"calculate_jacobian(sys::AbstractSystem)\n\nCalculate the jacobian matrix of a system.\n\nReturns a matrix of Num instances. The result from the first call will be cached in the system object.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.calculate_factorized_W","page":"The AbstractSystem Interface","title":"ModelingToolkit.calculate_factorized_W","text":"calculate_factorized_W(sys::AbstractSystem)\n\nCalculate the factorized W-matrix of a system.\n\nReturns a matrix of Num instances. The result from the first call will be cached in the system object.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.calculate_hessian","page":"The AbstractSystem Interface","title":"ModelingToolkit.calculate_hessian","text":"calculate_hessian(sys::AbstractSystem)\n\nCalculate the hessian matrix of a scalar system.\n\nReturns a matrix of Num instances. The result from the first call will be cached in the system object.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.generate_tgrad","page":"The AbstractSystem Interface","title":"ModelingToolkit.generate_tgrad","text":"generate_tgrad(sys::AbstractTimeDependentSystem, dvs = states(sys), ps = parameters(sys), expression = Val{true}; kwargs...)\n\nGenerates a function for the time gradient of a system. Extra arguments control the arguments to the internal build_function call.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.generate_gradient","page":"The AbstractSystem Interface","title":"ModelingToolkit.generate_gradient","text":"generate_gradient(sys::AbstractSystem, dvs = states(sys), ps = parameters(sys), expression = Val{true}; kwargs...)\n\nGenerates a function for the gradient of a system. Extra arguments control the arguments to the internal build_function call.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.generate_jacobian","page":"The AbstractSystem Interface","title":"ModelingToolkit.generate_jacobian","text":"generate_jacobian(sys::AbstractSystem, dvs = states(sys), ps = parameters(sys), expression = Val{true}; sparse = false, kwargs...)\n\nGenerates a function for the jacobian matrix matrix of a system. Extra arguments control the arguments to the internal build_function call.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.generate_factorized_W","page":"The AbstractSystem Interface","title":"ModelingToolkit.generate_factorized_W","text":"generate_factorized_W(sys::AbstractSystem, dvs = states(sys), ps = parameters(sys), expression = Val{true}; sparse = false, kwargs...)\n\nGenerates a function for the factorized W-matrix matrix of a system. Extra arguments control the arguments to the internal build_function call.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#ModelingToolkit.generate_hessian","page":"The AbstractSystem Interface","title":"ModelingToolkit.generate_hessian","text":"generate_hessian(sys::AbstractSystem, dvs = states(sys), ps = parameters(sys), expression = Val{true}; sparse = false, kwargs...)\n\nGenerates a function for the hessian matrix matrix of a system. Extra arguments control the arguments to the internal build_function call.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"Additionally, jacobian_sparsity(sys) and hessian_sparsity(sys) exist on the appropriate systems for fast generation of the sparsity patterns via an abstract interpretation without requiring differentiation.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Problem-Constructors","page":"The AbstractSystem Interface","title":"Problem Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"At the end, the system types have DEProblem constructors, like ODEProblem, which allow for directly generating the problem types required for numerical methods. The first argument is always the AbstractSystem, and the proceeding arguments match the argument order of their original constructors. Whenever an array would normally be provided, such as u0 the initial condition of an ODEProblem, it is instead replaced with a variable map, i.e., an array of pairs var=>value, which allows the user to designate the values without having to know the order that ModelingToolkit is internally using.","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"For the value maps, the parameters are allowed to be functions of each other, and value maps of states can be functions of the parameters, i.e. you can do:","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"u0 = [\n  lorenz1.x => 2.0\n  lorenz2.x => lorenz1.x * lorenz1.p\n]","category":"page"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/#Default-Value-Handling","page":"The AbstractSystem Interface","title":"Default Value Handling","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/AbstractSystem/","page":"The AbstractSystem Interface","title":"The AbstractSystem Interface","text":"The AbstractSystem types allow for specifying default values, for example defaults inside of them. At problem construction time, these values are merged into the value maps, where for any repeats the value maps override the default. In addition, defaults of a higher level in the system override the defaults of a lower level in the system.","category":"page"},{"location":"copies/GlobalSensitivity/methods/dgsm/#Derivative-based-Global-Sensitivity-Measure-Method","page":"Derivative based Global Sensitivity Measure Method","title":"Derivative based Global Sensitivity Measure Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/dgsm/","page":"Derivative based Global Sensitivity Measure Method","title":"Derivative based Global Sensitivity Measure Method","text":"struct DGSM <: GSAMethod\n    crossed::Bool \nend","category":"page"},{"location":"copies/GlobalSensitivity/methods/dgsm/","page":"Derivative based Global Sensitivity Measure Method","title":"Derivative based Global Sensitivity Measure Method","text":"The keyword arguments for DGSM are as follows:","category":"page"},{"location":"copies/GlobalSensitivity/methods/dgsm/","page":"Derivative based Global Sensitivity Measure Method","title":"Derivative based Global Sensitivity Measure Method","text":"crossed: A string(True/False) which act as indicator for computation of DGSM crossed indices. Defaults to false.","category":"page"},{"location":"copies/GlobalSensitivity/methods/dgsm/#Method-Details","page":"Derivative based Global Sensitivity Measure Method","title":"Method Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/dgsm/","page":"Derivative based Global Sensitivity Measure Method","title":"Derivative based Global Sensitivity Measure Method","text":"The DGSM method takes a probability distribution for each of the  parameters and samples are obtained from the distributions to create  random parameter sets. Derivatives of the function being analysed are  then computed at the sampled parameters and specific statistics of those  derivatives are used. The paper by Sobol and Kucherenko  discusses the relationship between the DGSM results, tao and  sigma and the Morris elementary effects and Sobol Indices.","category":"page"},{"location":"copies/GlobalSensitivity/methods/dgsm/#API","page":"Derivative based Global Sensitivity Measure Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/dgsm/","page":"Derivative based Global Sensitivity Measure Method","title":"Derivative based Global Sensitivity Measure Method","text":"function gsa(f, method::DGSM, dist::AbstractArray; samples::Int, kwargs...)","category":"page"},{"location":"copies/GlobalSensitivity/methods/dgsm/","page":"Derivative based Global Sensitivity Measure Method","title":"Derivative based Global Sensitivity Measure Method","text":"dist: Array of distribution of respective variables. E.g. dist = [Normal(5,6),Uniform(2,3)] for two variables.","category":"page"},{"location":"copies/GlobalSensitivity/methods/dgsm/#Example","page":"Derivative based Global Sensitivity Measure Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/dgsm/","page":"Derivative based Global Sensitivity Measure Method","title":"Derivative based Global Sensitivity Measure Method","text":"using GlobalSensitivity, Test, Distributions\n\nsamples = 2000000\n\nf1(x) = x[1] + 2*x[2] + 6.00*x[3]\ndist1 = [Uniform(4,10),Normal(4,23),Beta(2,3)]\nb =  gsa(f1,DGSM(),dist1,samples=samples)","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary:-Thermal-Components","page":"Thermal Components","title":"ModelingToolkitStandardLibrary: Thermal Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/","page":"Thermal Components","title":"Thermal Components","text":"CurrentModule = ModelingToolkitStandardLibrary.Thermal","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#Thermal-Utilities","page":"Thermal Components","title":"Thermal Utilities","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/","page":"Thermal Components","title":"Thermal Components","text":"HeatPort\nElement1D","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.HeatPort","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.HeatPort","text":"HeatPort(; name, T_start=273.15 + 20.0, Q_flow_start=0.0)\n\nPort for a thermal system.\n\nParameters:\n\nT_start: [K] Temperature of the port  \nQ_flow_start: [W] Heat flow rate at the port\n\nStates:\n\nT: [K] Temperature of the port  \nQ_flow: [W] Heat flow rate at the port\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.Element1D","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.Element1D","text":"Element1D(;name, dT0=0.0, Q_flow0=0.0)\n\nThis partial model contains the basic connectors and variables to allow heat transfer models to be created that do not  store energy. This model defines and includes equations for the temperature drop across the element, dT, and the heat flow rate through the element from port_a to port_b, Q_flow.\n\nParameters:\n\ndT_start:  [K] Initial temperature difference across the component a.T - b.T\nQ_flow_start: [W] Initial heat flow rate from port a -> port b\n\nStates:\n\ndT:  [K] Temperature difference across the component a.T - b.T\nQ_flow: [W] Heat flow rate from port a -> port b\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#Thermal-Components","page":"Thermal Components","title":"Thermal Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/","page":"Thermal Components","title":"Thermal Components","text":"BodyRadiation\nConvectiveConductor\nConvectiveResistor\nHeatCapacitor\nThermalConductor\nThermalResistor\nThermalCollector","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.BodyRadiation","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.BodyRadiation","text":"BodyRadiation(; name, G)\n\nLumped thermal element for radiation heat transfer.\n\nParameters:\n\nG: [m^2] Net radiation conductance between two surfaces\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.ConvectiveConductor","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.ConvectiveConductor","text":"ConvectiveConductor(; name, G)\n\nLumped thermal element for heat convection.\n\nParameters:\n\nG: [W/K] Convective thermal conductance\n\nStates:\n\ndT:  [K] Temperature difference across the component solid.T - fluid.T\nQ_flow: [W] Heat flow rate from solid -> fluid\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.ConvectiveResistor","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.ConvectiveResistor","text":"ConvectiveResistor(; name, R)\n\nLumped thermal element for heat convection.\n\nParameters:\n\nR: [K/W] Constant thermal resistance of material\n\nStates:\n\ndT:  [K] Temperature difference across the component solid.T - fluid.T\nQ_flow: [W] Heat flow rate from solid -> fluid\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.HeatCapacitor","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.HeatCapacitor","text":"HeatCapacitor(; name, C, T_start=273.15 + 20)\n\nLumped thermal element storing heat\n\nParameters:\n\nC: [J/K] Heat capacity of element (= cp*m)\nT_start: Initial temperature of element\n\nStates:\n\nT: [K] Temperature of element\nder_T: [K/s] Time derivative of temperature\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.ThermalConductor","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.ThermalConductor","text":"ThermalConductor(;name, G)\n\nLumped thermal element transporting heat without storing it.\n\nParameters:\n\nG: [W/K] Constant thermal conductance of material\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.ThermalResistor","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.ThermalResistor","text":"ThermalResistor(; name, R)\n\nLumped thermal element transporting heat without storing it.\n\nParameters:\n\nR: [K/W] Constant thermal resistance of material\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.ThermalCollector","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.ThermalCollector","text":"ThermalCollector(; name, m=1)\n\nCollects m heat flows\n\nThis is a model to collect the heat flows from m heatports to one single heatport.\n\nParameters:\n\nm: Number of heat ports (e.g. m=2: port_a1, port_a2)\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#Thermal-Sensors","page":"Thermal Components","title":"Thermal Sensors","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/","page":"Thermal Components","title":"Thermal Components","text":"RelativeTemperatureSensor\nHeatFlowSensor\nTemperatureSensor","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.RelativeTemperatureSensor","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.RelativeTemperatureSensor","text":"RelativeTemperatureSensor(; name)\n\nRelative Temperature sensor.\n\nThe relative temperature port_a.T - port_b.T is determined between the two ports of this component and is provided as  output signal in kelvin.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.HeatFlowSensor","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.HeatFlowSensor","text":"HeatFlowSensor(; name)\n\nHeat flow rate sensor.\n\nThis model is capable of monitoring the heat flow rate flowing through this component. The sensed value of heat flow rate is the amount that passes through this sensor while keeping the temperature drop across the sensor zero. This is an ideal  model so it does not absorb any energy and it has no direct effect on the thermal response of a system it is included in. The output signal is positive, if the heat flows from port_a to port_b.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.TemperatureSensor","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.TemperatureSensor","text":"TemperatureSensor(; name)\n\nAbsolute temperature sensor in kelvin.\n\nThis is an ideal absolute temperature sensor which returns the temperature of the connected port in kelvin as an output signal. The sensor itself has no thermal interaction with whatever it is connected to. Furthermore, no thermocouple-like  lags are associated with this sensor model.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#Thermal-Sources","page":"Thermal Components","title":"Thermal Sources","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/","page":"Thermal Components","title":"Thermal Components","text":"FixedHeatFlow\nFixedTemperature ","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.FixedHeatFlow","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.FixedHeatFlow","text":"FixedHeatFlow(; name, Q_flow=1.0, T_ref=293.15, alpha=0.0)\n\nFixed heat flow boundary condition.\n\nThis model allows a specified amount of heat flow rate to be \"injected\" into a thermal system at a given port. The constant amount of heat flow rate Q_flow is given as a parameter. The heat flows into the component to which the component FixedHeatFlow is connected, if parameter Q_flow is positive.\n\nParameters:\n\nQ_flow: [W] Fixed heat flow rate at port\nT_ref: [K] Reference temperature\nalpha: [1/K] Temperature coefficient of heat flow rate\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/thermal/#ModelingToolkitStandardLibrary.Thermal.FixedTemperature","page":"Thermal Components","title":"ModelingToolkitStandardLibrary.Thermal.FixedTemperature","text":"FixedTemperature(; name, T)\n\nFixed temperature boundary condition in kelvin.\n\nThis model defines a fixed temperature T at its port in kelvin, i.e., it defines a fixed temperature as a boundary condition.\n\nParameters:\n\nT: [K] Fixed temperature boundary condition\n\n\n\n\n\n","category":"function"},{"location":"copies/DiffEqFlux/#DiffEqFlux:-High-Level-Scientific-Machine-Learning-(SciML)-Pre-Built-Architectures","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"","category":"section"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"DiffEqFlux.jl is a parameter estimation system for the SciML ecosystem. It is a high level interface that pulls together all of the tools with heuristics and helper functions to make solving inverse problems and inferring models as easy as possible without losing efficiency.","category":"page"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"note: Note\nDiffEqFlux.jl is only for pre-built architectures and utility functions for model callibration and mixing differential equations with machine learning. For details on automatic differentiation of equation solvers and adjoint techniques, see SciMLSensitivity.jl","category":"page"},{"location":"copies/DiffEqFlux/#Pre-Built-Architectures","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"Pre-Built Architectures","text":"","category":"section"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"The approach of this package is the easy and efficient training of Universal Differential Equations. DiffEqFlux.jl provides architectures which match the interfaces of machine learning libraries such as Flux.jl to make it easy to compute continuous-time machine learning layers into larger machine learning applications.","category":"page"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"The following layer functions exist:","category":"page"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"Neural Ordinary Differential Equations (Neural ODEs)\nCollocation-Based Neural ODEs (Neural ODEs without a solver, by far the fastest way!)\nMultiple Shooting Neural Ordinary Differential Equations\nNeural Stochastic Differential Equations (Neural SDEs)\nNeural Differential-Algebriac Equations (Neural DAEs)\nNeural Delay Differential Equations (Neural DDEs)\nAugmented Neural ODEs\nHamiltonian Neural Networks (with specialized second order and symplectic integrators)\nContinuous Normalizing Flows (CNF) and FFJORD","category":"page"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"Examples of how to build architectures from scratch, with tutorials on things like Graph Neural ODEs, can be found in the SciMLSensitivity.jl documentation.","category":"page"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"WIP:","category":"page"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"Lagrangian Neural Networks\nGalerkin Neural ODEs","category":"page"},{"location":"copies/DiffEqFlux/#Citation","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"Citation","text":"","category":"section"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"If you use DiffEqFlux.jl or are influenced by its ideas, please cite:","category":"page"},{"location":"copies/DiffEqFlux/","page":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","title":"DiffEqFlux.jl: High Level Scientific Machine Learning (SciML) Pre-Built Architectures","text":"@article{rackauckas2020universal,\n  title={Universal differential equations for scientific machine learning},\n  author={Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},\n  journal={arXiv preprint arXiv:2001.04385},\n  year={2020}\n}","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/#Bayesian-Neural-ODEs:-NUTS","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"In this tutorial, we show how the DiffEqFlux.jl library in Julia can be seamlessly combined with Bayesian estimation libraries like AdvancedHMC.jl and Turing.jl. This enables converting Neural ODEs to Bayesian Neural ODEs, which enables us to estimate the error in the Neural ODE estimation and forecasting. In this tutorial, a working example of the Bayesian Neural ODE: NUTS sampler is shown.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"For more details, please refer to Bayesian Neural Ordinary Differential Equations.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/#Copy-Pasteable-Code","page":"Bayesian Neural ODEs: NUTS","title":"Copy-Pasteable Code","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"Before getting to the explanation, here's some code to start with. We will follow wil a full explanation of the definition and training process:","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"using DiffEqFlux, DifferentialEquations, Plots, AdvancedHMC, MCMCChains\nusing JLD, StatsPlots\n\nu0 = [2.0; 0.0]\ndatasize = 40\ntspan = (0.0, 1)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\n\ndudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\n\nfunction predict_neuralode(p)\n    Array(prob_neuralode(u0, p))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, ode_data .- pred)\n    return loss, pred\nend\n\nl(θ) = -sum(abs2, ode_data .- predict_neuralode(θ)) - sum(θ .* θ)\n\n\nfunction dldθ(θ)\n    x,lambda = Flux.Zygote.pullback(l,θ)\n    grad = first(lambda(1))\n    return x, grad\nend\n\nmetric  = DiagEuclideanMetric(length(prob_neuralode.p))\n\nh = Hamiltonian(metric, l, dldθ)\n\n\nintegrator = Leapfrog(find_good_stepsize(h, Float64.(prob_neuralode.p)))\n\n\nprop = AdvancedHMC.NUTS{MultinomialTS, GeneralisedNoUTurn}(integrator)\n\nadaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(0.45, integrator))\n\nsamples, stats = sample(h, prop, Float64.(prob_neuralode.p), 500, adaptor, 500; progress=true)\n\n\nlosses = map(x-> x[1],[loss_neuralode(samples[i]) for i in 1:length(samples)])\n\n##################### PLOTS: LOSSES ###############\nscatter(losses, ylabel = \"Loss\",  yscale= :log, label = \"Architecture1: 500 warmup, 500 sample\")\n\n################### RETRODICTED PLOTS: TIME SERIES #################\npl = scatter(tsteps, ode_data[1,:], color = :red, label = \"Data: Var1\", xlabel = \"t\", title = \"Spiral Neural ODE\")\nscatter!(tsteps, ode_data[2,:], color = :blue, label = \"Data: Var2\")\n\nfor k in 1:300\n    resol = predict_neuralode(samples[100:end][rand(1:400)])\n    plot!(tsteps,resol[1,:], alpha=0.04, color = :red, label = \"\")\n    plot!(tsteps,resol[2,:], alpha=0.04, color = :blue, label = \"\")\nend\n\nidx = findmin(losses)[2]\nprediction = predict_neuralode(samples[idx])\n\nplot!(tsteps,prediction[1,:], color = :black, w = 2, label = \"\")\nplot!(tsteps,prediction[2,:], color = :black, w = 2, label = \"Best fit prediction\", ylims = (-2.5, 3.5))\n\n\n\n#################### RETRODICTED PLOTS - CONTOUR ####################\npl = scatter(ode_data[1,:], ode_data[2,:], color = :red, label = \"Data\",  xlabel = \"Var1\", ylabel = \"Var2\", title = \"Spiral Neural ODE\")\n\nfor k in 1:300\n    resol = predict_neuralode(samples[100:end][rand(1:400)])\n    plot!(resol[1,:],resol[2,:], alpha=0.04, color = :red, label = \"\")\nend\n\nplot!(prediction[1,:], prediction[2,:], color = :black, w = 2, label = \"Best fit prediction\", ylims = (-2.5, 3))\n","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"Time Series Plots:","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"Contour Plots:","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"######################## CHAIN DIAGNOSIS PLOTS#########################\nsamples = hcat(samples...)\n\nsamples_reduced = samples[1:5, :]\n\nsamples_reshape = reshape(samples_reduced, (500, 5, 1))\n\nChain_Spiral = Chains(samples_reshape)\n\nplot(Chain_Spiral)\n\nautocorplot(Chain_Spiral)\n","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"Chain Mixing Plot:","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"Auto-Correlation Plot:","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/#Explanation","page":"Bayesian Neural ODEs: NUTS","title":"Explanation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/#Step-1:-Get-the-data-from-the-Spiral-ODE-example","page":"Bayesian Neural ODEs: NUTS","title":"Step 1: Get the data from the Spiral ODE example","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"u0 = [2.0; 0.0]\ndatasize = 40\ntspan = (0.0, 1)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/#Step-2:-Define-the-Neural-ODE-architecture.","page":"Bayesian Neural ODEs: NUTS","title":"Step 2: Define the Neural ODE architecture.","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"Note that this step potentially offers a lot of flexibility in the number of layers/ number of units in each layer. It may not necessarily be true that a 100 units architecture is better at prediction/forecasting than a 50 unit architecture. On the other hand, a complicated architecture can take a huge computational time without increasing performance.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"dudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/#Step-3:-Define-the-loss-function-for-the-Neural-ODE.","page":"Bayesian Neural ODEs: NUTS","title":"Step 3: Define the loss function for the Neural ODE.","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"function predict_neuralode(p)\n    Array(prob_neuralode(u0, p))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, ode_data .- pred)\n    return loss, pred\nend\n","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/#Step-4:-Now-we-start-integrating-the-Bayesian-estimation-workflow-as-prescribed-by-the-AdvancedHMC-interface-with-the-NeuralODE-defined-above.","page":"Bayesian Neural ODEs: NUTS","title":"Step 4: Now we start integrating the Bayesian estimation workflow as prescribed by the AdvancedHMC interface with the NeuralODE defined above.","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"The Advanced HMC interface requires us to specify: (a) the hamiltonian log density and its gradient , (b) the sampler and (c) the step size adaptor function.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"For the hamiltonian log density, we use the loss function. The θ*θ term denotes the use of Gaussian priors.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"The user can make several modifications to Step 4. The user can try different acceptance ratios, warmup samples and posterior samples. One can also use the Variational Inference (ADVI) framework, which doesn't work quite as well as NUTS. The SGLD (Stochastic Langevin Gradient Descent) sampler is seen to have a better performance than NUTS. Have a look at https://sebastiancallh.github.io/post/langevin/ for a quick introduction to SGLD.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"l(θ) = -sum(abs2, ode_data .- predict_neuralode(θ)) - sum(θ .* θ)\n\n\nfunction dldθ(θ)\n    x,lambda = Flux.Zygote.pullback(l,θ)\n    grad = first(lambda(1))\n    return x, grad\nend\n\nmetric  = DiagEuclideanMetric(length(prob_neuralode.p))\n\nh = Hamiltonian(metric, l, dldθ)\n","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"We use the NUTS sampler with a acceptance ratio of δ= 0.45 in this example. In addition, we use Nesterov Dual Averaging for the Step Size adaptation.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"We sample using 500 warmup samples and 500 posterior samples.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"\nintegrator = Leapfrog(find_good_stepsize(h, Float64.(prob_neuralode.p)))\n\n\nprop = AdvancedHMC.NUTS{MultinomialTS, GeneralisedNoUTurn}(integrator)\n\nadaptor = StanHMCAdaptor(MassMatrixAdaptor(metric), StepSizeAdaptor(0.45, integrator))\n\nsamples, stats = sample(h, prop, Float64.(prob_neuralode.p), 500, adaptor, 500; progress=true)\n","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/#Step-5:-Plot-diagnostics.","page":"Bayesian Neural ODEs: NUTS","title":"Step 5: Plot diagnostics.","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"A: Plot chain object and auto-correlation plot of the first 5 parameters.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"samples = hcat(samples...)\n\nsamples_reduced = samples[1:5, :]\n\nsamples_reshape = reshape(samples_reduced, (500, 5, 1))\n\nChain_Spiral = Chains(samples_reshape)\n\nplot(Chain_Spiral)\n\nautocorplot(Chain_Spiral)","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"B: Plot retrodicted data.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_NUTS/","page":"Bayesian Neural ODEs: NUTS","title":"Bayesian Neural ODEs: NUTS","text":"\n####################TIME SERIES PLOTS###################\npl = scatter(tsteps, ode_data[1,:], color = :red, label = \"Data: Var1\", xlabel = \"t\", title = \"Spiral Neural ODE\")\nscatter!(tsteps, ode_data[2,:], color = :blue, label = \"Data: Var2\")\n\nfor k in 1:300\n    resol = predict_neuralode(samples[100:end][rand(1:400)])\n    plot!(tsteps,resol[1,:], alpha=0.04, color = :red, label = \"\")\n    plot!(tsteps,resol[2,:], alpha=0.04, color = :blue, label = \"\")\nend\n\nidx = findmin(losses)[2]\nprediction = predict_neuralode(samples[idx])\n\nplot!(tsteps,prediction[1,:], color = :black, w = 2, label = \"\")\nplot!(tsteps,prediction[2,:], color = :black, w = 2, label = \"Best fit prediction\", ylims = (-2.5, 3.5))\n\n####################CONTOUR PLOTS#########################3\npl = scatter(ode_data[1,:], ode_data[2,:], color = :red, label = \"Data\",  xlabel = \"Var1\", ylabel = \"Var2\", title = \"Spiral Neural ODE\")\n\nfor k in 1:300\n    resol = predict_neuralode(samples[100:end][rand(1:400)])\n    plot!(resol[1,:],resol[2,:], alpha=0.04, color = :red, label = \"\")\nend\n\nplot!(prediction[1,:], prediction[2,:], color = :black, w = 2, label = \"Best fit prediction\", ylims = (-2.5, 3))\n","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/#Optimization-of-Ordinary-Differential-Equations","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/#Copy-Paste-Code","page":"Optimization of Ordinary Differential Equations","title":"Copy-Paste Code","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"If you want to just get things running, try the following! Explanation will follow.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"using DifferentialEquations, DiffEqFlux, Plots\n\nfunction lotka_volterra!(du, u, p, t)\n  x, y = u\n  α, β, δ, γ = p\n  du[1] = dx = α*x - β*x*y\n  du[2] = dy = -δ*y + γ*x*y\nend\n\n# Initial condition\nu0 = [1.0, 1.0]\n\n# Simulation interval and intermediary points\ntspan = (0.0, 10.0)\ntsteps = 0.0:0.1:10.0\n\n# LV equation parameter. p = [α, β, δ, γ]\np = [1.5, 1.0, 3.0, 1.0]\n\n# Setup the ODE problem, then solve\nprob = ODEProblem(lotka_volterra!, u0, tspan, p)\nsol = solve(prob, Tsit5())\n\n# Plot the solution\nusing Plots\nplot(sol)\nsavefig(\"LV_ode.png\")\n\nfunction loss(p)\n  sol = solve(prob, Tsit5(), p=p, saveat = tsteps)\n  loss = sum(abs2, sol.-1)\n  return loss, sol\nend\n\ncallback = function (p, l, pred)\n  display(l)\n  plt = plot(pred, ylim = (0, 6))\n  display(plt)\n  # Tell sciml_train to not halt the optimization. If return true, then\n  # optimization stops.\n  return false\nend\n\nresult_ode = DiffEqFlux.sciml_train(loss, p,\n                                    cb = callback,\n                                    maxiters = 100)\n# result_ode = DiffEqFlux.sciml_train(loss, p, ADAM(0.1), cb = callback)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/#Explanation","page":"Optimization of Ordinary Differential Equations","title":"Explanation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"First let's create a Lotka-Volterra ODE using DifferentialEquations.jl. For more details, see the DifferentialEquations.jl documentation. The Lotka-Volterra equations have the form:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"beginaligned\nfracdxdt = alpha x - beta x y      \nfracdydt = -delta y + gamma x y    \nendaligned","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"using DifferentialEquations, DiffEqFlux, Plots\n\nfunction lotka_volterra!(du, u, p, t)\n  x, y = u\n  α, β, δ, γ = p\n  du[1] = dx = α*x - β*x*y\n  du[2] = dy = -δ*y + γ*x*y\nend\n\n# Initial condition\nu0 = [1.0, 1.0]\n\n# Simulation interval and intermediary points\ntspan = (0.0, 10.0)\ntsteps = 0.0:0.1:10.0\n\n# LV equation parameter. p = [α, β, δ, γ]\np = [1.5, 1.0, 3.0, 1.0]\n\n# Setup the ODE problem, then solve\nprob = ODEProblem(lotka_volterra!, u0, tspan, p)\nsol = solve(prob, Tsit5())\n\n# Plot the solution\nusing Plots\nplot(sol)\nsavefig(\"LV_ode.png\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"(Image: LV Solution Plot)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"For this first example, we do not yet include a neural network. We take AD-compatible solve function function that takes the parameters and an initial condition and returns the solution of the differential equation. Next we choose a loss function. Our goal will be to find parameters that make the Lotka-Volterra solution constant x(t)=1, so we define our loss as the squared distance from 1. Note that when using sciml_train, the first return is the loss value, and the other returns are sent to the callback for monitoring convergence.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"function loss(p)\n  sol = solve(prob, Tsit5(), p=p, saveat = tsteps)\n  loss = sum(abs2, sol.-1)\n  return loss, sol\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"Lastly, we use the sciml_train function to train the parameters using ADAM to arrive at parameters which optimize for our goal. sciml_train allows defining a callback that will be called at each step of our training loop. It takes in the current parameter vector and the returns of the last call to the loss function. We will display the current loss and make a plot of the current situation:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"callback = function (p, l, pred)\n  display(l)\n  plt = plot(pred, ylim = (0, 6))\n  display(plt)\n  # Tell sciml_train to not halt the optimization. If return true, then\n  # optimization stops.\n  return false\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"Let's optimize the model.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"result_ode = DiffEqFlux.sciml_train(loss, p, cb = callback)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"In just seconds we found parameters which give a relative loss of 1e-16! We can get the final loss with result_ode.minimum, and get the optimal parameters with result_ode.u. For example, we can plot the final outcome and show that we solved the control problem and successfully found parameters to make the ODE solution constant:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"remade_solution = solve(remake(prob, p = result_ode.u), Tsit5(),      \n                        saveat = tsteps)\nplot(remade_solution, ylim = (0, 6))","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"(Image: Final plot)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"Note that this was done with the default optimizer. One can also pass an optimization method, like ADAM(0.1), and tweak settings like set maxiters=100 to force at most 100 iterations of the optimization. This looks like:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"result_ode = DiffEqFlux.sciml_train(loss, p, ADAM(0.1), cb = callback, maxiters=100)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/optimization_ode/","page":"Optimization of Ordinary Differential Equations","title":"Optimization of Ordinary Differential Equations","text":"For more information on tweaking this functionality, see the sciml_train documentation","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/#ModelingToolkitStandardLibrary.jl","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"ModelingToolkitStandardLibrary.jl","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","text":"ModelingToolkitStandardLibrary.jl is a standard library for the  ModelingToolkit acasual modeling system.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/#Installation","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"Installation","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","text":"Assuming that you already have Julia correctly installed, it suffices to import ModelingToolkitStandardLibrary.jl in the standard way:","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","text":"import Pkg; Pkg.add(\"ModelingToolkitStandardLibrary\")","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/#Tutorials","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"Tutorials","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","text":"RC Circuit Tutorial","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/#Libraries","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"Libraries","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","text":"The following are the constituant libraries of the ModelingToolkit Standard Library.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/","page":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","title":"ModelingToolkitStandardLibrary.jl: A Standard Library for ModelingToolkit","text":"Basic Blocks\nMechanical Components\nElectrical Components\nMagnetic Components\nThermal Components","category":"page"},{"location":"copies/Surrogates/tensor_prod/#Tensor-product-function","page":"Tensor product","title":"Tensor product function","text":"","category":"section"},{"location":"copies/Surrogates/tensor_prod/","page":"Tensor product","title":"Tensor product","text":"The tensor product function is defined as: f(x) = prod_i=1^d cos(api x_i)","category":"page"},{"location":"copies/Surrogates/tensor_prod/","page":"Tensor product","title":"Tensor product","text":"Let's import Surrogates and Plots:","category":"page"},{"location":"copies/Surrogates/tensor_prod/","page":"Tensor product","title":"Tensor product","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/tensor_prod/","page":"Tensor product","title":"Tensor product","text":"Define the 1D objective function:","category":"page"},{"location":"copies/Surrogates/tensor_prod/","page":"Tensor product","title":"Tensor product","text":"function f(x)\n    a = 0.5;\n    return cos(a*pi*x)\nend","category":"page"},{"location":"copies/Surrogates/tensor_prod/","page":"Tensor product","title":"Tensor product","text":"n = 30\nlb = -5.0\nub = 5.0\na = 0.5\nx = sample(n, lb, ub, SobolSample())\ny = f.(x)\nxs = lb:0.001:ub\nscatter(x, y, label=\"Sampled points\", xlims=(lb, ub), ylims=(-1, 1), legend=:top)\nplot!(xs, f.(xs), label=\"True function\", legend=:top)","category":"page"},{"location":"copies/Surrogates/tensor_prod/","page":"Tensor product","title":"Tensor product","text":"Fitting and plotting different surrogates:","category":"page"},{"location":"copies/Surrogates/tensor_prod/","page":"Tensor product","title":"Tensor product","text":"loba_1 = LobachevskySurrogate(x, y, lb, ub)\nkrig = Kriging(x, y, lb, ub)\nscatter(x, y, label=\"Sampled points\", xlims=(lb, ub), ylims=(-2.5, 2.5), legend=:bottom)\nplot!(xs,f.(xs), label=\"True function\", legend=:top)\nplot!(xs, loba_1.(xs), label=\"Lobachevsky\", legend=:top)\nplot!(xs, krig.(xs), label=\"Kriging\", legend=:top)","category":"page"},{"location":"copies/LinearSolve/basics/common_solver_opts/#Common-Solver-Options-(Keyword-Arguments-for-Solve)","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"","category":"section"},{"location":"copies/LinearSolve/basics/common_solver_opts/","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"While many algorithms have specific arguments within their constructor, the keyword arguments for solve are common across all of the algorithms in order to give composability. These are also the options taken at init time. The following are the options these algorithms take, along with their defaults.","category":"page"},{"location":"copies/LinearSolve/basics/common_solver_opts/#General-Controls","page":"Common Solver Options (Keyword Arguments for Solve)","title":"General Controls","text":"","category":"section"},{"location":"copies/LinearSolve/basics/common_solver_opts/","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"alias_A: Whether to alias the matrix A or use a copy by default. When true, algorithms like LU-factorization can be faster by reusing the memory via lu!, but care must be taken as the original input will be modified. Default is false.\nalias_b: Whether to alias the matrix b or use a copy by default. When true, algorithms can write and change b upon usage. Care must be taken as the original input will be modified. Default is false.\nverbose: Whether to print extra information. Defaults to false.","category":"page"},{"location":"copies/LinearSolve/basics/common_solver_opts/#Iterative-Solver-Controls","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Iterative Solver Controls","text":"","category":"section"},{"location":"copies/LinearSolve/basics/common_solver_opts/","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"Error controls are not used by all algorithms. Specifically, direct solves always solve completely. Error controls only apply to iterative solvers.","category":"page"},{"location":"copies/LinearSolve/basics/common_solver_opts/","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"abstol: The absolute tolerance. Defaults to √(eps(eltype(A)))\nreltol: The relative tolerance. Defaults to √(eps(eltype(A)))\nmaxiters: The number of iterations allowed. Defaults to length(prob.b)\nPl,Pr: The left and right preconditioners respectively. For more information see the Preconditioners page.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/#Continuous-Normalizing-Flows-with-GalacticOptim.jl","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"Now, we study a single layer neural network that can estimate the density p_x of a variable of interest x by re-parameterizing a base variable z with known density p_z through the Neural Network model passed to the layer.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/#Copy-Pasteable-Code","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Copy-Pasteable Code","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"Before getting to the explanation, here's some code to start with. We will follow a full explanation of the definition and training process:","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"using DiffEqFlux, DifferentialEquations, GalacticOptim, Distributions\n\nnn = Chain(\n    Dense(1, 3, tanh),\n    Dense(3, 1, tanh),\n) |> f32\ntspan = (0.0f0, 10.0f0)\nffjord_mdl = FFJORD(nn, tspan, Tsit5())\n\n# Training\ndata_dist = Normal(6.0f0, 0.7f0)\ntrain_data = rand(data_dist, 1, 100)\n\nfunction loss(θ)\n    logpx, λ₁, λ₂ = ffjord_mdl(train_data, θ)\n    -mean(logpx)\nend\n\nadtype = GalacticOptim.AutoZygote()\nres1 = DiffEqFlux.sciml_train(loss, ffjord_mdl.p, ADAM(0.1), adtype; maxiters=100)\nres2 = DiffEqFlux.sciml_train(loss, res1.u, LBFGS(), adtype; allow_f_increases=false)\n\n# Evaluation\nusing Distances\n\nactual_pdf = pdf.(data_dist, train_data)\nlearned_pdf = exp.(ffjord_mdl(train_data, res2.u)[1])\ntrain_dis = totalvariation(learned_pdf, actual_pdf) / size(train_data, 2)\n\n# Data Generation\nffjord_dist = FFJORDDistribution(FFJORD(nn, tspan, Tsit5(); p=res2.u))\nnew_data = rand(ffjord_dist, 100)","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/#Step-by-Step-Explanation","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Step-by-Step Explanation","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"We can use DiffEqFlux.jl to define, train and output the densities computed by CNF layers. In the same way as a neural ODE, the layer takes a neural network that defines its derivative function (see [1] for a reference). A possible way to define a CNF layer, would be:","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"using DiffEqFlux, DifferentialEquations, GalacticOptim, Distributions\n\nnn = Chain(\n    Dense(1, 3, tanh),\n    Dense(3, 1, tanh),\n) |> f32\ntspan = (0.0f0, 10.0f0)\nffjord_mdl = FFJORD(nn, tspan, Tsit5())","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"where we also pass as an input the desired timespan for which the differential equation that defines log p_x and z(t) will be solved.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/#Training","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Training","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"First, let's get an array from a normal distribution as the training data","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"data_dist = Normal(6.0f0, 0.7f0)\ntrain_data = rand(data_dist, 1, 100)","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"Now we define a loss function that we wish to minimize","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"function loss(θ)\n    logpx, λ₁, λ₂ = ffjord_mdl(train_data, θ)\n    -mean(logpx)\nend","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"In this example, we wish to choose the parameters of the network such that the likelihood of the re-parameterized variable is maximized. Other loss functions may be used depending on the application. Furthermore, the CNF layer gives the log of the density of the variable x, as one may guess from the code above.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"We then train the neural network to learn the distribution of x.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"Here we showcase starting the optimization with ADAM to more quickly find a minimum, and then honing in on the minimum by using LBFGS.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"adtype = GalacticOptim.AutoZygote()\nres1 = DiffEqFlux.sciml_train(loss, ffjord_mdl.p, ADAM(0.1), adtype; maxiters=100)\n\n# output\n* Status: success\n\n* Candidate solution\n   u: [-1.88e+00, 2.44e+00, 2.01e-01,  ...]\n   Minimum:   1.240627e+00\n\n* Found with\n   Algorithm:     ADAM\n   Initial Point: [9.33e-01, 1.13e+00, 2.92e-01,  ...]\n","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"We then complete the training using a different optimizer starting from where ADAM stopped.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"res2 = DiffEqFlux.sciml_train(loss, res1.u, LBFGS(), adtype; allow_f_increases=false)\n\n# output\n* Status: success\n\n* Candidate solution\n   u: [-1.06e+00, 2.24e+00, 8.77e-01,  ...]\n   Minimum:   1.157672e+00\n\n* Found with\n   Algorithm:     L-BFGS\n   Initial Point: [-1.88e+00, 2.44e+00, 2.01e-01,  ...]\n\n* Convergence measures\n   |x - x'|               = 0.00e+00 ≰ 0.0e+00\n   |x - x'|/|x'|          = 0.00e+00 ≰ 0.0e+00\n   |f(x) - f(x')|         = 0.00e+00 ≤ 0.0e+00\n   |f(x) - f(x')|/|f(x')| = 0.00e+00 ≤ 0.0e+00\n   |g(x)|                 = 4.09e-03 ≰ 1.0e-08\n\n* Work counters\n   Seconds run:   514  (vs limit Inf)\n   Iterations:    44\n   f(x) calls:    244\n   ∇f(x) calls:   244","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/#Evaluation","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Evaluation","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"For evaluating the result, we can use totalvariation function from Distances.jl. First, we compute densities using actual distribution and FFJORD model. then we use a distance function.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"using Distances\n\nactual_pdf = pdf.(data_dist, train_data)\nlearned_pdf = exp.(ffjord_mdl(train_data, res2.u)[1])\ntrain_dis = totalvariation(learned_pdf, actual_pdf) / size(train_data, 2)","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/#Data-Generation","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Data Generation","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"What's more, we can generate new data by using FFJORD as a distribution in rand.","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"ffjord_dist = FFJORDDistribution(FFJORD(nn, tspan, Tsit5(); p=res2.u))\nnew_data = rand(ffjord_dist, 100)","category":"page"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/#References","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"References","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/normalizing_flows/","page":"Continuous Normalizing Flows with GalacticOptim.jl","title":"Continuous Normalizing Flows with GalacticOptim.jl","text":"[1] Grathwohl, Will, Ricky TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. \"Ffjord: Free-form continuous dynamics for scalable reversible generative models.\" arXiv preprint arXiv:1810.01367 (2018).","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/#Smoothed-Collocation-for-Fast-Two-Stage-Training","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"One can avoid a lot of the computational cost of the ODE solver by pretraining the neural network against a smoothed collocation of the data. First the example and then an explanation.","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"using DiffEqFlux, DifferentialEquations, Plots\n\nu0 = Float32[2.0; 0.0]\ndatasize = 300\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\ndata = Array(solve(prob_trueode, Tsit5(), saveat = tsteps)) .+ 0.1randn(2,300)\n\ndu,u = collocate_data(data,tsteps,EpanechnikovKernel())\n\nscatter(tsteps,data')\nplot!(tsteps,u',lw=5)\nsavefig(\"colloc.png\")\nplot(tsteps,du')\nsavefig(\"colloc_du.png\")\n\ndudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\n\nfunction loss(p)\n    cost = zero(first(p))\n    for i in 1:size(du,2)\n      _du = dudt2(@view(u[:,i]),p)\n      dui = @view du[:,i]\n      cost += sum(abs2,dui .- _du)\n    end\n    sqrt(cost)\nend\n\npinit = initial_params(dudt2)\ncallback = function (p, l)\n  return false\nend\n\nresult_neuralode = DiffEqFlux.sciml_train(loss, pinit,\n                                          ADAM(0.05), cb = callback,\n                                          maxiters = 10000)\n\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\nnn_sol = prob_neuralode(u0, result_neuralode.u)\nscatter(tsteps,data')\nplot!(nn_sol)\nsavefig(\"colloc_trained.png\")\n\nfunction predict_neuralode(p)\n  Array(prob_neuralode(u0, p))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, data .- pred)\n    return loss\nend\n\n@time numerical_neuralode = DiffEqFlux.sciml_train(loss_neuralode, result_neuralode.u,\n                                                ADAM(0.05), cb = callback,\n                                                maxiters = 300)\n\nnn_sol = prob_neuralode(u0, numerical_neuralode.u)\nscatter(tsteps,data')\nplot!(nn_sol,lw=5)\nsavefig(\"post_trained.png\")","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/#Generating-the-Collocation","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Generating the Collocation","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"The smoothed collocation is a spline fit of the datapoints which allows us to get a an estimate of the approximate noiseless dynamics:","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"using DiffEqFlux, DifferentialEquations, Plots\n\nu0 = Float32[2.0; 0.0]\ndatasize = 300\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\ndata = Array(solve(prob_trueode, Tsit5(), saveat = tsteps)) .+ 0.1randn(2,300)\n\ndu,u = collocate_data(data,tsteps,EpanechnikovKernel())\n\nscatter(tsteps,data')\nplot!(tsteps,u',lw=5)","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"(Image: )","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"We can then differentiate the smoothed function to get estimates of the derivative at each datapoint:","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"plot(tsteps,du')","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"(Image: )","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"Because we have (u',u) pairs, we can write a loss function that calculates the squared difference between f(u,p,t) and u' at each point, and find the parameters which minimize this difference:","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"dudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\n\nfunction loss(p)\n    cost = zero(first(p))\n    for i in 1:size(du,2)\n      _du = dudt2(@view(u[:,i]),p)\n      dui = @view du[:,i]\n      cost += sum(abs2,dui .- _du)\n    end\n    sqrt(cost)\nend\n\npinit = initial_params(dudt2)\ncallback = function (p, l)\n  return false\nend\n\nresult_neuralode = DiffEqFlux.sciml_train(loss, pinit,\n                                          ADAM(0.05), cb = callback,\n                                          maxiters = 10000)\n\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\nnn_sol = prob_neuralode(u0, result_neuralode.u)\nscatter(tsteps,data')\nplot!(nn_sol)","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"(Image: )","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"While this doesn't look great, it has the characteristics of the full solution all throughout the timeseries, but it does have a drift. We can continue to optimize like this, or we can use this as the initial condition to the next phase of our fitting:","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"function predict_neuralode(p)\n  Array(prob_neuralode(u0, p))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, data .- pred)\n    return loss\nend\n\n@time numerical_neuralode = DiffEqFlux.sciml_train(loss_neuralode, result_neuralode.u,\n                                                ADAM(0.05), cb = callback,\n                                                maxiters = 300)\n\nnn_sol = prob_neuralode(u0, numerical_neuralode.u)\nscatter(tsteps,data')\nplot!(nn_sol,lw=5)","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"(Image: )","category":"page"},{"location":"copies/DiffEqFlux/examples/collocation/","page":"Smoothed Collocation for Fast Two-Stage Training","title":"Smoothed Collocation for Fast Two-Stage Training","text":"This method then has a good global starting position, making it less prone to local minima and is thus a great method to mix in with other fitting methods for neural ODEs.","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/#Contextual-Variable-Types","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"ModelingToolkit.jl has a system of contextual variable types which allows for helping the system transformation machinery do complex manipulations and automatic detection. The standard variable definition in ModelingToolkit.jl is the @variable which is defined by Symbolics.jl. For example:","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"@variables x y(x)","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"This is used for the \"normal\" variable of a given system, like the states of a differential equation or objective function. All of the macros below support the same syntax as @variables.","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/#Parameters","page":"Contextual Variable Types","title":"Parameters","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"All modeling projects have some form of parameters. @parameters marks a variable as being the parameter of some system, which allows automatic detection algorithms to ignore such variables when attempting to find the states of a system.","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/#Variable-metadata-[Experimental/TODO]","page":"Contextual Variable Types","title":"Variable metadata [Experimental/TODO]","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"In many engineering systems some variables act like \"flows\" while others do not. For example, in circuit models you have current which flows, and the related voltage which does not. Or in thermal models you have heat flows. In these cases, the connect statement enforces conservation of flow between all of the connected components.","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"For example, the following specifies that x is a 2x2 matrix of flow variables with the unit m^3/s:","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"@variables x[1:2,1:2] [connect = Flow; unit = u\"m^3/s\"]","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"ModelingToolkit defines connect, unit, noise, and description keys for the metadata. One can get and set metadata by","category":"page"},{"location":"copies/ModelingToolkit/basics/ContextualVariables/","page":"Contextual Variable Types","title":"Contextual Variable Types","text":"julia> @variables x [unit = u\"m^3/s\"];\n\njulia> hasmetadata(x, Symbolics.option_to_metadata_type(Val(:unit)))\ntrue\n\njulia> getmetadata(x, Symbolics.option_to_metadata_type(Val(:unit)))\nm³ s⁻¹\n\njulia> x = setmetadata(x, Symbolics.option_to_metadata_type(Val(:unit)), u\"m/s\")\nx\n\njulia> getmetadata(x, Symbolics.option_to_metadata_type(Val(:unit)))\nm s⁻¹","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"(Image: SurrogatesLogo)","category":"page"},{"location":"copies/Surrogates/#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"A surrogate model is an approximation method that mimics the behavior of a computationally expensive simulation. In more mathematical terms: suppose we are attempting to optimize a function  f(p), but each calculation of  f is very expensive. It may be the case that we need to solve a PDE for each point or use advanced numerical linear algebra machinery, which is usually costly. The idea is then to develop a surrogate model  g which approximates  f by training on previous data collected from evaluations of  f. The construction of a surrogate model can be seen as a three-step process:","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"Sample selection\nConstruction of the surrogate model\nSurrogate optimization","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"The sampling methods are super important for the behavior of the Surrogate. At the moment they are:","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"Grid sample\nUniform sample\nSobol sample\nLatin Hypercube sample\nLow discrepancy sample","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"The available surrogates are:","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"Linear\nRadial Basis\nKriging\nCustom Kriging provided with Stheno\nNeural Network\nSupport Vector Machine\nRandom Forest\nSecond Order Polynomial\nInverse Distance","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"After the surrogate is built, we need to optimize it with respect to some objective function. That is, simultaneously looking for a minimum and sampling the most unknown region. The available optimization methods are:","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"Stochastic RBF (SRBF)\nLower confidence bound strategy (LCBS)\nExpected improvement (EI)\nDynamic coordinate search (DYCORS)","category":"page"},{"location":"copies/Surrogates/#Multi-output-Surrogates","page":"Overview","title":"Multi-output Surrogates","text":"","category":"section"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"In certain situations, the function being modeled may have a multi-dimensional output space. In such a case, the surrogate models can take advantage of correlations between the observed output variables to obtain more accurate predictions.","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"When constructing the original surrogate, each element of the passed y vector should itself be a vector. For example, the following y are all valid.","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"using Surrogates\nusing StaticArrays\n\nx = sample(5, [0.0; 0.0], [1.0; 1.0], SobolSample())\nf_static = (x) -> StaticVector(x[1], log(x[2]*x[1]))\nf = (x) -> [x, log(x)/2]\n\ny = f_static.(x)\ny = f.(x)","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"Currently, the following are implemented as multi-output surrogates:","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"Radial Basis\nNeural Network (via Flux)\nSecond Order Polynomial\nInverse Distance\nCustom Kriging (via Stheno)","category":"page"},{"location":"copies/Surrogates/#Gradients","page":"Overview","title":"Gradients","text":"","category":"section"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"The surrogates implemented here are all automatically differentiable via Zygote. Because of this property, surrogates are useful models for processes which aren't explicitly differentiable, and can be used as layers in, for instance, Flux models.","category":"page"},{"location":"copies/Surrogates/#Installation","page":"Overview","title":"Installation","text":"","category":"section"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"Surrogates is registered in the Julia General Registry. In the REPL:","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"]add Surrogates","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"You can obtain the current master with:","category":"page"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"]add https://github.com/JuliaDiffEq/Surrogates.jl#master","category":"page"},{"location":"copies/Surrogates/#Quick-example","page":"Overview","title":"Quick example","text":"","category":"section"},{"location":"copies/Surrogates/","page":"Overview","title":"Overview","text":"using Surrogates\nnum_samples = 10\nlb = 0.0\nub = 10.0\n\n#Sampling\nx = sample(num_samples,lb,ub,SobolSample())\nf = x-> log(x)*x^2+x^3\ny = f.(x)\n\n#Creating surrogate\nalpha = 2.0\nn = 6\nmy_lobachevsky = LobachevskySurrogate(x,y,lb,ub,alpha=alpha,n=n)\n\n#Approximating value at 5.0\nvalue = my_lobachevsky(5.0)\n\n#Adding more data points\nsurrogate_optimize(f,SRBF(),lb,ub,my_lobachevsky,UniformSample())\n\n#New approximation\nvalue = my_lobachevsky(5.0)","category":"page"},{"location":"copies/Integrals/basics/solve/#Common-Solver-Options-(Solve-Keyword-Arguments)","page":"Common Solver Options (Solve Keyword Arguments)","title":"Common Solver Options (Solve Keyword Arguments)","text":"","category":"section"},{"location":"copies/Integrals/basics/solve/","page":"Common Solver Options (Solve Keyword Arguments)","title":"Common Solver Options (Solve Keyword Arguments)","text":"reltol: Relative tolerance\nabstol: Absolute tolerance\nmaxiters: The maximum number of iterations","category":"page"},{"location":"copies/Integrals/basics/solve/","page":"Common Solver Options (Solve Keyword Arguments)","title":"Common Solver Options (Solve Keyword Arguments)","text":"Additionally, the extra keyword arguments are splatted to the library calls, so see the documentation of the integrator library for all of the extra details. These extra keyword arguments are not guaranteed to act uniformly.","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/#Hamiltonian-Neural-Network","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"Hamiltonian Neural Networks introduced in [1] allow models to \"learn and respect exact conservation laws in an unsupervised manner\". In this example, we will train a model to learn the Hamiltonian for a 1D Spring mass system. This system is described by the equation:","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"mddot(x) + kx = 0","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"Now we make some simplifying assumptions, and assign m = 1 and k = 1. Analytically solving this equation, we get x = sin(t). Hence, q = sin(t), and p = cos(t). Using these solutions we generate our dataset and fit the NeuralHamiltonianDE to learn the dynamics of this system.","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"using DiffEqFlux, DifferentialEquations, Statistics, Plots\n\nt = range(0.0f0, 1.0f0, length = 1024)\nπ_32 = Float32(π)\nq_t = reshape(sin.(2π_32 * t), 1, :)\np_t = reshape(cos.(2π_32 * t), 1, :)\ndqdt = 2π_32 .* p_t\ndpdt = -2π_32 .* q_t\n\ndata = cat(q_t, p_t, dims = 1)\ntarget = cat(dqdt, dpdt, dims = 1)\ndataloader = Flux.Data.DataLoader(data, target; batchsize=256, shuffle=true)\n\nhnn = HamiltonianNN(\n    Chain(Dense(2, 64, relu), Dense(64, 1))\n)\n\np = hnn.p\n\nopt = ADAM(0.01)\n\nloss(x, y, p) = mean((hnn(x, p) .- y) .^ 2)\n\ncallback() = println(\"Loss Neural Hamiltonian DE = $(loss(data, target, p))\")\n\nepochs = 500\nfor epoch in 1:epochs\n    for (x, y) in dataloader\n        gs = ReverseDiff.gradient(p -> loss(x, y, p), p)\n        Flux.Optimise.update!(opt, p, gs)\n    end\n    if epoch % 100 == 1\n        callback()\n    end\nend\ncallback()\n\nmodel = NeuralHamiltonianDE(\n    hnn, (0.0f0, 1.0f0),\n    Tsit5(), save_everystep = false,\n    save_start = true, saveat = t\n)\n\npred = Array(model(data[:, 1]))\nplot(data[1, :], data[2, :], lw=4, label=\"Original\")\nplot!(pred[1, :], pred[2, :], lw=4, label=\"Predicted\")\nxlabel!(\"Position (q)\")\nylabel!(\"Momentum (p)\")","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/#Step-by-Step-Explanation","page":"Hamiltonian Neural Network","title":"Step by Step Explanation","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/#Data-Generation","page":"Hamiltonian Neural Network","title":"Data Generation","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"The HNN predicts the gradients (dot(q) dot(p)) given (q p). Hence, we generate the pairs (q p) using the equations given at the top. Additionally to supervise the training we also generate the gradients. Next we use use Flux DataLoader for automatically batching our dataset.","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"t = range(0.0f0, 1.0f0, length = 1024)\nπ_32 = Float32(π)\nq_t = reshape(sin.(2π_32 * t), 1, :)\np_t = reshape(cos.(2π_32 * t), 1, :)\ndqdt = 2π_32 .* p_t\ndpdt = -2π_32 .* q_t\n\ndata = cat(q_t, p_t, dims = 1)\ntarget = cat(dqdt, dpdt, dims = 1)\ndataloader = Flux.Data.DataLoader(data, target; batchsize=256, shuffle=true)","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/#Training-the-HamiltonianNN","page":"Hamiltonian Neural Network","title":"Training the HamiltonianNN","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"We parameterize the HamiltonianNN with a small MultiLayered Perceptron (HNN also works with the Fast* Layers provided in DiffEqFlux). HNNs are trained by optimizing the gradients of the Neural Network. Zygote currently doesn't support nesting itself, so we will be using ReverseDiff in the training loop to compute the gradients of the HNN Layer for Optimization.","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"hnn = HamiltonianNN(\n    Chain(Dense(2, 64, relu), Dense(64, 1))\n)\n\np = hnn.p\n\nopt = ADAM(0.01)\n\nloss(x, y, p) = mean((hnn(x, p) .- y) .^ 2)\n\ncallback() = println(\"Loss Neural Hamiltonian DE = $(loss(data, target, p))\")\n\nepochs = 500\nfor epoch in 1:epochs\n    for (x, y) in dataloader\n        gs = ReverseDiff.gradient(p -> loss(x, y, p), p)\n        Flux.Optimise.update!(opt, p, gs)\n    end\n    if epoch % 100 == 1\n        callback()\n    end\nend\ncallback()","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/#Solving-the-ODE-using-trained-HNN","page":"Hamiltonian Neural Network","title":"Solving the ODE using trained HNN","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"In order to visualize the learned trajectories, we need to solve the ODE. We will use the NeuralHamiltonianDE layer which is essentially a wrapper over HamiltonianNN layer and solves the ODE.","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"model = NeuralHamiltonianDE(\n    hnn, (0.0f0, 1.0f0),\n    Tsit5(), save_everystep = false,\n    save_start = true, saveat = t\n)\n\npred = Array(model(data[:, 1]))\nplot(data[1, :], data[2, :], lw=4, label=\"Original\")\nplot!(pred[1, :], pred[2, :], lw=4, label=\"Predicted\")\nxlabel!(\"Position (q)\")\nylabel!(\"Momentum (p)\")","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"(Image: HNN Prediction)","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/#Expected-Output","page":"Hamiltonian Neural Network","title":"Expected Output","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"Loss Neural Hamiltonian DE = 18.768814\nLoss Neural Hamiltonian DE = 0.022630047\nLoss Neural Hamiltonian DE = 0.015060622\nLoss Neural Hamiltonian DE = 0.013170851\nLoss Neural Hamiltonian DE = 0.011898238\nLoss Neural Hamiltonian DE = 0.009806873","category":"page"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/#References","page":"Hamiltonian Neural Network","title":"References","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/hamiltonian_nn/","page":"Hamiltonian Neural Network","title":"Hamiltonian Neural Network","text":"[1] Greydanus, Samuel, Misko Dzamba, and Jason Yosinski. \"Hamiltonian Neural Networks.\" Advances in Neural Information Processing Systems 32 (2019): 15379-15389.","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/#Neural-Stochastic-Differential-Equations","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"With neural stochastic differential equations, there is once again a helper form neural_dmsde which can be used for the multiplicative noise case (consult the layers API documentation, or this full example using the layer function).","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"However, since there are far too many possible combinations for the API to support, in many cases you will want to performantly define neural differential equations for non-ODE systems from scratch. For these systems, it is generally best to use TrackerAdjoint with non-mutating (out-of-place) forms. For example, the following defines a neural SDE with neural networks for both the drift and diffusion terms:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"dudt(u, p, t) = model(u)\ng(u, p, t) = model2(u)\nprob = SDEProblem(dudt, g, x, tspan, nothing)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"where model and model2 are different neural networks. The same can apply to a neural delay differential equation. Its out-of-place formulation is f(u,h,p,t). Thus for example, if we want to define a neural delay differential equation which uses the history value at p.tau in the past, we can define:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"dudt!(u, h, p, t) = model([u; h(t - p.tau)])\nprob = DDEProblem(dudt_, u0, h, tspan, nothing)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"First let's build training data from the same example as the neural ODE:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"using Plots, Statistics\nusing DiffEqFlux, StochasticDiffEq, DiffEqBase.EnsembleAnalysis\n\nu0 = Float32[2.; 0.]\ndatasize = 30\ntspan = (0.0f0, 1.0f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"function trueSDEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nmp = Float32[0.2, 0.2]\nfunction true_noise_func(du, u, p, t)\n    du .= mp.*u\nend\n\nprob_truesde = SDEProblem(trueSDEfunc, true_noise_func, u0, tspan)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"For our dataset we will use DifferentialEquations.jl's parallel ensemble interface to generate data from the average of 10,000 runs of the SDE:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"# Take a typical sample from the mean\nensemble_prob = EnsembleProblem(prob_truesde)\nensemble_sol = solve(ensemble_prob, SOSRI(), trajectories = 10000)\nensemble_sum = EnsembleSummary(ensemble_sol)\n\nsde_data, sde_data_vars = Array.(timeseries_point_meanvar(ensemble_sol, tsteps))","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"Now we build a neural SDE. For simplicity we will use the NeuralDSDE neural SDE with diagonal noise layer function:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"drift_dudt = FastChain((x, p) -> x.^3,\n                       FastDense(2, 50, tanh),\n                       FastDense(50, 2))\ndiffusion_dudt = FastChain(FastDense(2, 2))\n\nneuralsde = NeuralDSDE(drift_dudt, diffusion_dudt, tspan, SOSRI(),\n                       saveat = tsteps, reltol = 1e-1, abstol = 1e-1)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"Let's see what that looks like:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"# Get the prediction using the correct initial condition\nprediction0 = neuralsde(u0)\n\ndrift_(u, p, t) = drift_dudt(u, p[1:neuralsde.len])\ndiffusion_(u, p, t) = diffusion_dudt(u, p[(neuralsde.len+1):end])\n\nprob_neuralsde = SDEProblem(drift_, diffusion_, u0,(0.0f0, 1.2f0), neuralsde.p)\n\nensemble_nprob = EnsembleProblem(prob_neuralsde)\nensemble_nsol = solve(ensemble_nprob, SOSRI(), trajectories = 100,\n                      saveat = tsteps)\nensemble_nsum = EnsembleSummary(ensemble_nsol)\n\nplt1 = plot(ensemble_nsum, title = \"Neural SDE: Before Training\")\nscatter!(plt1, tsteps, sde_data', lw = 3)\n\nscatter(tsteps, sde_data[1,:], label = \"data\")\nscatter!(tsteps, prediction0[1,:], label = \"prediction\")","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"Now just as with the neural ODE we define a loss function that calculates the mean and variance from n runs at each time point and uses the distance from the data values:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"function predict_neuralsde(p, u = u0)\n  return Array(neuralsde(u, p))\nend\n\nfunction loss_neuralsde(p; n = 100)\n  u = repeat(reshape(u0, :, 1), 1, n)\n  samples = predict_neuralsde(p, u)\n  means = mean(samples, dims = 2)\n  vars = var(samples, dims = 2, mean = means)[:, 1, :]\n  means = means[:, 1, :]\n  loss = sum(abs2, sde_data - means) + sum(abs2, sde_data_vars - vars)\n  return loss, means, vars\nend","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"list_plots = []\niter = 0\n\n# Callback function to observe training\ncallback = function (p, loss, means, vars; doplot = false)\n  global list_plots, iter\n\n  if iter == 0\n    list_plots = []\n  end\n  iter += 1\n\n  # loss against current data\n  display(loss)\n\n  # plot current prediction against data\n  plt = Plots.scatter(tsteps, sde_data[1,:], yerror = sde_data_vars[1,:],\n                     ylim = (-4.0, 8.0), label = \"data\")\n  Plots.scatter!(plt, tsteps, means[1,:], ribbon = vars[1,:], label = \"prediction\")\n  push!(list_plots, plt)\n\n  if doplot\n    display(plt)\n  end\n  return false\nend","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"Now we train using this loss function. We can pre-train a little bit using a smaller n and then decrease it after it has had some time to adjust towards the right mean behavior:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"opt = ADAM(0.025)\n\n# First round of training with n = 10\nresult1 = DiffEqFlux.sciml_train((p) -> loss_neuralsde(p, n = 10),  \n                                 neuralsde.p, opt,\n                                 cb = callback, maxiters = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"We resume the training with a larger n. (WARNING - this step is a couple of orders of magnitude longer than the previous one).","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"result2 = DiffEqFlux.sciml_train((p) -> loss_neuralsde(p, n = 100),\n                                 result1.u, opt,\n                                 cb = callback, maxiters = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"And now we plot the solution to an ensemble of the trained neural SDE:","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"_, means, vars = loss_neuralsde(result2.u, n = 1000)\n\nplt2 = Plots.scatter(tsteps, sde_data', yerror = sde_data_vars',\n                     label = \"data\", title = \"Neural SDE: After Training\",\n                     xlabel = \"Time\")\nplot!(plt2, tsteps, means', lw = 8, ribbon = vars', label = \"prediction\")\n\nplt = plot(plt1, plt2, layout = (2, 1))\nsavefig(plt, \"NN_sde_combined.png\"); nothing # sde","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/sde_fitting/neural_sde/","page":"Neural Stochastic Differential Equations","title":"Neural Stochastic Differential Equations","text":"Try this with GPUs as well!","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/#Neural-ODEs-on-GPUs","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"Note that the differential equation solvers will run on the GPU if the initial condition is a GPU array. Thus, for example, we can define a neural ODE by hand that runs on the GPU (if no GPU is available, the calculation defaults back to the CPU):","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"using DifferentialEquations, Flux, Optim, DiffEqFlux, DiffEqSensitivity\n\nmodel_gpu = Chain(Dense(2, 50, tanh), Dense(50, 2)) |> gpu\np, re = Flux.destructure(model_gpu)\ndudt!(u, p, t) = re(p)(u)\n\n# Simulation interval and intermediary points\ntspan = (0.0, 10.0)\ntsteps = 0.0:0.1:10.0\n\nu0 = Float32[2.0; 0.0] |> gpu\nprob_gpu = ODEProblem(dudt!, u0, tspan, p)\n\n# Runs on a GPU\nsol_gpu = solve(prob_gpu, Tsit5(), saveat = tsteps)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"Or we could directly use the neural ODE layer function, like:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"prob_neuralode_gpu = NeuralODE(gpu(dudt2), tspan, Tsit5(), saveat = tsteps)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"If one is using FastChain, then the computation takes place on the GPU with f(x,p) if x and p are on the GPU. This commonly looks like:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"dudt2 = FastChain((x,p) -> x.^3,\n            FastDense(2,50,tanh),\n            FastDense(50,2))\n\nu0 = Float32[2.; 0.] |> gpu\np = initial_params(dudt2) |> gpu\n\ndudt2_(u, p, t) = dudt2(u,p)\n\n# Simulation interval and intermediary points\ntspan = (0.0, 10.0)\ntsteps = 0.0:0.1:10.0\n\nprob_gpu = ODEProblem(dudt2_, u0, tspan, p)\n\n# Runs on a GPU\nsol_gpu = solve(prob_gpu, Tsit5(), saveat = tsteps)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"or via the NeuralODE struct:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"prob_neuralode_gpu = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\nprob_neuralode_gpu(u0,p)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/#Neural-ODE-Example","page":"Neural ODEs on GPUs","title":"Neural ODE Example","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"Here is the full neural ODE example. Note that we use the gpu function so that the same code works on CPUs and GPUs, dependent on using CUDA.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/GPUs/","page":"Neural ODEs on GPUs","title":"Neural ODEs on GPUs","text":"using DiffEqFlux, OrdinaryDiffEq, Flux, Optim, Plots, CUDA, DiffEqSensitivity\nCUDA.allowscalar(false) # Makes sure no slow operations are occuring\n\n# Generate Data\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\n# Make the data into a GPU-based array if the user has a GPU\node_data = gpu(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\n\ndudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\nu0 = Float32[2.0; 0.0] |> gpu\np = initial_params(dudt2) |> gpu\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\n\nfunction predict_neuralode(p)\n  gpu(prob_neuralode(u0,p))\nend\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, ode_data .- pred)\n    return loss, pred\nend\n# Callback function to observe training\nlist_plots = []\niter = 0\ncallback = function (p, l, pred; doplot = false)\n  global list_plots, iter\n  if iter == 0\n    list_plots = []\n  end\n  iter += 1\n  display(l)\n  # plot current prediction against data\n  plt = scatter(tsteps, Array(ode_data[1,:]), label = \"data\")\n  scatter!(plt, tsteps, Array(pred[1,:]), label = \"prediction\")\n  push!(list_plots, plt)\n  if doplot\n    display(plot(plt))\n  end\n  return false\nend\nresult_neuralode = DiffEqFlux.sciml_train(loss_neuralode, p,\n                                          ADAM(0.05), cb = callback,\n                                          maxiters = 300)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/#optcontrol","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"Here we will solve a classic optimal control problem with a universal differential equation. Let","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"x^ = u^3(t)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"where we want to optimize our controller u(t) such that the following is minimized:","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"L(theta) = sum_i Vert 4 - x(t_i) Vert + 2 Vert x^prime(t_i) Vert + Vert u(t_i) Vert","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"where i is measured on (0,8) at 0.01 intervals. To do this, we rewrite the ODE in first order form:","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"beginaligned\nx^prime = v \nv^ = u^3(t) \nendaligned","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"and thus","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"L(theta) = sum_i Vert 4 - x(t_i) Vert + 2 Vert v(t_i) Vert + Vert u(t_i) Vert","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"is our loss function on the first order system. We thus choose a neural network form for u and optimize the equation with respect to this loss. Note that we will first reduce control cost (the last term) by 10x in order to bump the network out of a local minimum. This looks like:","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"using DiffEqFlux, DifferentialEquations, Plots, Statistics\ntspan = (0.0f0,8.0f0)\nann = FastChain(FastDense(1,32,tanh), FastDense(32,32,tanh), FastDense(32,1))\nθ = initial_params(ann)\nfunction dxdt_(dx,x,p,t)\n    x1, x2 = x\n    dx[1] = x[2]\n    dx[2] = ann([t],p)[1]^3\nend\nx0 = [-4f0,0f0]\nts = Float32.(collect(0.0:0.01:tspan[2]))\nprob = ODEProblem(dxdt_,x0,tspan,θ)\nsolve(prob,Vern9(),abstol=1e-10,reltol=1e-10)\nfunction predict_adjoint(θ)\n  Array(solve(prob,Vern9(),p=θ,saveat=ts,sensealg=InterpolatingAdjoint(autojacvec=ReverseDiffVJP(true))))\nend\nfunction loss_adjoint(θ)\n  x = predict_adjoint(θ)\n  mean(abs2,4.0 .- x[1,:]) + 2mean(abs2,x[2,:]) + mean(abs2,[first(ann([t],θ)) for t in ts])/10\nend\nl = loss_adjoint(θ)\ncb = function (θ,l)\n  println(l)\n  p = plot(solve(remake(prob,p=θ),Tsit5(),saveat=0.01),ylim=(-6,6),lw=3)\n  plot!(p,ts,[first(ann([t],θ)) for t in ts],label=\"u(t)\",lw=3)\n  display(p)\n  return false\nend\n# Display the ODE with the current parameter values.\ncb(θ,l)\nloss1 = loss_adjoint(θ)\nres1 = DiffEqFlux.sciml_train(loss_adjoint, θ, ADAM(0.005), cb = cb,maxiters=100)\nres2 = DiffEqFlux.sciml_train(loss_adjoint, res1.u,\n                              BFGS(initial_stepnorm=0.01), cb = cb,maxiters=100,\n                              allow_f_increases = false)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"Now that the system is in a better behaved part of parameter space, we return to the original loss function to finish the optimization:","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"function loss_adjoint(θ)\n  x = predict_adjoint(θ)\n  mean(abs2,4.0 .- x[1,:]) + 2mean(abs2,x[2,:]) + mean(abs2,[first(ann([t],θ)) for t in ts])\nend\n\nres3 = DiffEqFlux.sciml_train(loss_adjoint, res2.u,\n                              BFGS(initial_stepnorm=0.01), cb = cb,maxiters=100,\n                              allow_f_increases = false)\n\nl = loss_adjoint(res3.u)\ncb(res3.u,l)\np = plot(solve(remake(prob,p=res3.u),Tsit5(),saveat=0.01),ylim=(-6,6),lw=3)\nplot!(p,ts,[first(ann([t],res3.u)) for t in ts],label=\"u(t)\",lw=3)\nsavefig(\"optimal_control.png\")","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/optimal_control/","page":"Solving Optimal Control Problems with Universal Differential Equations","title":"Solving Optimal Control Problems with Universal Differential Equations","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_adjoints/#Newton-and-Hessian-Free-Newton-Krylov-with-Second-Order-Adjoint-Sensitivity-Analysis","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_adjoints/","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"In many cases it may be more optimal or more stable to fit using second order Newton-based optimization techniques. Since DiffEqSensitivity.jl provides second order sensitivity analysis for fast Hessians and Hessian-vector products (via forward-over-reverse), we can utilize these in our neural/universal differential equation training processes.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_adjoints/","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"sciml_train is setup to automatically use second order sensitivity analysis methods if a second order optimizer is requested via Optim.jl. Thus Newton and NewtonTrustRegion optimizers will use a second order Hessian-based optimization, while KrylovTrustRegion will utilize a Krylov-based method with Hessian-vector products (never forming the Hessian) for large parameter optimizations.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_adjoints/","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"using DiffEqFlux, DifferentialEquations, Plots\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\np = prob_neuralode.p\n\nfunction predict_neuralode(p)\n  Array(prob_neuralode(u0, p))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, ode_data .- pred)\n    return loss, pred\nend\n\n# Callback function to observe training\nlist_plots = []\niter = 0\ncb = function (p, l, pred; doplot = false)\n  global list_plots, iter\n\n  if iter == 0\n    list_plots = []\n  end\n  iter += 1\n\n  display(l)\n\n  # plot current prediction against data\n  plt = scatter(tsteps, ode_data[1,:], label = \"data\")\n  scatter!(plt, tsteps, pred[1,:], label = \"prediction\")\n  push!(list_plots, plt)\n  if doplot\n    display(plot(plt))\n  end\n\n  return l < 0.01\nend\n\npstart = DiffEqFlux.sciml_train(loss_neuralode, p, ADAM(0.01), cb=cb, maxiters = 100).u\npmin = DiffEqFlux.sciml_train(loss_neuralode, pstart, NewtonTrustRegion(), cb=cb, maxiters = 200)\npmin = DiffEqFlux.sciml_train(loss_neuralode, pstart, Optim.KrylovTrustRegion(), cb=cb, maxiters = 200)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_adjoints/","page":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","title":"Newton and Hessian-Free Newton-Krylov with Second Order Adjoint Sensitivity Analysis","text":"Note that we do not demonstrate Newton() because we have not found a single case where it is competitive with the other two methods. KrylovTrustRegion() is generally the fastest due to its use of Hessian-vector products.","category":"page"},{"location":"copies/LinearSolve/basics/LinearProblem/#Linear-Problems","page":"Linear Problems","title":"Linear Problems","text":"","category":"section"},{"location":"copies/LinearSolve/basics/LinearProblem/","page":"Linear Problems","title":"Linear Problems","text":"LinearProblem","category":"page"},{"location":"copies/LinearSolve/basics/LinearProblem/#SciMLBase.LinearProblem","page":"Linear Problems","title":"SciMLBase.LinearProblem","text":"Defines a linear system problem. Documentation Page: http://linearsolve.sciml.ai/dev/basics/LinearProblem/\n\nMathematical Specification of a Linear Problem\n\nConcrete LinearProblem\n\nTo define a LinearProblem, you simply need to give the AbstractMatrix A and an AbstractVector b which defines the linear system:\n\nAu = b\n\nMatrix-Free LinearProblem\n\nFor matrix-free versions, the specification of the problem is given by an operator A(u,p,t) which computes A*u, or in-place as A(du,u,p,t). These are specified via the AbstractSciMLOperator interface. For more details, see the SciMLBase Documentation.\n\nNote that matrix-free versions of LinearProblem definitions are not compatible with all solvers. To check a solver for compatibility, use the function xxxxx.\n\nProblem Type\n\nConstructors\n\nOptionally, an initial guess u₀ can be supplied which is used for iterative methods.\n\nLinearProblem{isinplace}(A,x,p=NullParameters();u0=nothing,kwargs...)\nLinearProblem(f::AbstractDiffEqOperator,u0,p=NullParameters();u0=nothing,kwargs...)\n\nisinplace optionally sets whether the function is in-place or not, i.e. whether the solvers are allowed to mutate. By default this is true for AbstractMatrix, and for AbstractSciMLOperators it matches the choice of the operator definition.\n\nParameters are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers.\n\nFields\n\nA: The representation of the linear operator.\nb: The right-hand side of the linear system.\np: The parameters for the problem. Defaults to NullParameters. Currently unused.\nu0: The initial condition used by iterative solvers.\nkwargs: The keyword arguments passed on to the solvers.\n\n\n\n","category":"type"},{"location":"copies/Optimization/tutorials/rosenbrock/#Rosenbrock-function-examples","page":"Rosenbrock function","title":"Rosenbrock function examples","text":"","category":"section"},{"location":"copies/Optimization/tutorials/rosenbrock/","page":"Rosenbrock function","title":"Rosenbrock function","text":"note: Note\nThis example uses many different solvers of Optimization.jl. Each solver subpackage needs to be installed separate. For example, for the details on  the installation and usage of OptimizationOptimJL.jl package, see the  Optim.jl page.","category":"page"},{"location":"copies/Optimization/tutorials/rosenbrock/","page":"Rosenbrock function","title":"Rosenbrock function","text":"using Optimization, Optim, ForwardDiff, Zygote, Test, Random\n\nrosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\n_p  = [1.0, 100.0]\n\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nl1 = rosenbrock(x0, _p)\nprob = OptimizationProblem(f, x0, _p)\n\n## Optim.jl Solvers\n\nusing OptimizationOptimJL\n\nsol = solve(prob, SimulatedAnnealing())\n@test 10*sol.minimum < l1\n\nRandom.seed!(1234)\nprob = OptimizationProblem(f, x0, _p, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, SAMIN())\n@test 10*sol.minimum < l1\n\nl1 = rosenbrock(x0)\nprob = OptimizationProblem(rosenbrock, x0)\nsol = solve(prob, NelderMead())\n@test 10*sol.minimum < l1\n\ncons= (x,p) -> [x[1]^2 + x[2]^2]\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= cons)\n\nprob = OptimizationProblem(optprob, x0)\n\nsol = solve(prob, ADAM(0.1), maxiters = 1000)\n@test 10*sol.minimum < l1\n\nsol = solve(prob, BFGS())\n@test 10*sol.minimum < l1\n\nsol = solve(prob, Newton())\n@test 10*sol.minimum < l1\n\nsol = solve(prob, Optim.KrylovTrustRegion())\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lcons = [-Inf], ucons = [Inf])\nsol = solve(prob, IPNewton())\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lcons = [-5.0], ucons = [10.0])\nsol = solve(prob, IPNewton())\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lcons = [-Inf], ucons = [Inf], lb = [-500.0,-500.0], ub=[50.0,50.0])\nsol = solve(prob, IPNewton())\n@test sol.minimum < l1\n\nfunction con2_c(x,p)\n    [x[1]^2 + x[2]^2, x[2]*sin(x[1])-x[1]]\nend\n\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= con2_c)\nprob = OptimizationProblem(optprob, x0, lcons = [-Inf,-Inf], ucons = [Inf,Inf])\nsol = solve(prob, IPNewton())\n@test 10*sol.minimum < l1\n\ncons_circ = (x,p) -> [x[1]^2 + x[2]^2]\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff();cons= cons_circ)\nprob = OptimizationProblem(optprob, x0, lcons = [-Inf], ucons = [0.25^2])\nsol = solve(prob, IPNewton())\n@test sqrt(cons(sol.minimizer,nothing)[1]) ≈ 0.25 rtol = 1e-6\n\noptprob = OptimizationFunction(rosenbrock, Optimization.AutoZygote())\nprob = OptimizationProblem(optprob, x0)\nsol = solve(prob, ADAM(), maxiters = 1000, progress = false)\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, Fminbox())\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lb=[-1.0, -1.0], ub=[0.8, 0.8])\n@test_broken @test_nowarn sol = solve(prob, SAMIN())\n@test 10*sol.minimum < l1\n\n## CMAEvolutionStrategy.jl solvers\n\nusing OptimizationCMAEvolutionStrategy\nsol = solve(prob, CMAEvolutionStrategyOpt())\n@test 10*sol.minimum < l1\n\nrosenbrock(x, p=nothing) =  (1 - x[1])^2 + 100 * (x[2] - x[1]^2)^2\n\n## NLopt.jl solvers\n\nusing OptimizationNLopt\nprob = OptimizationProblem(optprob, x0)\nsol = solve(prob, Opt(:LN_BOBYQA, 2))\n@test 10*sol.minimum < l1\n\nsol = solve(prob, Opt(:LD_LBFGS, 2))\n@test 10*sol.minimum < l1\n\nprob = OptimizationProblem(optprob, x0, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, Opt(:LD_LBFGS, 2))\n@test 10*sol.minimum < l1\n\nsol = solve(prob, Opt(:G_MLSL_LDS, 2), nstart=2, local_method = Opt(:LD_LBFGS, 2), maxiters=10000)\n@test 10*sol.minimum < l1\n\n## Evolutionary.jl Solvers\n\nusing OptimizationEvolutionary\nsol = solve(prob, CMAES(μ =40 , λ = 100),abstol=1e-15)\n@test 10*sol.minimum < l1\n\n## BlackBoxOptim.jl Solvers\n\nusing OptimizationBBO\nprob = Optimization.OptimizationProblem(optprob, x0, lb=[-1.0, -1.0], ub=[0.8, 0.8])\nsol = solve(prob, BBO())\n@test 10*sol.minimum < l1","category":"page"},{"location":"copies/DiffEqSensitivity/Benchmark/#Benchmarks","page":"Benchmarks","title":"Benchmarks","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/Benchmark/#Vs-Torchdiffeq-1-million-and-less-ODEs","page":"Benchmarks","title":"Vs Torchdiffeq 1 million and less ODEs","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"A raw ODE solver benchmark showcases >30x performance advantage for DifferentialEquations.jl for ODEs ranging in size from 3 to nearly 1 million.","category":"page"},{"location":"copies/DiffEqSensitivity/Benchmark/#Vs-Torchdiffeq-on-neural-ODE-training","page":"Benchmarks","title":"Vs Torchdiffeq on neural ODE training","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"A training benchmark using the spiral ODE from the original neural ODE paper demonstrates a 100x performance advantage for DiffEqFlux in training neural ODEs.","category":"page"},{"location":"copies/DiffEqSensitivity/Benchmark/#Vs-torchsde-on-small-SDEs","page":"Benchmarks","title":"Vs torchsde on small SDEs","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"Using the code from torchsde's README we demonstrated a >70,000x performance advantage over torchsde. Further benchmarking is planned but was found to be computationally infeasible for the time being.","category":"page"},{"location":"copies/DiffEqSensitivity/Benchmark/#A-bunch-of-adjoint-choices-on-neural-ODEs","page":"Benchmarks","title":"A bunch of adjoint choices on neural ODEs","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"Quick summary:","category":"page"},{"location":"copies/DiffEqSensitivity/Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"BacksolveAdjoint can be the fastest (but use with caution!); about 25% faster\nUsing ZygoteVJP is faster than other vjp choices with FastDense due to the overloads","category":"page"},{"location":"copies/DiffEqSensitivity/Benchmark/","page":"Benchmarks","title":"Benchmarks","text":"using DiffEqFlux, OrdinaryDiffEq, Flux, Optim, Plots, DiffEqSensitivity,\n      Zygote, BenchmarkTools, Random\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 1.5f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 50, tanh),\n                  FastDense(50, 2))\nRandom.seed!(100)\np = initial_params(dudt2)\n\nprob_neuralode = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps)\n\nfunction loss_neuralode(p)\n    pred = Array(prob_neuralode(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode,p)\n# 2.709 ms (56506 allocations: 6.62 MiB)\n\nprob_neuralode_interpolating = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps, sensealg=InterpolatingAdjoint(autojacvec=ReverseDiffVJP(true)))\n\nfunction loss_neuralode_interpolating(p)\n    pred = Array(prob_neuralode_interpolating(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_interpolating,p)\n# 5.501 ms (103835 allocations: 2.57 MiB)\n\nprob_neuralode_interpolating_zygote = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps, sensealg=InterpolatingAdjoint(autojacvec=ZygoteVJP()))\n\nfunction loss_neuralode_interpolating_zygote(p)\n    pred = Array(prob_neuralode_interpolating_zygote(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_interpolating_zygote,p)\n# 2.899 ms (56150 allocations: 6.61 MiB)\n\nprob_neuralode_backsolve = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps, sensealg=BacksolveAdjoint(autojacvec=ReverseDiffVJP(true)))\n\nfunction loss_neuralode_backsolve(p)\n    pred = Array(prob_neuralode_backsolve(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_backsolve,p)\n# 4.871 ms (85855 allocations: 2.20 MiB)\n\nprob_neuralode_quad = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps, sensealg=QuadratureAdjoint(autojacvec=ReverseDiffVJP(true)))\n\nfunction loss_neuralode_quad(p)\n    pred = Array(prob_neuralode_quad(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_quad,p)\n# 11.748 ms (79549 allocations: 3.87 MiB)\n\nprob_neuralode_backsolve_tracker = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps, sensealg=BacksolveAdjoint(autojacvec=TrackerVJP()))\n\nfunction loss_neuralode_backsolve_tracker(p)\n    pred = Array(prob_neuralode_backsolve_tracker(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_backsolve_tracker,p)\n# 27.604 ms (186143 allocations: 12.22 MiB)\n\nprob_neuralode_backsolve_zygote = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps, sensealg=BacksolveAdjoint(autojacvec=ZygoteVJP()))\n\nfunction loss_neuralode_backsolve_zygote(p)\n    pred = Array(prob_neuralode_backsolve_zygote(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_backsolve_zygote,p)\n# 2.091 ms (49883 allocations: 6.28 MiB)\n\nprob_neuralode_backsolve_false = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps, sensealg=BacksolveAdjoint(autojacvec=ReverseDiffVJP(false)))\n\nfunction loss_neuralode_backsolve_false(p)\n    pred = Array(prob_neuralode_backsolve_false(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_backsolve_false,p)\n# 4.822 ms (9956 allocations: 1.03 MiB)\n\nprob_neuralode_tracker = NeuralODE(dudt2, tspan, Tsit5(), saveat = tsteps, sensealg=TrackerAdjoint())\n\nfunction loss_neuralode_tracker(p)\n    pred = Array(prob_neuralode_tracker(u0, p))\n    loss = sum(abs2, ode_data .- pred)\n    return loss\nend\n\n@btime Zygote.gradient(loss_neuralode_tracker,p)\n# 12.614 ms (76346 allocations: 3.12 MiB)","category":"page"},{"location":"copies/Optimization/API/optimization_function/#optfunction","page":"OptimizationFunction","title":"OptimizationFunction","text":"","category":"section"},{"location":"copies/Optimization/API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"OptimizationFunction","category":"page"},{"location":"copies/Optimization/API/optimization_function/#SciMLBase.OptimizationFunction","page":"OptimizationFunction","title":"SciMLBase.OptimizationFunction","text":"OptimizationFunction{iip,AD,F,G,H,HV,C,CJ,CH,HP,CJP,CHP,S,HCV,CJCV,CHCV} <: AbstractOptimizationFunction{iip}\n\nA representation of an optimization of an objective function f, defined by:\n\nmin_u f(up)\n\nand all of its related functions, such as the gradient of f, its Hessian,  and more. For all cases, u is the state and p are the parameters.\n\nConstructor\n\nOptimizationFunction{iip}(f,adtype::AbstractADType=NoAD();                           grad=nothing,hess=nothing,hv=nothing,                           cons=nothing, consj=nothing,consh=nothing,                           hessprototype=nothing,consjacprototype=nothing,                           conshessprototype = nothing,                           syms = nothing, hesscolorvec = nothing,                           consjaccolorvec = nothing,                           conshesscolorvec = nothing)\n\nadtype: see the section \"Defining Optimization Functions via AD\"\ngrad(G,u,p) or G=grad(u,p): the gradient of f with respect to u\nhess(H,u,p) or H=hess(u,p): the Hessian of f with respect to u\nhv(Hv,u,v,p) or Hv=hv(u,v,p): the Hessian-vector product racd^2 fdu^2 v.\ncons(res,x,p) or res=cons(x,p): the equality constraints vector, where the constraints are satisfied when res = 0.\ncons_j(res,x,p) or res=cons_j(x,p): the Jacobian of the equality constraints.\ncons_h(res,x,p) or res=cons_h(x,p): the Hessian of the equality constratins, provided as and array of Hessians with res[i] being the Hessian with respect to the ith output on cons.\nparamjac(pJ,u,p): returns the parameter Jacobian racdfdp.\nhess_prototype: a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized Hessian matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Hessian. The default is nothing, which means a dense Hessian.\ncons_jac_prototype: a prototype matrix matching the type that matches the constraint Jacobian.  The default is nothing, which means a dense constraint Jacobian.\ncons_hess_prototype: a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where hess[i] is the Hessian w.r.t. the ith output. For example, if the Hessian is sparse, then hess is a Vector{SparseMatrixCSC}. The default is nothing, which means a dense constraint Hessian.  \nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nhess_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the hess_prototype. This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\ncons_jac_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the cons_jac_prototype.\ncons_hess_colorvec: an array of color vector according to the SparseDiffTools.jl definition for  the sparsity pattern of the cons_hess_prototype.\n\nDefining Optimization Functions Via AD\n\nWhile using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an OptimizationFunction is by specifying an AD type. By doing so, this will automatically fill in all of the extra functions. For example,\n\nOptimizationFunction(f,AutoZygote())\n\nwill use Zygote.jl to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice.\n\nEach of the AD-based constructors are documented separately via their own dispatches.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the OptimizationFunction type directly match the names of the inputs.\n\n\n\n\n\n","category":"type"},{"location":"copies/Optimization/API/optimization_function/#Automatic-Differentiation-Construction-Choice-Recommendations","page":"OptimizationFunction","title":"Automatic Differentiation Construction Choice Recommendations","text":"","category":"section"},{"location":"copies/Optimization/API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The choices for the auto-AD fill-ins with quick descriptions are:","category":"page"},{"location":"copies/Optimization/API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"AutoForwardDiff(): The fastest choice for small optimizations\nAutoReverseDiff(compile=false): A fast choice for large scalar optimizations\nAutoTracker(): Like ReverseDiff but GPU-compatible\nAutoZygote(): The fastest choice for non-mutating array-based (BLAS) functions\nAutoFiniteDiff(): Finite differencing, not optimal but always applicable\nAutoModelingToolkit(): The fastest choice for large scalar optimizations","category":"page"},{"location":"copies/Optimization/API/optimization_function/#Automatic-Differentiation-Choice-API","page":"OptimizationFunction","title":"Automatic Differentiation Choice API","text":"","category":"section"},{"location":"copies/Optimization/API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"The following sections describe the Auto-AD choices in detail.","category":"page"},{"location":"copies/Optimization/API/optimization_function/","page":"OptimizationFunction","title":"OptimizationFunction","text":"AutoForwardDiff\nAutoFiniteDiff\nAutoReverseDiff\nAutoZygote\nAutoTracker\nAutoModelingToolkit","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Symbolic-metadata","page":"Symbolic metadata","title":"Symbolic metadata","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"It is possible to add metadata to symbolic variables. The following information can be added (note, it's possible to extend this to user-defined metadata as well)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Input-or-output","page":"Symbolic metadata","title":"Input or output","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"Designate a variable as either an input or an output using the following","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"using ModelingToolkit\n@variables u [input=true]\nisinput(u)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"@variables y [output=true]\nisoutput(y)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Bounds","page":"Symbolic metadata","title":"Bounds","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"Bounds are useful when parameters are to be optimized, or to express intervals of uncertainty.","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"@variables u [bounds=(-1,1)]\nhasbounds(u)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"getbounds(u)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Mark-input-as-a-disturbance","page":"Symbolic metadata","title":"Mark input as a disturbance","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"Indicate that an input is not available for control, i.e., it's a disturbance input.","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"@variables u [input=true, disturbance=true]\nisdisturbance(u)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Mark-parameter-as-tunable","page":"Symbolic metadata","title":"Mark parameter as tunable","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"Indicate that a parameter can be automatically tuned by automatic control tuning apps.","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"@parameters Kp [tunable=true]\nistunable(Kp)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Probability-distributions","page":"Symbolic metadata","title":"Probability distributions","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"A probability distribution may be associated with a parameter to indicate either uncertainty about it's value, or as a prior distribution for Bayesian optimization.","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"using Distributions\nd = Normal(10, 1)\n@parameters m [dist=d]\nhasdist(m)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"getdist(m)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Additional-functions","page":"Symbolic metadata","title":"Additional functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"For systems that contain parameters with metadata like described above have some additional functions defined for convenience. In the example below, we define a system with tunable parameters and extract bounds vectors","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"@parameters t\nDₜ = Differential(t)\n@variables x(t)=0 u(t)=0 [input=true] y(t)=0 [output=true]\n@parameters T [tunable = true, bounds = (0, Inf)]\n@parameters k [tunable = true, bounds = (0, Inf)]\neqs = [\n    Dₜ(x) ~ (-x + k*u) / T # A first-order system with time constant T and gain k\n    y ~ x\n]\nsys = ODESystem(eqs, t, name=:tunable_first_order)","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"p = tunable_parameters(sys) # extract all parameters marked as tunable","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"lb, ub = getbounds(p) # operating on a vector, we get lower and upper bound vectors","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"b = getbounds(sys) # Operating on the system, we get a dict","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Index","page":"Symbolic metadata","title":"Index","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"Pages = [\"Variable_metadata.md\"]","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#Docstrings","page":"Symbolic metadata","title":"Docstrings","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/","page":"Symbolic metadata","title":"Symbolic metadata","text":"Modules = [ModelingToolkit]\nPages = [\"variables.jl\"]\nPrivate = false","category":"page"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.getbounds-Tuple{AbstractVector}","page":"Symbolic metadata","title":"ModelingToolkit.getbounds","text":"lb, ub = getbounds(p::AbstractVector)\n\nReturn vectors of lower and upper bounds of parameter vector p. Create parameters with bounds like this\n\n@parameters p [bounds=(-1, 1)]\n\nSee also tunable_parameters, hasbounds\n\n\n\n\n\n","category":"method"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.getbounds-Tuple{Any}","page":"Symbolic metadata","title":"ModelingToolkit.getbounds","text":"getbounds(x)\n\nGet the bounds associated with symbolc variable x. Create parameters with bounds like this\n\n@parameters p [bounds=(-1, 1)]\n\n\n\n\n\n","category":"method"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.getbounds-Tuple{ModelingToolkit.AbstractSystem}","page":"Symbolic metadata","title":"ModelingToolkit.getbounds","text":"getbounds(sys::ModelingToolkit.AbstractSystem)\n\nReturns a dict with pairs p => (lb, ub) mapping parameters of sys to lower and upper bounds. Create parameters with bounds like this\n\n@parameters p [bounds=(-1, 1)]\n\n\n\n\n\n","category":"method"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.getdist-Tuple{Any}","page":"Symbolic metadata","title":"ModelingToolkit.getdist","text":"getdist(x)\n\nGet the probability distribution associated with symbolc variable x. If no distribution is associated with x, nothing is returned. Create parameters with associated distributions like this\n\nusing Distributions\nd = Normal(0, 1)\n@parameters u [dist=d]\nhasdist(u) # true\ngetdist(u) # retrieve distribution\n\n\n\n\n\n","category":"method"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.hasbounds-Tuple{Any}","page":"Symbolic metadata","title":"ModelingToolkit.hasbounds","text":"hasbounds(x)\n\nDetermine whether or not symbolic variable x has bounds associated with it. See also getbounds.\n\n\n\n\n\n","category":"method"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.hasdist-Tuple{Any}","page":"Symbolic metadata","title":"ModelingToolkit.hasdist","text":"hasdist(x)\n\nDetermine whether or not symbolic variable x has a probability distribution associated with it.\n\n\n\n\n\n","category":"method"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.isdisturbance-Tuple{Any}","page":"Symbolic metadata","title":"ModelingToolkit.isdisturbance","text":"isdisturbance(x)\n\nDetermine whether or not symbolic variable x is marked as a disturbance input.\n\n\n\n\n\n","category":"method"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.istunable","page":"Symbolic metadata","title":"ModelingToolkit.istunable","text":"istunable(x, default = false)\n\nDetermine whether or not symbolic variable x is marked as a tunable for an automatic tuning algorithm.\n\ndefault indicates whether variables without tunable metadata are to be considered tunable or not.\n\nCreate a tunable parameter by\n\n@parameters u [tunable=true]\n\nSee also tunable_parameters, getbounds\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/Variable_metadata/#ModelingToolkit.tunable_parameters","page":"Symbolic metadata","title":"ModelingToolkit.tunable_parameters","text":"tunable_parameters(sys, p = parameters(sys); default=false)\n\nGet all parameters of sys that are marked as tunable.\n\nKeyword argument default indicates whether variables without tunable metadata are to be considered tunable or not.\n\nCreate a tunable parameter by\n\n@parameters u [tunable=true]\n\nSee also getbounds, istunable\n\n\n\n\n\n","category":"function"},{"location":"copies/DiffEqSensitivity/training_tips/multiple_nn/#Simultaneous-Fitting-of-Multiple-Neural-Networks","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"In many cases users are interested in fitting multiple neural networks or parameters simultaneously. This tutorial addresses how to perform this kind of study.","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"The following is a fully working demo on the Fitzhugh-Nagumo ODE:","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"using DiffEqFlux, DifferentialEquations\n\nfunction fitz(du,u,p,t)\n  v,w = u\n  a,b,τinv,l = p\n  du[1] = v - v^3/3 -w + l\n  du[2] = τinv*(v +  a - b*w)\nend\n\np_ = Float32[0.7,0.8,1/12.5,0.5]\nu0 = [1f0;1f0]\ntspan = (0f0,10f0)\nprob = ODEProblem(fitz,u0,tspan,p_)\nsol = solve(prob, Tsit5(), saveat = 0.5 )\n\n# Ideal data\nX = Array(sol)\nXₙ = X + Float32(1e-3)*randn(eltype(X), size(X))  #noisy data\n\n# For xz term\nNN_1 = FastChain(FastDense(2, 16, tanh), FastDense(16, 1))\np1 = initial_params(NN_1)\n\n# for xy term\nNN_2 = FastChain(FastDense(3, 16, tanh), FastDense(16, 1))\np2 = initial_params(NN_2)\nscaling_factor = 1f0\n\np = [p1;p2;scaling_factor]\nfunction dudt_(u,p,t)\n    v,w = u\n    z1 = NN_1([v,w], p[1:length(p1)])\n    z2 = NN_2([v,w,t], p[(length(p1)+1):end-1])\n    [z1[1],p[end]*z2[1]]\nend\nprob_nn = ODEProblem(dudt_,u0, tspan, p)\nsol_nn = solve(prob_nn, Tsit5(),saveat = sol.t)\n\nfunction predict(θ)\n    Array(solve(prob_nn, Vern7(), p=θ, saveat = sol.t,\n                         abstol=1e-6, reltol=1e-6,\n                         sensealg = InterpolatingAdjoint(autojacvec=ReverseDiffVJP(true))))\nend\n\n# No regularisation right now\nfunction loss(θ)\n    pred = predict(θ)\n    sum(abs2, Xₙ .- pred), pred\nend\nloss(p)\nconst losses = []\ncallback(θ,l,pred) = begin\n    push!(losses, l)\n    if length(losses)%50==0\n        println(losses[end])\n    end\n    false\nend\n\nres1_uode = DiffEqFlux.sciml_train(loss, p, ADAM(0.01), cb=callback, maxiters = 500)\nres2_uode = DiffEqFlux.sciml_train(loss, res1_uode.u, BFGS(initial_stepnorm=0.01), cb=callback, maxiters = 10000)","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"The key is that sciml_train acts on a single parameter vector p. Thus what we do here is concatenate all of the parameters into a single vector p = [p1;p2;scaling_factor] and then train on this parameter vector. Whenever we need to evaluate the neural networks, we cut the vector and grab the portion that corresponds to the neural network. For example, the p1 portion is p[1:length(p1)], which is why the first neural network's evolution is written like NN_1([v,w], p[1:length(p1)]).","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/multiple_nn/","page":"Simultaneous Fitting of Multiple Neural Networks","title":"Simultaneous Fitting of Multiple Neural Networks","text":"This method is flexible to use with many optimizers and in fairly optimized ways. The allocations can be reduced by using @view p[1:length(p1)]. We can also see with the scaling_factor that we can grab parameters directly out of the vector and use them as needed.","category":"page"},{"location":"copies/Surrogates/variablefidelity/#Variable-fidelity-Surrogates","page":"Variable Fidelity","title":"Variable fidelity Surrogates","text":"","category":"section"},{"location":"copies/Surrogates/variablefidelity/","page":"Variable Fidelity","title":"Variable Fidelity","text":"With the variable fidelity surrogate, we can specify two different surrogates: one for high fidelity data and one for low fidelity data. By default, the first half samples are considered high fidelity and the second half low fidelity.","category":"page"},{"location":"copies/Surrogates/variablefidelity/","page":"Variable Fidelity","title":"Variable Fidelity","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/variablefidelity/","page":"Variable Fidelity","title":"Variable Fidelity","text":"n = 20\nlower_bound = 1.0\nupper_bound = 6.0\nx = sample(n,lower_bound,upper_bound,SobolSample())\nf = x -> 1/3*x\ny = f.(x)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/variablefidelity/","page":"Variable Fidelity","title":"Variable Fidelity","text":"varfid = VariableFidelitySurrogate(x,y,lower_bound,upper_bound)","category":"page"},{"location":"copies/Surrogates/variablefidelity/","page":"Variable Fidelity","title":"Variable Fidelity","text":"plot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\nplot!(varfid, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/abstractgps/#Gaussian-Process-Surrogate-Tutorial","page":"Gaussian Process","title":"Gaussian Process Surrogate Tutorial","text":"","category":"section"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"note: Note\nThis surrogate requires the 'SurrogatesAbstractGPs' module which can be added by inputting \"]add SurrogatesAbstractGPs\" from the Julia command line. ","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"Gaussian Process regression in Surrogates.jl is implemented as a simple wrapper around the AbstractGPs.jl package. AbstractGPs comes with a variety of covariance functions (kernels). See KernelFunctions.jl for examples.","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"tip: Tip\nThe examples below demonstrate the use of AbstractGPs with out-of-the-box settings without hyperparameter optimization (i.e. without changing parameters like lengthscale, signal variance and noise variance.) Beyond hyperparameter optimization, careful initialization of hyperparameters and priors on the parameters is required for this surrogate to work properly. For more details on how to fit GPs in practice, check out A Practical Guide to Gaussian Processes.Also see this example to understand hyperparameter optimization with AbstractGPs.","category":"page"},{"location":"copies/Surrogates/abstractgps/#D-Example","page":"Gaussian Process","title":"1D Example","text":"","category":"section"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"In the example below, the 'gp_surrogate' assignment code can be commented / uncommented to see how the different kernels influence the predictions. ","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"using Surrogates\nusing Plots\ndefault()\nusing AbstractGPs #required to access different types of kernels\nusing SurrogatesAbstractGPs\n\nf(x) = (6 * x - 2)^2 * sin(12 * x - 4)\nn_samples = 4\nlower_bound = 0.0\nupper_bound = 1.0\nxs = lower_bound:0.001:upper_bound\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\ny = f.(x)\n#gp_surrogate = AbstractGPSurrogate(x,y, gp=GP(SqExponentialKernel()), Σy=0.05) #example of Squared Exponential Kernel\n#gp_surrogate = AbstractGPSurrogate(x,y, gp=GP(MaternKernel()), Σy=0.05) #example of MaternKernel\ngp_surrogate = AbstractGPSurrogate(x,y, gp=GP(PolynomialKernel(; c=2.0, degree=5)), Σy=0.25)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), ylims=(-7, 17), legend=:top)\nplot!(xs, f.(xs), label=\"True function\", legend=:top)\nplot!(0:0.001:1, gp_surrogate.gp_posterior; label=\"Posterior\", ribbon_scale=2)","category":"page"},{"location":"copies/Surrogates/abstractgps/#Optimization-Example","page":"Gaussian Process","title":"Optimization Example","text":"","category":"section"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"This example shows the use of AbstractGP Surrogates to find the minima of a function:","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"using Surrogates\nusing Plots\nusing AbstractGPs\nusing SurrogatesAbstractGPs\n\nf(x) = (x-2)^2\nn_samples = 4\nlower_bound = 0.0\nupper_bound = 4.0\nxs = lower_bound:0.1:upper_bound\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\ny = f.(x)\ngp_surrogate = AbstractGPSurrogate(x,y)\n@show surrogate_optimize(f, SRBF(), lower_bound, upper_bound, gp_surrogate, SobolSample())","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"Plotting the function and the sampled points: ","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"scatter(gp_surrogate.x, gp_surrogate.y, label=\"Sampled points\", ylims=(-1.0, 5.0), legend=:top)\nplot!(xs, gp_surrogate.(xs), label=\"Surrogate function\", ribbon=p->std_error_at_point(gp_surrogate, p), legend=:top)\nplot!(xs, f.(xs), label=\"True function\", legend=:top)","category":"page"},{"location":"copies/Surrogates/abstractgps/#ND-Example","page":"Gaussian Process","title":"ND Example","text":"","category":"section"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"using Plots\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\")\nusing Surrogates\nusing AbstractGPs\nusing SurrogatesAbstractGPs\n\n\nhypot_func = z -> 3*hypot(z...)+1\nn_samples = 50\nlower_bound = [-1.0, -1.0]\nupper_bound = [1.0, 1.0]\n\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\nzs = hypot_func.(xys);\n\nx, y = -2:2, -2:2 \np1 = surface(x, y, (x1,x2) -> hypot_func((x1,x2))) \nxs = [xy[1] for xy in xys] \nys = [xy[2] for xy in xys] \nscatter!(xs, ys, zs) \np2 = contour(x, y, (x1,x2) -> hypot_func((x1,x2)))\nscatter!(xs, ys)\nplot(p1, p2, title=\"True function\")","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"Now let's see how our surrogate performs:","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"gp_surrogate = AbstractGPSurrogate(xys, zs)\np1 = surface(x, y, (x, y) -> gp_surrogate([x y]))\nscatter!(xs, ys, zs, marker_z=zs)\np2 = contour(x, y, (x, y) -> gp_surrogate([x y]))\nscatter!(xs, ys, marker_z=zs)\nplot(p1, p2, title=\"Surrogate\")","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"@show gp_surrogate((0.2,0.2))","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"@show hypot_func((0.2,0.2))","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"And this is our log marginal posterior predictive probability:","category":"page"},{"location":"copies/Surrogates/abstractgps/","page":"Gaussian Process","title":"Gaussian Process","text":"@show logpdf_surrogate(gp_surrogate)","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#nonlinearsystemsolvers","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"solve(prob::NonlinearProblem,alg;kwargs)","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"Solves for f(u)=0 in the problem defined by prob using the algorithm alg. If no algorithm is given, a default algorithm will be chosen.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"This page is solely focused on the methods for nonlinear systems.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#Recommended-Methods","page":"Nonlinear System Solvers","title":"Recommended Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"NewtonRaphson is a good choice for most problems. It is non-allocating on static arrays and thus really well-optimized for small systems, while for large systems it can make use of sparsity patterns for sparse automatic differentiation and sparse linear solving of very large systems. That said, as a classic Newton method, its stability region can be smaller than other methods. NLSolveJL's :trust_region method can be a good choice for high stability, along with CMINPACK.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"For a system which is very non-stiff (i.e., the condition number of the Jacobian is small, or the eigenvalues of the Jacobian are within a few orders of magnitude), then NLSolveJL's :anderson can be a good choice.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#Full-List-of-Methods","page":"Nonlinear System Solvers","title":"Full List of Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#NonlinearSolve.jl","page":"Nonlinear System Solvers","title":"NonlinearSolve.jl","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"These are the core solvers.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"NewtonRaphson(;autodiff=true,chunk_size=12,diff_type=Val{:forward},linsolve=DEFAULT_LINSOLVE): A Newton-Raphson method with swappable nonlinear solvers and autodiff methods for high performance on large and sparse systems. When used on objects like static arrays, this method is non-allocating.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#SciMLNLSolve.jl","page":"Nonlinear System Solvers","title":"SciMLNLSolve.jl","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"This is a wrapper package for importing solvers from other packages into this interface. Note that these solvers do not come by default, and thus one needs to install the package before using these solvers:","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"]add SciMLNLSolve\nusing SciMLNLSolve","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"CMINPACK(): A wrapper for using the classic MINPACK method through MINPACK.jl\nNLSolveJL(): A wrapper for NLsolve.jl","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"NLSolveJL(;\n          method=:trust_region,\n          autodiff=:central,\n          store_trace=false,\n          extended_trace=false,\n          linesearch=LineSearches.Static(),\n          linsolve=(x, A, b) -> copyto!(x, A\\b),\n          factor = one(Float64),\n          autoscale=true,\n          m=10,\n          beta=one(Float64),\n          show_trace=false,\n       )","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"Choices for methods in NLSolveJL:","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":":fixedpoint: Fixed-point iteration\n:anderson: Anderson-accelerated fixed-point iteration\n:newton: Classical Newton method with an optional line search\n:trust_region: Trust region Newton method (the default choice)","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"For more information on these arguments, consult the NLsolve.jl documentation.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#Sundials.jl","page":"Nonlinear System Solvers","title":"Sundials.jl","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"This is a wrapper package for the SUNDIALS C library, specifically the KINSOL nonlinear solver included in that ecosystem. Note that these solvers do not come by default, and thus one needs to install the package before using these solvers:","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"]add Sundials\nusing Sundials","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"KINSOL: The KINSOL method of the SUNDIALS C library","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"KINSOL(;\n    linear_solver = :Dense,\n    jac_upper = 0,\n    jac_lower = 0,\n    userdata = nothing,\n)","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"The choices for the linear solver are:","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":":Dense: A dense linear solver\n:Band: A solver specialized for banded Jacobians. If used, you must set the position of the upper and lower non-zero diagonals via jac_upper and jac_lower.\n:LapackDense: A version of the dense linear solver that uses the Julia-provided OpenBLAS-linked LAPACK for multithreaded operations. This will be faster than :Dense on larger systems but has noticeable overhead on smaller (<100 ODE) systems.\n:LapackBand: A version of the banded linear solver that uses the Julia-provided OpenBLAS-linked LAPACK for multithreaded operations. This will be faster than :Band on larger systems but has noticeable overhead on smaller (<100 ODE) systems.\n:Diagonal: This method is specialized for diagonal Jacobians.\n:GMRES: A GMRES method. Recommended first choice Krylov method.\n:BCG: A biconjugate gradient method\n:PCG: A preconditioned conjugate gradient method. Only for symmetric linear systems.\n:TFQMR: A TFQMR method.\n:KLU: A sparse factorization method. Requires that the user specify a Jacobian. The Jacobian must be set as a sparse matrix in the ODEProblem type.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/#acausal","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"In this tutorial we will build a hierarchical acausal component-based model of the RC circuit. The RC circuit is a simple example where we connect a resistor and a capacitor. Kirchoff's laws are then applied to state equalities between currents and voltages. This specifies a differential-algebraic equation (DAE) system, where the algebraic equations are given by the constraints and equalities between different component variables. We then simplify this to an ODE by eliminating the equalities before solving. Let's see this in action.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"note: Note\nThis tutorial teaches how to build the entire RC circuit from scratch. However, to simulate electrical components with more ease, check out the ModelingToolkitStandardLibrary.jl which includes a  tutorial for simulating RC circuits with pre-built components","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/#Copy-Paste-Example","page":"Acausal Component-Based Modeling the RC Circuit","title":"Copy-Paste Example","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"using ModelingToolkit, Plots, DifferentialEquations\n\n@variables t\n@connector function Pin(;name)\n    sts = @variables v(t)=1.0 i(t)=1.0 [connect = Flow]\n    ODESystem(Equation[], t, sts, []; name=name)\nend\n\nfunction Ground(;name)\n    @named g = Pin()\n    eqs = [g.v ~ 0]\n    compose(ODESystem(eqs, t, [], []; name=name), g)\nend\n\nfunction OnePort(;name)\n    @named p = Pin()\n    @named n = Pin()\n    sts = @variables v(t)=1.0 i(t)=1.0\n    eqs = [\n           v ~ p.v - n.v\n           0 ~ p.i + n.i\n           i ~ p.i\n          ]\n    compose(ODESystem(eqs, t, sts, []; name=name), p, n)\nend\n\nfunction Resistor(;name, R = 1.0)\n    @named oneport = OnePort()\n    @unpack v, i = oneport\n    ps = @parameters R=R\n    eqs = [\n           v ~ i * R\n          ]\n    extend(ODESystem(eqs, t, [], ps; name=name), oneport)\nend\n\nfunction Capacitor(;name, C = 1.0)\n    @named oneport = OnePort()\n    @unpack v, i = oneport\n    ps = @parameters C=C\n    D = Differential(t)\n    eqs = [\n           D(v) ~ i / C\n          ]\n    extend(ODESystem(eqs, t, [], ps; name=name), oneport)\nend\n\nfunction ConstantVoltage(;name, V = 1.0)\n    @named oneport = OnePort()\n    @unpack v = oneport\n    ps = @parameters V=V\n    eqs = [\n           V ~ v\n          ]\n    extend(ODESystem(eqs, t, [], ps; name=name), oneport)\nend\n\nR = 1.0\nC = 1.0\nV = 1.0\n@named resistor = Resistor(R=R)\n@named capacitor = Capacitor(C=C)\n@named source = ConstantVoltage(V=V)\n@named ground = Ground()\n\nrc_eqs = [\n          connect(source.p, resistor.p)\n          connect(resistor.n, capacitor.p)\n          connect(capacitor.n, source.n)\n          connect(capacitor.n, ground.g)\n         ]\n\n@named _rc_model = ODESystem(rc_eqs, t)\n@named rc_model = compose(_rc_model,\n                          [resistor, capacitor, source, ground])\nsys = structural_simplify(rc_model)\nu0 = [\n      capacitor.v => 0.0\n     ]\nprob = ODAEProblem(sys, u0, (0, 10.0))\nsol = solve(prob, Tsit5())\nplot(sol)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/#Explanation","page":"Acausal Component-Based Modeling the RC Circuit","title":"Explanation","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/#Building-the-Component-Library","page":"Acausal Component-Based Modeling the RC Circuit","title":"Building the Component Library","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"For each of our components we use a Julia function which emits an ODESystem. At the top we start with defining the fundamental qualities of an electrical circuit component. At every input and output pin a circuit component has two values: the current at the pin and the voltage. Thus we define the Pin component (connector) to simply be the values there. Whenever two Pins in a circuit are connected together, the system satisfies Kirchoff's laws, i.e. that currents sum to zero and voltages across the pins are equal. [connect = Flow] informs MTK that currents ought to sum to zero, and by default, variables are equal in a connection.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"@connector function Pin(;name)\n    sts = @variables v(t)=1.0 i(t)=1.0 [connect = Flow]\n    ODESystem(Equation[], t, sts, []; name=name)\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Note that this is an incompletely specified ODESystem: it cannot be simulated on its own because the equations for v(t) and i(t) are unknown. Instead this just gives a common syntax for receiving this pair with some default values. Notice that in a component we define the name as a keyword argument: this is because later we will generate different Pin objects with different names to correspond to duplicates of this topology with unique variables. One can then construct a Pin like:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Pin(name=:mypin1)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"or equivalently using the @named helper macro:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"@named mypin1 = Pin()","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Next we build our ground node. A ground node is just a pin that is connected to a constant voltage reservoir, typically taken to be V=0. Thus to define this component, we generate an ODESystem with a Pin subcomponent and specify that the voltage in such a Pin is equal to zero. This gives:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"function Ground(;name)\n    @named g = Pin()\n    eqs = [g.v ~ 0]\n    compose(ODESystem(eqs, t, [], []; name=name), g)\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Next we build a OnePort: an abstraction for all simple electrical component with two pins. The voltage difference between the positive pin and the negative pin is the voltage of the component, the current between two pins must sum to zero, and the current of the component equals to the current of the positive pin.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"function OnePort(;name)\n    @named p = Pin()\n    @named n = Pin()\n    sts = @variables v(t)=1.0 i(t)=1.0\n    eqs = [\n           v ~ p.v - n.v\n           0 ~ p.i + n.i\n           i ~ p.i\n          ]\n    compose(ODESystem(eqs, t, sts, []; name=name), p, n)\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Next we build a resistor. A resistor is an object that has two Pins, the positive and the negative pins, and follows Ohm's law: v = i*r. The voltage of the resistor is given as the voltage difference across the two pins while by conservation of charge we know that the current in must equal the current out, which means (no matter the direction of the current flow) the sum of the currents must be zero. This leads to our resistor equations:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"function Resistor(;name, R = 1.0)\n    @named oneport = OnePort()\n    @unpack v, i = oneport\n    ps = @parameters R=R\n    eqs = [\n           v ~ i * R\n          ]\n    extend(ODESystem(eqs, t, [], ps; name=name), oneport)\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Notice that we have created this system with a default parameter R for the resistor's resistance. By doing so, if the resistance of this resistor is not overridden by a higher level default or overridden at ODEProblem construction time, this will be the value of the resistance. Also, note the use of @unpack and extend. For the Resistor, we want to simply inherit OnePort's equations and states and extend them with a new equation. ModelingToolkit makes a new namespaced variable oneport₊v(t) when using the syntax oneport.v, and we can use @unpack avoid the namespacing.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Using our knowledge of circuits we similarly construct the Capacitor:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"function Capacitor(;name, C = 1.0)\n    @named oneport = OnePort()\n    @unpack v, i = oneport\n    ps = @parameters C=C\n    D = Differential(t)\n    eqs = [\n           D(v) ~ i / C\n          ]\n    extend(ODESystem(eqs, t, [], ps; name=name), oneport)\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Now we want to build a constant voltage electrical source term. We can think of this as similarly being a two pin object, where the object itself is kept at a constant voltage, essentially generating the electrical current. We would then model this as:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"function ConstantVoltage(;name, V = 1.0)\n    @named oneport = OnePort()\n    @unpack v = oneport\n    ps = @parameters V=V\n    eqs = [\n           V ~ v\n          ]\n    extend(ODESystem(eqs, t, [], ps; name=name), oneport)\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/#Connecting-and-Simulating-Our-Electrical-Circuit","page":"Acausal Component-Based Modeling the RC Circuit","title":"Connecting and Simulating Our Electrical Circuit","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Now we are ready to simulate our circuit. Let's build our four components: a resistor, capacitor, source, and ground term. For simplicity we will make all of our parameter values 1. This is done by:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"R = 1.0\nC = 1.0\nV = 1.0\n@named resistor = Resistor(R=R)\n@named capacitor = Capacitor(C=C)\n@named source = ConstantVoltage(V=V)\n@named ground = Ground()","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Finally we will connect the pieces of our circuit together. Let's connect the positive pin of the resistor to the source, the negative pin of the resistor to the capacitor, and the negative pin of the capacitor to a junction between the source and the ground. This would mean our connection equations are:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"rc_eqs = [\n          connect(source.p, resistor.p)\n          connect(resistor.n, capacitor.p)\n          connect(capacitor.n, source.n)\n          connect(capacitor.n, ground.g)\n         ]","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Finally we build our four component model with these connection rules:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"@named _rc_model = ODESystem(rc_eqs, t)\n@named rc_model = compose(_rc_model,\n                          [resistor, capacitor, source, ground])","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Note that we can also specify the subsystems in a vector. This model is acasual because we have not specified anything about the causality of the model. We have simply specified what is true about each of the variables. This forms a system of differential-algebraic equations (DAEs) which define the evolution of each state of the system. The equations are:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"equations(expand_connections(rc_model))","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"the states are:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"states(rc_model)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"and the parameters are:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"parameters(rc_model)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/#Simplifying-and-Solving-this-System","page":"Acausal Component-Based Modeling the RC Circuit","title":"Simplifying and Solving this System","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"This system could be solved directly as a DAE using one of the DAE solvers from DifferentialEquations.jl. However, let's take a second to symbolically simplify the system before doing the solve. Although we can use ODE solvers that handles mass matrices to solve the above system directly, we want to run the structural_simplify function first, as it eliminates many unnecessary variables to build the leanest numerical representation of the system. Let's see what it does here:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"sys = structural_simplify(rc_model)\nequations(sys)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"states(sys)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"After structural simplification we are left with a system of only two equations with two state variables. One of the equations is a differential equation while the other is an algebraic equation. We can then give the values for the initial conditions of our states and solve the system by converting it to an ODEProblem in mass matrix form and solving it with an ODEProblem mass matrix DAE solver. This is done as follows:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"u0 = [\n      capacitor.v => 0.0\n      capacitor.p.i => 0.0\n     ]\nprob = ODEProblem(sys, u0, (0, 10.0))\nsol = solve(prob, Rodas4())\nplot(sol)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Since we have run structural_simplify, MTK can numerically solve all the unreduced algebraic equations numerically using the ODAEProblem (note the letter A):","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"u0 = [\n      capacitor.v => 0.0\n     ]\nprob = ODAEProblem(sys, u0, (0, 10.0))\nsol = solve(prob, Rodas4())\nplot(sol)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"Notice that this solves the whole system by only solving for one variable!","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"However, what if we wanted to plot the timeseries of a different variable? Do not worry, that information was not thrown away! Instead, transformations like structural_simplify simply change state variables into observed variables. Let's see what our observed variables are:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"observed(sys)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"These are explicit algebraic equations which can then be used to reconstruct the required variables on the fly. This leads to dramatic computational savings because implicitly solving an ODE scales like O(n^3), so making there be as few states as possible is good!","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"The solution object can be accessed via its symbols. For example, let's retrieve the voltage of the resistor over time:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"sol[resistor.v]","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"or we can plot the timeseries of the resistor's voltage:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/acausal_components/","page":"Acausal Component-Based Modeling the RC Circuit","title":"Acausal Component-Based Modeling the RC Circuit","text":"plot(sol, vars=[resistor.v])","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/#Solving-Nonlinear-Systems","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"","category":"section"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"A nonlinear system f(u) = 0 is specified by defining a function f(u,p), where p are the parameters of the system. For example, the following solves the vector equation f(u) = u^2 - p for a vector of equations:","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"using NonlinearSolve, StaticArrays\n\nf(u,p) = u .* u .- p\nu0 = @SVector[1.0, 1.0]\np = 2.0\nprobN = NonlinearProblem{false}(f, u0, p)\nsolver = solve(probN, NewtonRaphson(), tol = 1e-9)","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"where u0 is the initial condition for the rootfind. Native NonlinearSolve.jl solvers use the given type of u0 to determine the type used within the solver and the return. Note that the parameters p can be any type, but most are an AbstractArray for automatic differentiation.","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/#Using-Bracketing-Methods","page":"Solving Nonlinear Systems","title":"Using Bracketing Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"For scalar rootfinding problems, bracketing methods exist. In this case, one passes a bracket instead of an initial condition, for example:","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"f(u, p) = u .* u .- 2.0\nu0 = (1.0, 2.0) # brackets\nprobB = NonlinearProblem(f, u0)\nsol = solve(probB, Falsi())","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/#Data-Parallel-Multithreaded,-Distributed,-and-Multi-GPU-Batching","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"DiffEqFlux.jl allows for data-parallel batching optimally on one computer, across an entire compute cluster, and batching along GPUs. This can be done by parallelizing within an ODE solve or between the ODE solves. The automatic differentiation tooling is compatible with the parallelism. The following examples demonstrate training over a few different modes of parallelism. These examples are not exhaustive.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/#Within-ODE-Multithreaded-and-GPU-Batching","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Within-ODE Multithreaded and GPU Batching","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"We end by noting that there is an alternative way of batching which can be more efficient in some cases like neural ODEs. With a neural networks, columns are treated independently (by the properties of matrix multiplication). Thus for example, with FastChain we can define an ODE:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"using DiffEqFlux, DifferentialEquations\n\ndudt = FastChain(FastDense(2,50,tanh),FastDense(50,2))\np = initial_params(dudt)\nf(u,p,t) = dudt(u,p)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"and we can solve this ODE where the initial condition is a vector:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"u0 = Float32[2.; 0.]\nprob = ODEProblem(f,u0,(0f0,1f0),p)\nsolve(prob,Tsit5())","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"or we can solve this ODE where the initial condition is a matrix, where each column is an independent system:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"u0 = Float32.([0 1 2\n               0 0 0])\nprob = ODEProblem(f,u0,(0f0,1f0),p)\nsolve(prob,Tsit5())","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"On the CPU this will multithread across the system (due to BLAS) and on GPUs this will parallelize the operations across the GPU. To GPU this, you'd simply move the parameters and the initial condition to the GPU:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"xs = Float32.([0 1 2\n               0 0 0])\nprob = ODEProblem(f,gpu(u0),(0f0,1f0),gpu(p))\nsolve(prob,Tsit5())","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"This method of parallelism is optimal if all of the operations are linear algebra operations such as a neural ODE. Thus this method of parallelism is demonstrated in the MNIST tutorial.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"However, this method of parallelism has many limitations. First of all, the ODE function is required to be written in a way that is independent across the columns. Not all ODEs are written like this, so one needs to be careful. But additionally, this method is ineffective if the ODE function has many serial operations, like u[1]*u[2] - u[3]. In such a case, this indexing behavior will dominate the runtime and cause the parallelism to sometimes even be detrimental.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/#Out-of-ODE-Parallelism","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Out of ODE Parallelism","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Instead of parallelizing within an ODE solve, one can parallelize the solves to the ODE itself. While this will be less effective on very large ODEs, like big neural ODE image classifiers, this method be effective even if the ODE is small or the f function is not well-parallelized. This kind of parallelism is done via the DifferentialEquations.jl ensemble interface. The following examples showcase multithreaded, cluster, and (multi)GPU parallelism through this interface.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/#Multithreaded-Batching-At-a-Glance","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Multithreaded Batching At a Glance","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"The following is a full copy-paste example for the multithreading. Distributed and GPU minibatching are described below.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"using DifferentialEquations, DiffEqFlux\npa = [1.0]\nu0 = [3.0]\nθ = [u0;pa]\n\nfunction model1(θ,ensemble)\n  prob = ODEProblem((u, p, t) -> 1.01u .* p, [θ[1]], (0.0, 1.0), [θ[2]])\n\n  function prob_func(prob, i, repeat)\n    remake(prob, u0 = 0.5 .+ i/100 .* prob.u0)\n  end\n\n  ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\n  sim = solve(ensemble_prob, Tsit5(), ensemble, saveat = 0.1, trajectories = 100)\nend\n\n# loss function\nloss_serial(θ)   = sum(abs2,1.0.-Array(model1(θ,EnsembleSerial())))\nloss_threaded(θ) = sum(abs2,1.0.-Array(model1(θ,EnsembleThreads())))\n\ncb = function (θ,l) # callback function to observe training\n  @show l\n  false\nend\n\nopt = ADAM(0.1)\nl1 = loss_serial(θ)\nres_serial = DiffEqFlux.sciml_train(loss_serial, θ, opt; cb = cb, maxiters=100)\nres_threads = DiffEqFlux.sciml_train(loss_threaded, θ, opt; cb = cb, maxiters=100)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/#Multithreaded-Batching-In-Depth","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Multithreaded Batching In-Depth","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"In order to make use of the ensemble interface, we need to build an EnsembleProblem. The prob_func is the function for determining the different DEProblems to solve. This is the place where we can randomly sample initial conditions or pull initial conditions from an array of batches in order to perform our study. To do this, we first define a prototype DEProblem. Here we use the following ODEProblem as our base:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"prob = ODEProblem((u, p, t) -> 1.01u .* p, [θ[1]], (0.0, 1.0), [θ[2]])","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"In the prob_func we define how to build a new problem based on the base problem. In this case, we want to change u0 by a constant, i.e. 0.5 .+ i/100 .* prob.u0 for different trajectories labelled by i. Thus we use the remake function from the problem interface to do so:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"function prob_func(prob, i, repeat)\n  remake(prob, u0 = 0.5 .+ i/100 .* prob.u0)\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"We now build the EnsembleProblem with this basis:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Now to solve an ensemble problem, we need to choose an ensembling algorithm and choose the number of trajectories to solve. Here let's solve this in serial with 100 trajectories. Note that i will thus run from 1:100.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"sim = solve(ensemble_prob, Tsit5(), EnsembleSerial(), saveat = 0.1, trajectories = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"and thus running in multithreading would be:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"sim = solve(ensemble_prob, Tsit5(), EnsembleThreads(), saveat = 0.1, trajectories = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"This whole mechanism is differentiable, so we then put it in a training loop and it soars. Note that you need to make sure that Julia's multithreading is enabled, which you can do via:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Threads.nthreads()","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/#Distributed-Batching-Across-a-Cluster","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Distributed Batching Across a Cluster","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Changing to distributed computing is very simple as well. The setup is all the same, except you utilize EnsembleDistributed as the ensembler:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"sim = solve(ensemble_prob, Tsit5(), EnsembleDistributed(), saveat = 0.1, trajectories = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"Note that for this to work you need to ensure that your processes are already started. For more information on setting up processes and utilizing a compute cluster, see the official distributed documentation. The key feature to recognize is that, due to the message passing required for cluster compute, one needs to ensure that all of the required functions are defined on the worker processes. The following is a full example of a distributed batching setup:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"using Distributed\naddprocs(4)\n\n@everywhere begin\n  using DifferentialEquations, DiffEqFlux\n  function f(u,p,t)\n    1.01u .* p\n  end\nend\n\npa = [1.0]\nu0 = [3.0]\nθ = [u0;pa]\n\nfunction model1(θ,ensemble)\n  prob = ODEProblem(f, [θ[1]], (0.0, 1.0), [θ[2]])\n\n  function prob_func(prob, i, repeat)\n    remake(prob, u0 = 0.5 .+ i/100 .* prob.u0)\n  end\n\n  ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\n  sim = solve(ensemble_prob, Tsit5(), ensemble, saveat = 0.1, trajectories = 100)\nend\n\ncb = function (θ,l) # callback function to observe training\n  @show l\n  false\nend\n\nopt = ADAM(0.1)\nloss_distributed(θ) = sum(abs2,1.0.-Array(model1(θ,EnsembleDistributed())))\nl1 = loss_distributed(θ)\nres_distributed = DiffEqFlux.sciml_train(loss_distributed, θ, opt; cb = cb, maxiters=100)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"And note that only addprocs(4) needs to be changed in order to make this demo run across a cluster. For more information on adding processes to a cluster, check out ClusterManagers.jl.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/#Minibatching-Across-GPUs-with-DiffEqGPU","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Minibatching Across GPUs with DiffEqGPU","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"DiffEqGPU.jl allows for generating code parallelizes an ensemble on generated CUDA kernels. This method is efficient for sufficiently small (<100 ODE) problems where the significant computational cost is due to the large number of batch trajectories that need to be solved. This kernel-building process adds a few restrictions to the function, such as requiring it has no boundschecking or allocations. The following is an example of minibatch ensemble parallelism across a GPU:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"using DifferentialEquations, DiffEqFlux\nfunction f(du,u,p,t)\n  @inbounds begin\n    du[1] = 1.01 * u[1] * p[1] * p[2]\n  end\nend\n\npa = [1.0]\nu0 = [3.0]\nθ = [u0;pa]\n\nfunction model1(θ,ensemble)\n  prob = ODEProblem(f, [θ[1]], (0.0, 1.0), [θ[2]])\n\n  function prob_func(prob, i, repeat)\n    remake(prob, u0 = 0.5 .+ i/100 .* prob.u0)\n  end\n\n  ensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\n  sim = solve(ensemble_prob, Tsit5(), ensemble, saveat = 0.1, trajectories = 100)\nend\n\ncb = function (θ,l) # callback function to observe training\n  @show l\n  false\nend\n\nopt = ADAM(0.1)\nloss_gpu(θ) = sum(abs2,1.0.-Array(model1(θ,EnsembleGPUArray())))\nl1 = loss_gpu(θ)\nres_gpu = DiffEqFlux.sciml_train(loss_gpu, θ, opt; cb = cb, maxiters=100)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/#Multi-GPU-Batching","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Multi-GPU Batching","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/data_parallel/","page":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","title":"Data-Parallel Multithreaded, Distributed, and Multi-GPU Batching","text":"DiffEqGPU supports batching across multiple GPUs. See its README for details on setting it up.","category":"page"},{"location":"copies/DiffEqSensitivity/dde_fitting/delay_diffeq/#Delay-Differential-Equations","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dde_fitting/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"Other differential equation problem types from DifferentialEquations.jl are supported. For example, we can build a layer with a delay differential equation like:","category":"page"},{"location":"copies/DiffEqSensitivity/dde_fitting/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"using DifferentialEquations, DiffEqFlux\n\n\n# Define the same LV equation, but including a delay parameter\nfunction delay_lotka_volterra!(du, u, h, p, t)\n  x, y = u\n  α, β, δ, γ = p\n  du[1] = dx = (α   - β*y) * h(p, t-0.1)[1]\n  du[2] = dy = (δ*x - γ)   * y\nend\n\n# Initial parameters\np = [2.2, 1.0, 2.0, 0.4]\n\n# Define a vector containing delays for each variable (although only the first\n# one is used)\nh(p, t) = ones(eltype(p), 2)\n\n# Initial conditions\nu0 = [1.0, 1.0]\n\n# Define the problem as a delay differential equation\nprob_dde = DDEProblem(delay_lotka_volterra!, u0, h, (0.0, 10.0),\n                      constant_lags = [0.1])\n\nfunction predict_dde(p)\n  return Array(solve(prob_dde, MethodOfSteps(Tsit5()),\n                              u0=u0, p=p, saveat = 0.1,\n                              sensealg = ReverseDiffAdjoint()))\nend\n\nloss_dde(p) = sum(abs2, x-1 for x in predict_dde(p))\n\n#using Plots\ncb = function (p,l...)\n  display(loss_dde(p))\n  #display(plot(solve(remake(prob_dde,p=p),MethodOfSteps(Tsit5()),saveat=0.1),ylim=(0,6)))\n  return false\nend\n\ncb(p,loss_dde(p))\n\nresult_dde = DiffEqFlux.sciml_train(loss_dde, p, cb = cb)","category":"page"},{"location":"copies/DiffEqSensitivity/dde_fitting/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"Notice that we chose sensealg = ReverseDiffAdjoint() to utilize the ReverseDiff.jl reverse-mode to handle the delay differential equation.","category":"page"},{"location":"copies/DiffEqSensitivity/dde_fitting/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"We define a callback to display the solution at the current parameters for each step of the training:","category":"page"},{"location":"copies/DiffEqSensitivity/dde_fitting/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"#using Plots\ncb = function (p,l...)\n  display(loss_dde(p))\n  #display(plot(solve(remake(prob_dde,p=p),MethodOfSteps(Tsit5()),saveat=0.1),ylim=(0,6)))\n  return false\nend\n\ncb(p,loss_dde(p))","category":"page"},{"location":"copies/DiffEqSensitivity/dde_fitting/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"We use sciml_train to optimize the parameters for our loss function:","category":"page"},{"location":"copies/DiffEqSensitivity/dde_fitting/delay_diffeq/","page":"Delay Differential Equations","title":"Delay Differential Equations","text":"result_dde = DiffEqFlux.sciml_train(loss_dde, p, cb = cb)","category":"page"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#Dependency-Graphs","page":"Dependency Graphs","title":"Dependency Graphs","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#Types","page":"Dependency Graphs","title":"Types","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/","page":"Dependency Graphs","title":"Dependency Graphs","text":"BipartiteGraph","category":"page"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#ModelingToolkit.BipartiteGraphs.BipartiteGraph","page":"Dependency Graphs","title":"ModelingToolkit.BipartiteGraphs.BipartiteGraph","text":"mutable struct BipartiteGraph{I<:Integer, M} <: Graphs.AbstractGraph{I<:Integer}\n\nA bipartite graph representation between two, possibly distinct, sets of vertices (source and dependencies). Maps source vertices, labelled 1:N₁, to vertices on which they depend (labelled 1:N₂).\n\nFields\n\nne\nfadjlist\nbadjlist\nmetadata\n\nExample\n\nusing ModelingToolkit\n\nne = 4\nsrcverts = 1:4\ndepverts = 1:2\n\n# six source vertices\nfadjlist = [[1],[1],[2],[2],[1],[1,2]]\n\n# two vertices they depend on\nbadjlist = [[1,2,5,6],[3,4,6]]\n\nbg = BipartiteGraph(7, fadjlist, badjlist)\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#Utility-functions-for-BiPartiteGraphs","page":"Dependency Graphs","title":"Utility functions for BiPartiteGraphs","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/","page":"Dependency Graphs","title":"Dependency Graphs","text":"Base.isequal","category":"page"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#Base.isequal","page":"Dependency Graphs","title":"Base.isequal","text":"Base.isequal(bg1::BipartiteGraph{T}, bg2::BipartiteGraph{T}) where {T<:Integer}\n\nTest whether two BipartiteGraphs are equal.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#Functions-for-calculating-dependency-graphs","page":"Dependency Graphs","title":"Functions for calculating dependency graphs","text":"","category":"section"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/","page":"Dependency Graphs","title":"Dependency Graphs","text":"equation_dependencies\nasgraph\nvariable_dependencies\nasdigraph\neqeq_dependencies\nvarvar_dependencies","category":"page"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#ModelingToolkit.equation_dependencies","page":"Dependency Graphs","title":"ModelingToolkit.equation_dependencies","text":"equation_dependencies(sys::AbstractSystem; variables=states(sys))\n\nGiven an AbstractSystem calculate for each equation the variables it depends on.\n\nNotes:\n\nVariables that are not in variables are filtered out.\nget_variables! is used to determine the variables within a given equation.\nreturns a Vector{Vector{Variable}}() mapping the index of an equation to the variables it depends on.\n\nExample:\n\nusing ModelingToolkit\n@parameters β γ κ η \n@variables t S(t) I(t) R(t)\n\nrate₁   = β*S*I\nrate₂   = γ*I+t\naffect₁ = [S ~ S - 1, I ~ I + 1]\naffect₂ = [I ~ I - 1, R ~ R + 1]\nj₁ = ConstantRateJump(rate₁,affect₁)\nj₂ = VariableRateJump(rate₂,affect₂)\n\n# create a JumpSystem using these jumps\n@named jumpsys = JumpSystem([j₁,j₂], t, [S,I,R], [β,γ])\n\n# dependency of each jump rate function on state variables\nequation_dependencies(jumpsys)\n\n# dependency of each jump rate function on parameters\nequation_dependencies(jumpsys, variables=parameters(jumpsys))\n\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#ModelingToolkit.asgraph","page":"Dependency Graphs","title":"ModelingToolkit.asgraph","text":"asgraph(eqdeps, vtois)\n\nConvert a collection of equation dependencies, for example as returned by equation_dependencies, to a BipartiteGraph.\n\nNotes:\n\nvtois should provide a Dict like mapping from each Variable dependency in eqdeps to the integer idx of the variable to use in the graph.\n\nExample: Continuing the example started in equation_dependencies\n\ndigr = asgraph(equation_dependencies(odesys), Dict(s => i for (i,s) in enumerate(states(odesys))))\n\n\n\n\n\nasgraph(sys::AbstractSystem; variables=states(sys),\n                                      variablestoids=Dict(convert(Variable, v) => i for (i,v) in enumerate(variables)))\n\nConvert an AbstractSystem to a BipartiteGraph mapping the index of equations to the indices of variables they depend on.\n\nNotes:\n\nDefaults for kwargs creating a mapping from equations(sys) to states(sys) they depend on.\nvariables should provide the list of variables to use for generating the dependency graph.\nvariablestoids should provide Dict like mapping from a Variable to its Int index within variables.\n\nExample: Continuing the example started in equation_dependencies\n\ndigr = asgraph(odesys)\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#ModelingToolkit.variable_dependencies","page":"Dependency Graphs","title":"ModelingToolkit.variable_dependencies","text":"variable_dependencies(sys::AbstractSystem; variables=states(sys), variablestoids=nothing)\n\nFor each variable determine the equations that modify it and return as a BipartiteGraph.\n\nNotes:\n\nDependencies are returned as a BipartiteGraph mapping variable indices to the indices of equations that modify them.\nvariables denotes the list of variables to determine dependencies for.\nvariablestoids denotes a Dict mapping Variables to their Int index in variables.\n\nExample: Continuing the example of equation_dependencies\n\nvariable_dependencies(odesys)\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#ModelingToolkit.asdigraph","page":"Dependency Graphs","title":"ModelingToolkit.asdigraph","text":"asdigraph(g::BipartiteGraph, sys::AbstractSystem; variables = states(sys), equationsfirst = true)\n\nConvert a BipartiteGraph to a LightGraph.SimpleDiGraph.\n\nNotes:\n\nThe resulting SimpleDiGraph unifies the two sets of vertices (equations and then states in the case it comes from asgraph), producing one ordered set of integer vertices (SimpleDiGraph does not support two distinct collections of vertices so they must be merged).\nvariables gives the variables that g is associated with (usually the states of a system).\nequationsfirst (default is true) gives whether the BipartiteGraph gives a mapping from equations to variables they depend on (true), as calculated by asgraph, or whether it gives a mapping from variables to the equations that modify them, as calculated by variable_dependencies.\n\nExample: Continuing the example in asgraph\n\ndg = asdigraph(digr)\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#ModelingToolkit.eqeq_dependencies","page":"Dependency Graphs","title":"ModelingToolkit.eqeq_dependencies","text":"eqeq_dependencies(eqdeps::BipartiteGraph{T}, vardeps::BipartiteGraph{T}) where {T <: Integer}\n\nCalculate a LightGraph.SimpleDiGraph that maps each equation to equations they depend on.\n\nNotes:\n\nThe fadjlist of the SimpleDiGraph maps from an equation to the equations that modify variables it depends on.\nThe badjlist of the SimpleDiGraph maps from an equation to equations that depend on variables it modifies.\n\nExample: Continuing the example of equation_dependencies\n\neqeqdep = eqeq_dependencies(asgraph(odesys), variable_dependencies(odesys))\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/basics/DependencyGraphs/#ModelingToolkit.varvar_dependencies","page":"Dependency Graphs","title":"ModelingToolkit.varvar_dependencies","text":"varvar_dependencies(eqdeps::BipartiteGraph{T}, vardeps::BipartiteGraph{T}) where {T <: Integer} = eqeq_dependencies(vardeps, eqdeps)\n\nCalculate a LightGraph.SimpleDiGraph that maps each variable to variables they depend on.\n\nNotes:\n\nThe fadjlist of the SimpleDiGraph maps from a variable to the variables that depend on it.\nThe badjlist of the SimpleDiGraph maps from a variable to variables on which it depends.\n\nExample: Continuing the example of equation_dependencies\n\nvarvardep = varvar_dependencies(asgraph(odesys), variable_dependencies(odesys))\n\n\n\n\n\n","category":"function"},{"location":"copies/Optimization/API/modelingtoolkit/#ModelingToolkit-Integration","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"","category":"section"},{"location":"copies/Optimization/API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"Optimization.jl is heavily integrated with the ModelingToolkit.jl symbolic system for symbolic-numeric optimizations. It provides a front-end for automating the construction, parallelization, and optimization of code. Optimizers can better interface with the extra symbolic information provided by the system.","category":"page"},{"location":"copies/Optimization/API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"There are two ways that the user interacts with ModelingToolkit.jl. One can use OptimizationFunction with AutoModelingToolkit for automatically transforming numerical codes into symbolic codes. See the OptimizationFunction documentation for more details.","category":"page"},{"location":"copies/Optimization/API/modelingtoolkit/","page":"ModelingToolkit Integration","title":"ModelingToolkit Integration","text":"Secondly, one can generate OptimizationProblems for use in Optimization.jl from purely a symbolic front-end. This is the form users will encounter when using ModelingToolkit.jl directly, and its also the form supplied by domain-specific languages. For more information, see the OptimizationSystem documentation.","category":"page"},{"location":"copies/DiffEqFlux/layers/BasisLayers/#Classical-Basis-Layers","page":"Classical Basis Layers","title":"Classical Basis Layers","text":"","category":"section"},{"location":"copies/DiffEqFlux/layers/BasisLayers/","page":"Classical Basis Layers","title":"Classical Basis Layers","text":"The following basis are helper functions for easily building arrays of the form [f0(x), ..., f{n-1}(x)], where f is the corresponding function of the basis (e.g, Chebyshev Polynomials, Legendre Polynomials, etc.)","category":"page"},{"location":"copies/DiffEqFlux/layers/BasisLayers/","page":"Classical Basis Layers","title":"Classical Basis Layers","text":"ChebyshevBasis\nSinBasis\nCosBasis\nFourierBasis\nLegendreBasis\nPolynomialBasis","category":"page"},{"location":"copies/DiffEqFlux/layers/BasisLayers/#DiffEqFlux.ChebyshevBasis","page":"Classical Basis Layers","title":"DiffEqFlux.ChebyshevBasis","text":"Constructs a Chebyshev basis of the form [T{0}(x), T{1}(x), ..., T{n-1}(x)] where Tj(.) is the j-th Chebyshev polynomial of the first kind.\n\nChebyshevBasis(n)\n\nArguments:\n\nn: number of terms in the polynomial expansion.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/BasisLayers/#DiffEqFlux.SinBasis","page":"Classical Basis Layers","title":"DiffEqFlux.SinBasis","text":"Constructs a sine basis of the form [sin(x), sin(2x), ..., sin(nx)].\n\nSinBasis(n)\n\nArguments:\n\nn: number of terms in the sine expansion.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/BasisLayers/#DiffEqFlux.CosBasis","page":"Classical Basis Layers","title":"DiffEqFlux.CosBasis","text":"Constructs a cosine basis of the form [cos(x), cos(2x), ..., cos(nx)].\n\nCosBasis(n)\n\nArguments:\n\nn: number of terms in the cosine expansion.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/BasisLayers/#DiffEqFlux.FourierBasis","page":"Classical Basis Layers","title":"DiffEqFlux.FourierBasis","text":"Constructs a Fourier basis of the form Fj(x) = j is even ? cos((j÷2)x) : sin((j÷2)x) => [F0(x), F1(x), ..., Fn(x)].\n\nFourierBasis(n)\n\nArguments:\n\nn: number of terms in the Fourier expansion.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/BasisLayers/#DiffEqFlux.LegendreBasis","page":"Classical Basis Layers","title":"DiffEqFlux.LegendreBasis","text":"Constructs a Legendre basis of the form [P{0}(x), P{1}(x), ..., P{n-1}(x)] where Pj(.) is the j-th Legendre polynomial.\n\nLegendreBasis(n)\n\nArguments:\n\nn: number of terms in the polynomial expansion.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/BasisLayers/#DiffEqFlux.PolynomialBasis","page":"Classical Basis Layers","title":"DiffEqFlux.PolynomialBasis","text":"Constructs a Polynomial basis of the form [1, x, ..., x^(n-1)].\n\nPolynomialBasis(n)\n\nArguments:\n\nn: number of terms in the polynomial expansion.\n\n\n\n\n\n","category":"type"},{"location":"copies/Surrogates/radials/#Radial-Surrogates","page":"Radials","title":"Radial Surrogates","text":"","category":"section"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"The Radial Basis Surrogate model represents the interpolating function as a linear combination of basis functions, one for each training point. Let's start with something easy to get our hands dirty. I want to build a surrogate for:","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"f(x) = log(x)*x^2+x^3`","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"Let's choose the Radial Basis Surrogate for 1D. First of all we have to import these two packages: Surrogates and Plots,","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"using Surrogates\r\nusing Plots\r\ndefault()","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"We choose to sample f in 30 points between 5 to 25 using sample function. The sampling points are chosen using a Sobol sequence, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"f(x) = log(x)*x^2 + x^3\r\nn_samples = 30\r\nlower_bound = 5\r\nupper_bound = 25\r\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\ny = f.(x)\r\nscatter(x, y, label=\"Sampled Points\", xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(f, label=\"True function\", scatter(x, y, label=\"Sampled Points\", xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/radials/#Building-Surrogate","page":"Radials","title":"Building Surrogate","text":"","category":"section"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"With our sampled points we can build the Radial Surrogate using the RadialBasis function.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"We can simply calculate radial_surrogate for any value.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"radial_surrogate = RadialBasis(x, y, lower_bound, upper_bound)\r\nval = radial_surrogate(5.4)","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"We can also use cubic radial basis functions.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"radial_surrogate = RadialBasis(x, y, lower_bound, upper_bound, cubicRadial)\r\nval = radial_surrogate(5.4)","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"Currently available radial basis functions are linearRadial (the default), cubicRadial, multiquadricRadial, and thinplateRadial.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"Now, we will simply plot radial_surrogate:","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"plot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(radial_surrogate, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/radials/#Optimizing","page":"Radials","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"Having built a surrogate, we can now use it to search for minimas in our original function f.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"To optimize using our surrogate we call surrogate_optimize method. We choose to use Stochastic RBF as optimization technique and again Sobol sampling as sampling technique.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"@show surrogate_optimize(f, SRBF(), lower_bound, upper_bound, radial_surrogate, SobolSample())\r\nscatter(x, y, label=\"Sampled points\", legend=:top)\r\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\r\nplot!(radial_surrogate, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/radials/#Radial-Basis-Surrogate-tutorial-(ND)","page":"Radials","title":"Radial Basis Surrogate tutorial (ND)","text":"","category":"section"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"First of all we will define the Booth function we are going to build surrogate for:","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"f(x) = (x_1 + 2*x_2 - 7)^2 + (2*x_1 + x_2 - 5)^2","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"Notice, one how its argument is a vector of numbers, one for each coordinate, and its output is a scalar.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"using Plots # hide\r\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\r\nusing Surrogates # hide\r\n\r\nfunction booth(x)\r\n    x1=x[1]\r\n    x2=x[2]\r\n    term1 = (x1 + 2*x2 - 7)^2;\r\n    term2 = (2*x1 + x2 - 5)^2;\r\n    y = term1 + term2;\r\nend","category":"page"},{"location":"copies/Surrogates/radials/#Sampling","page":"Radials","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension x to have bounds -5, 10, and 0, 15 for the second dimension. We are taking 80 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"n_samples = 80\r\nlower_bound = [-5.0, 0.0]\r\nupper_bound = [10.0, 15.0]\r\n\r\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\nzs = booth.(xys);","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"x, y = -5:10, 0:15 # hide\r\np1 = surface(x, y, (x1,x2) -> booth((x1,x2))) # hide\r\nxs = [xy[1] for xy in xys] # hide\r\nys = [xy[2] for xy in xys] # hide\r\nscatter!(xs, ys, zs) # hide\r\np2 = contour(x, y, (x1,x2) -> booth((x1,x2))) # hide\r\nscatter!(xs, ys) # hide\r\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/radials/#Building-a-surrogate","page":"Radials","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"Using the sampled points we build the surrogate, the steps are analogous to the 1-dimensional case.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"radial_basis = RadialBasis(xys, zs,  lower_bound, upper_bound)","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"p1 = surface(x, y, (x, y) -> radial_basis([x y])) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> radial_basis([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2, title=\"Surrogate\") # hide","category":"page"},{"location":"copies/Surrogates/radials/#Optimizing-2","page":"Radials","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"With our surrogate we can now search for the minimas of the function.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"Notice how the new sampled points, which were created during the optimization process, are appended to the xys array. This is why its size changes.","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"surrogate_optimize(booth, SRBF(), lower_bound, upper_bound, radial_basis, UniformSample(), maxiters=50)","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/radials/","page":"Radials","title":"Radials","text":"p1 = surface(x, y, (x, y) -> radial_basis([x y])) # hide\r\nxs = [xy[1] for xy in xys] # hide\r\nys = [xy[2] for xy in xys] # hide\r\nzs = booth.(xys) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> radial_basis([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2) # hide","category":"page"},{"location":"copies/DiffEqSensitivity/manual/nonlinear_solve_sensitivities/#sensitivity_nonlinear","page":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/nonlinear_solve_sensitivities/","page":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","text":"SteadyStateAdjoint","category":"page"},{"location":"copies/DiffEqSensitivity/manual/nonlinear_solve_sensitivities/#DiffEqSensitivity.SteadyStateAdjoint","page":"Sensitivity Algorithms for Nonlinear Problems with Automatic Differentiation (AD)","title":"DiffEqSensitivity.SteadyStateAdjoint","text":"SteadyStateAdjoint{CS,AD,FDT,VJP,LS} <: AbstractAdjointSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of the adjoint differentiation of a nonlinear solve. Uses the implicit function theorem to directly compute the derivative of the solution to f(up) = 0 with respect to p.\n\nConstructor\n\nSteadyStateAdjoint(;chunk_size = 0, autodiff = true, \n                    diff_type = Val{:central},\n                    autojacvec = autodiff, linsolve = nothing)\n\nKeyword Arguments\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The default is true. The total set  of choices are:\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\nlinsolve: the linear solver used in the adjoint solve. Defaults to nothing, which uses a polyalgorithm to attempt to automatically choose an efficient  algorithm.\n\nFor more details on the vjp choices, please consult the sensitivity algorithms documentation page or the docstrings of the vjp types.\n\nReferences\n\nJohnson, S. G., Notes on Adjoint Methods for 18.336, Online at http://math.mit.edu/stevenj/18.336/adjoint.pdf (2007)\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Common-Keyword-Arguments","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"The following defines the keyword arguments which are meant to be preserved throughout all of the SciMLProblem cases (where applicable).","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Default-Algorithm-Hinting","page":"Common Keyword Arguments","title":"Default Algorithm Hinting","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"To help choose the default algorithm, the keyword argument alg_hints is provided to solve. alg_hints is a Vector{Symbol} which describe the problem at a high level to the solver. The options are:","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"This functionality is derived via the benchmarks in SciMLBenchmarks.jl","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"Currently this is only implemented for the differential equation solvers.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Output-Control","page":"Common Keyword Arguments","title":"Output Control","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"These arguments control the output behavior of the solvers. It defaults to maximum output to give the best interactive user experience, but can be reduced all the way to only saving the solution at the final timepoint.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"The following options are all related to output control. See the \"Examples\" section at the end of this page for some example usage.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"dense: Denotes whether to save the extra pieces required for dense (continuous) output. Default is save_everystep && !isempty(saveat) for algorithms which have the ability to produce dense output, i.e. by default it's true unless the user has turned off saving on steps or has chosen a saveat value. If dense=false, the solution still acts like a function, and sol(t) is a linear interpolation between the saved time points.\nsaveat: Denotes specific times to save the solution at, during the solving phase. The solver will save at each of the timepoints in this array in the most efficient manner available to the solver. If only saveat is given, then the arguments save_everystep and dense are false by default. If saveat is given a number, then it will automatically expand to tspan[1]:saveat:tspan[2]. For methods where interpolation is not possible, saveat may be equivalent to tstops. The default value is [].\nsave_idxs: Denotes the indices for the components of the equation to save. Defaults to saving all indices. For example, if you are solving a 3-dimensional ODE, and given save_idxs = [1, 3], only the first and third components of the solution will be outputted. Notice that of course in this case the outputed solution will be two-dimensional.\ntstops: Denotes extra times that the timestepping algorithm must step to. This should be used to help the solver deal with discontinuities and singularities, since stepping exactly at the time of the discontinuity will improve accuracy. If a method cannot change timesteps (fixed timestep multistep methods), then tstops will use an interpolation, matching the behavior of saveat. If a method cannot change timesteps and also cannot interpolate, then tstops must be a multiple of dt or else an error will be thrown. Default is [].\nd_discontinuities: Denotes locations of discontinuities in low order derivatives. This will force FSAL algorithms which assume derivative continuity to re-evaluate the derivatives at the point of discontinuity. The default is [].\nsave_everystep: Saves the result at every step. Default is true if isempty(saveat).\nsave_on: Denotes whether intermediate solutions are saved. This overrides the settings of dense, saveat and save_everystep and is used by some applicatioins to manually turn off saving temporarily. Everyday use of the solvers should leave this unchanged. Defaults to true.\nsave_start: Denotes whether the initial condition should be included in the solution type as the first timepoint. Defaults to true.\nsave_end: Denotes whether the final timepoint is forced to be saved, regardless of the other saving settings. Defaults to true.\ninitialize_save: Denotes whether to save after the callback initialization phase (when u_modified=true). Defaults to true.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"Note that dense requires save_everystep=true and saveat=false.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Stepsize-Control","page":"Common Keyword Arguments","title":"Stepsize Control","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"These arguments control the timestepping routines.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Basic-Stepsize-Control","page":"Common Keyword Arguments","title":"Basic Stepsize Control","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"adaptive: Turns on adaptive timestepping for appropriate methods. Default is true.\nabstol: Absolute tolerance in adaptive timestepping. This is the tolerance on local error estimates, not necessarily the global error (though these quantities are related).\nreltol: Relative tolerance in adaptive timestepping.  This is the tolerance on local error estimates, not necessarily the global error (though these quantities are related).\ndt: Sets the initial stepsize. This is also the stepsize for fixed timestep methods. Defaults to an automatic choice if the method is adaptive.\ndtmax: Maximum dt for adaptive timestepping. Defaults are package-dependent.\ndtmin: Minimum dt for adaptive timestepping. Defaults are package-dependent.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Fixed-Stepsize-Usage","page":"Common Keyword Arguments","title":"Fixed Stepsize Usage","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"Note that if a method does not have adaptivity, the following rules apply:","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"If dt is set, then the algorithm will step with size dt each iteration.\nIf tstops and dt are both set, then the algorithm will step with either a size dt, or use a smaller step to hit the tstops point.\nIf tstops is set without dt, then the algorithm will step directly to each value in tstops\nIf neither dt nor tstops are set, the solver will throw an error.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Memory-Optimizations","page":"Common Keyword Arguments","title":"Memory Optimizations","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"alias_u0: allows the solver to alias the initial condition array that is contained in the problem struct. Defaults to false.\ncache: pass a solver cache to decrease the construction time. This is not implemented for any of the problem interfaces at this moment.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Miscellaneous","page":"Common Keyword Arguments","title":"Miscellaneous","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"maxiters: Maximum number of iterations before stopping.\ncallback: Specifies a callback function that is called between iterations.\nverbose: Toggles whether warnings are thrown when the solver exits early. Defaults to true.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Progress-Monitoring","page":"Common Keyword Arguments","title":"Progress Monitoring","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"These arguments control the usage of the progressbar in the logger.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"progress: Turns on/off the Juno progressbar. Default is false.\nprogress_steps: Numbers of steps between updates of the progress bar. Default is 1000.\nprogress_name: Controls the name of the progressbar. Default is the name of the problem type.\nprogress_message: Controls the message with the progressbar. Defaults to showing dt, t, the maximum of u.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"The progress bars all use the Julia Logging interface in order to be generic to the IDE or programming tool that is used. For more information on how this is all put together, see this discussion.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Error-Calculations","page":"Common Keyword Arguments","title":"Error Calculations","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"If you are using the test problems (i.e. SciMLFunctions where f.analytic is defined), then options control the errors which are calculated. By default, any cheap error estimates are always calculated. Extra keyword arguments include:","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"timeseries_errors\ndense_errors","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"for specifying more expensive errors.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Automatic-Differentiation-Control","page":"Common Keyword Arguments","title":"Automatic Differentiation Control","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"See the Automatic Differentiation page for a full description of sensealg","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/#Strategies-to-Avoid-Local-Minima","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"Local minima can be an issue with fitting neural differential equations. However, there are many strategies to avoid local minima:","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"Insert stochasticity into the loss function through minibatching\nWeigh the loss function to allow for fitting earlier portions first\nChanging the optimizers to allow_f_increases\nIteratively grow the fit\nTraining the initial conditions and the parameters to start","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/#allow_f_increasestrue","page":"Strategies to Avoid Local Minima","title":"allow_f_increases=true","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"With Optim.jl optimizers, you can set allow_f_increases=true in order to let increases in the loss function not cause an automatic halt of the optimization process. Using a method like BFGS or NewtonTrustRegion is not guaranteed to have monotonic convergence and so this can stop early exits which can result in local minima. This looks like:","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"pmin = DiffEqFlux.sciml_train(loss_neuralode, pstart, NewtonTrustRegion(), cb=cb,\n                              maxiters = 200, allow_f_increases = true)","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/#Iterative-Growing-Of-Fits-to-Reduce-Probability-of-Bad-Local-Minima","page":"Strategies to Avoid Local Minima","title":"Iterative Growing Of Fits to Reduce Probability of Bad Local Minima","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"In this example we will show how to use strategy (4) in order to increase the robustness of the fit. Let's start with the same neural ODE example we've used before except with one small twist: we wish to find the neural ODE that fits on (0,5.0). Naively, we use the same training strategy as before:","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"using DiffEqFlux, DifferentialEquations, Plots\n\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 5.0f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = FastChain((x, p) -> x.^3,\n                  FastDense(2, 16, tanh),\n                  FastDense(16, 2))\nprob_neuralode = NeuralODE(dudt2, tspan, Vern7(), saveat = tsteps, abstol=1e-6, reltol=1e-6)\n\nfunction predict_neuralode(p)\n  Array(prob_neuralode(u0, p))\nend\n\nfunction loss_neuralode(p)\n    pred = predict_neuralode(p)\n    loss = sum(abs2, (ode_data[:,1:size(pred,2)] .- pred))\n    return loss, pred\nend\n\niter = 0\ncallback = function (p, l, pred; doplot = true)\n  global iter\n  iter += 1\n\n  display(l)\n  if doplot\n    # plot current prediction against data\n    plt = scatter(tsteps[1:size(pred,2)], ode_data[1,1:size(pred,2)], label = \"data\")\n    scatter!(plt, tsteps[1:size(pred,2)], pred[1,:], label = \"prediction\")\n    display(plot(plt))\n  end\n\n  return false\nend\n\nresult_neuralode = DiffEqFlux.sciml_train(loss_neuralode, prob_neuralode.p,\n                                          ADAM(0.05), cb = callback,\n                                          maxiters = 300)\n\ncallback(result_neuralode.u,loss_neuralode(result_neuralode.u)...;doplot=true)\nsavefig(\"local_minima.png\")","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"However, we've now fallen into a trap of a local minima. If the optimizer changes the parameters so it dips early, it will increase the loss because there will be more error in the later parts of the time series. Thus it tends to just stay flat and never fit perfectly. This thus suggests strategies (2) and (3): do not allow the later parts of the time series to influence the fit until the later stages. Strategy (3) seems to be more robust, so this is what will be demonstrated.","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"Let's start by reducing the timespan to (0,1.5):","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"prob_neuralode = NeuralODE(dudt2, (0.0,1.5), Tsit5(), saveat = tsteps[tsteps .<= 1.5])\n\nresult_neuralode2 = DiffEqFlux.sciml_train(loss_neuralode, prob_neuralode.p,\n                                           ADAM(0.05), cb = callback,\n                                           maxiters = 300)\n\ncallback(result_neuralode2.u,loss_neuralode(result_neuralode2.u)...;doplot=true)\nsavefig(\"shortplot1.png\")","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"This fits beautifully. Now let's grow the timespan and utilize the parameters from our (0,1.5) fit as the initial condition to our next fit:","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"prob_neuralode = NeuralODE(dudt2, (0.0,3.0), Tsit5(), saveat = tsteps[tsteps .<= 3.0])\n\nresult_neuralode3 = DiffEqFlux.sciml_train(loss_neuralode,\n                                           result_neuralode2.u,\n                                           ADAM(0.05), maxiters = 300,\n                                           cb = callback)\ncallback(result_neuralode3.u,loss_neuralode(result_neuralode3.u)...;doplot=true)\nsavefig(\"shortplot2.png\")","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"Once again a great fit. Now we utilize these parameters as the initial condition to the full fit:","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"prob_neuralode = NeuralODE(dudt2, (0.0,5.0), Tsit5(), saveat = tsteps)\n\nresult_neuralode4 = DiffEqFlux.sciml_train(loss_neuralode,\n                                           result_neuralode3.u,\n                                           ADAM(0.01), maxiters = 300,\n                                           cb = callback)\ncallback(result_neuralode4.u,loss_neuralode(result_neuralode4.u)...;doplot=true)\nsavefig(\"fullplot.png\")","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/#Training-both-the-initial-conditions-and-the-parameters-to-start","page":"Strategies to Avoid Local Minima","title":"Training both the initial conditions and the parameters to start","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"In this example we will show how to use strategy (5) in order to accomplish the same goal, except rather than growing the trajectory iteratively, we can train on the whole trajectory. We do this by allowing the neural ODE to learn both the initial conditions and parameters to start, and then reset the initial conditions back and train only the parameters. Note: this strategy is demonstrated for the (0, 5) time span and (0, 10), any longer and more iterations will be required. Alternatively, one could use a mix of (4) and (5), or breaking up the trajectory into chunks and just (5).","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"\nusing DiffEqFlux, Plots, DifferentialEquations\n\n\n#Starting example with tspan (0, 5)\nu0 = Float32[2.0; 0.0]\ndatasize = 30\ntspan = (0.0f0, 5.0f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\n#Using flux here to easily demonstrate the idea, but this can be done with sciml_train!\ndudt2 = Chain(Dense(2,16, tanh),\n             Dense(16,2))\n\n\np,re = Flux.destructure(dudt2) # use this p as the initial condition!\ndudt(u,p,t) = re(p)(u) # need to restrcture for backprop!\nprob = ODEProblem(dudt,u0,tspan)\n\nfunction predict_n_ode()\n    Array(solve(prob,u0=u0,p=p, saveat=tsteps))\nend\n\nfunction loss_n_ode()\n      pred = predict_n_ode()\n      sqnorm(x) = sum(abs2, x)\n      loss = sum(abs2,ode_data .- pred)\n      loss\nend\n\nfunction cb(;doplot=false) #callback function to observe training\n    pred = predict_n_ode()\n    display(sum(abs2,ode_data .- pred))\n    if doplot\n      # plot current prediction against data\n      pl = plot(tsteps,ode_data[1,:],label=\"data\")\n      plot!(pl,tsteps,pred[1,:],label=\"prediction\")\n      display(plot(pl))\n    end\n    return false\nend\npredict_n_ode()\nloss_n_ode()\ncb(;doplot=true)\n\ndata = Iterators.repeated((), 1000)\n\n#Specify to flux to include both the initial conditions (IC) and parameters of the NODE to train\nFlux.train!(loss_n_ode, Flux.params(u0, p), data,\n                    Flux.Optimise.ADAM(0.05), cb = cb)\n\n#Here we reset the IC back to the original and train only the NODE parameters\nu0 = Float32[2.0; 0.0]\nFlux.train!(loss_n_ode, Flux.params(p), data,\n            Flux.Optimise.ADAM(0.05), cb = cb)\n\ncb(;doplot=true)\n\n#Now use the same technique for a longer tspan (0, 10)\ndatasize = 30\ntspan = (0.0f0, 10.0f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\ndudt2 = Chain(Dense(2,16, tanh),\n             Dense(16,2))\n\np,re = Flux.destructure(dudt2) # use this p as the initial condition!\ndudt(u,p,t) = re(p)(u) # need to restrcture for backprop!\nprob = ODEProblem(dudt,u0,tspan)\n\n\n\ndata = Iterators.repeated((), 1500)\n\nFlux.train!(loss_n_ode, Flux.params(u0, p), data,\n                    Flux.Optimise.ADAM(0.05), cb = cb)\n\n\n\nu0 = Float32[2.0; 0.0]\nFlux.train!(loss_n_ode, Flux.params(p), data,\n            Flux.Optimise.ADAM(0.05), cb = cb)\n\ncb(;doplot=true)\n","category":"page"},{"location":"copies/DiffEqSensitivity/training_tips/local_minima/","page":"Strategies to Avoid Local Minima","title":"Strategies to Avoid Local Minima","text":"And there we go, a set of robust strategies for fitting an equation that would otherwise get stuck in a local optima.","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/#Bracketing-Solvers","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"solve(prob::NonlinearProblem,alg;kwargs)","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"Solves for f(u)=0 in the problem defined by prob using the algorithm alg. If no algorithm is given, a default algorithm will be chosen.","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"This page is solely focused on the bracketing methods for scalar nonlinear equations.","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/#Recommended-Methods","page":"Bracketing Solvers","title":"Recommended Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"Falsi() can have a faster convergence and is discretely differentiable, but is less stable than Bisection.","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/#Full-List-of-Methods","page":"Bracketing Solvers","title":"Full List of Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/#NonlinearSolve.jl","page":"Bracketing Solvers","title":"NonlinearSolve.jl","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"Falsi: A non-allocating regula falsi method\nBisection: A common bisection method","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/#sensealg","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"Automatic differentiation control is done through the sensealg keyword argument. Hooks exist in the high level interfaces for solve which shuttle the definitions of automatic differentiation overloads to dispatches defined in DiffEqSensitivity.jl (should be renamed SciMLSensitivity.jl as it expands). This is done by first entering a top-level solve definition, for example:","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"function solve(prob::DEProblem, args...; sensealg=nothing,\n  u0=nothing, p=nothing, kwargs...)\n  u0 = u0 !== nothing ? u0 : prob.u0\n  p = p !== nothing ? p : prob.p\n  if sensealg === nothing && haskey(prob.kwargs, :sensealg)\n    sensealg = prob.kwargs[:sensealg]\n  end\n  solve_up(prob, sensealg, u0, p, args...; kwargs...)\nend","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"solve_up then drops down the differentiable arguments as positional arguments, which is required for the ChainRules.jl interface. Then the ChainRules overloads are written on the solve_up calls, like:","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"function ChainRulesCore.frule(::typeof(solve_up), prob,\n  sensealg::Union{Nothing,AbstractSensitivityAlgorithm},\n  u0, p, args...;\n  kwargs...)\n  _solve_forward(prob, sensealg, u0, p, args...; kwargs...)\nend\n\nfunction ChainRulesCore.rrule(::typeof(solve_up), prob::SciMLBase.DEProblem,\n  sensealg::Union{Nothing,AbstractSensitivityAlgorithm},\n  u0, p, args...;\n  kwargs...)\n  _solve_adjoint(prob, sensealg, u0, p, args...; kwargs...)\nend","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"Default definitions then exist to throw an informative error if the sensitivity mechanism is not added:","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"function _concrete_solve_adjoint(args...; kwargs...)\n  error(\"No adjoint rules exist. Check that you added `using DiffEqSensitivity`\")\nend\n\nfunction _concrete_solve_forward(args...; kwargs...)\n  error(\"No sensitivity rules exist. Check that you added `using DiffEqSensitivity`\")\nend","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"The sensitivity mechanism is kept in a separate package because of the high dependency and load time cost introduced by the automatic differentiation libraries. Different choices of automatic differentiation are then selected by the sensealg keyword argument in solve, which is made into a positional argument in the _solve_adjoint and other functions in order to allow dispatch.","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/#SensitivityADPassThrough","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"SensitivityADPassThrough","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"The special sensitivity algorithm SensitivityADPassThrough is used to ignore the internal sensitivity dispatches and instead do automatic differentiation directly through the solver. Generally this sensealg is only used internally.","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/#Note-about-ForwardDiff","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Note about ForwardDiff","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"ForwardDiff does not use ChainRules.jl and thus it completely ignores the special handling.","category":"page"},{"location":"copies/Surrogates/multi_objective_opt/#Multi-objective-optimization-benchmarks","page":"Multi objective optimization","title":"Multi objective optimization benchmarks","text":"","category":"section"},{"location":"copies/Surrogates/multi_objective_opt/#Case-1:-Non-colliding-objective-functions","page":"Multi objective optimization","title":"Case 1: Non colliding objective functions","text":"","category":"section"},{"location":"copies/Surrogates/multi_objective_opt/","page":"Multi objective optimization","title":"Multi objective optimization","text":"using Surrogates\n#EGO\nm = 10\nf  = x -> [x^i for i = 1:m]\nlb = 1.0\nub = 10.0\nx  = sample(100, lb, ub, SobolSample())\ny  = f.(x)\nmy_radial_basis_ego = RadialBasis(x, y, lb, ub, rad = linearRadial)\npareto_set, pareto_front = surrogate_optimize(f,EGO(),lb,ub,my_radial_basis_ego,SobolSample())\n\nm = 5\nf  = x -> [x^i for i =1:m]\nlb = 1.0\nub = 10.0\nx  = sample(100, lb, ub, SobolSample())\ny  = f.(x)\nmy_radial_basis_rtea = RadialBasis(x, y, lb, ub, rad = linearRadial)\nZ = 0.8\nK = 2\np_cross = 0.5\nn_c = 1.0\nsigma = 1.5\nsurrogate_optimize(f,RTEA(Z,K,p_cross,n_c,sigma),lb,ub,my_radial_basis_rtea,SobolSample())","category":"page"},{"location":"copies/Surrogates/multi_objective_opt/#Case-2:-objective-functions-with-conflicting-minima","page":"Multi objective optimization","title":"Case 2: objective functions with conflicting minima","text":"","category":"section"},{"location":"copies/Surrogates/multi_objective_opt/","page":"Multi objective optimization","title":"Multi objective optimization","text":"#EGO\nf  = x -> [sqrt((x[1] - 4)^2 + 25*(x[2])^2),\n           sqrt((x[1]+4)^2 + 25*(x[2])^2),\n           sqrt((x[1]-3)^2 + (x[2]-1)^2)]\nlb = [2.5,-0.5]\nub = [3.5,0.5]\nx  = sample(100, lb, ub, SobolSample())\ny  = f.(x)\nmy_radial_basis_ego = RadialBasis(x, y, lb, ub, rad = linearRadial)\n#I can find my pareto set and pareto front by calling again the surrogate_optimize function:\npareto_set, pareto_front = surrogate_optimize(f,EGO(),lb,ub,my_radial_basis_ego,SobolSample(),maxiters=30);","category":"page"},{"location":"copies/Optimization/tutorials/symbolic/#Symbolic-Problem-Building-with-ModelingToolkit","page":"Symbolic Modeling","title":"Symbolic Problem Building with ModelingToolkit","text":"","category":"section"},{"location":"copies/Optimization/tutorials/symbolic/","page":"Symbolic Modeling","title":"Symbolic Modeling","text":"note: Note\nThis example uses the OptimizationOptimJL.jl package. See the Optim.jl page for details on the installation and usage.","category":"page"},{"location":"copies/Optimization/tutorials/symbolic/","page":"Symbolic Modeling","title":"Symbolic Modeling","text":"using ModelingToolkit, Optimization, OptimizationOptimJL\r\n\r\n@variables x y\r\n@parameters a b\r\nloss = (a - x)^2 + b * (y - x^2)^2\r\nsys = OptimizationSystem(loss,[x,y],[a,b])\r\n\r\nu0 = [\r\n    x=>1.0\r\n    y=>2.0\r\n]\r\np = [\r\n    a => 6.0\r\n    b => 7.0\r\n]\r\n\r\nprob = OptimizationProblem(sys,u0,p,grad=true,hess=true)\r\nsolve(prob,Newton())","category":"page"},{"location":"copies/Optimization/tutorials/symbolic/","page":"Symbolic Modeling","title":"Symbolic Modeling","text":"Needs text but it's super cool and auto-parallelizes and sparsifies too. Plus you can hierarchically nest systems to have it generate huge optimization problems. Check out the ModelingToolkit.jl OptimizationSystem documentation for more information.","category":"page"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/#nonlinearfunctions","page":"NonlinearFunctions and Jacobian Types","title":"NonlinearFunctions and Jacobian Types","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/","page":"NonlinearFunctions and Jacobian Types","title":"NonlinearFunctions and Jacobian Types","text":"The SciML ecosystem provides an extensive interface for declaring extra functions associated with the differential equation's data. In traditional libraries there is usually only one option: the Jacobian. However, we allow for a large array of pre-computed functions to speed up the calculations. This is offered via the NonlinearFunction types, which can be passed to the problems.","category":"page"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/#Function-Type-Definitions","page":"NonlinearFunctions and Jacobian Types","title":"Function Type Definitions","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/","page":"NonlinearFunctions and Jacobian Types","title":"NonlinearFunctions and Jacobian Types","text":"SciMLBase.NonlinearFunction","category":"page"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/#SciMLBase.NonlinearFunction","page":"NonlinearFunctions and Jacobian Types","title":"SciMLBase.NonlinearFunction","text":"NonlinearFunction{iip,F,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractNonlinearFunction{iip}\n\nA representation of an nonlinear system of equations f, defined by:\n\n0 = f(up)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nNonlinearFunction{iip,recompile}(f;\n                           analytic=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           paramjac = nothing,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p) or du = f(u,p). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nanalytic(u0,p): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\njac(J,u,p) or J=jac(u,p): returns fracdfdu\njvp(Jv,v,u,p) or Jv=jvp(v,u,p): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p) or Jv=vjp(v,u,p): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the NonlinearFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLAlgorithms","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Definition-of-the-SciMLAlgorithm-Interface","page":"SciMLAlgorithms","title":"Definition of the SciMLAlgorithm Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"SciMLAlgorithms are defined as types which have dispatches to the function signature:","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"CommonSolve.solve(prob::SciMLProblem,alg::SciMLAlgorithm;kwargs...)","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Algorithm-Specific-Arguments","page":"SciMLAlgorithms","title":"Algorithm-Specific Arguments","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"Note that because the keyword arguments of solve are designed to be common across the whole problem type, algorithms should have the algorithm-specific keyword arguments defined as part of the algorithm constructor. For example, Rodas5 has a choice of autodiff::Bool which is not common across all ODE solvers, and thus autodiff is a algorithm-specific keyword argument handled via Rodas5(autodiff=true).","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Remake","page":"SciMLAlgorithms","title":"Remake","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"Note that remake is applicable to SciMLAlgorithm types, but this is not used in the public API. It's used for solvers to swap out components like ForwardDiff chunk sizes.","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Common-Algorithm-Keyword-Arguments","page":"SciMLAlgorithms","title":"Common Algorithm Keyword Arguments","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"Commonly used algorithm keyword arguments are:","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Traits","page":"SciMLAlgorithms","title":"Traits","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"SciMLBase.isautodifferentiable\nSciMLBase.allows_arbitrary_number_types\nSciMLBase.allowscomplex\nSciMLBase.isadaptive\nSciMLBase.isdiscrete","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.isautodifferentiable","page":"SciMLAlgorithms","title":"SciMLBase.isautodifferentiable","text":"isautodifferentiable(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with direct automatic differentiation, i.e. can have algorithms like ForwardDiff or ReverseDiff attempt to differentiate directly through the solver.\n\nDefaults to false as only pure-Julia algorithms can have this be true.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.allows_arbitrary_number_types","page":"SciMLAlgorithms","title":"SciMLBase.allows_arbitrary_number_types","text":"allowsarbitrarynumber_types(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with direct automatic differentiation, i.e. can have algorithms like ForwardDiff or ReverseDiff attempt to differentiate directly through the solver.\n\nDefaults to false as only pure-Julia algorithms can have this be true.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.allowscomplex","page":"SciMLAlgorithms","title":"SciMLBase.allowscomplex","text":"allowscomplex(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with having complex numbers as the state variables.\n\nDefaults to false.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.isadaptive","page":"SciMLAlgorithms","title":"SciMLBase.isadaptive","text":"isadaptive(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm uses adaptivity, i.e. has a non-quasi-static compute graph.\n\nDefaults to true.\n\n\n\n\n\nis_integrator_adaptive(i::DEIntegrator)\n\nChecks if the integrator is adaptive\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.isdiscrete","page":"SciMLAlgorithms","title":"SciMLBase.isdiscrete","text":"isdiscrete(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm allows for discrete state values, such as integers.\n\nDefaults to false.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Abstract-SciML-Algorithms","page":"SciMLAlgorithms","title":"Abstract SciML Algorithms","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"SciMLBase.SciMLAlgorithm\nSciMLBase.DEAlgorithm\nSciMLBase.AbstractLinearAlgorithm\nSciMLBase.AbstractNonlinearAlgorithm\nSciMLBase.AbstractQuadratureAlgorithm\nSciMLBase.AbstractOptimizationAlgorithm\nSciMLBase.AbstractSteadyStateAlgorithm\nSciMLBase.AbstractODEAlgorithm\nSciMLBase.AbstractSecondOrderODEAlgorithm\nSciMLBase.AbstractRODEAlgorithm\nSciMLBase.AbstractSDEAlgorithm\nSciMLBase.AbstractDAEAlgorithm\nSciMLBase.AbstractDDEAlgorithm\nSciMLBase.AbstractSDDEAlgorithm","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.SciMLAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.SciMLAlgorithm","text":"abstract type SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.DEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.DEAlgorithm","text":"abstract type DEAlgorithm <: SciMLBase.SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractLinearAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractLinearAlgorithm","text":"abstract type AbstractLinearAlgorithm <: SciMLBase.SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractNonlinearAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractNonlinearAlgorithm","text":"abstract type AbstractNonlinearAlgorithm <: SciMLBase.SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractQuadratureAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractQuadratureAlgorithm","text":"abstract type AbstractIntegralAlgorithm <: SciMLBase.SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractOptimizationAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractOptimizationAlgorithm","text":"abstract type AbstractOptimizationAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractSteadyStateAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSteadyStateAlgorithm","text":"abstract type AbstractSteadyStateAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractODEAlgorithm","text":"abstract type AbstractODEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractSecondOrderODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSecondOrderODEAlgorithm","text":"abstract type AbstractSecondOrderODEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractRODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractRODEAlgorithm","text":"abstract type AbstractRODEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractSDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSDEAlgorithm","text":"abstract type AbstractSDEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractDAEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractDAEAlgorithm","text":"abstract type AbstractDAEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractDDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractDDEAlgorithm","text":"abstract type AbstractDDEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractSDDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSDDEAlgorithm","text":"abstract type AbstractSDDEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Concrete-SciML-Algorithms","page":"SciMLAlgorithms","title":"Concrete SciML Algorithms","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"The concrete SciML algorithms are found in the respective solver documentations.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Neural-Graph-Differential-Equations","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"This tutorial has been adapted from here.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"In this tutorial we will use Graph Differential Equations (GDEs) to perform classification on the CORA Dataset. We shall be using the Graph Neural Networks primitives from the package GeometricFlux.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"# Load the packages\nusing GeometricFlux, JLD2, SparseArrays, DiffEqFlux, DifferentialEquations\nusing Flux: onehotbatch, onecold, throttle\nusing Flux.Losses: logitcrossentropy\nusing Statistics: mean\nusing LightGraphs: adjacency_matrix\n\n# Download the dataset\ndownload(\"https://rawcdn.githack.com/yuehhua/GeometricFlux.jl/a94ca7ce2ad01a12b23d68eb6cd991ee08569303/data/cora_features.jld2\", \"cora_features.jld2\")\ndownload(\"https://rawcdn.githack.com/yuehhua/GeometricFlux.jl/a94ca7ce2ad01a12b23d68eb6cd991ee08569303/data/cora_graph.jld2\", \"cora_graph.jld2\")\ndownload(\"https://rawcdn.githack.com/yuehhua/GeometricFlux.jl/a94ca7ce2ad01a12b23d68eb6cd991ee08569303/data/cora_labels.jld2\", \"cora_labels.jld2\")\n\n# Load the dataset\n@load \"./cora_features.jld2\" features\n@load \"./cora_labels.jld2\" labels\n@load \"./cora_graph.jld2\" g\n\n# Model and Data Configuration\nnum_nodes = 2708\nnum_features = 1433\nhidden = 16\ntarget_catg = 7\nepochs = 40\n\n# Preprocess the data and compute adjacency matrix\ntrain_X = Float32.(features)  # dim: num_features * num_nodes\ntrain_y = Float32.(labels)  # dim: target_catg * num_nodes\n\nadj_mat = FeaturedGraph(Matrix{Float32}(adjacency_matrix(g)))\n\n# Define the Neural GDE\ndiffeqarray_to_array(x) = reshape(cpu(x), size(x)[1:2])\n\nnode = NeuralODE(\n    GCNConv(adj_mat, hidden=>hidden),\n    (0.f0, 1.f0), Tsit5(), save_everystep = false,\n    reltol = 1e-3, abstol = 1e-3, save_start = false\n)\n\nmodel = Chain(GCNConv(adj_mat, num_features=>hidden, relu),\n              Dropout(0.5),\n              node,\n              diffeqarray_to_array,\n              GCNConv(adj_mat, hidden=>target_catg))\n\n# Loss\nloss(x, y) = logitcrossentropy(model(x), y)\naccuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n\n# Training\n## Model Parameters\nps = Flux.params(model, node.p);\n\n## Training Data\ntrain_data = [(train_X, train_y)]\n\n## Optimizer\nopt = ADAM(0.01)\n\n## Callback Function for printing accuracies\nevalcb() = @show(accuracy(train_X, train_y))\n\n## Training Loop\nfor i = 1:epochs\n    Flux.train!(loss, ps, train_data, opt, cb=throttle(evalcb, 10))\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Step-by-Step-Explanation","page":"Neural Graph Differential Equations","title":"Step by Step Explanation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Load-the-Required-Packages","page":"Neural Graph Differential Equations","title":"Load the Required Packages","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"# Load the packages\nusing GeometricFlux, JLD2, SparseArrays, DiffEqFlux, DifferentialEquations\nusing Flux: onehotbatch, onecold, throttle\nusing Flux.Losses: crossentropy\nusing Statistics: mean\nusing LightGraphs: adjacency_matrix","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Load-the-Dataset","page":"Neural Graph Differential Equations","title":"Load the Dataset","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"The dataset is available in the desired format in the GeometricFlux repository. We shall download the dataset from there, and use the JLD2 package to load the data.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"download(\"https://rawcdn.githack.com/yuehhua/GeometricFlux.jl/a94ca7ce2ad01a12b23d68eb6cd991ee08569303/data/cora_features.jld2\", \"cora_features.jld2\")\ndownload(\"https://rawcdn.githack.com/yuehhua/GeometricFlux.jl/a94ca7ce2ad01a12b23d68eb6cd991ee08569303/data/cora_graph.jld2\", \"cora_graph.jld2\")\ndownload(\"https://rawcdn.githack.com/yuehhua/GeometricFlux.jl/a94ca7ce2ad01a12b23d68eb6cd991ee08569303/data/cora_labels.jld2\", \"cora_labels.jld2\")\n\n@load \"./cora_features.jld2\" features\n@load \"./cora_labels.jld2\" labels\n@load \"./cora_graph.jld2\" g","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Model-and-Data-Configuration","page":"Neural Graph Differential Equations","title":"Model and Data Configuration","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"The num_nodes, target_catg and num_features are defined by the data itself. We shall use a shallow GNN with only 16 hidden state dimension.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"num_nodes = 2708\nnum_features = 1433\nhidden = 16\ntarget_catg = 7\nepochs = 40","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Preprocessing-the-Data","page":"Neural Graph Differential Equations","title":"Preprocessing the Data","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"Convert the data to float32 and use LightGraphs to get the adjacency matrix from the graph g.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"train_X = Float32.(features)  # dim: num_features * num_nodes\ntrain_y = Float32.(labels)  # dim: target_catg * num_nodes\n\nadj_mat = Matrix{Float32}(adjacency_matrix(g))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Neural-Graph-Ordinary-Differential-Equations","page":"Neural Graph Differential Equations","title":"Neural Graph Ordinary Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"Let us now define the final model. We will use a single layer GNN for approximating the gradients for the neural ODE. We use two additional GCNConv layers, one to project the data to a latent space and the other to project it from the latent space to the predictions. Finally a softmax layer gives us the probability of the input belonging to each target category.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"diffeqarray_to_array(x) = reshape(cpu(x), size(x)[1:2])\n\nnode = NeuralODE(\n    GCNConv(adj_mat, hidden=>hidden),\n    (0.f0, 1.f0), Tsit5(), save_everystep = false,\n    reltol = 1e-3, abstol = 1e-3, save_start = false\n)\n\nmodel = Chain(GCNConv(adj_mat, num_features=>hidden, relu),\n              Dropout(0.5),\n              node,\n              diffeqarray_to_array,\n              GCNConv(adj_mat, hidden=>target_catg))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Training-Configuration","page":"Neural Graph Differential Equations","title":"Training Configuration","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Loss-Function-and-Accuracy","page":"Neural Graph Differential Equations","title":"Loss Function and Accuracy","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"We shall be using the standard categorical crossentropy loss function which is used for multiclass classification tasks.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"loss(x, y) = logitcrossentropy(model(x), y)\naccuracy(x, y) = mean(onecold(model(x)) .== onecold(y))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Model-Parameters","page":"Neural Graph Differential Equations","title":"Model Parameters","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"Now we extract the model parameters which we want to learn.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"ps = Flux.params(model, node.p);","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Training-Data","page":"Neural Graph Differential Equations","title":"Training Data","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"GNNs operate on an entire graph, so we can't do any sort of minibatching here. We need to pass the entire data in a single pass. So our dataset is an array with a single tuple.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"train_data = [(train_X, train_y)]","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Optimizer","page":"Neural Graph Differential Equations","title":"Optimizer","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"For this task we will be using the ADAM optimizer with a learning rate of 0.01.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"opt = ADAM(0.01)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Callback-Function","page":"Neural Graph Differential Equations","title":"Callback Function","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"We also define a utility function for printing the accuracy of the model over time.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"evalcb() = @show(accuracy(train_X, train_y))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Training-Loop","page":"Neural Graph Differential Equations","title":"Training Loop","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"Finally, with the configuration ready and all the utilities defined we can use the Flux.train! function to learn the parameters ps. We run the training loop for epochs number of iterations.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"for i = 1:epochs\n    Flux.train!(loss, ps, train_data, opt, cb=throttle(evalcb, 10))\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/#Expected-Output","page":"Neural Graph Differential Equations","title":"Expected Output","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/neural_gde/","page":"Neural Graph Differential Equations","title":"Neural Graph Differential Equations","text":"accuracy(train_X, train_y) = 0.12370753323485968\naccuracy(train_X, train_y) = 0.11632200886262925\naccuracy(train_X, train_y) = 0.1189069423929099\naccuracy(train_X, train_y) = 0.13404726735598227\naccuracy(train_X, train_y) = 0.15620384047267355\naccuracy(train_X, train_y) = 0.1776218611521418\naccuracy(train_X, train_y) = 0.19793205317577547\naccuracy(train_X, train_y) = 0.21122599704579026\naccuracy(train_X, train_y) = 0.22673559822747416\naccuracy(train_X, train_y) = 0.2429837518463811\naccuracy(train_X, train_y) = 0.25406203840472674\naccuracy(train_X, train_y) = 0.26809453471196454\naccuracy(train_X, train_y) = 0.2869276218611521\naccuracy(train_X, train_y) = 0.2961595273264402\naccuracy(train_X, train_y) = 0.30797636632200887\naccuracy(train_X, train_y) = 0.31831610044313147\naccuracy(train_X, train_y) = 0.3257016248153619\naccuracy(train_X, train_y) = 0.3378877400295421\naccuracy(train_X, train_y) = 0.3500738552437223\naccuracy(train_X, train_y) = 0.3629985228951256\naccuracy(train_X, train_y) = 0.37259970457902514\naccuracy(train_X, train_y) = 0.3777695716395864\naccuracy(train_X, train_y) = 0.3895864106351551\naccuracy(train_X, train_y) = 0.396602658788774\naccuracy(train_X, train_y) = 0.4010339734121123\naccuracy(train_X, train_y) = 0.40472673559822747\naccuracy(train_X, train_y) = 0.41285081240768096\naccuracy(train_X, train_y) = 0.422821270310192\naccuracy(train_X, train_y) = 0.43057607090103395\naccuracy(train_X, train_y) = 0.43833087149187594\naccuracy(train_X, train_y) = 0.44645494830132937\naccuracy(train_X, train_y) = 0.4538404726735598\naccuracy(train_X, train_y) = 0.45901033973412114\naccuracy(train_X, train_y) = 0.4630723781388479\naccuracy(train_X, train_y) = 0.46971935007385524\naccuracy(train_X, train_y) = 0.474519940915805\naccuracy(train_X, train_y) = 0.47858197932053176\naccuracy(train_X, train_y) = 0.4815361890694239\naccuracy(train_X, train_y) = 0.4804283604135894\naccuracy(train_X, train_y) = 0.4848596750369276","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/#Metaheuristics.jl","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics is a is a Julia package implementing metaheuristic algorithms for global optiimization that do not require for the optimized function to be differentiable.","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/#Installation:-OptimizationMetaheuristics.jl","page":"Metaheuristics.jl","title":"Installation: OptimizationMetaheuristics.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"To use this package, install the OptimizationMetaheuristics package:","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"import Pkg; Pkg.add(\"OptimizationMetaheuristics\")","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/#Global-Optimizer","page":"Metaheuristics.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/metaheuristics/#Without-Constraint-Equations","page":"Metaheuristics.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"A Metaheuristics Single-Objective algorithm is called using one of the following:","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Evolutionary Centers Algorithm: ECA()\nDifferential Evolution: DE() with 5 different stratgies\nDE(strategy=:rand1) - default strategy\nDE(strategy=:rand2)\nDE(strategy=:best1)\nDE(strategy=:best2)\nDE(strategy=:randToBest1)\nParticle Swarm Optimization: PSO()\nArtificial Bee Colony: ABC()\nGravitational Search Algorithm: CGSA()\nSimulated Annealing: SA()\nWhale Optimization Algorithm: WOA()","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Metaheuristics also performs Multiobjective optimization but this is not yet supported by Optimization.","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Each optimizer sets default settings based on the optimization problem but specific parameters can be set as shown in the original Documentation ","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Additionally, Metaheuristics common settings which would be defined by Metaheuristics.Options can be simply passed as special keywoard arguments to solve without the need to use the Metaheuristics.Options struct.","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Lastly, information about the optimization problem such as the true optimum is set via Metaheuristics.Information and passed as part of the optimizer struct to solve e.g. solve(prob, ECA(information=Metaheuristics.Inoformation(f_optimum = 0.0)))","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The currently available algorithms and their parameters are listed here.","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/#Notes","page":"Metaheuristics.jl","title":"Notes","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The algorithms in Metaheuristics are performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/#Examples","page":"Metaheuristics.jl","title":"Examples","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"The Rosenbrock function can optimized using the Evolutionary Centers Algorithm ECA() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, ECA(), maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"Per default Metaheuristics ignores the initial values x0 set in the OptimizationProblem. In order to for Optimization to use x0 we have to set use_initial=true:","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, ECA(), use_initial=true, maxiters=100000, maxtime=1000.0)","category":"page"},{"location":"copies/Optimization/optimization_packages/metaheuristics/#With-Constraint-Equations","page":"Metaheuristics.jl","title":"With Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/metaheuristics/","page":"Metaheuristics.jl","title":"Metaheuristics.jl","text":"While Metaheuristics.jl supports such constraints, Optimization.jl currently does not relay these constraints.","category":"page"},{"location":"copies/DiffEqFlux/layers/HamiltonianNN/#Hamiltonian-Neural-Network","page":"Hamiltonian Neural Network Layer","title":"Hamiltonian Neural Network","text":"","category":"section"},{"location":"copies/DiffEqFlux/layers/HamiltonianNN/","page":"Hamiltonian Neural Network Layer","title":"Hamiltonian Neural Network Layer","text":"The following layer helps construct a neural network which allows learning dynamics and conservation laws by approximating the hamiltonian of a system.","category":"page"},{"location":"copies/DiffEqFlux/layers/HamiltonianNN/","page":"Hamiltonian Neural Network Layer","title":"Hamiltonian Neural Network Layer","text":"HamiltonianNN\nNeuralHamiltonianDE","category":"page"},{"location":"copies/DiffEqFlux/layers/HamiltonianNN/#DiffEqFlux.HamiltonianNN","page":"Hamiltonian Neural Network Layer","title":"DiffEqFlux.HamiltonianNN","text":"Constructs a Hamiltonian Neural Network [1]. This neural network is useful for learning symmetries and conservation laws by supervision on the gradients of the trajectories. It takes as input a concatenated vector of length 2n containing the position (of size n) and momentum (of size n) of the particles. It then returns the time derivatives for position and momentum.\n\nnote: Note\nThis doesn't solve the Hamiltonian Problem. Use NeuralHamiltonianDE for such applications.\n\nnote: Note\nThis layer currently doesn't support GPU. The support will be added in future with some AD fixes.\n\nTo obtain the gradients to train this network, ReverseDiff.gradient is supposed to be used. This prevents the usage of DiffEqFlux.sciml_train or Flux.train. Follow this tutorial to see how to define a training loop to circumvent this issue.\n\nHamiltonianNN(model; p = nothing)\nHamiltonianNN(model::FastChain; p = initial_params(model))\n\nArguments:\n\nmodel: A Chain or FastChain neural network that returns the Hamiltonian of the          system.\np: The initial parameters of the neural network.\n\nReferences:\n\n[1] Greydanus, Samuel, Misko Dzamba, and Jason Yosinski. \"Hamiltonian Neural Networks.\" Advances in Neural Information Processing Systems 32 (2019): 15379-15389.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/HamiltonianNN/#DiffEqFlux.NeuralHamiltonianDE","page":"Hamiltonian Neural Network Layer","title":"DiffEqFlux.NeuralHamiltonianDE","text":"Contructs a Neural Hamiltonian DE Layer for solving Hamiltonian Problems parameterized by a Neural Network HamiltonianNN.\n\nNeuralHamiltonianDE(model, tspan, args...; kwargs...)\n\nArguments:\n\nmodel: A Chain, FastChain or Hamiltonian Neural Network that predicts the          Hamiltonian of the system.\ntspan: The timespan to be solved on.\nkwargs: Additional arguments splatted to the ODE solver. See the           Common Solver Arguments           documentation for more details.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Enforcing-Physical-Constraints-via-Universal-Differential-Algebraic-Equations","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"As shown in the stiff ODE tutorial, differential-algebraic equations (DAEs) can be used to impose physical constraints. One way to define a DAE is through an ODE with a singular mass matrix. For example, if we make Mu' = f(u) where the last row of M is all zeros, then we have a constraint defined by the right hand side. Using NeuralODEMM, we can use this to define a neural ODE where the sum of all 3 terms must add to one. An example of this is as follows:","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"using DiffEqFlux, DifferentialEquations, Plots\n\nfunction f!(du, u, p, t)\n    y₁, y₂, y₃ = u\n    k₁, k₂, k₃ = p\n    du[1] = -k₁*y₁ + k₃*y₂*y₃\n    du[2] =  k₁*y₁ - k₃*y₂*y₃ - k₂*y₂^2\n    du[3] =  y₁ + y₂ + y₃ - 1\n    return nothing\nend\n\nu₀ = [1.0, 0, 0]\nM = [1. 0  0\n     0  1. 0\n     0  0  0]\n\ntspan = (0.0,1.0)\np = [0.04, 3e7, 1e4]\n\nstiff_func = ODEFunction(f!, mass_matrix = M)\nprob_stiff = ODEProblem(stiff_func, u₀, tspan, p)\nsol_stiff = solve(prob_stiff, Rodas5(), saveat = 0.1)\n\nnn_dudt2 = FastChain(FastDense(3, 64, tanh),\n                     FastDense(64, 2))\n\nmodel_stiff_ndae = NeuralODEMM(nn_dudt2, (u, p, t) -> [u[1] + u[2] + u[3] - 1],\n                               tspan, M, Rodas5(autodiff=false), saveat = 0.1)\nmodel_stiff_ndae(u₀)\n\nfunction predict_stiff_ndae(p)\n    return model_stiff_ndae(u₀, p)\nend\n\nfunction loss_stiff_ndae(p)\n    pred = predict_stiff_ndae(p)\n    loss = sum(abs2, Array(sol_stiff) .- pred)\n    return loss, pred\nend\n\ncallback = function (p, l, pred) #callback function to observe training\n  display(l)\n  return false\nend\n\nl1 = first(loss_stiff_ndae(model_stiff_ndae.p))\nresult_stiff = DiffEqFlux.sciml_train(loss_stiff_ndae, model_stiff_ndae.p,\n                                      BFGS(initial_stepnorm = 0.001),\n                                      cb = callback, maxiters = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Step-by-Step-Description","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Step-by-Step Description","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Load-Packages","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Load Packages","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"using DiffEqFlux, DifferentialEquations, Plots","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Differential-Equation","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Differential Equation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"First, we define our differential equations as a highly stiff problem which makes the fitting difficult.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"function f!(du, u, p, t)\n    y₁, y₂, y₃ = u\n    k₁, k₂, k₃ = p\n    du[1] = -k₁*y₁ + k₃*y₂*y₃\n    du[2] =  k₁*y₁ - k₃*y₂*y₃ - k₂*y₂^2\n    du[3] =  y₁ + y₂ + y₃ - 1\n    return nothing\nend","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Parameters","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Parameters","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"u₀ = [1.0, 0, 0]\n\nM = [1. 0  0\n     0  1. 0\n     0  0  0]\n\ntspan = (0.0,1.0)\n\np = [0.04, 3e7, 1e4]","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"u₀ = Initial Conditions\nM = Semi-explicit Mass Matrix (last row is the constraint equation and are therefore","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"all zeros)","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"tspan = Time span over which to evaluate\np = parameters k1, k2 and k3 of the differential equation above","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#ODE-Function,-Problem-and-Solution","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"ODE Function, Problem and Solution","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"We define and solve our ODE problem to generate the \"labeled\" data which will be used to train our Neural Network.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"stiff_func = ODEFunction(f!, mass_matrix = M)\nprob_stiff = ODEProblem(stiff_func, u₀, tspan, p)\nsol_stiff = solve(prob_stiff, Rodas5(), saveat = 0.1)","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Because this is a DAE we need to make sure to use a compatible solver. Rodas5 works well for this example.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Neural-Network-Layers","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Neural Network Layers","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Next, we create our layers using FastChain. We use this instead of Chain because it reduces the overhead making it faster for smaller NNs of <200 layers (similarly for FastDense). The input to our network will be the initial conditions fed in as u₀.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"nn_dudt2 = FastChain(FastDense(3, 64, tanh),\n                     FastDense(64, 2))\n\nmodel_stiff_ndae = NeuralODEMM(nn_dudt2, (u, p, t) -> [u[1] + u[2] + u[3] - 1],\n                               tspan, M, Rodas5(autodiff = false), saveat = 0.1)\nmodel_stiff_ndae(u₀)","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Because this is a stiff problem, we have manually imposed that sum constraint via (u,p,t) -> [u[1] + u[2] + u[3] - 1], making the fitting easier.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Prediction-Function","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Prediction Function","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"For simplicity, we define a wrapper function that only takes in the model's parameters to make predictions.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"function predict_stiff_ndae(p)\n    return model_stiff_ndae(u₀, p)\nend","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Train-Parameters","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Train Parameters","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Training our network requires a loss function, an optimizer and a callback function to display the progress.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Loss","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Loss","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"We first make our predictions based on the current parameters, then calculate the loss from these predictions. In this case, we use least squares as our loss.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"function loss_stiff_ndae(p)\n    pred = predict_stiff_ndae(p)\n    loss = sum(abs2, sol_stiff .- pred)\n    return loss, pred\nend\n\nl1 = first(loss_stiff_ndae(model_stiff_ndae.p))","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Notice that we are feeding the parameters of model_stiff_ndae to the loss_stiff_ndae function. model_stiff_node.p are the weights of our NN and is of size 386 (4 * 64 + 65 * 2) including the biases.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Optimizer","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Optimizer","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"The optimizer BFGS is directly passed in the training step (see below).","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Callback","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Callback","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"The callback function displays the loss during training.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"callback = function (p, l, pred) #callback function to observe training\n  display(l)\n  return false\nend","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Train","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Train","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"Finally, training with sciml_train by passing: loss function, model parameters, optimizer, callback and maximum iteration.","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","text":"result_stiff = DiffEqFlux.sciml_train(loss_stiff_ndae, model_stiff_ndae.p,\n                                      BFGS(initial_stepnorm = 0.001),\n                                      cb = callback, maxiters = 100)","category":"page"},{"location":"copies/DiffEqSensitivity/dae_fitting/physical_constraints/#Expected-Output","page":"Enforcing Physical Constraints via Universal Differential-Algebraic Equations","title":"Expected Output","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/NonlinearProblem/#Nonlinear-Problems","page":"Nonlinear Problems","title":"Nonlinear Problems","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/NonlinearProblem/","page":"Nonlinear Problems","title":"Nonlinear Problems","text":"NonlinearProblem","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/#Parallelized-Morris-and-Sobol-Sensitivity-Analysis-of-an-ODE","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"","category":"section"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"Let's run GSA on the Lotka-Volterra model to and study the sensitivity of the maximum of predator population and the average prey population.","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"using GlobalSensitivity, Statistics, OrdinaryDiffEq #load packages","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"First, let's define our model:","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"function f(du,u,p,t)\n  du[1] = p[1]*u[1] - p[2]*u[1]*u[2] #prey\n  du[2] = -p[3]*u[2] + p[4]*u[1]*u[2] #predator\nend\nu0 = [1.0;1.0]\ntspan = (0.0,10.0)\np = [1.5,1.0,3.0,1.0]\nprob = ODEProblem(f,u0,tspan,p)\nt = collect(range(0, stop=10, length=200))","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"Now, let's create a function that takes in a parameter set and calculates the maximum of the predator population and the average of the prey population for those parameter values. To do this, we will make use of the remake function, which creates a new ODEProblem, and use the p keyword argument to set the new parameters:","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"f1 = function (p)\n  prob1 = remake(prob;p=p)\n  sol = solve(prob1,Tsit5();saveat=t)\n  [mean(sol[1,:]), maximum(sol[2,:])]\nend","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"Now, let's perform a Morris global sensitivity analysis on this model. We specify that the parameter range is [1,5] for each of the parameters, and thus call:","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"m = gsa(f1,Morris(total_num_trajectory=1000,num_trajectory=150),[[1,5],[1,5],[1,5],[1,5]])","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"Let's get the means and variances from the MorrisResult struct.","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"m.means\n2×2 Array{Float64,2}:\n 0.474053  0.114922\n 1.38542   5.26094\n\nm.variances\n2×2 Array{Float64,2}:\n 0.208271    0.0317397\n 3.07475   118.103","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"Let's plot the result","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"scatter(m.means[1,:], m.variances[1,:],series_annotations=[:a,:b,:c,:d],color=:gray)\nscatter(m.means[2,:], m.variances[2,:],series_annotations=[:a,:b,:c,:d],color=:gray)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"For the Sobol method, we can similarly do:","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"m = gsa(f1,Sobol(),[[1,5],[1,5],[1,5],[1,5]],N=1000)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/#Direct-Use-of-Design-Matrices","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Direct Use of Design Matrices","text":"","category":"section"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"For the Sobol Method, we can have more control over the sampled points by generating design matrices. Doing it in this manner lets us directly specify a quasi-Monte Carlo sampling method for the parameter space. Here we use QuasiMonteCarlo.jl to generate the design matrices as follows:","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"using GlobalSensitivity, QuasiMonteCarlo, Plots\nN = 10000\nlb = [1.0, 1.0, 1.0, 1.0]\nub = [5.0, 5.0, 5.0, 5.0]\nsampler = SobolSample()\nA,B = QuasiMonteCarlo.generate_design_matrices(N,lb,ub,sampler)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"and now we tell it to calculate the Sobol indices on these designs for the function f1 we defined in the Lotka Volterra example:","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"sobol_result = gsa(f1,Sobol(),A,B)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"We plot the first order and total order Sobol Indices for the parameters (a and b).","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"\np1 = bar([\"a\",\"b\",\"c\",\"d\"],sobol_result.ST[1,:],title=\"Total Order Indices prey\",legend=false)\np2 = bar([\"a\",\"b\",\"c\",\"d\"],sobol_result.S1[1,:],title=\"First Order Indices prey\",legend=false)\np1_ = bar([\"a\",\"b\",\"c\",\"d\"],sobol_result.ST[2,:],title=\"Total Order Indices predator\",legend=false)\np2_ = bar([\"a\",\"b\",\"c\",\"d\"],sobol_result.S1[2,:],title=\"First Order Indices predator\",legend=false)\nplot(p1,p2,p1_,p2_)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"(Image: sobolbars)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/#Parallelizing-the-Global-Sensitivity-Analysis","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelizing the Global Sensitivity Analysis","text":"","category":"section"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"In all of the previous examples, f(p) was calculated serially. However, we can parallelize our computations by using the batch interface. In the batch interface, each column p[:,i] is a set of parameters, and we output a column for each set of parameters. Here we showcase using the Ensemble Interface to use EnsembleGPUArray to perform automatic multithreaded-parallelization of the ODE solves.","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"using GlobalSensitivity, QuasiMonteCarlo, OrdinaryDiffEq\n\nfunction f(du,u,p,t)\n  du[1] = p[1]*u[1] - p[2]*u[1]*u[2] #prey\n  du[2] = -p[3]*u[2] + p[4]*u[1]*u[2] #predator\nend\n\nu0 = [1.0;1.0]\ntspan = (0.0,10.0)\np = [1.5,1.0,3.0,1.0]\nprob = ODEProblem(f,u0,tspan,p)\nt = collect(range(0, stop=10, length=200))\n\nf1 = function (p)\n  prob_func(prob,i,repeat) = remake(prob;p=p[:,i])\n  ensemble_prob = EnsembleProblem(prob,prob_func=prob_func)\n  sol = solve(ensemble_prob,Tsit5(),EnsembleThreads();saveat=t,trajectories=size(p,2))\n  # Now sol[i] is the solution for the ith set of parameters\n  out = zeros(2,size(p,2))\n  for i in 1:size(p,2)\n    out[1,i] = mean(sol[i][1,:])\n    out[2,i] = maximum(sol[i][2,:])\n  end\n  out\nend","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"And now to do the parallelized calls we simply add the batch=true keyword argument:","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"sobol_result = gsa(f1,Sobol(),A,B,batch=true)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/parallelized_gsa/","page":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","title":"Parallelized Morris and Sobol Sensitivity Analysis of an ODE","text":"This user-side parallelism thus allows you to take control, and thus for example you can use DiffEqGPU.jl for automated GPU-parallelism of the ODE-based global sensitivity analysis!","category":"page"},{"location":"copies/Surrogates/gramacylee/#Gramacy-and-Lee-Function","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"","category":"section"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"Gramacy & Lee Function is a continues function. It is not convex. The function is defined on 1-dimensional space. It is an unimodal. The function can be defined on any input domain but it is usually evaluated on x in -05 25.","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"The Gramacy & Lee is as follows: f(x) = fracsin(10pi x)2x + (x-1)^4.","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"Let's import these two packages Surrogates and Plots:","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"Now, let's define our objective function:","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"function gramacylee(x)\n    term1 = sin(10*pi*x) / 2*x;\n    term2 = (x - 1)^4;\n    y = term1 + term2;\nend","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"Let's sample f in 25 points between -0.5 and 2.5 using the sample function. The sampling points are chosen using a Sobol Sample, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"n = 25\nlower_bound = -0.5\nupper_bound = 2.5\nx = sample(n, lower_bound, upper_bound, SobolSample())\ny = gramacylee.(x)\nxs = lower_bound:0.001:upper_bound\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound), ylims=(-5, 20), legend=:top)\nplot!(xs, gramacylee.(xs), label=\"True function\", legend=:top)","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"Now, let's fit Gramacy & Lee Function with different Surrogates:","category":"page"},{"location":"copies/Surrogates/gramacylee/","page":"Gramacy & Lee Function","title":"Gramacy & Lee Function","text":"my_pol = PolynomialChaosSurrogate(x, y, lower_bound, upper_bound)\nloba_1 = LobachevskySurrogate(x, y, lower_bound, upper_bound)\nkrig = Kriging(x, y, lower_bound, upper_bound)\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound), ylims=(-5, 20), legend=:top)\nplot!(xs, gramacylee.(xs), label=\"True function\", legend=:top)\nplot!(xs, my_pol.(xs), label=\"Polynomial expansion\", legend=:top)\nplot!(xs, loba_1.(xs), label=\"Lobachevsky\", legend=:top)\nplot!(xs, krig.(xs), label=\"Kriging\", legend=:top)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/#Exposing-More-Parallelism-By-Tearing-Algebraic-Equations-in-ODESystems","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"Sometimes it can be very non-trivial to parallelize a system. In this tutorial we will demonstrate how to make use of structural_simplify to expose more parallelism in the solution process and parallelize the resulting simulation.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/#The-Component-Library","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"The Component Library","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"The following tutorial will use the following set of components describing electrical circuits:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"using ModelingToolkit, OrdinaryDiffEq\n\n# Basic electric components\n@variables t\nconst D = Differential(t)\n@connector function Pin(;name)\n    @variables v(t)=1.0 i(t)=1.0 [connect = Flow]\n    ODESystem(Equation[], t, [v, i], [], name=name)\nend\n\nfunction Ground(;name)\n    @named g = Pin()\n    eqs = [g.v ~ 0]\n    compose(ODESystem(eqs, t, [], [], name=name), g)\nend\n\nfunction ConstantVoltage(;name, V = 1.0)\n    val = V\n    @named p = Pin()\n    @named n = Pin()\n    @parameters V=V\n    eqs = [\n           V ~ p.v - n.v\n           0 ~ p.i + n.i\n          ]\n    compose(ODESystem(eqs, t, [], [V], name=name), p, n)\nend\n\n@connector function HeatPort(;name)\n    @variables T(t)=293.15 Q_flow(t)=0.0 [connect = Flow]\n    ODESystem(Equation[], t, [T, Q_flow], [], name=name)\nend\n\nfunction HeatingResistor(;name, R=1.0, TAmbient=293.15, alpha=1.0)\n    @named p = Pin()\n    @named n = Pin()\n    @named h = HeatPort()\n    @variables v(t) RTherm(t)\n    @parameters R=R TAmbient=TAmbient alpha=alpha\n    eqs = [\n           RTherm ~ R*(1 + alpha*(h.T - TAmbient))\n           v ~ p.i * RTherm\n           h.Q_flow ~ -v * p.i # -LossPower\n           v ~ p.v - n.v\n           0 ~ p.i + n.i\n          ]\n    compose(ODESystem(\n        eqs, t, [v, RTherm], [R, TAmbient, alpha],\n        name=name,\n    ), p, n, h)\nend\n\nfunction HeatCapacitor(;name, rho=8050, V=1, cp=460, TAmbient=293.15)\n    @parameters rho=rho V=V cp=cp\n    C = rho*V*cp\n    @named h = HeatPort()\n    eqs = [\n           D(h.T) ~ h.Q_flow / C\n          ]\n    compose(ODESystem(\n        eqs, t, [], [rho, V, cp],\n        name=name,\n    ), h)\nend\n\nfunction Capacitor(;name, C = 1.0)\n    @named p = Pin()\n    @named n = Pin()\n    @variables v(t)=0.0\n    @parameters C=C\n    eqs = [\n           v ~ p.v - n.v\n           0 ~ p.i + n.i\n           D(v) ~ p.i / C\n          ]\n    compose(ODESystem(\n        eqs, t, [v], [C],\n        name=name\n    ), p, n)\nend\n\nfunction parallel_rc_model(i; name, source, ground, R, C)\n    resistor = HeatingResistor(name=Symbol(:resistor, i), R=R)\n    capacitor = Capacitor(name=Symbol(:capacitor, i), C=C)\n    heat_capacitor = HeatCapacitor(name=Symbol(:heat_capacitor, i))\n\n    rc_eqs = [\n              connect(source.p, resistor.p)\n              connect(resistor.n, capacitor.p)\n              connect(capacitor.n, source.n, ground.g)\n              connect(resistor.h, heat_capacitor.h)\n             ]\n\n    compose(ODESystem(rc_eqs, t, name=Symbol(name, i)),\n            [resistor, capacitor, source, ground, heat_capacitor])\nend","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/#The-Model","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"The Model","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"Assuming that the components are defined, our model is 50 resistors and capacitors connected in parallel. Thus following the acausal components tutorial, we can connect a bunch of RC components as follows:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"V = 2.0\n@named source = ConstantVoltage(V=V)\n@named ground = Ground()\nN = 50\nRs = 10 .^range(0, stop=-4, length=N)\nCs = 10 .^range(-3, stop=0, length=N)\nrc_systems = map(1:N) do i\n    parallel_rc_model(i; name=:rc, source=source, ground=ground, R=Rs[i], C=Cs[i])\nend;\n@variables E(t)=0.0\neqs = [\n       D(E) ~ sum(((i, sys),)->getproperty(sys, Symbol(:resistor, i)).h.Q_flow, enumerate(rc_systems))\n      ]\n@named _big_rc = ODESystem(eqs, t, [E], [])\n@named big_rc = compose(_big_rc, rc_systems)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"Now let's say we want to expose a bit more parallelism via running tearing. How do we do that?","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"sys = structural_simplify(big_rc)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"Done, that's it. There's no more to it.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/#What-Happened?","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"What Happened?","text":"","category":"section"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"Yes, that's a good question! Let's investigate a little bit more what had happened. If you look at the system we defined:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"length(equations(big_rc))","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"You see it started as a massive 1051 set of equations. However, after eliminating redundancies we arrive at 151 equations:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"equations(sys)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"That's not all though. In addition, the tearing process has turned the sets of nonlinear equations into separate blocks and constructed a DAG for the dependencies between the blocks. We can use the bipartite graph functionality to dig in and investigate what this means:","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"using ModelingToolkit.BipartiteGraphs\nts = TearingState(expand_connections(big_rc))\ninc_org = BipartiteGraphs.incidence_matrix(ts.structure.graph)\nblt_org = StructuralTransformations.sorted_incidence_matrix(ts, only_algeqs=true, only_algvars=true)\nblt_reduced = StructuralTransformations.sorted_incidence_matrix(ModelingToolkit.get_tearing_state(sys), only_algeqs=true, only_algvars=true)","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"(Image: )","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"The figure on the left is the original incidence matrix of the algebraic equations. Notice that the original formulation of the model has dependencies between different equations, and so the full set of equations must be solved together. That exposes no parallelism. However, the Block Lower Triangular (BLT) transformation exposes independent blocks. This is then further improved by the tearing process, which removes 90% of the equations and transforms the nonlinear equations into 50 independent blocks which can now all be solved in parallel. The conclusion is that, your attempts to parallelize are neigh: performing parallelism after structural simplification greatly improves the problem that can be parallelized, so this is better than trying to do it by hand.","category":"page"},{"location":"copies/ModelingToolkit/tutorials/tearing_parallelism/","page":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","title":"Exposing More Parallelism By Tearing Algebraic Equations in ODESystems","text":"After performing this, you can construct the ODEProblem/ODAEProblem and set parallel_form to use the exposed parallelism in multithreaded function constructions, but this showcases why structural_simplify is so important to that process.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#sensitivity_diffeq","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"DiffEqSensitivity.jl's high level interface allows for specifying a  sensitivity algorithm (sensealg) to control the method by which solve is differentiated in an automatic differentiation (AD) context by a compatible AD library. The underlying algorithms then  use the direct interface methods, like ODEForwardSensitivityProblem  and adjoint_sensitivities, to compute the derivatives without  requiring the user to do any of the setup.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Current AD libraries whose calls are captured by the sensitivity system are:","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Zygote.jl\nDiffractor.jl","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Using-and-Controlling-Sensitivity-Algorithms-within-AD","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Using and Controlling Sensitivity Algorithms within AD","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Take for example this simple differential equation solve on Lotka-Volterra:","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"using DiffEqSensitivity, OrdinaryDiffEq, Zygote\n\nfunction fiip(du,u,p,t)\n  du[1] = dx = p[1]*u[1] - p[2]*u[1]*u[2]\n  du[2] = dy = -p[3]*u[2] + p[4]*u[1]*u[2]\nend\np = [1.5,1.0,3.0,1.0]; u0 = [1.0;1.0]\nprob = ODEProblem(fiip,u0,(0.0,10.0),p)\nsol = solve(prob,Tsit5())\nloss(u0,p) = sum(solve(prob,Tsit5(),u0=u0,p=p,saveat=0.1))\ndu0,dp = Zygote.gradient(loss,u0,p)","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"This will compute the gradient of the loss function \"sum of the values of the solution to the ODE at timepoints dt=0.1\" using an adjoint method, where du0 is the derivative of the loss function with respect to the initial condition and dp is the derivative of the loss function with respect to the parameters.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Because the gradient is calculated by Zygote.gradient and Zygote.jl is one of the compatible AD libraries, this derivative calculation will be captured by the sensealg system, and one of DiffEqSensitivity.jl's adjoint overloads will be used to compute the derivative. By default, if the sensealg keyword argument is not defined, then a smart polyalgorithm is used to automatically determine the most appropriate method for a given equation.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Likewise, the sensealg argument can be given to directly control the method by which the derivative is computed. For example:","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"loss(u0,p) = sum(solve(prob,Tsit5(),u0=u0,p=p,saveat=0.1))\ndu0,dp = Zygote.gradient(loss,u0,p)","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Choosing-a-Sensitivity-Algorithm","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Choosing a Sensitivity Algorithm","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"There are two classes of algorithms: the continuous sensitivity analysis methods, and the discrete sensitivity analysis methods (direct automatic differentiation). Generally:","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Continuous sensitivity analysis are more efficient while the discrete  sensitivity analysis is more stable (full discussion is in the appendix of that paper)\nContinuous sensitivity analysis methods only support a subset of equations, which currently includes:\nODEProblem (with mass matrices for differential-algebraic equations (DAEs)\nSDEProblem\nSteadyStateProblem / NonlinearProblem\nDiscrete sensitivity analysis methods only support a subset of algorithms, namely, the pure Julia solvers which are written generically.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"For an analysis of which methods will be most efficient for computing the solution derivatives for a given problem, consult our analysis in this arxiv paper. A general rule of thumb is:","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ForwardDiffSensitivity is the fastest for differential equations with small numbers of parameters (<100) and can be used on any differential equation solver that is native Julia. If the chosen ODE solver is not compatible with direct automatic differentiation, ForwardSensitivty may be used instead.\nAdjoint senstivity analysis is the fastest when the number of parameters is sufficiently large. There are three configurations of note. Using QuadratureAdjoint is the fastest but uses the most memory, BacksolveAdjoint uses the least memory but on very stiff problems it may be unstable and require a lot of checkpoints, while InterpolatingAdjoint is in the middle, allowing checkpointing to control total memory use.\nThe methods which use direct automatic differentiation (ReverseDiffAdjoint, TrackerAdjoint, ForwardDiffSensitivity, and ZygoteAdjoint) support the full range of DifferentialEquations.jl features (SDEs, DDEs, events, etc.), but only work on native Julia solvers.\nFor non-ODEs with large numbers of parameters, TrackerAdjoint in out-of-place form may be the best performer on GPUs, and ReverseDiffAdjoint\nTrackerAdjoint is able to use a TrackedArray form with out-of-place functions du = f(u,p,t) but requires an Array{TrackedReal} form for f(du,u,p,t) mutating du. The latter has much more overhead, and should be avoided if possible. Thus if solving non-ODEs with lots of parameters, using TrackerAdjoint with an out-of-place definition may be the current best option.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"note: Note\nCompatibility with direct automatic differentiation algorithms (ForwardDiffSensitivity, ReverseDiffAdjoint, etc.) can be queried using the  SciMLBase.isautodifferentiable(::SciMLAlgorithm) trait function.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"If the chosen algorithm is a continuous sensitivity analysis algorithm, then an autojacvec argument can be given for choosing how the Jacobian-vector product (J*v) or vector-Jacobian product (J'*v) calculation is computed. For the forward sensitivity methods, autojacvec=true is the most efficient, though autojacvec=false is slightly less accurate but very close in efficiency. For adjoint methods it's more complicated and dependent on the way that the user's f function is implemented:","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"EnzymeVJP() is the most efficient if it's applicable on your equation.\nIf your function has no branching (no if statements) but uses mutation, ReverseDiffVJP(true) will be the most efficient after Enzyme. Otherwise ReverseDiffVJP(), but you may wish to proceed with eliminating mutation as without compilation enabled this can be slow.\nIf your on the CPU or GPU and your function is very vectorized and has no mutation, choose ZygoteVJP().\nElse fallback to TrackerVJP() if Zygote does not support the function.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Special-Notes-on-Non-ODE-Differential-Equation-Problems","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Special Notes on Non-ODE Differential Equation Problems","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"While all of the choices are compatible with ordinary differential equations, specific notices apply to other forms:","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Differential-Algebraic-Equations","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Differential-Algebraic Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"We note that while all 3 are compatible with index-1 DAEs via the derivation in the universal differential equations paper (note the reinitialization), we do not recommend BacksolveAdjoint one DAEs because the stiffness inherent in these problems tends to cause major difficulties with the accuracy of the backwards solution due to reinitialization of the algebraic variables.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Stochastic-Differential-Equations","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Stochastic Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"We note that all of the adjoints except QuadratureAdjoint are applicable to stochastic differential equations.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Delay-Differential-Equations","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Delay Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"We note that only the discretize-then-optimize methods are applicable to delay differential equations. Constant lag and variable lag delay differential equation parameters can be estimated, but the lag times themselves are unable to be estimated through these automatic differentiation techniques.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Hybrid-Equations-(Equations-with-events/callbacks)-and-Jump-Equations","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Hybrid Equations (Equations with events/callbacks) and Jump Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ForwardDiffSensitivity can differentiate code with callbacks when convert_tspan=true. ForwardSensitivity is not compatible with hybrid equations. The shadowing methods are  not compatible with callbacks. All methods based on discrete adjoint sensitivity analysis  via automatic differentiation, like ReverseDiffAdjoint, TrackerAdjoint, or  QuadratureAdjoint are fully compatible with events. This applies to ODEs, SDEs, DAEs,  and DDEs. The continuous adjoint sensitivities BacksolveAdjoint, InterpolatingAdjoint, and QuadratureAdjoint are compatible with events for ODEs. BacksolveAdjoint and InterpolatingAdjoint can also handle events for SDEs. Use BacksolveAdjoint if the event terminates the time evolution and several states are saved. Currently, the continuous adjoint sensitivities do not support multiple events per time point.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Manual-VJPs","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Manual VJPs","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Note that when defining your differential equation the vjp can be manually overwritten by providing the AbstractSciMLFunction definition with  a vjp(u,p,t) that returns a tuple f(u,p,t),v->J*v in the form of  ChainRules.jl. When this is done, the choice of ZygoteVJP will utilize your VJP function during the internal steps of the adjoint. This is useful for models where automatic differentiation may have trouble producing optimal code. This can be paired with  ModelingToolkit.jl for producing hyper-optimized, sparse, and parallel VJP functions utilizing the automated symbolic conversions.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Sensitivity-Algorithms","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"The following algorithm choices exist for sensealg. See the sensitivity mathematics page for more details on the definition of the methods.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ForwardSensitivity\nForwardDiffSensitivity\nBacksolveAdjoint\nInterpolatingAdjoint\nQuadratureAdjoint\nReverseDiffAdjoint\nTrackerAdjoint\nZygoteAdjoint\nForwardLSS\nAdjointLSS\nNILSS\nNILSAS","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.ForwardSensitivity","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.ForwardSensitivity","text":"ForwardSensitivity{CS,AD,FDT} <: AbstractForwardSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of continuous forward sensitivity analysis for propagating  derivatives by solving the extended ODE. When used within adjoint differentiation (i.e. via Zygote), this will cause forward differentiation of the solve call within the reverse-mode automatic differentiation environment.\n\nConstructor\n\nfunction ForwardSensitivity(;\n                            chunk_size=0,autodiff=true,\n                            diff_type=Val{:central},\n                            autojacvec=autodiff,\n                            autojacmat=false)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation in the internal sensitivity algorithm computations. Default is true.\nchunk_size: Chunk size for forward mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\nautojacvec: Calculate the Jacobian-vector product via automatic differentiation with special seeding.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\n\nFurther details:\n\nIf autodiff=true and autojacvec=true, then the one chunk J*v forward-mode directional derivative calculation trick is used to compute the product without constructing the Jacobian (via ForwardDiff.jl). \nIf autodiff=false and autojacvec=true, then the numerical direction derivative trick (f(x+epsilon*v)-f(x))/epsilon is used to compute J*v without constructing the Jacobian.\nIf autodiff=true and autojacvec=false, then the Jacobian is constructed via chunked forward-mode automatic differentiation (via ForwardDiff.jl).\nIf autodiff=false and autojacvec=false, then the Jacobian is constructed via finite differences via FiniteDiff.jl.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems without callbacks (events).\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.ForwardDiffSensitivity","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.ForwardDiffSensitivity","text":"ForwardDiffSensitivity{CS,CTS} <: AbstractForwardSensitivityAlgorithm{CS,Nothing,Nothing}\n\nAn implementation of discrete forward sensitivity analysis through ForwardDiff.jl. When used within adjoint differentiation (i.e. via Zygote), this will cause forward  differentiation of the solve call within the reverse-mode automatic differentiation  environment.\n\nConstructor\n\nForwardDiffSensitivity(;chunk_size=0,convert_tspan=nothing)\n\nKeyword Arguments\n\nchunk_size: the chunk size used by ForwardDiff for computing the Jacobian, i.e. the number of simultaneous columns computed.\nconvert_tspan: whether to convert time to also be Dual valued. By default this is nothing which will only convert if callbacks are found. Conversion is required in order to accurately differentiate callbacks (hybrid equations).\n\nSciMLProblem Support\n\nThis sensealg supports any SciMLProblems, provided that the solver algorithms is SciMLBase.isautodifferentiable. Note that ForwardDiffSensitivity can  accurately differentiate code with callbacks only when convert_tspan=true.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.BacksolveAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.BacksolveAdjoint","text":"BacksolveAdjoint{CS,AD,FDT,VJP,NOISE} <: AbstractAdjointSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of adjoint sensitivity analysis using a backwards solution of the ODE.  By default this algorithm will use the values from the forward pass to perturb the  backwards solution to the correct spot, allowing reduced memory (O(1) memory). Checkpointing stabilization is included for additional numerical stability over the naive implementation.\n\nConstructor\n\nBacksolveAdjoint(;chunk_size=0,autodiff=true,\n                  diff_type=Val{:central},\n                  autojacvec=autodiff,\n                  checkpointing=true, noise=true, noisemixing=false)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The default is true. The total set  of choices are:\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\ncheckpointing: whether checkpointing is enabled for the reverse pass. Defaults to true.\nnoise: Calculate the vector-Jacobian product (J'*v) of the diffusion term  of an SDE via automatic differentiation with special seeding. The default is true.  The total set of choices are:\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nDiffEqSensitivity.ZygoteNoise(): Uses Zygote.jl for the vjp.\nDiffEqSensitivity.ReverseDiffNoise(compile=false): Uses ReverseDiff.jl for  the vjp. compile is a boolean for whether to precompile the tape, which  should only be done if there are no branches (if or while statements) in  the f function.\nnoisemixing: Handle noise processes that are not of the form du[i] = f(u[i]).  For example, to compute the sensitivities of an SDE with diagonal diffusion\nfunction g_mixing!(du,u,p,t)\n  du[1] = p[3]*u[1] + p[4]*u[2]\n  du[2] = p[3]*u[1] + p[4]*u[2]\n  nothing\nend\ncorrectly, noisemixing=true must be enabled. The default is false.\n\nFor more details on the vjp choices, please consult the sensitivity algorithms documentation page or the docstrings of the vjp types.\n\nApplicability of Backsolve and Caution\n\nWhen BacksolveAdjoint is applicable, it is a fast method and requires the least memory. However, one must be cautious because not all ODEs are stable under backwards integration by the majority of ODE solvers. An example of such an equation is the Lorenz equation. Notice that if one solves the Lorenz equation forward and then in reverse with any adaptive time step and non-reversible integrator, then the backwards solution diverges from the forward solution. As a quick demonstration:\n\nusing Sundials\nfunction lorenz(du,u,p,t)\n du[1] = 10.0*(u[2]-u[1])\n du[2] = u[1]*(28.0-u[3]) - u[2]\n du[3] = u[1]*u[2] - (8/3)*u[3]\nend\nu0 = [1.0;0.0;0.0]\ntspan = (0.0,100.0)\nprob = ODEProblem(lorenz,u0,tspan)\nsol = solve(prob,Tsit5(),reltol=1e-12,abstol=1e-12)\nprob2 = ODEProblem(lorenz,sol[end],(100.0,0.0))\nsol = solve(prob,Tsit5(),reltol=1e-12,abstol=1e-12)\n@show sol[end]-u0 #[-3.22091, -1.49394, 21.3435]\n\nThus one should check the stability of the backsolve on their type of problem before enabling this method. Additionally, using checkpointing with backsolve can be a low memory way to stabilize it.\n\nFor more details on this topic, see  Stiff Neural Ordinary Differential Equations.\n\nCheckpointing\n\nTo improve the numerical stability of the reverse pass, BacksolveAdjoint includes a checkpointing feature. If sol.u is a time series, then whenever a time sol.t is hit while reversing, a callback will replace the reversing ODE portion with sol.u[i]. This nudges the solution back onto the appropriate trajectory and reduces the numerical caused by drift.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems, SDEProblems, and RODEProblems. This sensealg supports  callback functions (events).\n\nReferences\n\nODE:  Rackauckas, C. and Ma, Y. and Martensen, J. and Warner, C. and Zubov, K. and Supekar,  R. and Skinner, D. and Ramadhana, A. and Edelman, A., Universal Differential Equations  for Scientific Machine Learning,\tarXiv:2001.04385\n\nHindmarsh, A. C. and Brown, P. N. and Grant, K. E. and Lee, S. L. and Serban, R.  and Shumaker, D. E. and Woodward, C. S., SUNDIALS: Suite of nonlinear and  differential/algebraic equation solvers, ACM Transactions on Mathematical  Software (TOMS), 31, pp:363–396 (2005)\n\nChen, R.T.Q. and Rubanova, Y. and Bettencourt, J. and Duvenaud, D. K.,  Neural ordinary differential equations. In Advances in neural information processing  systems, pp. 6571–6583 (2018)\n\nPontryagin, L. S. and Mishchenko, E.F. and Boltyanskii, V.G. and Gamkrelidze, R.V.  The mathematical theory of optimal processes. Routledge, (1962)\n\nRackauckas, C. and Ma, Y. and Dixit, V. and Guo, X. and Innes, M. and Revels, J.  and Nyberg, J. and Ivaturi, V., A comparison of automatic differentiation and  continuous sensitivity analysis for derivatives of differential equation solutions,  arXiv:1812.01892\n\nDAE:  Cao, Y. and Li, S. and Petzold, L. and Serban, R., Adjoint sensitivity analysis  for differential-algebraic equations: The adjoint DAE system and its numerical  solution, SIAM journal on scientific computing 24 pp: 1076-1089 (2003)\n\nSDE:  Gobet, E. and Munos, R., Sensitivity Analysis Using Ito-Malliavin Calculus and  Martingales, and Application to Stochastic Optimal Control,  SIAM Journal on control and optimization, 43, pp. 1676-1713 (2005)\n\nLi, X. and Wong, T.-K. L.and Chen, R. T. Q. and Duvenaud, D.,  Scalable Gradients for Stochastic Differential Equations,  PMLR 108, pp. 3870-3882 (2020), http://proceedings.mlr.press/v108/li20i.html\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.InterpolatingAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.InterpolatingAdjoint","text":"InterpolatingAdjoint{CS,AD,FDT,VJP,NOISE} <: AbstractAdjointSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of adjoint sensitivity analysis which uses the interpolation of the forward solution for the reverse solve vector-Jacobian products. By default it requires a dense solution of the forward pass and will internally ignore saving arguments during the gradient calculation. When checkpointing is enabled it will only require the memory to interpolate between checkpoints.\n\nConstructor\n\nfunction InterpolatingAdjoint(;chunk_size=0,autodiff=true,\n                               diff_type=Val{:central},\n                               autojacvec=autodiff,\n                               checkpointing=false, noise=true, noisemixing=false)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The default is true. The total set  of choices are:\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\ncheckpointing: whether checkpointing is enabled for the reverse pass. Defaults to true.\nnoise: Calculate the vector-Jacobian product (J'*v) of the diffusion term  of an SDE via automatic differentiation with special seeding. The default is true.  The total set of choices are:\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nDiffEqSensitivity.ZygoteNoise(): Uses Zygote.jl for the vjp.\nDiffEqSensitivity.ReverseDiffNoise(compile=false): Uses ReverseDiff.jl for  the vjp. compile is a boolean for whether to precompile the tape, which  should only be done if there are no branches (if or while statements) in  the f function.\nnoisemixing: Handle noise processes that are not of the form du[i] = f(u[i]).  For example, to compute the sensitivities of an SDE with diagonal diffusion\nfunction g_mixing!(du,u,p,t)\n  du[1] = p[3]*u[1] + p[4]*u[2]\n  du[2] = p[3]*u[1] + p[4]*u[2]\n  nothing\nend\ncorrectly, noisemixing=true must be enabled. The default is false.\n\nFor more details on the vjp choices, please consult the sensitivity algorithms documentation page or the docstrings of the vjp types.\n\nCheckpointing\n\nTo reduce the memory usage of the reverse pass, InterpolatingAdjoint includes a checkpointing feature. If sol is dense, checkpointing is ignored and the continuous solution is used for calculating u(t) at arbitrary time points. If checkpointing=true and sol is not dense, then dense intervals between sol.t[i] and sol.t[i+1] are reconstructed on-demand for calculating u(t) at arbitrary time points. This reduces the total memory requirement to only the cost of holding the dense solution over the largest time interval (in terms of number of required steps). The total compute cost is no more than double the original forward compute cost.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems, SDEProblems, and RODEProblems. This sensealg  supports callbacks (events).\n\nReferences\n\nRackauckas, C. and Ma, Y. and Martensen, J. and Warner, C. and Zubov, K. and Supekar,  R. and Skinner, D. and Ramadhana, A. and Edelman, A., Universal Differential Equations  for Scientific Machine Learning,\tarXiv:2001.04385\n\nHindmarsh, A. C. and Brown, P. N. and Grant, K. E. and Lee, S. L. and Serban, R.  and Shumaker, D. E. and Woodward, C. S., SUNDIALS: Suite of nonlinear and  differential/algebraic equation solvers, ACM Transactions on Mathematical  Software (TOMS), 31, pp:363–396 (2005)\n\nRackauckas, C. and Ma, Y. and Dixit, V. and Guo, X. and Innes, M. and Revels, J.  and Nyberg, J. and Ivaturi, V., A comparison of automatic differentiation and  continuous sensitivity analysis for derivatives of differential equation solutions,  arXiv:1812.01892\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.QuadratureAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.QuadratureAdjoint","text":"QuadratureAdjoint{CS,AD,FDT,VJP} <: AbstractAdjointSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of adjoint sensitivity analysis which develops a full continuous solution of the reverse solve in order to perform a post-ODE quadrature. This method requires the the dense solution and will ignore saving arguments during the gradient calculation. The tolerances in the constructor control the inner quadrature. The inner quadrature uses a ReverseDiff vjp if autojacvec, and compile=false by default but can compile the tape under the same circumstances as ReverseDiffVJP.\n\nThis method is O(n^3 + p) for stiff / implicit equations (as opposed to the O((n+p)^3) scaling of BacksolveAdjoint and InterpolatingAdjoint), and thus is much more compute efficient. However, it requires holding a dense reverse pass and is thus memory intensive.\n\nConstructor\n\nfunction QuadratureAdjoint(;chunk_size=0,autodiff=true,\n                            diff_type=Val{:central},\n                            autojacvec=autodiff,abstol=1e-6,\n                            reltol=1e-3,compile=false)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The default is true. The total set  of choices are:\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\nabstol: absolute tolerance for the quadrature calculation\nreltol: relative tolerance for the quadrature calculation\ncompile: whether to compile the vjp calculation for the integrand calculation. See ReverseDiffVJP for more details.\n\nFor more details on the vjp choices, please consult the sensitivity algorithms documentation page or the docstrings of the vjp types.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg supports events (callbacks).\n\nReferences\n\nRackauckas, C. and Ma, Y. and Martensen, J. and Warner, C. and Zubov, K. and Supekar,  R. and Skinner, D. and Ramadhana, A. and Edelman, A., Universal Differential Equations  for Scientific Machine Learning,\tarXiv:2001.04385\n\nHindmarsh, A. C. and Brown, P. N. and Grant, K. E. and Lee, S. L. and Serban, R.  and Shumaker, D. E. and Woodward, C. S., SUNDIALS: Suite of nonlinear and  differential/algebraic equation solvers, ACM Transactions on Mathematical  Software (TOMS), 31, pp:363–396 (2005)\n\nRackauckas, C. and Ma, Y. and Dixit, V. and Guo, X. and Innes, M. and Revels, J.  and Nyberg, J. and Ivaturi, V., A comparison of automatic differentiation and  continuous sensitivity analysis for derivatives of differential equation solutions,  arXiv:1812.01892\n\nKim, S., Ji, W., Deng, S., Ma, Y., & Rackauckas, C. (2021). Stiff neural ordinary   differential equations. Chaos: An Interdisciplinary Journal of Nonlinear Science, 31(9), 093122.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.ReverseDiffAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.ReverseDiffAdjoint","text":"ReverseDiffAdjoint <: AbstractAdjointSensitivityAlgorithm{nothing,true,nothing}\n\nAn implementation of discrete adjoint sensitivity analysis using the ReverseDiff.jl  tracing-based AD. Supports in-place functions through an Array of Structs formulation,  and supports out of place through struct of arrays.\n\nConstructor\n\nReverseDiffAdjoint()\n\nSciMLProblem Support\n\nThis sensealg supports any DEProblem if the algorithm is SciMLBase.isautodifferentiable. Requires that the state variables are CPU-based Array types.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.TrackerAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.TrackerAdjoint","text":"TrackerAdjoint <: AbstractAdjointSensitivityAlgorithm{nothing,true,nothing}\n\nAn implementation of discrete adjoint sensitivity analysis using the Tracker.jl tracing-based AD. Supports in-place functions through an Array of Structs formulation, and supports out of place through struct of arrays.\n\nConstructor\n\nTrackerAdjoint()\n\nSciMLProblem Support\n\nThis sensealg supports any DEProblem if the algorithm is SciMLBase.isautodifferentiable Compatible with a limited subset of AbstractArray types for u0, including CuArrays.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.ZygoteAdjoint","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.ZygoteAdjoint","text":"ZygoteAdjoint <: AbstractAdjointSensitivityAlgorithm{nothing,true,nothing}\n\nAn implementation of discrete adjoint sensitivity analysis using the Zygote.jl source-to-source AD directly on the differential equation solver. \n\nConstructor\n\nZygoteAdjoint()\n\nSciMLProblem Support\n\nCurrently fails on almost every solver.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.ForwardLSS","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.ForwardLSS","text":"ForwardLSS{CS,AD,FDT,RType,gType} <: AbstractShadowingSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of the discrete, forward-mode least squares shadowing (LSS) method. LSS replaces the ill-conditioned initial value probem (ODEProblem) for chaotic systems by a  well-conditioned least-squares problem. This allows for computing sensitivities of  long-time averaged quantities with respect to the parameters of the ODEProblem. The  computational cost of LSS scales as (number of states x number of time steps). Converges to the correct sensitivity at a rate of T^(-1/2), where T is the time of the trajectory. See NILSS() and NILSAS() for a more efficient non-intrusive formulation. \n\nConstructor\n\nForwardLSS(;\n          chunk_size=0,autodiff=true,\n          diff_type=Val{:central},\n          LSSregularizer=TimeDilation(10.0,0.0,0.0),\n          g=nothing)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nLSSregularizer: Using LSSregularizer, one can choose between three different regularization routines. The default choice is TimeDilation(10.0,0.0,0.0).\nCosWindowing(): cos windowing of the time grid, i.e. the time grid (saved time steps) is transformed using a cosine. \nCos2Windowing(): cos^2 windowing of the time grid.\nTimeDilation(alpha::Number,t0skip::Number,t1skip::Number): Corresponds to  a time dilation. alpha controls the weight. t0skip and t1skip indicate  the times truncated at the beginnning and end of the trajectory, respectively. \ng: instantaneous objective function of the long-time averaged objective.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg does not support  events (callbacks). This sensealg assumes that the objective is a long-time averaged quantity and ergodic, i.e. the time evolution of the system behaves qualitatively the  same over infinite time independent of the specified initial conditions, such that only the sensitivity with respect to the parameters is of interest.\n\nReferences\n\nWang, Q., Hu, R., and Blonigan, P. Least squares shadowing sensitivity analysis of chaotic limit cycle oscillations. Journal of Computational Physics, 267, 210-224 (2014).\n\nWang, Q., Convergence of the Least Squares Shadowing Method for Computing Derivative of Ergodic Averages, SIAM Journal on Numerical Analysis, 52, 156–170 (2014).\n\nBlonigan, P., Gomez, S., Wang, Q., Least Squares Shadowing for sensitivity analysis of turbulent  fluid flows, in: 52nd Aerospace Sciences Meeting, 1–24 (2014).\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.AdjointLSS","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.AdjointLSS","text":"AdjointLSS{CS,AD,FDT,RType,gType} <: AbstractShadowingSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of the discrete, adjoint-mode least square shadowing method. LSS replaces the ill-conditioned initial value probem (ODEProblem) for chaotic systems by a  well-conditioned least-squares problem. This allows for computing sensitivities of  long-time averaged quantities with respect to the parameters of the ODEProblem. The  computational cost of LSS scales as (number of states x number of time steps). Converges to the correct sensitivity at a rate of T^(-1/2), where T is the time of the trajectory. See NILSS() and NILSAS() for a more efficient non-intrusive formulation. \n\nConstructor\n\nAdjointLSS(;\n          chunk_size=0,autodiff=true,\n          diff_type=Val{:central},\n          LSSRegularizer=CosWindowing(),\n          g=nothing)\n\nKeyword Arguments\n\nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nLSSregularizer: Using LSSregularizer, one can choose between different regularization routines. The default choice is TimeDilation(10.0,0.0,0.0).\nTimeDilation(alpha::Number,t0skip::Number,t1skip::Number): Corresponds to  a time dilation. alpha controls the weight. t0skip and t1skip indicate  the times truncated at the beginnning and end of the trajectory, respectively. The default value for t0skip and t1skip is zero(alpha). \ng: instantaneous objective function of the long-time averaged objective.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg does not support  events (callbacks). This sensealg assumes that the objective is a long-time averaged quantity and ergodic, i.e. the time evolution of the system behaves qualitatively the  same over infinite time independent of the specified initial conditions, such that only the sensitivity with respect to the parameters is of interest.\n\nReferences\n\nWang, Q., Hu, R., and Blonigan, P. Least squares shadowing sensitivity analysis of chaotic limit cycle oscillations. Journal of Computational Physics, 267, 210-224 (2014).\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.NILSS","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.NILSS","text":"struct NILSS{CS,AD,FDT,RNG,nType,gType} <: AbstractShadowingSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of the forward-mode, continuous non-intrusive least squares shadowing method. NILSS  allows for computing sensitivities of long-time averaged quantities with respect to the  parameters of an ODEProblem by constraining the computation to the unstable subspace. NILSS employs the continuous-time ForwardSensitivity method as tangent solver. To avoid an exponential blow-up of the (homogenous and inhomogenous) tangent solutions,  the trajectory should be divided into sufficiently small segments, where the tangent solutions  are rescaled on the interfaces. The computational and memory cost of NILSS scale with  the number of unstable (positive) Lyapunov exponents (instead of the number of states as  in the LSS method). NILSS avoids the explicit construction of the Jacobian at each time  step and thus should generally be preferred (for large system sizes) over ForwardLSS. \n\nConstructor\n\nNILSS(nseg, nstep; nus = nothing, \n                   rng = Xorshifts.Xoroshiro128Plus(rand(UInt64)),\n                   chunk_size=0,autodiff=true,\n                   diff_type=Val{:central},\n                   autojacvec=autodiff,\n                   g=nothing)\n\nArguments\n\nnseg: Number of segments on full time interval on the attractor.\nnstep: number of steps on each segment.\n\nKeyword Arguments\n\nnus: Dimension of the unstable subspace. Default is nothing. nus must be smaller or equal to the state dimension (length(u0)). With the default choice,  nus = length(u0) - 1 will be set at compile time. \nrng: (Pseudo) random number generator. Used for initializing the homogenous  tangent states (w). Default is Xorshifts.Xoroshiro128Plus(rand(UInt64)).\nautodiff: Use automatic differentiation in the internal sensitivity algorithm computations. Default is true.\nchunk_size: Chunk size for forward mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\nautojacvec: Calculate the Jacobian-vector product via automatic differentiation with special seeding.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\ng: instantaneous objective function of the long-time averaged objective.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg does not support  events (callbacks). This sensealg assumes that the objective is a long-time averaged quantity and ergodic, i.e. the time evolution of the system behaves qualitatively the  same over infinite time independent of the specified initial conditions, such that only the sensitivity with respect to the parameters is of interest.\n\nReferences\n\nNi, A., Blonigan, P. J., Chater, M., Wang, Q., Zhang, Z., Sensitivity analy- sis on chaotic dynamical system by Non-Intrusive Least Square Shadowing (NI-LSS), in: 46th AIAA Fluid Dynamics Conference, AIAA AVIATION Forum (AIAA 2016-4399),  American Institute of Aeronautics and Astronautics, 1–16 (2016).\n\nNi, A., and Wang, Q. Sensitivity analysis on chaotic dynamical systems by Non-Intrusive Least Squares Shadowing (NILSS). Journal of Computational Physics 347, 56-77 (2017).\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.NILSAS","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.NILSAS","text":"NILSAS{CS,AD,FDT,RNG,SENSE,gType} <: AbstractShadowingSensitivityAlgorithm{CS,AD,FDT}\n\nAn implementation of the adjoint-mode, continuous non-intrusive adjoint least squares shadowing method.  NILSAS allows for computing sensitivities of long-time averaged quantities with respect  to the parameters of an ODEProblem by constraining the computation to the unstable subspace. NILSAS employs SciMLSensitivity.jl's continuous adjoint sensitivity methods on each segment  to compute (homogenous and inhomogenous) adjoint solutions. To avoid an exponential blow-up  of the adjoint solutions, the trajectory should be divided into sufficiently small segments,  where the adjoint solutions are rescaled on the interfaces. The computational and memory cost  of NILSAS scale with the number of unstable, adjoint Lyapunov exponents (instead of the number  of states as in the LSS method). NILSAS avoids the explicit construction of the Jacobian at  each time step and thus should generally be preferred (for large system sizes) over AdjointLSS.  NILSAS is favourable over NILSS for many parameters because NILSAS computes the gradient  with respect to multiple parameters with negligible additional cost. \n\nConstructor\n\nNILSAS(nseg, nstep, M=nothing; rng = Xorshifts.Xoroshiro128Plus(rand(UInt64)),\n                                adjoint_sensealg = BacksolveAdjoint(),\n                                chunk_size=0,autodiff=true,\n                                diff_type=Val{:central},\n                                autojacvec=autodiff,\n                                g=nothing\n                                )\n\nArguments\n\nnseg: Number of segments on full time interval on the attractor.\nnstep: number of steps on each segment.\nM: number of homogenous adjoint solutions. This number must be bigger or equal  than the number of (positive, adjoint) Lyapunov exponents. Default is nothing. \n\nKeyword Arguments\n\nrng: (Pseudo) random number generator. Used for initializing the terminate  conditions of the homogenous adjoint states (w). Default is Xorshifts.Xoroshiro128Plus(rand(UInt64)).\nadjoint_sensealg: Continuous adjoint sensitivity method to compute homogenous and inhomogenous adjoint solutions on each segment. Default is BacksolveAdjoint().  \nautodiff: Use automatic differentiation for constructing the Jacobian if the Jacobian needs to be constructed.  Defaults to true.\nchunk_size: Chunk size for forward-mode differentiation if full Jacobians are built (autojacvec=false and autodiff=true). Default is 0 for automatic choice of chunk size.\ndiff_type: The method used by FiniteDiff.jl for constructing the Jacobian if the full Jacobian is required with autodiff=false.\nautojacvec: Calculate the vector-Jacobian product (J'*v) via automatic differentiation with special seeding. The default is true. The total set  of choices are:\nfalse: the Jacobian is constructed via FiniteDiff.jl\ntrue: the Jacobian is constructed via ForwardDiff.jl\nTrackerVJP: Uses Tracker.jl for the vjp.\nZygoteVJP: Uses Zygote.jl for the vjp.\nEnzymeVJP: Uses Enzyme.jl for the vjp.\nReverseDiffVJP(compile=false): Uses ReverseDiff.jl for the vjp. compile is a boolean for whether to precompile the tape, which should only be done if there are no branches (if or while statements) in the f function.\ng: instantaneous objective function of the long-time averaged objective.\n\nSciMLProblem Support\n\nThis sensealg only supports ODEProblems. This sensealg does not support  events (callbacks). This sensealg assumes that the objective is a long-time averaged quantity and ergodic, i.e. the time evolution of the system behaves qualitatively the  same over infinite time independent of the specified initial conditions, such that only the sensitivity with respect to the parameters is of interest.\n\nReferences\n\nNi, A., and Talnikar, C., Adjoint sensitivity analysis on chaotic dynamical systems  by Non-Intrusive Least Squares Adjoint Shadowing (NILSAS). Journal of Computational  Physics 395, 690-709 (2019).\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Vector-Jacobian-Product-(VJP)-Choices","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Vector-Jacobian Product (VJP) Choices","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ZygoteVJP\nEnzymeVJP\nTrackerVJP\nReverseDiffVJP","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.ZygoteVJP","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.ZygoteVJP","text":"ZygoteVJP <: VJPChoice\n\nUses Zygote.jl to compute vector-Jacobian products. Tends to be the fastest VJP method if the  ODE/DAE/SDE/DDE is written with mostly vectorized  functions (like neural networks and other  layers from Flux.jl) and the f functions is given out-of-place. If the f function is  in-place, then Zygote.Buffer arrays are used internally which can greatly reduce the  performance of the VJP method. \n\nConstructor\n\nZygoteVJP(compile=false)\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.EnzymeVJP","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.EnzymeVJP","text":"EnzymeVJP <: VJPChoice\n\nUses Enzyme.jl to compute vector-Jacobian products. Is the fastest VJP whenever applicable, though Enzyme.jl currently has low coverage over the Julia programming language, for example restricting the user's defined f function to not do things like require garbage collection or calls to BLAS/LAPACK. However, mutation is supported, meaning that in-place f with  fully mutating non-allocating code will work with Enzyme (provided no high level calls to C like BLAS/LAPACK are used) and this will be the most efficient adjoint implementation.\n\nConstructor\n\nEnzymeVJP(compile=false)\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.TrackerVJP","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.TrackerVJP","text":"TrackerVJP <: VJPChoice\n\nUses Tracker.jl to compute the vector-Jacobian products. If f is in-place, then it uses a array of structs formulation to do scalarized reverse mode,  while if f is out-of-place then it uses an array-based reverse mode.\n\nNot as efficient as ReverseDiffVJP, but supports GPUs when doing array-based reverse mode.\n\nConstructor\n\nTrackerVJP(compile=false)\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#DiffEqSensitivity.ReverseDiffVJP","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"DiffEqSensitivity.ReverseDiffVJP","text":"ReverseDiffVJP{compile} <: VJPChoice\n\nUses ReverseDiff.jl to compute the vector-Jacobian products. If f is in-place, then it uses a array of structs formulation to do scalarized reverse mode,  while if f is out-of-place then it uses an array-based reverse mode.\n\nUsually the fastest when scalarized operations exist in the f function  (like in scientific machine learning applications like Universal Differential Equations)  and the boolean compilation is enabled (i.e. ReverseDiffVJP(true)), if EnzymeVJP fails on a given choice of f.\n\nDoes not support GPUs (CuArrays).\n\nConstructor\n\nReverseDiffVJP(compile=false)\n\nKeyword Arguments\n\ncompile: Whether to cache the compilation of the reverse tape. This heavily increases the performance of the method but requires that the f function of the ODE/DAE/SDE/DDE  has no branching. \n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Noise-VJP-Choices","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Noise VJP Choices","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"ZygoteNoise\nReverseDiffNoise","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#More-Details-on-Sensitivity-Algorithm-Choices","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"More Details on Sensitivity Algorithm Choices","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"The following section describes a bit more details to consider when choosing a sensitivity algorithm.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Optimize-then-Discretize","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Optimize-then-Discretize","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"The original neural ODE paper popularized optimize-then-discretize with O(1) adjoints via backsolve. This is the methodology BacksolveAdjoint When training non-stiff neural ODEs, BacksolveAdjoint with ZygoteVJP is generally the fastest method. Additionally, this method does not require storing the values of any intermediate points and is thus the most memory efficient. However, BacksolveAdjoint is prone to instabilities whenever the Lipschitz constant is sufficiently large, like in stiff equations, PDE discretizations, and many other contexts, so it is not used by default. When training a neural ODE for machine learning applications, the user should try BacksolveAdjoint and see if it is sufficiently accurate on their problem. More details on this topic can be found in  Stiff Neural Ordinary Differential Equations","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"Note that DiffEqFlux's implementation of BacksolveAdjoint includes an extra feature BacksolveAdjoint(checkpointing=true) which mixes checkpointing with BacksolveAdjoint. What this method does is that, at saveat points, values from the forward pass are saved. Since the reverse solve should numerically be the same as the forward pass, issues with divergence of the reverse pass are mitigated by restarting the reverse pass at the saveat value from the forward pass. This reduces the divergence and can lead to better gradients at the cost of higher memory usage due to having to save some values of the forward pass. This can stabilize the adjoint in some applications, but for highly stiff applications the divergence can be too fast for this to work in practice.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"To avoid the issues of backwards solving the ODE, InterpolatingAdjoint and QuadratureAdjoint utilize information from the forward pass. By default these methods utilize the continuous solution provided by DifferentialEquations.jl in the calculations of the adjoint pass. QuadratureAdjoint uses this to build a continuous function for the solution of adjoint equation and then performs an adaptive quadrature via Quadrature.jl, while InterpolatingAdjoint appends the integrand to the ODE so it's computed simultaneously to the Lagrange multiplier. When memory is not an issue, we find that the QuadratureAdjoint approach tends to be the most efficient as it has a significantly smaller adjoint differential equation and the quadrature converges very fast, but this form requires holding the full continuous solution of the adjoint which can be a significant burden for large parameter problems. The InterpolatingAdjoint is thus a compromise between memory efficiency and compute efficiency, and is in the same spirit as CVODES.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"However, if the memory cost of the InterpolatingAdjoint is too high, checkpointing can be used via InterpolatingAdjoint(checkpointing=true). When this is used, the checkpoints default to sol.t of the forward pass (i.e. the saved timepoints usually set by saveat). Then in the adjoint, intervals of sol.t[i-1] to sol.t[i] are re-solved in order to obtain a short interpolation which can be utilized in the adjoints. This at most results in two full solves of the forward pass, but dramatically reduces the computational cost while being a low-memory format. This is the preferred method for highly stiff equations when memory is an issue, i.e. stiff PDEs or large neural DAEs.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"For forward-mode, the ForwardSensitivty is the version that performs the optimize-then-discretize approach. In this case, autojacvec corresponds to the method for computing J*v within the forward sensitivity equations, which is either true or false for whether to use Jacobian-free forward-mode AD (via ForwardDiff.jl) or Jacobian-free numerical differentiation.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/#Discretize-then-Optimize","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Discretize-then-Optimize","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"In this approach the discretization is done first and then optimization is done on the discretized system. While traditionally this can be done discrete sensitivity analysis, this is can be equivalently done by automatic differentiation on the solver itself. ReverseDiffAdjoint performs reverse-mode automatic differentiation on the solver via ReverseDiff.jl, ZygoteAdjoint performs reverse-mode automatic differentiation on the solver via Zygote.jl, and TrackerAdjoint performs reverse-mode automatic differentiation on the solver via Tracker.jl. In addition, ForwardDiffSensitivty performs forward-mode automatic differentiation on the solver via ForwardDiff.jl.","category":"page"},{"location":"copies/DiffEqSensitivity/manual/differential_equation_sensitivities/","page":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","title":"Sensitivity Algorithms for Differential Equations with Automatic Differentiation (AD)","text":"We note that many studies have suggested that this approach produces more accurate gradients than the optimize-than-discretize approach","category":"page"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#OptimizationSystem","page":"OptimizationSystem","title":"OptimizationSystem","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#System-Constructors","page":"OptimizationSystem","title":"System Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/","page":"OptimizationSystem","title":"OptimizationSystem","text":"OptimizationSystem","category":"page"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#ModelingToolkit.OptimizationSystem","page":"OptimizationSystem","title":"ModelingToolkit.OptimizationSystem","text":"struct OptimizationSystem <: AbstractTimeIndependentSystem\n\nA scalar equation for optimization.\n\nFields\n\nop\nVector of equations defining the system.\nstates\nUnknown variables.\nps\nParameters.\nvar_to_name\nArray variables.\nobserved\nequality_constraints\ninequality_constraints\nname\nName: the name of the system.  These are required to have unique names.\n\nsystems\nsystems: The internal systems\n\ndefaults\ndefaults: The default values to use when initial conditions and/or parameters are not supplied in ODEProblem.\n\nExamples\n\n@variables x y z\n@parameters σ ρ β\n\nop = σ*(y-x) + x*(ρ-z)-y + x*y - β*z\n@named os = OptimizationSystem(op, [x,y,z],[σ,ρ,β])\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#Composition-and-Accessor-Functions","page":"OptimizationSystem","title":"Composition and Accessor Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/","page":"OptimizationSystem","title":"OptimizationSystem","text":"get_eqs(sys) or equations(sys): The equation to be minimized.\nget_states(sys) or states(sys): The set of states for the optimization.\nget_ps(sys) or parameters(sys): The parameters for the optimization.","category":"page"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#Transformations","page":"OptimizationSystem","title":"Transformations","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#Analyses","page":"OptimizationSystem","title":"Analyses","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#Applicable-Calculation-and-Generation-Functions","page":"OptimizationSystem","title":"Applicable Calculation and Generation Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/","page":"OptimizationSystem","title":"OptimizationSystem","text":"calculate_gradient\r\ncalculate_hessian\r\ngenerate_gradient\r\ngenerate_hessian\r\nhessian_sparsity","category":"page"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#Problem-Constructors","page":"OptimizationSystem","title":"Problem Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/","page":"OptimizationSystem","title":"OptimizationSystem","text":"OptimizationProblem","category":"page"},{"location":"copies/ModelingToolkit/systems/OptimizationSystem/#SciMLBase.OptimizationProblem","page":"OptimizationSystem","title":"SciMLBase.OptimizationProblem","text":"Defines a optimization problem. Documentation Page: https://galacticoptim.sciml.ai/dev/API/optimization_problem/\n\nMathematical Specification of a Optimization Problem\n\nTo define an Optimization Problem, you simply need to give the function f which defines the cost function to minimize:\n\nmin_u f(up) = 0\n\nu₀ is an initial guess of the minimum. f should be specified as f(u,p) and u₀ should be an AbstractArray (or number) whose geometry matches the  desired geometry of u. Note that we are not limited to numbers or vectors  for u₀; one is allowed to provide u₀ as arbitrary matrices /  higher-dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nOptimizationProblem{iip}(f, x, p = SciMLBase.NullParameters(),;\n                        lb = nothing,\n                        ub = nothing,\n                        lcons = nothing,\n                        ucons = nothing,\n                        sense = nothing,\n                        kwargs...)\n\nisinplace optionally sets whether the function is in-place or not. This is determined automatically, but not inferred. Note that for OptimizationProblem, in-place only refers to the Jacobian and Hessian functions, and thus by default if the OptimizationFunction is not defined directly then iip = true is done by default.\n\nParameters are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nlb and ub are the upper and lower bounds for box constraints on the optimization. They should be an AbstractArray matching the geometry of u, where (lb[I],ub[I]) is the box constraint (lower and upper bounds) for u[I].\n\nlcons and ucons are the upper and lower bounds for equality constraints on the optimization. They should be an AbstractArray matching the geometry of u, where (lcons[I],ucons[I]) is the constraint (lower and upper bounds) for cons[I].\n\nIf f is a standard Julia function, it is automatically converted into an OptimizationFunction with NoAD(), i.e., no automatic generation of the derivative functions.\n\nAny extra keyword arguments are captured to be sent to the optimizers.\n\nFields\n\nf: The function in the problem.\nu0: The initial guess for the optima.\np: The parameters for the problem. Defaults to NullParameters.\nlb: the lower bounds for the optimization of u.\nub: the upper bounds for the optimization of u.\nlcons:\nucons:\nsense:\nkwargs: The keyword arguments passed on to the solvers.\n\n\n\n","category":"type"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/#Handling-Exogenous-Input-Signals","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"The key to using exogeneous input signals is the same as in the rest of the SciML universe: just use the function in the definition of the differential equation. For example, if it's a standard differential equation, you can use the form","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"I(t) = t^2\n\nfunction f(du,u,p,t)\n  du[1] = I(t)\n  du[2] = u[1]\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"so that I(t) is an exogenous input signal into f. Another form that could be useful is a closure. For example:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"function f(du,u,p,t,I)\n  du[1] = I(t)\n  du[2] = u[1]\nend\n\n_f(du,u,p,t) = f(du,u,p,t,x -> x^2)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"which encloses an extra argument into f so that _f is now the interface-compliant differential equation definition.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"Note that you can also learn what the exogenous equation is from data. For an example on how to do this, you can use the Optimal Control Example which shows how to parameterize a u(t) by a universal function and learn that from data.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/#Example-of-a-Neural-ODE-with-Exogenous-Input","page":"Handling Exogenous Input Signals","title":"Example of a Neural ODE with Exogenous Input","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"In the following example, a discrete exogenous input signal ex is defined and used as an input into the neural network of a neural ODE system.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"using DifferentialEquations, DiffEqFlux, Plots\n\ntspan = (0.1f0, Float32(10.0))\ntsteps = range(tspan[1], tspan[2], length = 100)\nt_vec = collect(tsteps)\nex = vec(ones(Float32,length(tsteps), 1))\nf(x) = (atan(8.0 * x - 4.0) + atan(4.0)) / (2.0 * atan(4.0))\n\nfunction hammerstein_system(u)\n    y= zeros(size(u))\n    for k in 2:length(u)\n        y[k] = 0.2 * f(u[k-1]) + 0.8 * y[k-1]\n    end\n    return y\nend\n\ny = Float32.(hammerstein_system(ex))\nplot(collect(tsteps), y, ticks=:native)\n\nnn_model = FastChain(FastDense(2,8, tanh), FastDense(8, 1))\np_model = initial_params(nn_model)\n\nu0 = Float32.([0.0])\n\nfunction dudt(u, p, t)\n    #input_val = u_vals[Int(round(t*10)+1)]\n    nn_model(vcat(u[1], ex[Int(round(10*0.1))]), p)\nend\n\nprob = ODEProblem(dudt,u0,tspan,nothing)\n\nfunction predict_neuralode(p)\n    _prob = remake(prob,p=p)\n    Array(solve(_prob, Tsit5(), saveat=tsteps, abstol = 1e-8, reltol = 1e-6))\nend\n\nfunction loss(p)\n    sol = predict_neuralode(p)\n    N = length(sol)\n    return sum(abs2.(y[1:N] .- sol'))/N\nend\n\nres0 = DiffEqFlux.sciml_train(loss,p_model,maxiters=100)\n\nsol = predict_neuralode(res0.u)\nplot(tsteps,sol')\nN = length(sol)\nscatter!(tsteps,y[1:N])\n\nsavefig(\"trained.png\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/exogenous_input/","page":"Handling Exogenous Input Signals","title":"Handling Exogenous Input Signals","text":"(Image: )","category":"page"},{"location":"copies/Integrals/tutorials/numerical_integrals/#Numerically-Solving-Integrals","page":"Numerically Solving Integrals","title":"Numerically Solving Integrals","text":"","category":"section"},{"location":"copies/Integrals/tutorials/numerical_integrals/","page":"Numerically Solving Integrals","title":"Numerically Solving Integrals","text":"For basic multidimensional quadrature we can construct and solve a IntegralProblem:","category":"page"},{"location":"copies/Integrals/tutorials/numerical_integrals/","page":"Numerically Solving Integrals","title":"Numerically Solving Integrals","text":"using Integrals\nf(x,p) = sum(sin.(x))\nprob = IntegralProblem(f,ones(2),3ones(2))\nsol = solve(prob,HCubatureJL(),reltol=1e-3,abstol=1e-3)","category":"page"},{"location":"copies/Integrals/tutorials/numerical_integrals/","page":"Numerically Solving Integrals","title":"Numerically Solving Integrals","text":"If we would like to parallelize the computation, we can use the batch interface to compute multiple points at once. For example, here we do allocation-free multithreading with Cubature.jl:","category":"page"},{"location":"copies/Integrals/tutorials/numerical_integrals/","page":"Numerically Solving Integrals","title":"Numerically Solving Integrals","text":"using Integrals, Cubature, Base.Threads\nfunction f(dx,x,p)\n  Threads.@threads for i in 1:size(x,2)\n    dx[i] = sum(sin.(@view(x[:,i])))\n  end\nend\nprob = IntegralProblem(f,ones(2),3ones(2),batch=2)\nsol = solve(prob,CubatureJLh(),reltol=1e-3,abstol=1e-3)","category":"page"},{"location":"copies/Integrals/tutorials/numerical_integrals/","page":"Numerically Solving Integrals","title":"Numerically Solving Integrals","text":"If we would like to compare the results against Cuba.jl's Cuhre method, then the change is a one-argument change:","category":"page"},{"location":"copies/Integrals/tutorials/numerical_integrals/","page":"Numerically Solving Integrals","title":"Numerically Solving Integrals","text":"using IntegralsCuba\nsol = solve(prob,CubaCuhre(),reltol=1e-3,abstol=1e-3)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#Optimization-Based-Methods","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#The-Objective-Function-Builders","page":"Optimization-Based Methods","title":"The Objective Function Builders","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#Standard-Nonlinear-Regression","page":"Optimization-Based Methods","title":"Standard Nonlinear Regression","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"build_loss_objective builds an objective function to be used with Optim.jl and MathProgBase-associated solvers like NLopt.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"function build_loss_objective(prob::DEProblem,alg,loss_func\n                              regularization=nothing;\n                              mpg_autodiff = false,\n                              verbose_opt = false,\n                              verbose_steps = 100,\n                              prob_generator = (prob,p)->remake(prob,p=p),\n                              kwargs...)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"The first argument is the DEProblem to solve, and next is the alg to use. The alg must match the problem type, which can be any DEProblem (ODEs, SDEs, DAEs, DDEs, etc.). regularization defaults to nothing which has no regularization function. One can also choose verbose_opt and verbose_steps, which, in the optimization routines, will print the steps and the values at the steps every verbose_steps steps. mpg_autodiff uses autodifferentiation to define the derivative for the MathProgBase solver. The extra keyword arguments are passed to the differential equation solver.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#Multiple-Shooting","page":"Optimization-Based Methods","title":"Multiple Shooting","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"Multiple Shooting is generally used in Boundary Value Problems (BVP) and is more robust than the regular objective function used in these problems. It proceeds as follows:","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"Divide up the time span into short time periods and solve the equation with the current parameters which here consist of both, the parameters of the differential equations and also the initial values for the short time periods.\nThis objective additionally involves a discontinuity error term that imposes higher cost if the end of the solution of one time period doesn't match the beginning of the next one.\nMerge the solutions from the shorter intervals and then calculate the loss.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"function multiple_shooting_objective(prob::DiffEqBase.DEProblem,alg,loss,\n                              regularization=nothing;prior=nothing,\n                              mpg_autodiff = false,discontinuity_weight=1.0,\n                              verbose_opt = false,\n                              prob_generator = STANDARD_PROB_GENERATOR,\n                              autodiff_prototype = mpg_autodiff ? zeros(init_N_params) : nothing,\n                              autodiff_chunk = mpg_autodiff ? ForwardDiff.Chunk(autodiff_prototype) : nothing,\n                              kwargs...)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"For consistency multiple_shooting_objective takes exactly the same arguments as build_loss_objective. It also has the option for discontinuity_error as a keyword argument which assigns weight to the error occurring due to the discontinuity that arises from the breaking up of the time span.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#Detailed-Explanations-of-Arguments","page":"Optimization-Based Methods","title":"Detailed Explanations of Arguments","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#The-Loss-Function","page":"Optimization-Based Methods","title":"The Loss Function","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"loss_func(sol)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"is a function which reduces the problem's solution to a scalar which the optimizer will try to minimize. While this is very flexible, two convenience routines are included for fitting to data with standard cost functions:","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"L2Loss(t,data;differ_weight=nothing,data_weight=nothing,\n              colloc_grad=nothing,dudt=nothing)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"where t is the set of timepoints which the data is found at, and data are the values that are known where each column corresponds to measures of the values of the system. L2Loss is an optimized version of the L2-distance. The data_weight is a scalar or vector of weights for the loss function which must match the size of the data. Note that minimization of a weighted L2Loss is equivalent to maximum likelihood estimation of a heteroskedastic Normally distributed likelihood. differ_weight allows one to add a weight on the first differencing terms sol[i+1]-sol[i] against the data first differences. This smooths out the loss term and can make it easier to fit strong solutions of stochastic models, but is zero (nothing) by default. Additionally, colloc_grad allows one to give a matrix of the collocation gradients for the data. This is used to add an interpolation derivative term, like the two-stage method. A convenience function colloc_grad(t,data) returns a collocation gradient from a 3rd order spline calculated by Dierckx.jl, which can be used as the colloc_grad. Note that, with a collocation gradient and regularization, this loss is equivalent to a 4DVAR.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"Additionally, we include a more flexible log-likelihood approach:","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"LogLikeLoss(t,distributions,diff_distributions=nothing)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"In this case, there are two forms. The simple case is where distributions[i,j] is the likelihood distributions from a UnivariateDistribution from Distributions.jl, where it corresponds to the likelihood at t[i] for component j. The second case is where distributions[i] is a MultivariateDistribution which corresponds to the likelihood at t[i] over the vector of components. This likelihood function then calculates the negative of the total loglikelihood over time as its objective value (negative since optimizers generally find minimums, and thus this corresponds to maximum likelihood estimation). The third term, diff_distributions, acts similarly but allows putting a distribution on the first difference terms sol[i+1]-sol[i].","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"Note that these distributions can be generated via fit_mle on some dataset against some chosen distribution type.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#Note-About-Loss-Functions","page":"Optimization-Based Methods","title":"Note About Loss Functions","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"For parameter estimation problems, it's not uncommon for the optimizers to hit unstable regions of parameter space. This causes warnings that the solver exited early, and the built-in loss functions like L2Loss automatically handle this. However, if using a user-supplied loss function, you should make sure it's robust to these issues. One common pattern is to apply infinite loss when the integration is not successful. Using the retcodes, this can be done via:","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"function my_loss_function(sol)\n   tot_loss = 0.0\n   if any((s.retcode != :Success for s in sol))\n     tot_loss = Inf\n   else\n     # calculation for the loss here\n   end\n   tot_loss\nend","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#Note-on-First-Differencing","page":"Optimization-Based Methods","title":"Note on First Differencing","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"L2Loss(t,data,differ_weight=0.3,data_weight=0.7)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"First differencing incorporates the differences of data points at consecutive time points which adds more information about the trajectory in the loss function. Adding first differencing is helpful in cases where the L2Loss alone leads to non-identifiable parameters but adding a first differencing term makes it more identifiable. This can be noted on stochastic differential equation models, where this aims to capture the autocorrelation and therefore helps us avoid getting the same stationary distribution despite different trajectories and thus wrong parameter estimates.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#The-Regularization-Function","page":"Optimization-Based Methods","title":"The Regularization Function","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"The regularization can be any function of p, the parameter vector:","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"regularization(p)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"The Regularization helper function builds a regularization using a penalty function penalty from PenaltyFunctions.jl:","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"Regularization(λ,penalty=L2Penalty())","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"The regularization defaults to L2 if no penalty function is specified. λ is the weight parameter for the addition of the regularization term.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#The-Problem-Generator-Function","page":"Optimization-Based Methods","title":"The Problem Generator Function","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"The argument prob_generator allows one to specify a function for generating new problems from a given parameter set. By default, this just builds a new problem which fixes the element types in a way that's autodifferentiation compatible and adds the new parameter vector p. For example, the code for this is:","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"prob_generator = (prob,p) -> remake(prob,u0=convert.(eltype(p),prob.u0),p=p)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"Then the new problem with these new values is returned.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"One can use this to change the meaning of the parameters using this function. For example, if one instead wanted to optimize the initial conditions for a function without parameters, you could change this to:","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"prob_generator = (prob,p) -> remake(prob.f,u0=p)","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"which simply uses p as the initial condition in the initial value problem.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/#Using-the-Objectives-for-MAP-estimates","page":"Optimization-Based Methods","title":"Using the Objectives for MAP estimates","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"You can also add a prior option to build_loss_objective and multiple_shooting_objective that essentially turns it into MAP by multiplying the loglikelihood (the cost) by the prior. The option was added as a keyword argument priors, it can take in either an array of univariate distributions for each of the parameters or a multivariate distribution.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/optimization_based_methods/","page":"Optimization-Based Methods","title":"Optimization-Based Methods","text":"ms_obj = multiple_shooting_objective(ms_prob,Tsit5(),L2Loss(t,data);priors=priors,discontinuity_weight=1.0,abstol=1e-12,reltol=1e-12)","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Ask more questions.","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/#How-do-I-use-IterativeSolvers-solvers-with-a-weighted-tolerance-vector?","page":"Frequently Asked Questions","title":"How do I use IterativeSolvers solvers with a weighted tolerance vector?","text":"","category":"section"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"IterativeSolvers.jl computes the norm after the application of the left precondtioner Pl. Thus in order to use a vector tolerance weights, one can mathematically hack the system via the following formulation:","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"using LinearSolve, LinearAlgebra\nPl = LinearSolve.InvPreconditioner(Diagonal(weights))\nPr = Diagonal(weights)\n\nA = rand(n,n)\nb = rand(n)\n\nprob = LinearProblem(A,b)\nsol = solve(prob,IterativeSolvers_GMRES(),Pl=Pl,Pr=Pr)","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"If you want to use a \"real\" preconditioner under the norm weights, then one can use ComposePreconditioner to apply the preconditioner after the application of the weights like as follows:","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"using LinearSolve, LinearAlgebra\nPl = ComposePreconitioner(LinearSolve.InvPreconditioner(Diagonal(weights),realprec))\nPr = Diagonal(weights)\n\nA = rand(n,n)\nb = rand(n)\n\nprob = LinearProblem(A,b)\nsol = solve(prob,IterativeSolvers_GMRES(),Pl=Pl,Pr=Pr)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/feedback_control/#Universal-Differential-Equations-for-Neural-Feedback-Control","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"You can also mix a known differential equation and a neural differential equation, so that the parameters and the neural network are estimated simultaneously!","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"We will assume that we know the dynamics of the second equation (linear dynamics), and our goal is to find a neural network that is dependent on the current state of the dynamical system that will control the second equation to stay close to 1.","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"using DiffEqFlux, DifferentialEquations, Plots\n\nu0 = 1.1f0\ntspan = (0.0f0, 25.0f0)\ntsteps = 0.0f0:1.0:25.0f0\n\nmodel_univ = FastChain(FastDense(2, 16, tanh),\n                       FastDense(16, 16, tanh),\n                       FastDense(16, 1))\n\n# The model weights are destructured into a vector of parameters\np_model = initial_params(model_univ)\nn_weights = length(p_model)\n\n# Parameters of the second equation (linear dynamics)\np_system = Float32[0.5, -0.5]\n\np_all = [p_model; p_system]\nθ = Float32[u0; p_all]\n\nfunction dudt_univ!(du, u, p, t)\n    # Destructure the parameters\n    model_weights = p[1:n_weights]\n    α = p[end - 1]\n    β = p[end]\n\n    # The neural network outputs a control taken by the system\n    # The system then produces an output\n    model_control, system_output = u\n\n    # Dynamics of the control and system\n    dmodel_control = model_univ(u, model_weights)[1]\n    dsystem_output = α*system_output + β*model_control\n\n    # Update in place\n    du[1] = dmodel_control\n    du[2] = dsystem_output\nend\n\nprob_univ = ODEProblem(dudt_univ!, [0f0, u0], tspan, p_all)\nsol_univ = solve(prob_univ, Tsit5(),abstol = 1e-8, reltol = 1e-6)\n\nfunction predict_univ(θ)\n  return Array(solve(prob_univ, Tsit5(), u0=[0f0, θ[1]], p=θ[2:end],\n                              sensealg = InterpolatingAdjoint(autojacvec=ReverseDiffVJP(true)),\n                              saveat = tsteps))\nend\n\nloss_univ(θ) = sum(abs2, predict_univ(θ)[2,:] .- 1)\nl = loss_univ(θ)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"list_plots = []\niter = 0\ncallback = function (θ, l)\n  global list_plots, iter\n\n  if iter == 0\n    list_plots = []\n  end\n  iter += 1\n\n  println(l)\n\n  plt = plot(predict_univ(θ)', ylim = (0, 6))\n  push!(list_plots, plt)\n  display(plt)\n  return false\nend","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/feedback_control/","page":"Universal Differential Equations for Neural Feedback Control","title":"Universal Differential Equations for Neural Feedback Control","text":"result_univ = DiffEqFlux.sciml_train(loss_univ, θ,\n                                     cb = callback)","category":"page"},{"location":"copies/Surrogates/kriging/#Kriging-surrogate-tutorial-(1D)","page":"Kriging","title":"Kriging surrogate tutorial (1D)","text":"","category":"section"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"Kriging or Gaussian process regression is a method of interpolation for which the interpolated values are modeled by a Gaussian process.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"We are going to use a Kriging surrogate to optimize f(x)=(6x-2)^2sin(12x-4). (function from Forrester et al. (2008)).","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"First of all import Surrogates and Plots.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/kriging/#Sampling","page":"Kriging","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"We choose to sample f in 4 points between 0 and 1 using the sample function. The sampling points are chosen using a Sobol sequence, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"# https://www.sfu.ca/~ssurjano/forretal08.html\n# Forrester et al. (2008) Function\nf(x) = (6 * x - 2)^2 * sin(12 * x - 4)\n\nn_samples = 4\nlower_bound = 0.0\nupper_bound = 1.0\n\nxs = lower_bound:0.001:upper_bound\n\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\ny = f.(x)\n\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound), ylims=(-7, 17))\nplot!(xs, f.(xs), label=\"True function\", legend=:top)","category":"page"},{"location":"copies/Surrogates/kriging/#Building-a-surrogate","page":"Kriging","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"With our sampled points we can build the Kriging surrogate using the Kriging function.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"kriging_surrogate behaves like an ordinary function which we can simply plot. A nice statistical property of this surrogate is being able to calculate the error of the function at each point, we plot this as a confidence interval using the ribbon argument.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"kriging_surrogate = Kriging(x, y, lower_bound, upper_bound, p=1.9);\n\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), ylims=(-7, 17), legend=:top)\nplot!(xs, f.(xs), label=\"True function\", legend=:top)\nplot!(xs, kriging_surrogate.(xs), label=\"Surrogate function\", ribbon=p->std_error_at_point(kriging_surrogate, p), legend=:top)","category":"page"},{"location":"copies/Surrogates/kriging/#Optimizing","page":"Kriging","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"Having built a surrogate, we can now use it to search for minimas in our original function f.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"To optimize using our surrogate we call surrogate_optimize method. We choose to use Stochastic RBF as optimization technique and again Sobol sampling as sampling technique.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"@show surrogate_optimize(f, SRBF(), lower_bound, upper_bound, kriging_surrogate, SobolSample())\n\nscatter(x, y, label=\"Sampled points\", ylims=(-7, 7), legend=:top)\nplot!(xs, f.(xs), label=\"True function\", legend=:top)\nplot!(xs, kriging_surrogate.(xs), label=\"Surrogate function\", ribbon=p->std_error_at_point(kriging_surrogate, p), legend=:top)","category":"page"},{"location":"copies/Surrogates/kriging/#Kriging-surrogate-tutorial-(ND)","page":"Kriging","title":"Kriging surrogate tutorial (ND)","text":"","category":"section"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"First of all let's define the function we are going to build a surrogate for. Notice how its argument is a vector of numbers, one for each coordinate, and its output is a scalar.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"using Plots # hide\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\nusing Surrogates # hide\n\nfunction branin(x)\n    x1=x[1]\n    x2=x[2]\n    a=1;\n    b=5.1/(4*π^2);\n    c=5/π;\n    r=6;\n    s=10;\n    t=1/(8π);\n    a*(x2-b*x1+c*x1-r)^2+s*(1-t)*cos(x1)+s\nend","category":"page"},{"location":"copies/Surrogates/kriging/#Sampling-2","page":"Kriging","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension x to have bounds -5, 10, and 0, 15 for the second dimension. We are taking 50 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"n_samples = 50\nlower_bound = [-5.0, 0.0]\nupper_bound = [10.0, 15.0]\n\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\nzs = branin.(xys);","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"x, y = -5:10, 0:15 # hide\np1 = surface(x, y, (x1,x2) -> branin((x1,x2))) # hide\nxs = [xy[1] for xy in xys] # hide\nys = [xy[2] for xy in xys] # hide\nscatter!(xs, ys, zs) # hide\np2 = contour(x, y, (x1,x2) -> branin((x1,x2))) # hide\nscatter!(xs, ys) # hide\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/kriging/#Building-a-surrogate-2","page":"Kriging","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"Using the sampled points we build the surrogate, the steps are analogous to the 1-dimensional case.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"kriging_surrogate = Kriging(xys, zs, lower_bound, upper_bound, p=[1.9, 1.9])","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"p1 = surface(x, y, (x, y) -> kriging_surrogate([x y])) # hide\nscatter!(xs, ys, zs, marker_z=zs) # hide\np2 = contour(x, y, (x, y) -> kriging_surrogate([x y])) # hide\nscatter!(xs, ys, marker_z=zs) # hide\nplot(p1, p2, title=\"Surrogate\") # hide","category":"page"},{"location":"copies/Surrogates/kriging/#Optimizing-2","page":"Kriging","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"With our surrogate we can now search for the minimas of the branin function.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"Notice how the new sampled points, which were created during the optimization process, are appended to the xys array. This is why its size changes.","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"surrogate_optimize(branin, SRBF(), lower_bound, upper_bound, kriging_surrogate, SobolSample(), maxiters=10)","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/kriging/","page":"Kriging","title":"Kriging","text":"p1 = surface(x, y, (x, y) -> kriging_surrogate([x y])) # hide\nxs = [xy[1] for xy in xys] # hide\nys = [xy[2] for xy in xys] # hide\nzs = branin.(xys) # hide\nscatter!(xs, ys, zs, marker_z=zs) # hide\np2 = contour(x, y, (x, y) -> kriging_surrogate([x y])) # hide\nscatter!(xs, ys, marker_z=zs) # hide\nplot(p1, p2) # hide","category":"page"},{"location":"copies/Surrogates/wendland/#Wendland-Surrogate","page":"Wendland","title":"Wendland Surrogate","text":"","category":"section"},{"location":"copies/Surrogates/wendland/","page":"Wendland","title":"Wendland","text":"The Wendland surrogate is a compact surrogate: it allocates much less memory then other surrogates. The coefficients are found using an iterative solver.","category":"page"},{"location":"copies/Surrogates/wendland/","page":"Wendland","title":"Wendland","text":"f = x - exp(-x^2)","category":"page"},{"location":"copies/Surrogates/wendland/","page":"Wendland","title":"Wendland","text":"using Surrogates\nusing Plots","category":"page"},{"location":"copies/Surrogates/wendland/","page":"Wendland","title":"Wendland","text":"n = 40\nlower_bound = 0.0\nupper_bound = 1.0\nf = x -> exp(-x^2)\nx = sample(n,lower_bound,upper_bound,SobolSample())\ny = f.(x)","category":"page"},{"location":"copies/Surrogates/wendland/","page":"Wendland","title":"Wendland","text":"We choose to sample f in 30 points between 5 to 25 using sample function. The sampling points are chosen using a Sobol sequence, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/wendland/#Building-Surrogate","page":"Wendland","title":"Building Surrogate","text":"","category":"section"},{"location":"copies/Surrogates/wendland/","page":"Wendland","title":"Wendland","text":"The choice of the right parameter is especially important here: a slight change in ϵ would produce a totally different fit. Try it yourself with this function!","category":"page"},{"location":"copies/Surrogates/wendland/","page":"Wendland","title":"Wendland","text":"my_eps = 0.5\nwend = Wendland(x,y,lower_bound,upper_bound,eps=my_eps)","category":"page"},{"location":"copies/Surrogates/wendland/","page":"Wendland","title":"Wendland","text":"plot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\nplot!(wend, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/#Morris-Method","page":"Morris Method","title":"Morris Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"struct Morris <: GSAMethod\n    p_steps::Array{Int,1}\n    relative_scale::Bool\n    num_trajectory::Int\n    total_num_trajectory::Int\n    len_design_mat::Int\nend","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"Morris has the following keyword arguments:","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"p_steps - Vector of Delta for the step sizes in each direction. Required.\nrelative_scale - The elementary effects are calculated with the assumption that the parameters lie in the range [0,1] but as this is not always the case scaling is used to get more informative, scaled effects. Defaults to false.\ntotal_num_trajectory, num_trajectory - The total number of design matrices that are generated out of which num_trajectory matrices with the highest spread are used in calculation.\nlen_design_mat - The size of a design matrix.","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/#Morris-Method-Details","page":"Morris Method","title":"Morris Method Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"The Morris method also known as Morris’s OAT method where OAT stands for One At a Time can be described in the following steps:","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"We calculate local sensitivity measures known as “elementary effects”, which are calculated by measuring the perturbation in the output of the model on changing one parameter.","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"EE_i = fracf(x_1x_2x_i+ Deltax_k) - yDelta","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"These are evaluated at various points in the input chosen such that a wide “spread” of the parameter space is explored and considered in the analysis, to provide an approximate global importance measure. The mean and variance of these elementary effects is computed. A high value of the mean implies that a parameter is important, a high variance implies that its effects are non-linear or the result of interactions with other inputs. This method does not evaluate separately the contribution from the interaction and the contribution of the parameters individually and gives the effects for each parameter which takes into consideration all the interactions and its individual contribution.","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/#API","page":"Morris Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"function gsa(f, method::Morris, p_range::AbstractVector; batch=false, kwargs...)","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/#Example","page":"Morris Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"Morris method on Ishigami function ","category":"page"},{"location":"copies/GlobalSensitivity/methods/morris/","page":"Morris Method","title":"Morris Method","text":"using GlobalSensitivity\n\nfunction ishi(X)\n    A= 7\n    B= 0.1\n    sin(X[1]) + A*sin(X[2])^2+ B*X[3]^4 *sin(X[1])\nend\n\nlb = -ones(4)*π\nub = ones(4)*π\n\nm = gsa(ishi, Morris(num_trajectory=500000), [[lb[i],ub[i]] for i in 1:4])","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/#GCMAES.jl","page":"GCMAES.jl","title":"GCMAES.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"GCMAES is a Julia package implementing the Gradient-based Covariance Matrix Adaptation Evolutionary Strategy which can utilize the gradient information to speed up the optimization process.","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/#Installation:-OptimizationGCMAES.jl","page":"GCMAES.jl","title":"Installation: OptimizationGCMAES.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"To use this package, install the OptimizationGCMAES package:","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"import Pkg; Pkg.add(\"OptimizationGCMAES\")","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/#Global-Optimizer","page":"GCMAES.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/gcmaes/#Without-Constraint-Equations","page":"GCMAES.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The GCMAES algorithm is called by GCMAESOpt() and the initial search variance is set as a keyword argument σ0 (default: σ0 = 0.2)","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The method in GCMAES is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/#Example","page":"GCMAES.jl","title":"Example","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"The Rosenbrock function can optimized using the GCMAESOpt() without utilizing the gradient information as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, GCMAESOpt())","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"We can also utilise the gradient information of the optimization problem to aid the optimization as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/gcmaes/","page":"GCMAES.jl","title":"GCMAES.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock, Optimization.ForwardDiff)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, GCMAESOpt())","category":"page"},{"location":"copies/DiffEqParamEstim/methods/recommended_methods/#Recommended-Methods","page":"Recommended Methods","title":"Recommended Methods","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/methods/recommended_methods/","page":"Recommended Methods","title":"Recommended Methods","text":"The recommended method is to use build_loss_objective with the optimizer of your choice. This method can thus be paired with global optimizers from packages like BlackBoxOptim.jl or NLopt.jl which can be much less prone to finding local minima than local optimization methods. Also, it allows the user to define the cost function in the way they choose as a function loss(sol), and thus can fit using any cost function on the solution, making it applicable to fitting non-temporal data and other types of problems. Also, build_loss_objective works for all of the DEProblem types, allowing it to optimize parameters on ODEs, SDEs, DDEs, DAEs, etc.","category":"page"},{"location":"copies/DiffEqParamEstim/methods/recommended_methods/","page":"Recommended Methods","title":"Recommended Methods","text":"However, this method requires repeated solution of the differential equation. If the data is temporal data, the most efficient method is the two_stage_method which does not require repeated solutions but is not as accurate. Usage of the two_stage_method should have a post-processing step which refines using a method like build_loss_objective.","category":"page"},{"location":"copies/Optimization/#Optimization.jl","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl","text":"","category":"section"},{"location":"copies/Optimization/","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Optimization.jl is a package with a scope that is beyond your normal global optimization package. Optimization.jl seeks to bring together all of the optimization packages it can find, local and global, into one unified Julia interface. This means, you learn one package and you learn them all! Optimization.jl adds a few high-level features, such as integrating with automatic differentiation, to make its usage fairly simple for most cases, while allowing all of the options in a single unified interface.","category":"page"},{"location":"copies/Optimization/#Installation","page":"Optimization.jl: A Unified Optimization Package","title":"Installation","text":"","category":"section"},{"location":"copies/Optimization/","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Assuming that you already have Julia correctly installed, it suffices to import Optimization.jl in the standard way:","category":"page"},{"location":"copies/Optimization/","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"import Pkg; Pkg.add(\"Optimization\")","category":"page"},{"location":"copies/Optimization/","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"The packages relevant to the core functionality of Optimization.jl will be imported accordingly and, in most cases, you do not have to worry about the manual installation of dependencies. However, you will need to add the specific optimizer packages.","category":"page"},{"location":"copies/Optimization/#Overview-of-the-Optimizers","page":"Optimization.jl: A Unified Optimization Package","title":"Overview of the Optimizers","text":"","category":"section"},{"location":"copies/Optimization/","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"Package Local Gradient-Based Local Hessian-Based Local Derivative-Free Local Constrained Global Unconstrained Global Constrained\nBlackBoxOptim ❌ ❌ ❌ ❌ ✅ ❌\nCMAEvolutionaryStrategy ❌ ❌ ❌ ❌ ✅ ❌\nEvolutionary ❌ ❌ ❌ ❌ ✅ 🟡\nFlux ✅ ❌ ❌ ❌ ❌ ❌\nGCMAES ❌ ❌ ❌ ❌ ✅ ❌\nMathOptInterface ✅ ✅ ✅ ✅ ✅ 🟡\nMultistartOptimization ❌ ❌ ❌ ❌ ✅ ❌\nMetaheuristics ❌ ❌ ❌ ❌ ✅ 🟡\nNOMAD ❌ ❌ ❌ ❌ ✅ 🟡\nNLopt ✅ ❌ ✅ 🟡 ✅ 🟡\nNonconvex ✅ ✅ ✅ 🟡 ✅ 🟡\nOptim ✅ ✅ ✅ ✅ ✅ ✅\nQuadDIRECT ❌ ❌ ❌ ❌ ✅ ❌","category":"page"},{"location":"copies/Optimization/","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"✅ = supported","category":"page"},{"location":"copies/Optimization/","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"🟡 = supported in downstream library but not yet implemented in Optimization; PR to add this functionality are welcome","category":"page"},{"location":"copies/Optimization/","page":"Optimization.jl: A Unified Optimization Package","title":"Optimization.jl: A Unified Optimization Package","text":"❌ = not supported","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/#Multiple-Shooting","page":"Multiple Shooting","title":"Multiple Shooting","text":"","category":"section"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"In Multiple Shooting, the training data is split into overlapping intervals. The solver is then trained on individual intervals. If the end conditions of any interval coincide with the initial conditions of the next immediate interval, then the joined/combined solution is same as solving on the whole dataset (without splitting).","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"To ensure that the overlapping part of two consecutive intervals coincide, we add a penalizing term, continuity_term * absolute_value_of(prediction of last point of group i - prediction of first point of group i+1), to the loss.","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"Note that the continuity_term should have a large positive value to add high penalties in case the solver predicts discontinuous values.","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"The following is a working demo, using Multiple Shooting","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"using DiffEqFlux, DifferentialEquations, Plots\nusing DiffEqFlux: group_ranges\n\n# Define initial conditions and time steps\ndatasize = 30\nu0 = Float32[2.0, 0.0]\ntspan = (0.0f0, 5.0f0)\ntsteps = range(tspan[1], tspan[2], length = datasize)\n\n\n# Get the data\nfunction trueODEfunc(du, u, p, t)\n    true_A = [-0.1 2.0; -2.0 -0.1]\n    du .= ((u.^3)'true_A)'\nend\nprob_trueode = ODEProblem(trueODEfunc, u0, tspan)\node_data = Array(solve(prob_trueode, Tsit5(), saveat = tsteps))\n\n\n# Define the Neural Network\nnn = FastChain((x, p) -> x.^3,\n                  FastDense(2, 16, tanh),\n                  FastDense(16, 2))\np_init = initial_params(nn)\n\nneuralode = NeuralODE(nn, tspan, Tsit5(), saveat = tsteps)\nprob_node = ODEProblem((u,p,t)->nn(u,p), u0, tspan, p_init)\n\n\nfunction plot_multiple_shoot(plt, preds, group_size)\n\tstep = group_size-1\n\tranges = group_ranges(datasize, group_size)\n\n\tfor (i, rg) in enumerate(ranges)\n\t\tplot!(plt, tsteps[rg], preds[i][1,:], markershape=:circle, label=\"Group $(i)\")\n\tend\nend\n\n# Animate training\nanim = Animation()\ncallback = function (p, l, preds; doplot = true)\n  display(l)\n  if doplot\n\t# plot the original data\n\tplt = scatter(tsteps, ode_data[1,:], label = \"Data\")\n\n\t# plot the different predictions for individual shoot\n\tplot_multiple_shoot(plt, preds, group_size)\n\n    frame(anim)\n    display(plot(plt))\n  end\n  return false\nend\n\n# Define parameters for Multiple Shooting\ngroup_size = 3\ncontinuity_term = 200\n\nfunction loss_function(data, pred)\n\treturn sum(abs2, data - pred)\nend\n\nfunction loss_multiple_shooting(p)\n    return multiple_shoot(p, ode_data, tsteps, prob_node, loss_function, Tsit5(),\n                          group_size; continuity_term)\nend\n\nres_ms = DiffEqFlux.sciml_train(loss_multiple_shooting, p_init,\n                                cb = callback)\ngif(anim, \"multiple_shooting.gif\", fps=15)\n","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"Here's the animation that we get from above","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"(Image: pic) The connected lines show the predictions of each group (Notice that there are overlapping points as well. These are the points we are trying to coincide.)","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"Here is an output with group_size = 30 (which is same as solving on the whole interval without splitting also called single shooting)","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"(Image: pic_single_shoot3)","category":"page"},{"location":"copies/DiffEqFlux/examples/multiple_shooting/","page":"Multiple Shooting","title":"Multiple Shooting","text":"It is clear from the above picture, a single shoot doesn't perform very well with the ODE Problem we have and gets stuck in a local minima.","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/#sensitivity_math","page":"Sensitivity Math Details","title":"Mathematics of Sensitivity Analysis","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/sensitivity_math/#Forward-Sensitivity-Analysis","page":"Sensitivity Math Details","title":"Forward Sensitivity Analysis","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"The local sensitivity is computed using the sensitivity ODE:","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"fracddtfracpartial upartial p_j=fracpartial fpartial ufracpartial upartial p_j+fracpartial fpartial p_j=Jcdot S_j+F_j","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"where","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"J=left(beginarraycccc\nfracpartial f_1partial u_1  fracpartial f_1partial u_2  cdots  fracpartial f_1partial u_k\nfracpartial f_2partial u_1  fracpartial f_2partial u_2  cdots  fracpartial f_2partial u_k\ncdots  cdots  cdots  cdots\nfracpartial f_kpartial u_1  fracpartial f_kpartial u_2  cdots  fracpartial f_kpartial u_k\nendarrayright)","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"is the Jacobian of the system,","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"F_j=left(beginarrayc\nfracpartial f_1partial p_j\nfracpartial f_2partial p_j\nvdots\nfracpartial f_kpartial p_j\nendarrayright)","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"are the parameter derivatives, and","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"S_j=left(beginarrayc\nfracpartial u_1partial p_j\nfracpartial u_2partial p_j\nvdots\nfracpartial u_kpartial p_j\nendarrayright)","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"is the vector of sensitivities. Since this ODE is dependent on the values of the independent variables themselves, this ODE is computed simultaneously with the actual ODE system.","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"Note that the Jacobian-vector product","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"fracpartial fpartial ufracpartial upartial p_j","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"can be computed without forming the Jacobian. With finite differences, this through using the following formula for the directional derivative","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"Jv approx fracf(x+v epsilon) - f(x)epsilon","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"or, alternatively and without truncation error, by using a dual number with a single partial dimension, d = x + v epsilon we get that","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"f(d) = f(x) + Jv epsilon","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"as a fast way to calcuate Jv. Thus, except when a sufficiently good function for J is given by the user, the Jacobian is never formed. For more details, consult the MIT 18.337 lecture notes on forward mode AD.","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/#Adjoint-Sensitivity-Analysis","page":"Sensitivity Math Details","title":"Adjoint Sensitivity Analysis","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"This adjoint requires the definition of some scalar functional g(up) where u(tp) is the (numerical) solution to the differential equation ddt u(tp)=f(tup) with tin 0T and u(t_0p)=u_0. Adjoint sensitivity analysis finds the gradient of","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"G(up)=G(u(cdotp))=int_t_0^Tg(u(tp)p)dt","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"some integral of the solution. It does so by solving the adjoint problem","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"fracdlambda^stardt=g_u(u(tp)p)-lambda^star(t)f_u(tu(tp)p)thinspacethinspacethinspacelambda^star(T)=0","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"where f_u is the Jacobian of the system with respect to the state u while f_p is the Jacobian with respect to the parameters. The adjoint problem's solution gives the sensitivities through the integral:","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"fracdGdp=int_t_0^Tlambda^star(t)f_p(t)+g_p(t)dt+lambda^star(t_0)u_p(t_0)","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"Notice that since the adjoints require the Jacobian of the system at the state, it requires the ability to evaluate the state at any point in time. Thus it requires the continuous forward solution in order to solve the adjoint solution, and the adjoint solution is required to be continuous in order to calculate the resulting integral.","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"There is one extra detail to consider. In many cases we would like to calculate the adjoint sensitivity of some discontinuous functional of the solution. One canonical function is the L2 loss against some data points, that is:","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"L(up)=sum_i=1^nVerttildeu(t_i)-u(t_ip)Vert^2","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"In this case, we can reinterpret our summation as the distribution integral:","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"G(up)=int_0^Tsum_i=1^nVerttildeu(t_i)-u(t_ip)Vert^2delta(t_i-t)dt","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"where δ is the Dirac distribution. In this case, the integral is continuous except at finitely many points. Thus it can be calculated between each t_i. At a given t_i, given that the t_i are unique, we have that","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"g_u(t_i)=2left(tildeu(t_i)-u(t_ip)right)","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"Thus the adjoint solution lambda^star(t) is given by integrating between the integrals and applying the jump function g_u at every data point t_i.","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"We note that","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"lambda^star(t)f_u(t)","category":"page"},{"location":"copies/DiffEqSensitivity/sensitivity_math/","page":"Sensitivity Math Details","title":"Sensitivity Math Details","text":"is a vector-transpose Jacobian product, also known as a vjp, which can be efficiently computed using the pullback of backpropogation on the user function f with a forward pass at u with a pullback vector lambda^star. For more information, consult the MIT 18.337 lecture notes on reverse mode AD","category":"page"},{"location":"copies/DiffEqFlux/layers/CNFLayer/#CNF-Layer-Functions","page":"Continuous Normalizing Flows Layer","title":"CNF Layer Functions","text":"","category":"section"},{"location":"copies/DiffEqFlux/layers/CNFLayer/","page":"Continuous Normalizing Flows Layer","title":"Continuous Normalizing Flows Layer","text":"The following layers are helper functions for easily building neural differential equation architectures specialized for the task of density estimation through Continuous Normalizing Flows (CNF).","category":"page"},{"location":"copies/DiffEqFlux/layers/CNFLayer/","page":"Continuous Normalizing Flows Layer","title":"Continuous Normalizing Flows Layer","text":"DeterministicCNF\nFFJORD\nFFJORDDistribution","category":"page"},{"location":"copies/DiffEqFlux/layers/CNFLayer/#DiffEqFlux.DeterministicCNF","page":"Continuous Normalizing Flows Layer","title":"DiffEqFlux.DeterministicCNF","text":"Constructs a continuous-time recurrent neural network, also known as a neural ordinary differential equation (neural ODE), with fast gradient calculation via adjoints [1] and specialized for density estimation based on continuous normalizing flows (CNF) [2] with a direct computation of the trace of the dynamics' jacobian. At a high level this corresponds to the following steps:\n\nParameterize the variable of interest x(t) as a function f(z, θ, t) of a base variable z(t) with known density p_z;\nUse the transformation of variables formula to predict the density px as a function of the density pz and the trace of the Jacobian of f;\nChoose the parameter θ to minimize a loss function of p_x (usually the negative likelihood of the data);\n\n!!!note     This layer has been deprecated in favour of FFJORD. Use FFJORD with monte_carlo=false instead.\n\nAfter these steps one may use the NN model and the learned θ to predict the density p_x for new values of x.\n\nDeterministicCNF(model, tspan, basedist=nothing, monte_carlo=false, args...; kwargs...)\n\nArguments:\n\nmodel: A Chain neural network that defines the dynamics of the model.\nbasedist: Distribution of the base variable. Set to the unit normal by default.\ntspan: The timespan to be solved on.\nkwargs: Additional arguments splatted to the ODE solver. See the Common Solver Arguments documentation for more details.\n\nReferences:\n\n[1] Pontryagin, Lev Semenovich. Mathematical theory of optimal processes. CRC press, 1987.\n\n[2] Chen, Ricky TQ, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. \"Neural ordinary differential equations.\" In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 6572-6583. 2018.\n\n[3] Grathwohl, Will, Ricky TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. \"Ffjord: Free-form continuous dynamics for scalable reversible generative models.\" arXiv preprint arXiv:1810.01367 (2018).\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/CNFLayer/#DiffEqFlux.FFJORD","page":"Continuous Normalizing Flows Layer","title":"DiffEqFlux.FFJORD","text":"Constructs a continuous-time recurrent neural network, also known as a neural ordinary differential equation (neural ODE), with fast gradient calculation via adjoints [1] and specialized for density estimation based on continuous normalizing flows (CNF) [2] with a stochastic approach [2] for the computation of the trace of the dynamics' jacobian. At a high level this corresponds to the following steps:\n\nParameterize the variable of interest x(t) as a function f(z, θ, t) of a base variable z(t) with known density p_z;\nUse the transformation of variables formula to predict the density px as a function of the density pz and the trace of the Jacobian of f;\nChoose the parameter θ to minimize a loss function of p_x (usually the negative likelihood of the data);\n\nAfter these steps one may use the NN model and the learned θ to predict the density p_x for new values of x.\n\nFFJORD(model, basedist=nothing, monte_carlo=false, tspan, args...; kwargs...)\n\nArguments:\n\nmodel: A Chain neural network that defines the dynamics of the model.\nbasedist: Distribution of the base variable. Set to the unit normal by default.\ntspan: The timespan to be solved on.\nkwargs: Additional arguments splatted to the ODE solver. See the Common Solver Arguments documentation for more details.\n\nReferences:\n\n[1] Pontryagin, Lev Semenovich. Mathematical theory of optimal processes. CRC press, 1987.\n\n[2] Chen, Ricky TQ, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. \"Neural ordinary differential equations.\" In Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 6572-6583. 2018.\n\n[3] Grathwohl, Will, Ricky TQ Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud. \"Ffjord: Free-form continuous dynamics for scalable reversible generative models.\" arXiv preprint arXiv:1810.01367 (2018).\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/CNFLayer/#DiffEqFlux.FFJORDDistribution","page":"Continuous Normalizing Flows Layer","title":"DiffEqFlux.FFJORDDistribution","text":"FFJORD can be used as a distribution to generate new samples by rand or estimate densities by pdf or logpdf (from Distributions.jl).\n\nArguments:\n\nmodel: A FFJORD instance\nregularize: Whether we use regularization (default: false)\nmonte_carlo: Whether we use monte carlo (default: true)\n\n\n\n\n\n","category":"type"},{"location":"copies/LinearSolve/tutorials/linear/#Solving-Linear-Systems-in-Julia","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"","category":"section"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"A linear system Au=b is specified by defining an AbstractMatrix A, or by providing a matrix-free operator for performing A*x operations via the function A(u,p,t) out-of-place and A(du,u,p,t) for in-place. For the sake of simplicity, this tutorial will only showcase concrete matrices.","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"The following defines a matrix and a LinearProblem which is subsequently solved by the default linear solver.","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"using LinearSolve\n\nA = rand(4,4)\nb = rand(4)\nprob = LinearProblem(A, b)\nsol = solve(prob)\nsol.u\n\n#=\n4-element Vector{Float64}:\n  0.3784870087078603\n  0.07275749718047864\n  0.6612816064734302\n -0.10598367531463938\n=#","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"Note that solve(prob) is equivalent to solve(prob,nothing) where nothing denotes the choice of the default linear solver. This is equivalent to the Julia built-in A\\b, where the solution is recovered via sol.u. The power of this package comes into play when changing the algorithms. For example, IterativeSolvers.jl has some nice methods like GMRES which can be faster in some cases. With LinearSolve.jl, there is one interface and changing linear solvers is simply the switch of the algorithm choice:","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"sol = solve(prob,IterativeSolversJL_GMRES())\n\n#=\nu: 4-element Vector{Float64}:\n  0.37848700870786\n  0.07275749718047908\n  0.6612816064734302\n -0.10598367531463923\n=#","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"Thus a package which uses LinearSolve.jl simply needs to allow the user to pass in an algorithm struct and all wrapped linear solvers are immediately available as tweaks to the general algorithm.","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"CurrentModule = NeuralOperators","category":"page"},{"location":"copies/NeuralOperators/#NeuralOperators","page":"Home","title":"NeuralOperators","text":"","category":"section"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"(Image: ) (Image: )\nGround Truth Inferenced","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"The demonstration shown above is Navier-Stokes equation learned by the MarkovNeuralOperator with only one time step information. Example can be found in example/FlowOverCircle.","category":"page"},{"location":"copies/NeuralOperators/#Quick-start","page":"Home","title":"Quick start","text":"","category":"section"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"The package can be installed with the Julia package manager. From the Julia REPL, type ] to enter the Pkg REPL mode and run:","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"pkg> add NeuralOperators","category":"page"},{"location":"copies/NeuralOperators/#Usage","page":"Home","title":"Usage","text":"","category":"section"},{"location":"copies/NeuralOperators/#Fourier-Neural-Operator","page":"Home","title":"Fourier Neural Operator","text":"","category":"section"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"model = Chain(\n    # lift (d + 1)-dimensional vector field to n-dimensional vector field\n    # here, d == 1 and n == 64\n    Dense(2, 64),\n    # map each hidden representation to the next by integral kernel operator\n    OperatorKernel(64=>64, (16, ), FourierTransform, gelu),\n    OperatorKernel(64=>64, (16, ), FourierTransform, gelu),\n    OperatorKernel(64=>64, (16, ), FourierTransform, gelu),\n    OperatorKernel(64=>64, (16, ), FourierTransform),\n    # project back to the scalar field of interest space\n    Dense(64, 128, gelu),\n    Dense(128, 1),\n)","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"Or one can just call:","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"model = FourierNeuralOperator(\n    ch=(2, 64, 64, 64, 64, 64, 128, 1),\n    modes=(16, ),\n    σ=gelu\n)","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"And then train as a Flux model.","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"loss(𝐱, 𝐲) = l₂loss(model(𝐱), 𝐲)\nopt = Flux.Optimiser(WeightDecay(1f-4), Flux.ADAM(1f-3))\nFlux.@epochs 50 Flux.train!(loss, params(model), data, opt)","category":"page"},{"location":"copies/NeuralOperators/#DeepONet","page":"Home","title":"DeepONet","text":"","category":"section"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"# tuple of Ints for branch net architecture and then for trunk net,\n# followed by activations for branch and trunk respectively\nmodel = DeepONet((32, 64, 72), (24, 64, 72), σ, tanh)","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"Or specify branch and trunk as separate Chain from Flux and pass to DeepONet","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"branch = Chain(Dense(32, 64, σ), Dense(64, 72, σ))\ntrunk = Chain(Dense(24, 64, tanh), Dense(64, 72, tanh))\nmodel = DeepONet(branch, trunk)","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"You can again specify loss, optimization and training parameters just as you would for a simple neural network with Flux.","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"loss(xtrain, ytrain, sensor) = Flux.Losses.mse(model(xtrain, sensor), ytrain)\nevalcb() = @show(loss(xval, yval, grid))\n\nlearning_rate = 0.001\nopt = ADAM(learning_rate)\nparameters = params(model)\nFlux.@epochs 400 Flux.train!(loss, parameters, [(xtrain, ytrain, grid)], opt, cb=evalcb)","category":"page"},{"location":"copies/NeuralOperators/","page":"Home","title":"Home","text":"A more complete example using DeepONet architecture to solve Burgers' equation can be found in the examples.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#mnist","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"Training a classifier for MNIST using a neural ordinary differential equation NN-ODE on GPUs with Minibatching.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"(Step-by-step description below)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"using DiffEqFlux, DifferentialEquations, NNlib, MLDataUtils, Printf\nusing Flux.Losses: logitcrossentropy\nusing Flux.Data: DataLoader\nusing MLDatasets\nusing CUDA\nCUDA.allowscalar(false)\n\nfunction loadmnist(batchsize = bs, train_split = 0.9)\n    # Use MLDataUtils LabelEnc for natural onehot conversion\n    onehot(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw,\n                                      LabelEnc.NativeLabels(collect(0:9)))\n    # Load MNIST\n    imgs, labels_raw = MNIST.traindata();\n    # Process images into (H,W,C,BS) batches\n    x_data = Float32.(reshape(imgs, size(imgs,1), size(imgs,2), 1, size(imgs,3)))\n    y_data = onehot(labels_raw)\n    (x_train, y_train), (x_test, y_test) = stratifiedobs((x_data, y_data),\n                                                         p = train_split)\n    return (\n        # Use Flux's DataLoader to automatically minibatch and shuffle the data\n        DataLoader(gpu.(collect.((x_train, y_train))); batchsize = batchsize,\n                   shuffle = true),\n        # Don't shuffle the test data\n        DataLoader(gpu.(collect.((x_test, y_test))); batchsize = batchsize,\n                   shuffle = false)\n    )\nend\n\n# Main\nconst bs = 128\nconst train_split = 0.9\ntrain_dataloader, test_dataloader = loadmnist(bs, train_split)\n\ndown = Chain(Flux.flatten, Dense(784, 20, tanh)) |> gpu\n\nnn = Chain(Dense(20, 10, tanh),\n           Dense(10, 10, tanh),\n           Dense(10, 20, tanh)) |> gpu\n\n\nnn_ode = NeuralODE(nn, (0.f0, 1.f0), Tsit5(),\n                   save_everystep = false,\n                   reltol = 1e-3, abstol = 1e-3,\n                   save_start = false) |> gpu\n\nfc  = Chain(Dense(20, 10)) |> gpu\n\nfunction DiffEqArray_to_Array(x)\n    xarr = gpu(x)\n    return reshape(xarr, size(xarr)[1:2])\nend\n\n# Build our overall model topology\nmodel = Chain(down,\n              nn_ode,\n              DiffEqArray_to_Array,\n              fc) |> gpu;\n\n# To understand the intermediate NN-ODE layer, we can examine it's dimensionality\nimg, lab = train_dataloader.data[1][:, :, :, 1:1], train_dataloader.data[2][:, 1:1]\n\nx_d = down(img)\n\n# We can see that we can compute the forward pass through the NN topology\n# featuring an NNODE layer.\nx_m = model(img)\n\nclassify(x) = argmax.(eachcol(x))\n\nfunction accuracy(model, data; n_batches = 100)\n    total_correct = 0\n    total = 0\n    for (i, (x, y)) in enumerate(collect(data))\n        # Only evaluate accuracy for n_batches\n        i > n_batches && break\n        target_class = classify(cpu(y))\n        predicted_class = classify(cpu(model(x)))\n        total_correct += sum(target_class .== predicted_class)\n        total += length(target_class)\n    end\n    return total_correct / total\nend\n\n# burn in accuracy\naccuracy(model, train_dataloader)\n\nloss(x, y) = logitcrossentropy(model(x), y)\n\n# burn in loss\nloss(img, lab)\n\nopt = ADAM(0.05)\niter = 0\n\ncb() = begin\n    global iter += 1\n    # Monitor that the weights do infact update\n    # Every 10 training iterations show accuracy\n    if iter % 10 == 1\n        train_accuracy = accuracy(model, train_dataloader) * 100\n        test_accuracy = accuracy(model, test_dataloader;\n                                 n_batches = length(test_dataloader)) * 100\n        @printf(\"Iter: %3d || Train Accuracy: %2.3f || Test Accuracy: %2.3f\\n\",\n                iter, train_accuracy, test_accuracy)\n    end\nend\n\n# Train the NN-ODE and monitor the loss and weights.\nFlux.train!(loss, Flux.params(down, nn_ode.p, fc), train_dataloader, opt, cb = cb)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Step-by-Step-Description","page":"GPU-based MNIST Neural ODE Classifier","title":"Step-by-Step Description","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Load-Packages","page":"GPU-based MNIST Neural ODE Classifier","title":"Load Packages","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"using DiffEqFlux, DifferentialEquations, NNlib, MLDataUtils, Printf\nusing Flux.Losses: logitcrossentropy\nusing Flux.Data: DataLoader\nusing MLDatasets","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#GPU","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"A good trick used here:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"using CUDA\nCUDA.allowscalar(false)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"ensures that only optimized kernels are called when using the GPU. Additionally, the gpu function is shown as a way to translate models and data over to the GPU. Note that this function is CPU-safe, so if the GPU is disabled or unavailable, this code will fallback to the CPU.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Load-MNIST-Dataset-into-Minibatches","page":"GPU-based MNIST Neural ODE Classifier","title":"Load MNIST Dataset into Minibatches","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"The preprocessing is done in loadmnist where the raw MNIST data is split into features x_train and labels y_train by specifying batchsize bs. The function convertlabel will then transform the current labels (labels_raw) from numbers 0 to 9 (LabelEnc.NativeLabels(collect(0:9))) into one hot encoding (LabelEnc.OneOfK).","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"Features are reshaped into format [Height, Width, Color, BatchSize] or in this case [28, 28, 1, 128] meaning that every minibatch will contain 128 images with a single color channel of 28x28 pixels. The entire dataset of 60,000 images is split into the train and test dataset, ensuring a balanced ratio of labels. These splits are then passed to Flux's DataLoader. This automatically minibatches both the images and labels. Additionally, it allows us to shuffle the train dataset in each epoch while keeping the order of the test data the same.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"function loadmnist(batchsize = bs, train_split = 0.9)\n    # Use MLDataUtils LabelEnc for natural onehot conversion\n    onehot(labels_raw) = convertlabel(LabelEnc.OneOfK, labels_raw,\n                                      LabelEnc.NativeLabels(collect(0:9)))\n    # Load MNIST\n    imgs, labels_raw = MNIST.traindata();\n    # Process images into (H,W,C,BS) batches\n    x_data = Float32.(reshape(imgs, size(imgs,1), size(imgs,2), 1, size(imgs,3)))\n    y_data = onehot(labels_raw)\n    (x_train, y_train), (x_test, y_test) = stratifiedobs((x_data, y_data),\n                                                         p = train_split)\n    return (\n        # Use Flux's DataLoader to automatically minibatch and shuffle the data\n        DataLoader(gpu.(collect.((x_train, y_train))); batchsize = batchsize,\n                   shuffle = true),\n        # Don't shuffle the test data\n        DataLoader(gpu.(collect.((x_test, y_test))); batchsize = batchsize,\n                   shuffle = false)\n    )\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"and then loaded from main:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"# Main\nconst bs = 128\nconst train_split = 0.9\ntrain_dataloader, test_dataloader = loadmnist(bs, train_split)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Layers","page":"GPU-based MNIST Neural ODE Classifier","title":"Layers","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"The Neural Network requires passing inputs sequentially through multiple layers. We use Chain which allows inputs to functions to come from previous layer and sends the outputs to the next. Four different sets of layers are used here:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"down = Chain(Flux.flatten, Dense(784, 20, tanh)) |> gpu\n\nnn = Chain(Dense(20, 10, tanh),\n           Dense(10, 10, tanh),\n           Dense(10, 20, tanh)) |> gpu\n\n\nnn_ode = NeuralODE(nn, (0.f0, 1.f0), Tsit5(),\n                   save_everystep = false,\n                   reltol = 1e-3, abstol = 1e-3,\n                   save_start = false) |> gpu\n\nfc  = Chain(Dense(20, 10)) |> gpu","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"down: This layer downsamples our images into a 20 dimensional feature vector.         It takes a 28 x 28 image, flattens it, and then passes it through a fully connected         layer with tanh activation","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"nn: A 3 layers Deep Neural Network Chain with tanh activation which is used to model       our differential equation","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"nn_ode: ODE solver layer","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"fc: The final fully connected layer which maps our learned feature vector to the probability of       the feature vector of belonging to a particular class","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"|> gpu: An utility function which transfers our model to GPU, if it is available","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Array-Conversion","page":"GPU-based MNIST Neural ODE Classifier","title":"Array Conversion","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"When using NeuralODE, this function converts the ODESolution's DiffEqArray to a Matrix (CuArray), and reduces the matrix from 3 to 2 dimensions for use in the next layer.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"function DiffEqArray_to_Array(x)\n    xarr = gpu(x)\n    return reshape(xarr, size(xarr)[1:2])\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"For CPU: If this function does not automatically fallback to CPU when no GPU is present, we can change gpu(x) to Array(x).","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Build-Topology","page":"GPU-based MNIST Neural ODE Classifier","title":"Build Topology","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"Next we connect all layers together in a single chain:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"# Build our overall model topology\nmodel = Chain(down,\n              nn_ode,\n              DiffEqArray_to_Array,\n              fc) |> gpu;","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"There are a few things we can do to examine the inner workings of our neural network:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"img, lab = train_dataloader.data[1][:, :, :, 1:1], train_dataloader.data[2][:, 1:1]\n\n# To understand the intermediate NN-ODE layer, we can examine it's dimensionality\nx_d = down(img)\n\n# We can see that we can compute the forward pass through the NN topology\n# featuring an NNODE layer.\nx_m = model(img)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"This can also be built without the NN-ODE by replacing nn-ode with a simple nn:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"# We can also build the model topology without a NN-ODE\nm_no_ode = Chain(down,\n                 nn,\n                 fc) |> gpu\n\nx_m = m_no_ode(img)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Prediction","page":"GPU-based MNIST Neural ODE Classifier","title":"Prediction","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"To convert the classification back into readable numbers, we use classify which returns the prediction by taking the arg max of the output for each column of the minibatch:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"classify(x) = argmax.(eachcol(x))","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Accuracy","page":"GPU-based MNIST Neural ODE Classifier","title":"Accuracy","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"We then evaluate the accuracy on n_batches at a time through the entire network:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"function accuracy(model, data; n_batches = 100)\n    total_correct = 0\n    total = 0\n    for (i, (x, y)) in enumerate(collect(data))\n        # Only evaluate accuracy for n_batches\n        i > n_batches && break\n        target_class = classify(cpu(y))\n        predicted_class = classify(cpu(model(x)))\n        total_correct += sum(target_class .== predicted_class)\n        total += length(target_class)\n    end\n    return total_correct / total\nend\n\n# burn in accuracy\naccuracy(m, train_dataloader)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Training-Parameters","page":"GPU-based MNIST Neural ODE Classifier","title":"Training Parameters","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"Once we have our model, we can train our neural network by backpropagation using Flux.train!. This function requires Loss, Optimizer and Callback functions.","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Loss","page":"GPU-based MNIST Neural ODE Classifier","title":"Loss","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"Cross Entropy is the loss function computed here which applies a Softmax operation on the final output of our model. logitcrossentropy takes in the prediction from our model model(x) and compares it to actual output y:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"loss(x, y) = logitcrossentropy(model(x), y)\n\n# burn in loss\nloss(img, lab)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Optimizer","page":"GPU-based MNIST Neural ODE Classifier","title":"Optimizer","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"ADAM is specified here as our optimizer with a learning rate of 0.05:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"opt = ADAM(0.05)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#CallBack","page":"GPU-based MNIST Neural ODE Classifier","title":"CallBack","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"This callback function is used to print both the training and testing accuracy after 10 training iterations:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"cb() = begin\n    global iter += 1\n    # Monitor that the weights update\n    # Every 10 training iterations show accuracy\n    if iter % 10 == 1\n        train_accuracy = accuracy(model, train_dataloader) * 100\n        test_accuracy = accuracy(model, test_dataloader;\n                                 n_batches = length(test_dataloader)) * 100\n        @printf(\"Iter: %3d || Train Accuracy: %2.3f || Test Accuracy: %2.3f\\n\",\n                iter, train_accuracy, test_accuracy)\n    end\nend","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Train","page":"GPU-based MNIST Neural ODE Classifier","title":"Train","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"To train our model, we select the appropriate trainable parameters of our network with params. In our case, backpropagation is required for down, nn_ode and fc. Notice that the parameters for Neural ODE is given by nn_ode.p:","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"# Train the NN-ODE and monitor the loss and weights.\nFlux.train!(loss, Flux.params( down, nn_ode.p, fc), zip( x_train, y_train ), opt, cb = cb)","category":"page"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/#Expected-Output","page":"GPU-based MNIST Neural ODE Classifier","title":"Expected Output","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/neural_ode/mnist_neural_ode/","page":"GPU-based MNIST Neural ODE Classifier","title":"GPU-based MNIST Neural ODE Classifier","text":"Iter:   1 || Train Accuracy: 16.203 || Test Accuracy: 16.933\nIter:  11 || Train Accuracy: 64.406 || Test Accuracy: 64.900\nIter:  21 || Train Accuracy: 76.656 || Test Accuracy: 76.667\nIter:  31 || Train Accuracy: 81.758 || Test Accuracy: 81.683\nIter:  41 || Train Accuracy: 81.078 || Test Accuracy: 81.967\nIter:  51 || Train Accuracy: 83.953 || Test Accuracy: 84.417\nIter:  61 || Train Accuracy: 85.266 || Test Accuracy: 85.017\nIter:  71 || Train Accuracy: 85.938 || Test Accuracy: 86.400\nIter:  81 || Train Accuracy: 84.836 || Test Accuracy: 85.533\nIter:  91 || Train Accuracy: 86.148 || Test Accuracy: 86.583\nIter: 101 || Train Accuracy: 83.859 || Test Accuracy: 84.500\nIter: 111 || Train Accuracy: 86.227 || Test Accuracy: 86.617\nIter: 121 || Train Accuracy: 87.508 || Test Accuracy: 87.200\nIter: 131 || Train Accuracy: 86.227 || Test Accuracy: 85.917\nIter: 141 || Train Accuracy: 84.453 || Test Accuracy: 84.850\nIter: 151 || Train Accuracy: 86.063 || Test Accuracy: 85.650\nIter: 161 || Train Accuracy: 88.375 || Test Accuracy: 88.033\nIter: 171 || Train Accuracy: 87.398 || Test Accuracy: 87.683\nIter: 181 || Train Accuracy: 88.070 || Test Accuracy: 88.350\nIter: 191 || Train Accuracy: 86.836 || Test Accuracy: 87.150\nIter: 201 || Train Accuracy: 89.266 || Test Accuracy: 88.583\nIter: 211 || Train Accuracy: 86.633 || Test Accuracy: 85.550\nIter: 221 || Train Accuracy: 89.313 || Test Accuracy: 88.217\nIter: 231 || Train Accuracy: 88.641 || Test Accuracy: 89.417\nIter: 241 || Train Accuracy: 88.617 || Test Accuracy: 88.550\nIter: 251 || Train Accuracy: 88.211 || Test Accuracy: 87.950\nIter: 261 || Train Accuracy: 87.742 || Test Accuracy: 87.317\nIter: 271 || Train Accuracy: 89.070 || Test Accuracy: 89.217\nIter: 281 || Train Accuracy: 89.703 || Test Accuracy: 89.067\nIter: 291 || Train Accuracy: 88.484 || Test Accuracy: 88.250\nIter: 301 || Train Accuracy: 87.898 || Test Accuracy: 88.367\nIter: 311 || Train Accuracy: 88.438 || Test Accuracy: 88.633\nIter: 321 || Train Accuracy: 88.664 || Test Accuracy: 88.567\nIter: 331 || Train Accuracy: 89.906 || Test Accuracy: 89.883\nIter: 341 || Train Accuracy: 88.883 || Test Accuracy: 88.667\nIter: 351 || Train Accuracy: 89.609 || Test Accuracy: 89.283\nIter: 361 || Train Accuracy: 89.516 || Test Accuracy: 89.117\nIter: 371 || Train Accuracy: 89.898 || Test Accuracy: 89.633\nIter: 381 || Train Accuracy: 89.055 || Test Accuracy: 89.017\nIter: 391 || Train Accuracy: 89.445 || Test Accuracy: 89.467\nIter: 401 || Train Accuracy: 89.156 || Test Accuracy: 88.250\nIter: 411 || Train Accuracy: 88.977 || Test Accuracy: 89.083\nIter: 421 || Train Accuracy: 90.109 || Test Accuracy: 89.417","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/#Custom-Component","page":"Custom Components","title":"Custom Component","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"In this tutorial the creation of a custom component is demonstrated via the Chua's circuit. The circuit is a simple circuit that shows chaotic behaviour.  Except for a non-linear resistor every other component already is part of ModelingToolkitStandardLibrary.Electrical.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"First we need to make some imports.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"using ModelingToolkit\nusing ModelingToolkitStandardLibrary.Electrical\nusing ModelingToolkitStandardLibrary.Electrical: OnePort\nusing OrdinaryDiffEq\nusing IfElse: ifelse\nusing Plots","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/#Custom-Component-2","page":"Custom Components","title":"Custom Component","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"Now the custom component can be defined. The Modelica implementation of the NonlinearResistor looks as follows:","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"model NonlinearResistor \"Chua's resistor\"\n  extends Interfaces.OnePort;\n\n  parameter SI.Conductance Ga \"conductance in inner voltage range\";\n  parameter SI.Conductance Gb \"conductance in outer voltage range\";\n  parameter SI.Voltage Ve \"inner voltage range limit\";\nequation \n  i = if (v < -Ve) then Gb*(v + Ve) - Ga*Ve else if (v > Ve) then Gb*(v - Ve) + Ga*Ve else Ga*v;\nend NonlinearResistor;","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"this can almost be directly translate it to the syntax of ModelingToolkit.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"@parameters t\n\nfunction NonlinearResistor(;name, Ga, Gb, Ve)\n    @named oneport = OnePort()\n    @unpack v, i = oneport\n    pars = @parameters Ga=Ga Gb=Gb Ve=Ve\n    eqs = [\n        i ~ ifelse(v < -Ve, \n                Gb*(v + Ve) - Ga*Ve, \n                ifelse(v > Ve, \n                    Gb*(v - Ve) + Ga*Ve, \n                    Ga*v,\n                ),\n            )\n    ]\n    extend(ODESystem(eqs, t, [], pars; name=name), oneport)\nend","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/#Explanation","page":"Custom Components","title":"Explanation","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"All components in ModelingToolkit are created via a function that serves as the constructor and returns some form of system, in this case a ODESystem. Since the non-linear resistor is essentially a standard electrical component with two ports, we can extend from the OnePort component of the library.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"@named oneport = OnePort()","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"This creates a OnePort with the name = :oneport. For easier notation we can unpack the states of the component","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"@unpack v, i = oneport","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"It might be a good idea to create parameters for the constants of the NonlinearResistor.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"pars = @parameters Ga=Ga Gb=Gb Ve=Ve","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"The syntax looks funny but it simply creates symbolic parameters with the name Ga where it's default value is set from the function's argument Ga. While this is not strictly necessary it allows the user to remake the problem easily with different parameters or allow for auto-tuning or parameter optimization without having to do all costly steps that may be involved with building and simplifying a model. The non-linear (in this case piece-wise constant) equation for the current can be implemented using IfElse.ifelse. Finally, the created oneport component is extended with the created equations and parameters. In this case no extra state variables are added, hence an empty vector is supplied. The independent variable t needs to be supplied as second argument.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"extend(ODESystem(eqs, t, [], pars; name=name), oneport)","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/#Building-the-Model","page":"Custom Components","title":"Building the Model","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"The final model can now be created with the components from the library and the new custom component.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"@named L = Inductor(L=18)\n@named Ro = Resistor(R=12.5e-3)\n@named G = Conductor(G=0.565)\n@named C1 = Capacitor(C=10, v_start=4)\n@named C2 = Capacitor(C=100)\n@named Nr = NonlinearResistor(\n    Ga = -0.757576,\n    Gb = -0.409091,\n    Ve=1)\n@named Gnd = Ground()\n\nconnections = [\n    connect(L.p, G.p)\n    connect(G.n, Nr.p)\n    connect(Nr.n, Gnd.g)\n    connect(C1.p, G.n)\n    connect(L.n, Ro.p)\n    connect(G.p, C2.p)\n    connect(C1.n, Gnd.g)\n    connect(C2.n, Gnd.g)\n    connect(Ro.n, Gnd.g)\n]\n\n@named model = ODESystem(connections, t, systems=[L, Ro, G, C1, C2, Nr])","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/#Simulating-the-Model","page":"Custom Components","title":"Simulating the Model","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"Now the model can be simulated. First structural_simplify is called on the model and a ODEProblem is build from the result. Since the initial voltage of the first capacitor was already specified via v_start, no initial condition is given and an empty pair is supplied.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"sys = structural_simplify(model)\nprob = ODEProblem(sys, Pair[], (0, 5e4), saveat=0.01)\nsol = solve(prob, Rodas4())\n\nPlots.plot(sol[C1.v], sol[C2.v], title=\"Chaotic Attractor\", label=\"\", ylabel=\"C1 Voltage in V\", xlabel=\"C2 Voltage in V\")\nPlots.savefig(\"chua_phase_plane.png\")\n\nPlots.plot(sol; vars=[C1.v, C2.v, L.i], labels=[\"C1 Voltage in V\" \"C1 Voltage in V\" \"Inductor Current in A\"])\nPlots.savefig(\"chua.png\")","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"(Image: Time series plot of C1.v, C2.v and L.i)","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/custom_component/","page":"Custom Components","title":"Custom Components","text":"(Image: Phase plane plot of C1.v and C2.v)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Controlling-Stochastic-Differential-Equations","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"In this tutorial, we show how to use DiffEqFlux to control the time evolution of a system described by a stochastic differential equations (SDE). Specifically, we consider a continuously monitored qubit described by an SDE in the Ito sense with multiplicative scalar noise (see [1] for a reference):","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"dψ = b(ψ(t) Ω(t))ψ(t) dt + σ(ψ(t))ψ(t) dW_t ","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We use a predictive model to map the quantum state of the qubit, ψ(t), at each time to the control parameter Ω(t) which rotates the quantum state about the x-axis of the Bloch sphere to ultimately prepare and stabilize the qubit in the excited state.","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Copy-Pasteable-Code","page":"Controlling Stochastic Differential Equations","title":"Copy-Pasteable Code","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"Before getting to the explanation, here's some code to start with. We will follow a full explanation of the definition and training process:","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# load packages\nusing DiffEqFlux\nusing StochasticDiffEq, DiffEqCallbacks, DiffEqNoiseProcess\nusing Statistics, LinearAlgebra, Random\nusing Plots\n\n\n#################################################\nlr = 0.01f0\nepochs = 100\n\nnumtraj = 16 # number of trajectories in parallel simulations for training\nnumtrajplot = 32 # .. for plotting\n\n# time range for the solver\ndt = 0.0005f0\ntinterval = 0.05f0\ntstart = 0.0f0\nNintervals = 20 # total number of intervals, total time = t_interval*Nintervals\ntspan = (tstart,tinterval*Nintervals)\nts = Array(tstart:dt:(Nintervals*tinterval+dt)) # time array for noise grid\n\n# Hamiltonian parameters\nΔ = 20.0f0\nΩmax = 10.0f0 # control parameter (maximum amplitude)\nκ = 0.3f0\n\n# loss hyperparameters\nC1 = Float32(1.0)  # evolution state fidelity\n\nstruct Parameters{flType,intType,tType}\n  lr::flType\n  epochs::intType\n  numtraj::intType\n  numtrajplot::intType\n  dt::flType\n  tinterval::flType\n  tspan::tType\n  Nintervals::intType\n  ts::Vector{flType}\n  Δ::flType\n  Ωmax::flType\n  κ::flType\n  C1::flType\nend\n\nmyparameters = Parameters{typeof(dt),typeof(numtraj), typeof(tspan)}(\n  lr, epochs, numtraj, numtrajplot, dt, tinterval, tspan, Nintervals, ts,\n  Δ, Ωmax, κ, C1)\n\n################################################\n# Define Neural Network\n\n# state-aware\nnn = FastChain(\n  FastDense(4, 32, relu),\n  FastDense(32, 1, tanh))\n\np_nn = initial_params(nn) # random initial parameters\n\n\n###############################################\n# initial state anywhere on the Bloch sphere\nfunction prepare_initial(dt, n_par)\n  # shape 4 x n_par\n  # input number of parallel realizations and dt for type inference\n  # random position on the Bloch sphere\n  theta = acos.(2*rand(typeof(dt),n_par).-1)  # uniform sampling for cos(theta) between -1 and 1\n  phi = rand(typeof(dt),n_par)*2*pi  # uniform sampling for phi between 0 and 2pi\n  # real and imaginary parts ceR, cdR, ceI, cdI\n  u0 = [cos.(theta/2), sin.(theta/2).*cos.(phi), false*theta, sin.(theta/2).*sin.(phi)]\n  return vcat(transpose.(u0)...) # build matrix\nend\n\n# target state\n# ψtar = |up>\n\nu0 = prepare_initial(myparameters.dt, myparameters.numtraj)\n\n###############################################\n# Define SDE\n\nfunction qubit_drift!(du,u,p,t)\n  # expansion coefficients |Ψ> = ce |e> + cd |d>\n  ceR, cdR, ceI, cdI = u # real and imaginary parts\n\n  # Δ: atomic frequency\n  # Ω: Rabi frequency for field in x direction\n  # κ: spontaneous emission\n  Δ, Ωmax, κ = p[end-2:end]\n  nn_weights = p[1:end-3]\n  Ω = (nn(u, nn_weights).*Ωmax)[1]\n\n  @inbounds begin\n    du[1] = 1//2*(ceI*Δ-ceR*κ+cdI*Ω)\n    du[2] = -cdI*Δ/2 + 1*ceR*(cdI*ceI+cdR*ceR)*κ+ceI*Ω/2\n    du[3] = 1//2*(-ceR*Δ-ceI*κ-cdR*Ω)\n    du[4] = cdR*Δ/2 + 1*ceI*(cdI*ceI+cdR*ceR)*κ-ceR*Ω/2\n  end\n  return nothing\nend\n\nfunction qubit_diffusion!(du,u,p,t)\n  ceR, cdR, ceI, cdI = u # real and imaginary parts\n\n  κ = p[end]\n\n  du .= false\n\n  @inbounds begin\n    #du[1] = zero(ceR)\n    du[2] += sqrt(κ)*ceR\n    #du[3] = zero(ceR)\n    du[4] += sqrt(κ)*ceI\n  end\n  return nothing\nend\n\n# normalization callback\ncondition(u,t,integrator) = true\nfunction affect!(integrator)\n  integrator.u=integrator.u/norm(integrator.u)\nend\ncb = DiscreteCallback(condition,affect!,save_positions=(false,false))\n\nCreateGrid(t,W1) = NoiseGrid(t,W1)\nZygote.@nograd CreateGrid #avoid taking grads of this function\n\n# set scalar random process\nW = sqrt(myparameters.dt)*randn(typeof(myparameters.dt),size(myparameters.ts)) #for 1 trajectory\nW1 = cumsum([zero(myparameters.dt); W[1:end-1]], dims=1)\nNG = CreateGrid(myparameters.ts,W1)\n\n# get control pulses\np_all = [p_nn; myparameters.Δ; myparameters.Ωmax; myparameters.κ]\n# define SDE problem\nprob = SDEProblem{true}(qubit_drift!, qubit_diffusion!, vec(u0[:,1]), myparameters.tspan, p_all,\n   callback=cb, noise=NG\n   )\n\n#########################################\n# compute loss\nfunction g(u,p,t)\n  ceR = @view u[1,:,:]\n  cdR = @view u[2,:,:]\n  ceI = @view u[3,:,:]\n  cdI = @view u[4,:,:]\n  p[1]*mean((cdR.^2 + cdI.^2) ./ (ceR.^2 + cdR.^2 + ceI.^2 + cdI.^2))\nend\n\n\nfunction loss(p, u0, prob::SDEProblem, myparameters::Parameters;\n\t alg=EM(), sensealg = BacksolveAdjoint()\n\t )\n  pars = [p; myparameters.Δ; myparameters.Ωmax; myparameters.κ]\n\n  function prob_func(prob, i, repeat)\n    # prepare initial state and applied control pulse\n    u0tmp = deepcopy(vec(u0[:,i]))\n    W = sqrt(myparameters.dt)*randn(typeof(myparameters.dt),size(myparameters.ts)) #for 1 trajectory\n    W1 = cumsum([zero(myparameters.dt); W[1:end-1]], dims=1)\n    NG = CreateGrid(myparameters.ts,W1)\n\n    remake(prob,\n      p = pars,\n      u0 = u0tmp,\n      callback = cb,\n      noise=NG)\n  end\n\n  ensembleprob = EnsembleProblem(prob,\n   prob_func = prob_func,\n   safetycopy = true\n   )\n\n  _sol = solve(ensembleprob, alg, EnsembleThreads(),\n    sensealg=sensealg,\n    saveat=myparameters.tinterval,\n    dt=myparameters.dt,\n    adaptive=false,\n    trajectories=myparameters.numtraj, batch_size=myparameters.numtraj)\n  A = convert(Array,_sol)\n\n  loss = g(A,[myparameters.C1],nothing)\n\n  return loss\nend\n\n#########################################\n# visualization -- run for new batch\nfunction visualize(p, u0, prob::SDEProblem, myparameters::Parameters;\n   alg=EM(),\n   )\n  pars = [p; myparameters.Δ; myparameters.Ωmax; myparameters.κ]\n\n  function prob_func(prob, i, repeat)\n    # prepare initial state and applied control pulse\n    u0tmp = deepcopy(vec(u0[:,i]))\n    W = sqrt(myparameters.dt)*randn(typeof(myparameters.dt),size(myparameters.ts)) #for 1 trajectory\n    W1 = cumsum([zero(myparameters.dt); W[1:end-1]], dims=1)\n    NG = CreateGrid(myparameters.ts,W1)\n\n    remake(prob,\n      p = pars,\n      u0 = u0tmp,\n      callback = cb,\n      noise=NG)\n  end\n\n  ensembleprob = EnsembleProblem(prob,\n   prob_func = prob_func,\n   safetycopy = true\n   )\n\n  u = solve(ensembleprob, alg, EnsembleThreads(),\n    saveat=myparameters.tinterval,\n    dt=myparameters.dt,\n    adaptive=false, #abstol=1e-6, reltol=1e-6,\n    trajectories=myparameters.numtrajplot, batch_size=myparameters.numtrajplot)\n\n\n  ceR = @view u[1,:,:]\n  cdR = @view u[2,:,:]\n  ceI = @view u[3,:,:]\n  cdI = @view u[4,:,:]\n  infidelity = @. (cdR^2 + cdI^2) / (ceR^2 + cdR^2 + ceI^2 + cdI^2)\n  meaninfidelity = mean(infidelity)\n  loss = myparameters.C1*meaninfidelity\n\n  @info \"Loss: \" loss\n\n  fidelity = @. (ceR^2 + ceI^2) / (ceR^2 + cdR^2 + ceI^2 + cdI^2)\n\n  mf = mean(fidelity, dims=2)[:]\n  sf = std(fidelity, dims=2)[:]\n\n  pl1 = plot(0:myparameters.Nintervals, mf,\n    ribbon = sf,\n    ylim = (0,1), xlim = (0,myparameters.Nintervals),\n    c=1, lw = 1.5, xlabel = \"steps i\", ylabel=\"Fidelity\", legend=false)\n\n  pl = plot(pl1, legend = false, size=(400,360))\n  return pl, loss\nend\n\n###################################\n# training loop\n@info \"Start Training..\"\n\n# optimize the parameters for a few epochs with ADAM on time span Nint\nopt = ADAM(myparameters.lr)\nlist_plots = []\nlosses = []\nfor epoch in 1:myparameters.epochs\n  println(\"epoch: $epoch / $(myparameters.epochs)\")\n  local u0 = prepare_initial(myparameters.dt, myparameters.numtraj)\n  _dy, back = @time Zygote.pullback(p -> loss(p, u0, prob, myparameters,\n    sensealg=BacksolveAdjoint()\n  ), p_nn)\n  @show _dy\n  gs = @time back(one(_dy))[1]\n  # store loss\n  push!(losses, _dy)\n  if (epoch % myparameters.epochs == 0) || (epoch == 1)\n    # plot/store every xth epoch\n    @info \"plotting..\"\n    local u0 = prepare_initial(myparameters.dt, myparameters.numtrajplot)\n    pl, test_loss = visualize(p_nn, u0, prob, myparameters)\n    println(\"Loss (epoch: $epoch): $test_loss\")\n    display(pl)\n    push!(list_plots, pl)\n  end\n  Flux.Optimise.update!(opt, p_nn, gs)\n  println(\"\")\nend\n\n# plot training loss\npl = plot(losses, lw = 1.5, xlabel = \"some epochs\", ylabel=\"Loss\", legend=false)\n\nsavefig(display(list_plots[end], \"fidelity.png\")","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"Output:","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"[ Info: Start Training..\nepoch: 1 / 100\n38.519219 seconds (85.38 M allocations: 4.316 GiB, 3.37% gc time)\n_dy = 0.63193643f0\n 26.232970 seconds (122.33 M allocations: 5.899 GiB, 7.26% gc time)\n ...\n\n[ Info: plotting..\n┌ Info: Loss:\n└   loss = 0.11777343f0\nLoss (epoch: 100): 0.11777343","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Step-by-step-description","page":"Controlling Stochastic Differential Equations","title":"Step-by-step description","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Load-packages","page":"Controlling Stochastic Differential Equations","title":"Load packages","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"using DiffEqFlux\nusing StochasticDiffEq, DiffEqCallbacks, DiffEqNoiseProcess\nusing Statistics, LinearAlgebra, Random\nusing Plots","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Parameters","page":"Controlling Stochastic Differential Equations","title":"Parameters","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We define the parameters of the qubit and hyper-parameters of the training process.","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"lr = 0.01f0\nepochs = 100\n\nnumtraj = 16 # number of trajectories in parallel simulations for training\nnumtrajplot = 32 # .. for plotting\n\n# time range for the solver\ndt = 0.0005f0\ntinterval = 0.05f0\ntstart = 0.0f0\nNintervals = 20 # total number of intervals, total time = t_interval*Nintervals\ntspan = (tstart,tinterval*Nintervals)\nts = Array(tstart:dt:(Nintervals*tinterval+dt)) # time array for noise grid\n\n# Hamiltonian parameters\nΔ = 20.0f0\nΩmax = 10.0f0 # control parameter (maximum amplitude)\nκ = 0.3f0\n\n# loss hyperparameters\nC1 = Float32(1.0)  # evolution state fidelity\n\nstruct Parameters{flType,intType,tType}\n  lr::flType\n  epochs::intType\n  numtraj::intType\n  numtrajplot::intType\n  dt::flType\n  tinterval::flType\n  tspan::tType\n  Nintervals::intType\n  ts::Vector{flType}\n  Δ::flType\n  Ωmax::flType\n  κ::flType\n  C1::flType\nend\n\nmyparameters = Parameters{typeof(dt),typeof(numtraj), typeof(tspan)}(\n  lr, epochs, numtraj, numtrajplot, dt, tinterval, tspan, Nintervals, ts,\n  Δ, Ωmax, κ, C1)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"In plain terms, the quantities that were defined are:","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"lr = learning rate of the optimizer\nepochs = number of epochs in the training process\nnumtraj = number of simulated trajectories in the training process\nnumtrajplot = number of simulated trajectories to visualize the performance\ndt = time step for solver (initial dt if adaptive)\ntinterval = time spacing between checkpoints\ntspan = time span\nNintervals = number of checkpoints\nts = discretization of the entire time interval, used for NoiseGrid\nΔ = detuning between the qubit and the laser\nΩmax = maximum frequency of the control laser\nκ = decay rate\nC1 = loss function hyper-parameter","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Controller","page":"Controlling Stochastic Differential Equations","title":"Controller","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We use a neural network to control the parameter Ω(t). Alternatively, one could also, e.g., use tensor layers.","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# state-aware\nnn = FastChain(\n  FastDense(4, 32, relu),\n  FastDense(32, 1, tanh))\n\np_nn = initial_params(nn) # random initial parameters","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Initial-state","page":"Controlling Stochastic Differential Equations","title":"Initial state","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We prepare n_par initial states, uniformly distributed over the Bloch sphere. To avoid complex numbers in our simulations, we split the state of the qubit","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"  ψ(t) = c_e(t) (10) + c_d(t) (01)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"into its real and imaginary part.","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# initial state anywhere on the Bloch sphere\nfunction prepare_initial(dt, n_par)\n  # shape 4 x n_par\n  # input number of parallel realizations and dt for type inference\n  # random position on the Bloch sphere\n  theta = acos.(2*rand(typeof(dt),n_par).-1)  # uniform sampling for cos(theta) between -1 and 1\n  phi = rand(typeof(dt),n_par)*2*pi  # uniform sampling for phi between 0 and 2pi\n  # real and imaginary parts ceR, cdR, ceI, cdI\n  u0 = [cos.(theta/2), sin.(theta/2).*cos.(phi), false*theta, sin.(theta/2).*sin.(phi)]\n  return vcat(transpose.(u0)...) # build matrix\nend\n\n# target state\n# ψtar = |e>\n\nu0 = prepare_initial(myparameters.dt, myparameters.numtraj)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Defining-the-SDE","page":"Controlling Stochastic Differential Equations","title":"Defining the SDE","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We define the drift and diffusion term of the qubit. The SDE doesn't preserve the norm of the quantum state. To ensure the normalization of the state, we add a DiscreteCallback after each time step. Further, we use a NoiseGrid from the DiffEqNoiseProcess package, as one possibility to simulate a 1D Brownian motion. Note that the NN is placed directly into the drift function, thus the control parameter Ω is continuously updated.","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# Define SDE\nfunction qubit_drift!(du,u,p,t)\n  # expansion coefficients |Ψ> = ce |e> + cd |d>\n  ceR, cdR, ceI, cdI = u # real and imaginary parts\n\n  # Δ: atomic frequency\n  # Ω: Rabi frequency for field in x direction\n  # κ: spontaneous emission\n  Δ, Ωmax, κ = p[end-2:end]\n  nn_weights = p[1:end-3]\n  Ω = (nn(u, nn_weights).*Ωmax)[1]\n\n  @inbounds begin\n    du[1] = 1//2*(ceI*Δ-ceR*κ+cdI*Ω)\n    du[2] = -cdI*Δ/2 + 1*ceR*(cdI*ceI+cdR*ceR)*κ+ceI*Ω/2\n    du[3] = 1//2*(-ceR*Δ-ceI*κ-cdR*Ω)\n    du[4] = cdR*Δ/2 + 1*ceI*(cdI*ceI+cdR*ceR)*κ-ceR*Ω/2\n  end\n  return nothing\nend\n\nfunction qubit_diffusion!(du,u,p,t)\n  ceR, cdR, ceI, cdI = u # real and imaginary parts\n\n  κ = p[end]\n\n  du .= false\n\n  @inbounds begin\n    #du[1] = zero(ceR)\n    du[2] += sqrt(κ)*ceR\n    #du[3] = zero(ceR)\n    du[4] += sqrt(κ)*ceI\n  end\n  return nothing\nend\n\n# normalization callback\ncondition(u,t,integrator) = true\nfunction affect!(integrator)\n  integrator.u=integrator.u/norm(integrator.u)\nend\ncb = DiscreteCallback(condition,affect!,save_positions=(false,false))\n\nCreateGrid(t,W1) = NoiseGrid(t,W1)\nZygote.@nograd CreateGrid #avoid taking grads of this function\n\n# set scalar random process\nW = sqrt(myparameters.dt)*randn(typeof(myparameters.dt),size(myparameters.ts)) #for 1 trajectory\nW1 = cumsum([zero(myparameters.dt); W[1:end-1]], dims=1)\nNG = CreateGrid(myparameters.ts,W1)\n\n# get control pulses\np_all = [p_nn; myparameters.Δ; myparameters.Ωmax; myparameters.κ]\n# define SDE problem\nprob = SDEProblem{true}(qubit_drift!, qubit_diffusion!, vec(u0[:,1]), myparameters.tspan, p_all,\n   callback=cb, noise=NG\n   )","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Compute-loss-function","page":"Controlling Stochastic Differential Equations","title":"Compute loss function","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We'd like to prepare the excited state of the qubit. An appropriate choice for the loss function is the infidelity of the state ψ(t) with respect to the excited state. We create a parallelized EnsembleProblem, where the prob_func creates a new NoiseGrid for every trajectory and loops over the initial states. The number of parallel trajectories and the used batch size can be tuned by the kwargs trajectories=.. and batchsize=.. in the solve call. See also the parallel ensemble simulation docs for a description of the available ensemble algorithms. To optimize only the parameters of the neural network, we use pars = [p; myparameters.Δ; myparameters.Ωmax; myparameters.κ]","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# compute loss\nfunction g(u,p,t)\n  ceR = @view u[1,:,:]\n  cdR = @view u[2,:,:]\n  ceI = @view u[3,:,:]\n  cdI = @view u[4,:,:]\n  p[1]*mean((cdR.^2 + cdI.^2) ./ (ceR.^2 + cdR.^2 + ceI.^2 + cdI.^2))\nend\n\n\nfunction loss(p, u0, prob::SDEProblem, myparameters::Parameters;\n\t alg=EM(), sensealg = BacksolveAdjoint()\n\t )\n  pars = [p; myparameters.Δ; myparameters.Ωmax; myparameters.κ]\n\n  function prob_func(prob, i, repeat)\n    # prepare initial state and applied control pulse\n    u0tmp = deepcopy(vec(u0[:,i]))\n    W = sqrt(myparameters.dt)*randn(typeof(myparameters.dt),size(myparameters.ts)) #for 1 trajectory\n    W1 = cumsum([zero(myparameters.dt); W[1:end-1]], dims=1)\n    NG = CreateGrid(myparameters.ts,W1)\n\n    remake(prob,\n      p = pars,\n      u0 = u0tmp,\n      callback = cb,\n      noise=NG)\n  end\n\n  ensembleprob = EnsembleProblem(prob,\n   prob_func = prob_func,\n   safetycopy = true\n   )\n\n  _sol = solve(ensembleprob, alg, EnsembleThreads(),\n    sensealg=sensealg,\n    saveat=myparameters.tinterval,\n    dt=myparameters.dt,\n    adaptive=false,\n    trajectories=myparameters.numtraj, batch_size=myparameters.numtraj)\n  A = convert(Array,_sol)\n\n  loss = g(A,[myparameters.C1],nothing)\n\n  return loss\nend","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Visualization","page":"Controlling Stochastic Differential Equations","title":"Visualization","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"To visualize the performance of the controller, we plot the mean value and standard deviation of the fidelity of a bunch of trajectories (myparameters.numtrajplot) as a function of the time steps at which loss values are computed.","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"function visualize(p, u0, prob::SDEProblem, myparameters::Parameters;\n   alg=EM(),\n   )\n  pars = [p; myparameters.Δ; myparameters.Ωmax; myparameters.κ]\n\n  function prob_func(prob, i, repeat)\n    # prepare initial state and applied control pulse\n    u0tmp = deepcopy(vec(u0[:,i]))\n    W = sqrt(myparameters.dt)*randn(typeof(myparameters.dt),size(myparameters.ts)) #for 1 trajectory\n    W1 = cumsum([zero(myparameters.dt); W[1:end-1]], dims=1)\n    NG = CreateGrid(myparameters.ts,W1)\n\n    remake(prob,\n      p = pars,\n      u0 = u0tmp,\n      callback = cb,\n      noise=NG)\n  end\n\n  ensembleprob = EnsembleProblem(prob,\n   prob_func = prob_func,\n   safetycopy = true\n   )\n\n  u = solve(ensembleprob, alg, EnsembleThreads(),\n    saveat=myparameters.tinterval,\n    dt=myparameters.dt,\n    adaptive=false, #abstol=1e-6, reltol=1e-6,\n    trajectories=myparameters.numtrajplot, batch_size=myparameters.numtrajplot)\n\n\n  ceR = @view u[1,:,:]\n  cdR = @view u[2,:,:]\n  ceI = @view u[3,:,:]\n  cdI = @view u[4,:,:]\n  infidelity = @. (cdR^2 + cdI^2) / (ceR^2 + cdR^2 + ceI^2 + cdI^2)\n  meaninfidelity = mean(infidelity)\n  loss = myparameters.C1*meaninfidelity\n\n  @info \"Loss: \" loss\n\n  fidelity = @. (ceR^2 + ceI^2) / (ceR^2 + cdR^2 + ceI^2 + cdI^2)\n\n  mf = mean(fidelity, dims=2)[:]\n  sf = std(fidelity, dims=2)[:]\n\n  pl1 = plot(0:myparameters.Nintervals, mf,\n    ribbon = sf,\n    ylim = (0,1), xlim = (0,myparameters.Nintervals),\n    c=1, lw = 1.5, xlabel = \"steps i\", ylabel=\"Fidelity\", legend=false)\n\n  pl = plot(pl1, legend = false, size=(400,360))\n  return pl, loss\nend","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#Training","page":"Controlling Stochastic Differential Equations","title":"Training","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"We use the ADAM optimizer to optimize the parameters of the neural network. In each epoch, we draw new initial quantum states, compute the forward evolution, and, subsequently, the gradients of the loss function with respect to the parameters of the neural network. sensealg allows one to switch between the different sensitivity modes. InterpolatingAdjoint and BacksolveAdjoint are the two possible continuous adjoint sensitivity methods. The necessary correction between Ito and Stratonovich integrals is computed under the hood in the DiffEqSensitivity package.","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"# optimize the parameters for a few epochs with ADAM on time span Nint\nopt = ADAM(myparameters.lr)\nlist_plots = []\nlosses = []\nfor epoch in 1:myparameters.epochs\n  println(\"epoch: $epoch / $(myparameters.epochs)\")\n  local u0 = prepare_initial(myparameters.dt, myparameters.numtraj)\n  _dy, back = @time Zygote.pullback(p -> loss(p, u0, prob, myparameters,\n    sensealg=BacksolveAdjoint()\n  ), p_nn)\n  @show _dy\n  gs = @time back(one(_dy))[1]\n  # store loss\n  push!(losses, _dy)\n  if (epoch % myparameters.epochs == 0) || (epoch == 1)\n    # plot/store every xth epoch\n    @info \"plotting..\"\n    local u0 = prepare_initial(myparameters.dt, myparameters.numtrajplot)\n    pl, test_loss = visualize(p_nn, u0, prob, myparameters)\n    println(\"Loss (epoch: $epoch): $test_loss\")\n    display(pl)\n    push!(list_plots, pl)\n  end\n  Flux.Optimise.update!(opt, p_nn, gs)\n  println(\"\")\nend","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"(Image: Evolution of the fidelity as a function of time)","category":"page"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/#References","page":"Controlling Stochastic Differential Equations","title":"References","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/optimal_control/SDE_control/","page":"Controlling Stochastic Differential Equations","title":"Controlling Stochastic Differential Equations","text":"[1] Schäfer, Frank, Pavel Sekatski, Martin Koppenhöfer, Christoph Bruder, and Michal Kloc. \"Control of stochastic quantum dynamics by differentiable programming.\" Machine Learning: Science and Technology 2, no. 3 (2021): 035004.","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/#Regression-Method","page":"Regression Method","title":"Regression Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"struct RegressionGSA <: GSAMethod\n    rank::Bool = false\nend","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"RegressionGSA has the following keyword arguments:","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"rank: flag which determines whether to calculate the rank coefficients. Defaults to false.","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"It returns a RegressionGSAResult, which contains the pearson, standard_regression, and partial_correlation coefficients, described below. If rank is true, then it also contains the ranked versions of these coefficients. Note that the ranked version of the pearson coefficient is also known as the Spearman coefficient, which is returned here as the pearson_rank coefficient.","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"For multi-variable models, the coefficient for the X_i input variable relating to the Y_j output variable is given as the [i, j] entry in the corresponding returned matrix.","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/#Regression-Details","page":"Regression Method","title":"Regression Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"It is possible to fit a linear model explaining the behavior of Y given the values of X, provided that the sample size n is sufficiently large (at least n > d).","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"The measures provided for this analysis by us in GlobalSensitivity.jl are","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"a) Pearson Correlation Coefficient:","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"r = fracsum_i=1^n (x_i - overlinex)(y_i - overliney)sqrtsum_i=1^n (x_i - overlinex)^2(y_i - overliney)^2","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"b) Standard Regression Coefficient (SRC):","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"SRC_j = beta_j sqrtfracVar(X_j)Var(Y)","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"where beta_j is the linear regression coefficient associated to X_j. This is also known as a sigma-normalized derivative.","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"c) Partial Correlation Coefficient (PCC):","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"PCC_j = rho(X_j - hatX_-jY_j - hatY_-j)","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"where hatX_-j is the prediction of the linear model, expressing X_j with respect to the other inputs and hatY_-j is the prediction of the linear model where X_j is absent. PCC measures the sensitivity of Y to X_j when the effects of the other inputs have been canceled.","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"If rank is set to true, then the rank coefficients are also calculated.","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/#API","page":"Regression Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"function gsa(f, method::RegressionGSA, p_range::AbstractVector; samples::Int = 1000, batch::Bool = false, kwargs...)","category":"page"},{"location":"copies/GlobalSensitivity/methods/regression/#Example","page":"Regression Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/regression/","page":"Regression Method","title":"Regression Method","text":"using GlobalSensitivity\n\nfunction linear_batch(X)\n    A= 7\n    B= 0.1\n    @. A*X[1,:]+B*X[2,:]\nend\nfunction linear(X)\n    A= 7\n    B= 0.1\n    A*X[1]+B*X[2]\nend\n\np_range = [[-1, 1], [-1, 1]]\nreg = gsa(linear_batch, RegressionGSA(), p_range; batch = true)\n\nreg = gsa(linear, RegressionGSA(), p_range; batch = false)\nreg = gsa(linear, RegressionGSA(true), p_range; batch = false) #with rank coefficients","category":"page"},{"location":"copies/ModelingToolkit/#ModelingToolkit.jl:-High-Performance-Symbolic-Numeric-Equation-Based-Modeling","page":"Home","title":"ModelingToolkit.jl: High-Performance Symbolic-Numeric Equation-Based Modeling","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"ModelingToolkit.jl is a modeling language for high-performance symbolic-numeric computation in scientific computing and scientific machine learning. It then mixes ideas from symbolic computational algebra systems with causal and acausal equation-based modeling frameworks to give an extendable and parallel modeling system. It allows for users to give a high-level description of a model for symbolic preprocessing to analyze and enhance the model. Automatic transformations, such as index reduction, can be applied to the model before solving in order to make it easily handle equations would could not be solved when modeled without symbolic intervention.","category":"page"},{"location":"copies/ModelingToolkit/#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"To install ModelingToolkit.jl, use the Julia package manager:","category":"page"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"ModelingToolkit\")","category":"page"},{"location":"copies/ModelingToolkit/#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"If you use ModelingToolkit in your work, please cite the following:","category":"page"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"@misc{ma2021modelingtoolkit,\n      title={ModelingToolkit: A Composable Graph Transformation System For Equation-Based Modeling},\n      author={Yingbo Ma and Shashi Gowda and Ranjan Anantharaman and Chris Laughman and Viral Shah and Chris Rackauckas},\n      year={2021},\n      eprint={2103.05244},\n      archivePrefix={arXiv},\n      primaryClass={cs.MS}\n}","category":"page"},{"location":"copies/ModelingToolkit/#Feature-Summary","page":"Home","title":"Feature Summary","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"ModelingToolkit.jl is a symbolic-numeric modeling package. Thus it combines some of the features from symbolic computing packages like SymPy or Mathematica with the ideas of equation-based modeling systems like the causal Simulink and the acausal Modelica. It bridges the gap between many different kinds of equations, allowing one to quickly and easily transform systems of DAEs into optimization problems, or vice-versa, and then simplify and parallelize the resulting expressions before generating code.","category":"page"},{"location":"copies/ModelingToolkit/#Feature-List","page":"Home","title":"Feature List","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"Causal and acausal modeling (Simulink/Modelica)\nAutomated model transformation, simplification, and composition\nAutomatic conversion of numerical models into symbolic models\nComposition of models through the components, a lazy connection system, and tools for expanding/flattening\nPervasive parallelism in symbolic computations and generated functions\nTransformations like alias elimination and tearing of nonlinear systems for efficiently numerically handling large-scale systems of equations\nThe ability to use the entire Symbolics.jl Computer Algebra System (CAS) as part of the modeling process.\nImport models from common formats like SBML, CellML, BioNetGen, and more.\nExtendability: the whole system is written in pure Julia, so adding new functions, simplification rules, and model transformations has no barrier.","category":"page"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"For information on how to use the Symbolics.jl CAS system that ModelingToolkit.jl is built on, consult the Symbolics.jl documentation","category":"page"},{"location":"copies/ModelingToolkit/#Equation-Types","page":"Home","title":"Equation Types","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"Ordinary differential equations\nStochastic differential equations\nPartial differential equations\nNonlinear systems\nOptimization problems\nContinuous-Time Markov Chains\nChemical Reactions (via Catalyst.jl)\nNonlinear Optimal Control","category":"page"},{"location":"copies/ModelingToolkit/#Standard-Library","page":"Home","title":"Standard Library","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"For quick development, ModelingToolkit.jl includes  ModelingToolkitStandardLibrary.jl, a standard library of prebuilt components for the ModelingToolkit ecosystem.","category":"page"},{"location":"copies/ModelingToolkit/#Model-Import-Formats","page":"Home","title":"Model Import Formats","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"CellMLToolkit.jl: Import CellML models into ModelingToolkit\nRepository of more than a thousand pre-made models\nFocus on biomedical models in areas such as: Calcium Dynamics, Cardiovascular Circulation, Cell Cycle, Cell Migration, Circadian Rhythms, Electrophysiology, Endocrine, Excitation-Contraction Coupling, Gene Regulation, Hepatology, Immunology, Ion Transport, Mechanical Constitutive Laws, Metabolism, Myofilament Mechanics, Neurobiology, pH Regulation, PKPD, Protein Modules, Signal Transduction, and Synthetic Biology.\nSBMLToolkit.jl: Import SBML models into ModelingToolkit\nUses the robust libsbml library for parsing and transforming the SBML\nReactionNetworkImporters.jl: Import various models into ModelingToolkit\nSupports the BioNetGen .net file\nSupports importing networks specified by stoichiometric matrices","category":"page"},{"location":"copies/ModelingToolkit/#Extension-Libraries","page":"Home","title":"Extension Libraries","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"Because ModelingToolkit.jl is the core foundation of a equation-based modeling ecosystem, there is a large set of libraries adding features to this system. Below is an incomplete list of extension libraries one may want to be aware of:","category":"page"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"Catalyst.jl: Symbolic representations of chemical reactions\nSymbolically build and represent large systems of chemical reactions\nGenerate code for ODEs, SDEs, continuous-time Markov Chains, and more\nSimulate the models using the SciML ecosystem with O(1) Gillespie methods\nDataDrivenDiffEq.jl: Automatic identification of equations from data\nAutomated construction of ODEs and DAEs from data\nRepresentations of Koopman operators and Dynamic Mode Decomposition (DMD)\nMomentClosure.jl: Automatic transformation of ReactionSystems into deterministic systems\nGenerates ODESystems for the moment closures\nAllows for geometrically-distributed random reaction rates\nReactionMechanismSimulator.jl: Simulating and analyzing large chemical reaction mechanisms\nIdeal gas and dilute liquid phases.\nConstant T and P and constant V adiabatic ideal gas reactors.\nConstant T and V dilute liquid reactors.\nDiffusion limited rates. Sensitivity analysis for all reactors.\nFlux diagrams with molecular images (if molecular information is provided).\nNumCME.jl: High-performance simulation of chemical master equations (CME)\nTransient solution of the CME\nDynamic state spaces\nAccepts reaction systems defined using Catalyst.jl DSL.\nFiniteStateProjection.jl: High-performance simulation of  chemical master equations (CME) via finite state projections\nAccepts reaction systems defined using Catalyst.jl DSL.","category":"page"},{"location":"copies/ModelingToolkit/#Compatible-Numerical-Solvers","page":"Home","title":"Compatible Numerical Solvers","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"All of the symbolic systems have a direct conversion to a numerical system which can then be handled through the SciML interfaces. For example, after building a model and performing symbolic manipulations, an ODESystem can be converted into an ODEProblem to then be solved by a numerical ODE solver. Below is a list of the solver libraries which are the numerical targets of the ModelingToolkit system:","category":"page"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"DifferentialEquations.jl\nMulti-package interface of high performance numerical solvers for ODESystem, SDESystem, and JumpSystem\nNonlinearSolve.jl\nHigh performance numerical solving of NonlinearSystem\nGalacticOptim.jl\nMulti-package interface for numerical solving OptimizationSystem\nNeuralPDE.jl\nPhysics-Informed Neural Network (PINN) training on PDESystem\nMethodOfLines.jl\nAutomated finite difference method (FDM) discretization of PDESystem","category":"page"},{"location":"copies/ModelingToolkit/#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"copies/ModelingToolkit/","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to ModelingToolkit.\nThere are a few community forums:\nThe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\nOn the Julia Discourse forums (look for the modelingtoolkit tag\nSee also SciML Community page","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary:-Blocks","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary: Blocks","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/","page":"Basic Blocks","title":"Basic Blocks","text":"CurrentModule = ModelingToolkitStandardLibrary.Blocks","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#Utility-Blocks","page":"Basic Blocks","title":"Utility Blocks","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/","page":"Basic Blocks","title":"Basic Blocks","text":"RealInput\nRealOutput\nSISO","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.RealInput","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.RealInput","text":"RealInput(;name, nin=1, u_start=nin > 1 ? 0.0 : zeros(nin))\n\nConnector with one input signal of type Real.\n\nParameters:\n\nnin: Number of inputs\nu_start: Initial value for u  \n\nStates:\n\nu: Value of of the connector; if nin=1 this is a scalar\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.RealOutput","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.RealOutput","text":"RealOutput(;name, nout=1, u_start=nout > 1 ? 0.0 : zeros(nout))\n\nConnector with one output signal of type Real.\n\nParameters:\n\nnout: Number of inputs\nu_start: Initial value for u  \n\nStates:\n\nu: Value of of the connector; if nout=1 this is a scalar\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.SISO","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.SISO","text":"SISO(;name, u_start=0.0, y_start=0.0)\n\nSingle Input Single Output continuous control block.\n\nParameters:\n\nu_start: Initial value for the input\ny_start: Initial value for the output\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#Math-Blocks","page":"Basic Blocks","title":"Math Blocks","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/","page":"Basic Blocks","title":"Basic Blocks","text":"Gain\nMatrixGain\nSum\nFeedback\nAdd\nAdd3\nProduct\nDivision\nStaticNonLinearity\nAbs\nSign\nSqrt\nSin\nCos\nTan\nAsin\nAcos\nAtan\nAtan2\nSinh\nCosh\nTanh\nExp\nLog\nLog10","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Gain","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Gain","text":"Gain(k; name)\n\nOutput the product of a gain value with the input signal.\n\nParameters:\n\nk: Scalar gain\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.MatrixGain","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.MatrixGain","text":"MatrixGain(K::AbstractArray; name)\n\nOutput the product of a gain matrix with the input signal vector.\n\nParameters:\n\nK: Matrix gain\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Sum","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Sum","text":"Sum(n::Int; name)\n\nOutput the sum of the elements of the input port vector.\n\nParameters:\n\nn: Input port dimension\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Feedback","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Feedback","text":"Feedback(;name)\n\nOutput difference between reference input (input1) and feedback input (input2).\n\nConnectors:\n\ninput1\ninput2\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Add","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Add","text":"Add(;name, k1=1, k2=1)\n\nOutput the sum of the two scalar inputs.\n\nParameters:\n\nk1: Gain for first input\nk2: Gain for second input\n\nConnectors:\n\ninput1\ninput2\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Add3","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Add3","text":"Add(;name, k1=1, k2=1,k3=1)\n\nOutput the sum of the three scalar inputs.\n\nParameters:\n\nk1: Gain for first input\nk2: Gain for second input\nk3: Gain for third input\n\nConnectors:\n\ninput1\ninput2\ninput3\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Product","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Product","text":"Product(;name)\n\nOutput product of the two inputs.\n\nConnectors:\n\ninput1\ninput2\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Division","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Division","text":"Division(;name)\n\nOutput first input divided by second input.\n\nConnectors:\n\ninput1\ninput2\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.StaticNonLinearity","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.StaticNonLinearity","text":"StaticNonLinearity(func ;name)\n\nApplies the given function to the input. \n\nIf the given function is not composed of simple core methods (e.g. sin, abs, ...), it has to be registered via @register_symbolic func(u)\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Abs","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Abs","text":"Abs(;name)\n\nOutput the absolute value of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Sign","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Sign","text":"Sign(;name)\n\nOutput the sign of the input\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Sqrt","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Sqrt","text":"Sqrt(;name)\n\nOutput the square root of the input (input >= 0 required).\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Sin","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Sin","text":"Sin(;name)\n\nOutput the sine of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Cos","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Cos","text":"Cos(;name)\n\nOutput the cosine of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Tan","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Tan","text":"Tan(;name)\n\nOutput the tangent of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Asin","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Asin","text":"Asin(;name)\n\nOutput the arc sine of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Acos","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Acos","text":"Acos(;name)\n\nOutput the arc cosine of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Atan","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Atan","text":"Atan(;name)\n\nOutput the arc tangent of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Atan2","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Atan2","text":"Atan2(;name)\n\nOutput the arc tangent of the input.\n\nConnectors:\n\ninput1\ninput2\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Sinh","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Sinh","text":"Sinh(;name)\n\nOutput the hyperbolic sine of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Cosh","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Cosh","text":"Cosh(;name)\n\nOutput the hyperbolic cosine of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Tanh","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Tanh","text":"Tanh(;name)\n\nOutput the hyperbolic tangent of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Exp","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Exp","text":"Exp(;name)\n\nOutput the exponential (base e) of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Log","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Log","text":"Log(;name)\n\nOutput the natural (base e) logarithm of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Log10","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Log10","text":"Log10(;name)\n\nOutput the base 10 logarithm of the input.\n\nConnectors:\n\nSee StaticNonLinearity\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#Source-Blocks","page":"Basic Blocks","title":"Source Blocks","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/","page":"Basic Blocks","title":"Basic Blocks","text":"Constant\nSine\nCosine\nContinuousClock\nRamp\nStep\nExpSine","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Constant","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Constant","text":"Generate constant signal.\n\nParameters:\n\nk: Constant output value\n\nConnectors:\n\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Sine","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Sine","text":"Generate sine signal.\n\nParameters:\n\nfrequency: [Hz] Frequency of sine wave\namplitude: Amplitude of sine wave\nphase: [rad] Phase of sine wave\noffset: Offset of output signal\nstart_time: [s] Output y = offset for t < start_time\nsmooth:  If true, returns a smooth wave. Defaults to false            It uses a smoothing factor of δ=1e-5\n\nConnectors:\n\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.ContinuousClock","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.ContinuousClock","text":"Generate current time signal.\n\nParameters:\n\noffset: Offset of output signal\nstart_time: [s] Output y = offset for t < start_time\n\nConnectors:\n\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Ramp","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Ramp","text":"Generate ramp signal.\n\nParameters:\n\nheight: Height of ramp\nduration: [s] Duration of ramp (= 0.0 gives a Step)\noffset: Offset of output signal\nstart_time: [s] Output y = offset for t < start_time\nsmooth:  If true, returns a smooth wave. Defaults to false            It uses a smoothing factor of δ=1e-5\n\nConnectors:\n\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Step","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Step","text":"Generate step signal.\n\nParameters:\n\nheight: Height of step\noffset: Offset of output signal\nstart_time: [s] Output y = offset for t < start_time\nsmooth:  If true, returns a smooth wave. Defaults to false            It uses a smoothing factor of δ=1e-5\n\nConnectors:\n\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.ExpSine","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.ExpSine","text":"Generate exponentially damped sine signal.\n\nParameters:\n\nfrequency: [Hz] Frequency of sine wave\namplitude: Amplitude of sine wave\ndamping: [1/s] Damping coefficient of sine wave\nphase: [rad] Phase of sine wave\noffset: Offset of output signal\nstart_time: [s] Output y = offset for t < start_time\nsmooth:  If true, returns a smooth wave. Defaults to false            It uses a smoothing factor of δ=1e-5\n\nConnectors:\n\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#Nonlinear-Blocks","page":"Basic Blocks","title":"Nonlinear Blocks","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/","page":"Basic Blocks","title":"Basic Blocks","text":"Limiter\nDeadZone\nSlewRateLimiter","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Limiter","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Limiter","text":"Limiter(;name, y_max, y_min=y_max > 0 ? -y_max : -Inf)\n\nLimit the range of a signal.\n\nParameters:\n\ny_max: Maximum of output signal\ny_min: Minimum of output signal\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.DeadZone","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.DeadZone","text":"DeadZone(; name, u_max, u_min=-u_max)\n\nThe DeadZone block defines a region of zero output. If the input is within u_min ... u_max, the output is zero. Outside of this zone, the output is a linear function of the input with a slope of 1.\n\n       y▲\n        │     /\n        │    /\n  u_min │   /\n─────|──┼──|───────► u\n    /   │   u_max\n   /    │\n  /     │\n\nParameters:\n\nu_max: Upper limit of dead zone\nu_min: Lower limit of dead zone\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.SlewRateLimiter","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.SlewRateLimiter","text":"SlewRateLimiter(;name, rising=1, falling=-rising, Td=0.001, y_start=0.0)\n\nLimits the slew rate of a signal.\n\nParameters:\n\nrising: Maximum rising slew rate\nfalling: Maximum falling slew rate\nTd: [s] Derivative time constant\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#Continuous-Blocks","page":"Basic Blocks","title":"Continuous Blocks","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/","page":"Basic Blocks","title":"Basic Blocks","text":"Integrator\nDerivative\nFirstOrder\nSecondOrder\nStateSpace\nPI\nLimPI\nPID\nLimPID","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Integrator","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Integrator","text":"Integrator(;name, k=1, x_start=0.0)\n\nOutputs y = ∫k*u dt, corresponding to the transfer function 1/s.\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.Derivative","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.Derivative","text":"Derivative(; name, k=1, T, x_start=0.0)\n\nOutputs an approximate derivative of the input. The transfer function of this block is\n\nk       k     \n─ - ──────────\nT    2 ⎛    1⎞\n    T ⋅⎜s + ─⎟\n       ⎝    T⎠\n\nand a state-space realization is given by ss(-1/T, 1/T, -k/T, k/T) where T is the time constant of the filter. A smaller T leads to a more ideal approximation of the derivative.\n\nParameters:\n\nk: Gain\nT: [s] Time constants (T>0 required; T=0 is ideal derivative block)\nx_start: Initial value of state\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.FirstOrder","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.FirstOrder","text":"FirstOrder(; name, k=1, T, x_start=0.0)\n\nA first-order filter with a single real pole in s = -T and gain k. The transfer function is given by Y(s)/U(s) =\n\n   k   \n───────\nsT + 1\n\nParameters:\n\nk: Gain\nT: [s] Time constants (T>0 required)\nx_start: Initial value of state\n\nConnectors:\n\ninput\noutput\n\nSee also SecondOrder\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.SecondOrder","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.SecondOrder","text":"SecondOrder(; name, k=1, w, d, x_start=0.0, xd_start=0.0)\n\nA second-order filter with gain k, a bandwidth of w rad/s and relative damping d. The transfer function is given by Y(s)/U(s) =\n\n      k*w^2   \n─────────────────\ns² + 2d*w*s + w^2\n\nCritical damping corresponds to d=1, which yields the fastest step response without overshoot, d < 1results in an under-damped filter whiled > 1results in an over-damped filter.d = 1/√2` corresponds to a Butterworth filter of order 2 (maximally flat frequency response).\n\nParameters:\n\nk: Gain\nw: Angular frequency\nd: Damping\nx_start: Initial value of state (output)\nxd_start: Initial value of derivative of state (output)\n\nConnectors:\n\ninput\noutput\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.StateSpace","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.StateSpace","text":"StateSpace(A, B, C, D=0; x_start=zeros(size(A,1)), name)\n\nA linear, time-invariant state-space system on the form.\n\nẋ = Ax + Bu\ny = Cx + Du\n\nTransfer functions can also be simulated by converting them to a StateSpace form.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.PI","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.PI","text":"PI(;name, k=1, T, x_start=0.0)\n\nTextbook version of a PI-controller without actuator saturation and anti-windup measure.\n\nParameters:\n\nk: Gain\nT: [s] Integrator time constant (T>0 required)\nx_start: Initial value for the integrator\n\nConnectors:\n\nerr_input\nctr_output\n\nSee also LimPI\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.LimPI","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.LimPI","text":"LimPI(;name, k=1, T, u_max=1, u_min=-u_max, Ta)\n\nText-book version of a PI-controller with actuator saturation and anti-windup measure.\n\nParameters:\n\nk: Gain\nT: [s] Integrator time constant (T>0 required)\nTa: [s] Tracking time constant (Ta>0 required)\nx_start: Initial value for the integrator\n\nConnectors:\n\nerr_input\nctr_output\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.PID","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.PID","text":"PID(;name, k=1, Ti=false, Td=false, Nd=10, xi_start=0, xd_start=0)\n\nText-book version of a PID-controller without actuator saturation and anti-windup measure.\n\nParameters:\n\nk: Gain\nTi: [s] Integrator time constant (Ti>0 required). If set to false no integral action is used.\nTd: [s] Derivative time constant (Td>0 required). If set to false no derivative action is used.\nNd: [s] Time constant for the derivative approximation (Nd>0 required; Nd=0 is ideal derivative).\nx_start: Initial value for the integrator.\nxd_start: Initial value for the derivative state.\n\nConnectors:\n\nerr_input\nctr_output\n\nSee also LimPID\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/blocks/#ModelingToolkitStandardLibrary.Blocks.LimPID","page":"Basic Blocks","title":"ModelingToolkitStandardLibrary.Blocks.LimPID","text":"LimPID(; k, Ti=false, Td=false, wp=1, wd=1, Ni, Nd=12, u_max=Inf, u_min=-u_max, gains = false, name)\n\nProportional-Integral-Derivative (PID) controller with output saturation, set-point weighting and integrator anti-windup.\n\nThe equation for the control signal is roughly\n\nk(ep + 1/Ti * ∫e + 1/Td * d/dt(ed))\ne = u_r - u_y\nep = wp*u_r - u_y\ned = wd*u_r - u_y\n\nwhere the transfer function for the derivative includes additional filtering, see ? Derivative for more details.\n\nParameters:\n\nk: Proportional gain\nTi: [s] Integrator time constant. Set to false to turn off integral action.\nTd: [s] Derivative time constant. Set to false to turn off derivative action.\nwp: [0,1] Set-point weighting in the proportional part.\nwd: [0,1] Set-point weighting in the derivative part.\nNd: [1/s] Derivative limit, limits the derivative gain to Nd/Td. Reasonable values are ∈ [8, 20]. A higher value gives a better approximation of an ideal derivative at the expense of higher noise amplification.\nNi: Ni*Ti controls the time constant Ta of anti-windup tracking. A common (default) choice is Ta = √(Ti*Td) which is realized by Ni = √(Td / Ti). Anti-windup can be effectively turned off by setting Ni = Inf.\n\ngains: Ifgains = true,TiandTdwill be interpreted as gains with a fundamental PID transfer function on parallel formki=Ti, kd=Td, k + ki/s + kd*s`\n\nConnectors:\n\nreference\nmeasurement\nctr_output\n\n\n\n\n\n","category":"function"},{"location":"copies/DiffEqSensitivity/bayesian/turing_bayesian/#Bayesian-Estimation-of-Differential-Equations-with-Probabilistic-Programming","page":"Bayesian Estimation of Differential Equations with Probabilistic Programming","title":"Bayesian Estimation of Differential Equations with Probabilistic Programming","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/turing_bayesian/","page":"Bayesian Estimation of Differential Equations with Probabilistic Programming","title":"Bayesian Estimation of Differential Equations with Probabilistic Programming","text":"For a good overview of how to use the tools of SciML in conjunction with the Turing.jl probabilistic programming language, see the Bayesian Differential Equation Tutorial.","category":"page"},{"location":"copies/Integrals/#NonlinearSolve.jl:-High-Performance-Unified-Nonlinear-Solvers","page":"Home","title":"NonlinearSolve.jl: High-Performance Unified Nonlinear Solvers","text":"","category":"section"},{"location":"copies/Integrals/","page":"Home","title":"Home","text":"NonlinearSolve.jl is a unified interface for the nonlinear solving packages of Julia. It includes its own high-performance nonlinear solvers which include the ability to swap out to fast direct and iterative linear solvers, along with the ability to use sparse automatic differentiation for Jacobian construction and Jacobian-vector products. It interfaces with other packages of the Julia ecosystem to make it easy to test alternative solver packages and pass small types to control algorithm swapping. It also interfaces with the ModelingToolkit.jl world of symbolic modeling to allow for automatically generating high-performance code.","category":"page"},{"location":"copies/Integrals/","page":"Home","title":"Home","text":"Performance is key: the current methods are made to be highly performant on scalar and statically sized small problems, with options for large-scale systems. If you run into any performance issues, please file an issue. Note that this package is distinct from SciMLNLSolve.jl. Consult the NonlinearSystemSolvers page for information on how to import solvers from different packages.","category":"page"},{"location":"copies/Integrals/#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"copies/Integrals/","page":"Home","title":"Home","text":"To install NonlinearSolve.jl, use the Julia package manager:","category":"page"},{"location":"copies/Integrals/","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"NonlinearSolve\")","category":"page"},{"location":"copies/Integrals/#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"copies/Integrals/","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to ModelingToolkit.\nThere are a few community forums:\nthe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\non the Julia Discourse forums (look for the modelingtoolkit tag\nsee also SciML Community page","category":"page"},{"location":"copies/Integrals/#Roadmap","page":"Home","title":"Roadmap","text":"","category":"section"},{"location":"copies/Integrals/","page":"Home","title":"Home","text":"The current algorithms should support automatic differentiation, though improved adjoint overloads are planned to be added in the current update (which will make use of the f(u,p) form). Future updates will include standard methods for larger scale nonlinear solving like Newton-Krylov methods.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/#Prediction-error-method-(PEM)","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"When identifying linear systems from noisy data, the prediction-error method [Ljung] is close to a gold standard when it comes to the quality of the models it produces, but is also one of the computationally more expensive methods due to its reliance on iterative, gradient-based estimation. When we are identifying nonlinear models, we typically do not have the luxury of closed-form, non-iterative solutions, while PEM is easier to adopt to the nonlinear setting.[Larsson]","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Fundamentally, PEM changes the problem from minimizing a loss based on the simulation performance, to minimizing a loss based on shorter-term predictions. There are several benefits of doing so, and this example will highlight two:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"The loss is often easier to optimize.\nIn addition to an accurate simulator, you also obtain a prediction for the system.\nWith PEM, it's possible to estimate disturbance models.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"The last point will not be illustrated in this tutorial, but we will briefly expand upon it here. Gaussian, zero-mean measurement noise is usually not very hard to handle. Disturbances that affect the state of the system may, however, cause all sorts of havoc on the estimate. Consider wind affecting an aircraft, deriving a statistical and dynamical model of the wind may be doable, but unless you measure the exact wind affecting the aircraft, making use of the model during parameter estimation is impossible. The wind is an unmeasured load disturbance that affects the state of the system through its own dynamics model. Using the techniques illustrated in this tutorial, it's possible to estimate the influence of the wind during the experiment that generated the data and reduce or eliminate the bias it otherwise causes in the parameter estimates. ","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We will start by illustrating a common problem with simulation-error minimization. Imagine a pendulum with unknown length that is to be estimated. A small error in the pendulum length causes the frequency of oscillation to change. Over sufficiently large horizon, two sinusoidal signals with different frequencies become close to orthogonal to each other. If some form of squared-error loss is used, the loss landscape will be horribly non-convex in this case, indeed, we will illustrate exactly this below.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Another case that poses a problem for simulation-error estimation is when the system is unstable or chaotic. A small error in either the initial condition or the parameters may cause the simulation error to diverge and its gradient to become meaningless.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"In both of these examples, we may make use of measurements we have of the evolution of the system to prevent the simulation error from diverging. For instance, if we have measured the angle of the pendulum, we can make use of this measurement to adjust the angle during the simulation to make sure it stays close to the measured angle. Instead of performing a pure simulation, we instead say that we predict the state a while forward in time, given all the measurements up until the current time point. By minimizing this prediction rather than the pure simulation, we can often prevent the model error from diverging even though we have a poor initial guess. ","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We start by defining a model of the pendulum. The model takes a parameter L corresponding to the length of the pendulum. ","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"using DifferentialEquations, DiffEqFlux, Plots, Statistics, DataInterpolations\n\ntspan = (0.1f0, Float32(20.0))\ntsteps = range(tspan[1], tspan[2], length = 1000)\n\nu0 = [0f0, 3f0] # Initial angle and angular velocity\n\nfunction simulator(du,u,p,t) # Pendulum dynamics\n    g = 9.82f0 # Gravitational constant\n    L = p isa Number ? p : p[1] # Length of the pendulum\n    gL = g/L\n    θ  = u[1]\n    dθ = u[2]\n    du[1] = dθ\n    du[2] = -gL * sin(θ)\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We assume that the true length of the pendulum is L = 1, and generate some data from this system.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"prob = ODEProblem(simulator,u0,tspan,1.0) # Simulate with L = 1\nsol = solve(prob, Tsit5(), saveat=tsteps, abstol = 1e-8, reltol = 1e-6)\ny = sol[1,:] # This is the data we have available for parameter estimation\nplot(y, title=\"Pendulum simulation\", label=\"angle\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"(Image: img1)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We also define functions that simulate the system and calculate the loss, given a parameter p corresponding to the length.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"function simulate(p)\n    _prob = remake(prob,p=p)\n    solve(_prob, Tsit5(), saveat=tsteps, abstol = 1e-8, reltol = 1e-6)[1,:]\nend\n\nfunction simloss(p)\n    yh = simulate(p)\n    e2 = yh\n    e2 .= abs2.(y .- yh)\n    return mean(e2)\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We now look at the loss landscape as a function of the pendulum length:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Ls = 0.01:0.01:2\nsimlosses = simloss.(Ls)\nfig_loss = plot(Ls, simlosses, title = \"Loss landscape\", xlabel=\"Pendulum length\", ylabel = \"MSE loss\", lab=\"Simulation loss\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"(Image: img2)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"This figure is interesting, the loss is of course 0 for the true value L=1, but for values L  1, the overall slope actually points in the wrong direction! Moreover, the loss is oscillatory, indicating that this is a terrible function to optimize, and that we would need a very good initial guess for a local search to converge to the true value. Note, this example is chosen to be one-dimensional in order to allow these kinds of visualizations, and one-dimensional problems are typically not hard to solve, but the reasoning extends to higher-dimensional and harder problems.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We will now move on to defining a predictor model. Our predictor will be very simple, each time step, we will calculate the error e between the simulated angle theta and the measured angle y. A part of this error will be used to correct the state of the pendulum. The correction we use is linear and looks like Ke = K(y - theta). We have formed what is commonly referred to as a (linear) observer. The Kalman filter is a particular kind of linear observer, where K is calculated based on a statistical model of the disturbances that act on the system. We will stay with a simple, fixed-gain observer here for simplicity. ","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"To feed the sampled data into the continuous-time simulation, we make use of an interpolator. We also define new functions, predictor that contains the pendulum dynamics with the observer correction, a prediction function that performs the rollout (we're not using the word simulation to not confuse with the setting above) and a loss function.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"y_int = LinearInterpolation(y,tsteps)\n\nfunction predictor(du,u,p,t)\n    g = 9.82f0\n    L, K, y = p # pendulum length, observer gain and measurements\n    gL = g/L\n    θ  = u[1]\n    dθ = u[2]\n    yt = y(t)\n    e = yt - θ\n    du[1] = dθ + K*e\n    du[2] = -gL * sin(θ) \nend\n\npredprob = ODEProblem(predictor,u0,tspan,nothing)\n\nfunction prediction(p)\n    p_full = (p..., y_int)\n    _prob = remake(predprob,p=p_full)\n    solve(_prob, Tsit5(), saveat=tsteps, abstol = 1e-8, reltol = 1e-6)[1,:]\nend\n\nfunction predloss(p)\n    yh = prediction(p)\n    e2 = yh\n    e2 .= abs2.(y .- yh)\n    return mean(e2)\nend\n\npredlosses = map(Ls) do L\n    p = (L, 1) # use K = 1\n    predloss(p)\nend\n\nplot!(Ls, predlosses, lab=\"Prediction loss\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"(Image: img3)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Once gain we look at the loss as a function of the parameter, and this time it looks a lot better. The loss is not convex, but the gradient points in the right direction over a much larger interval. Here, we arbitrarily set the observer gain to K=1, we will later let the optimizer learn this parameter.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"For completeness, we also perform estimation using both losses. We choose an initial guess we know will be hard for the simulation-error minimization just to drive home the point:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"L0 = [0.7] # Initial guess of pendulum length\nressim = DiffEqFlux.sciml_train(simloss,L0,maxiters=5000)\nysim = simulate(ressim.u)\n\nplot(tsteps, [y ysim], label=[\"Data\" \"Simulation model\"])\n\np0 = [0.7, 1.0] # Initial guess of length and observer gain K\nrespred = DiffEqFlux.sciml_train(predloss,p0,maxiters=5000)\nypred = simulate(respred.u)\n\nplot!(tsteps, ypred, label=\"Prediction model\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"(Image: img4)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"The estimated parameters (L K) are","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"respred.u","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"Now, we might ask ourselves why we used a correct on the form Ke and didn't instead set the angle in the simulation equal to the measurement. The reason is twofold","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"If our prediction of the angle is 100% based on the measurements, the model parameters do not matter for the prediction and we can thus not hope to learn their values.\nThe measurement is usually noisy, and we thus want to fuse the predictive power of the model with the information of the measurements. The Kalman filter is an optimal approach to this information fusion under special circumstances (linear model, Gaussian noise).","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"We thus let the optimization learn the best value of the observer gain in order to make the best predictions. ","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"As a last step, we perform the estimation also with some measurement noise to verify that it does something reasonable:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"yn = y .+ 0.1f0 .* randn.(Float32)\ny_int = LinearInterpolation(yn,tsteps) # redefine the interpolator to contain noisy measurements\n\nresprednoise = DiffEqFlux.sciml_train(predloss,p0,maxiters=5000)\nyprednoise = prediction(resprednoise.u)\nplot!(tsteps, yprednoise, label=\"Prediction model with noisy measurements\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"(Image: img5)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"resprednoise.u","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"This example has illustrated basic use of the prediction-error method for parameter estimation. In our example, the measurement we had corresponded directly to one of the states, and coming up with an observer/predictor that worked was not too hard. For more difficult cases, we may opt to use a nonlinear observer, such as an extended Kalman filter (EKF) or design a Kalman filter based on a linearization of the system around some operating point.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"As a last note, there are several other methods available to improve the loss landscape and avoid local minima, such as multiple-shooting. The prediction-error method can easily be combined with most of those methods. ","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"References:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"[Ljung]: Ljung, Lennart. \"System identification–-Theory for the user\".","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/prediction_error_method/","page":"Prediction error method (PEM)","title":"Prediction error method (PEM)","text":"[Larsson]: Larsson, Roger, et al. \"Direct prediction-error identification of unstable nonlinear systems applied to flight test data.\"","category":"page"},{"location":"copies/SciMLBase/fundamentals/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/#What-are-the-code-styling-rules-for-SciML?","page":"Frequently Asked Questions","title":"What are the code styling rules for SciML?","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"All SciML libraries are supposed to follow SciMLStyle. Any deviation from that style is something to be fixed.","category":"page"},{"location":"copies/SciMLBase/fundamentals/FAQ/#Where-do-I-find-more-information-on-the-internals-of-some-packages?","page":"Frequently Asked Questions","title":"Where do I find more information on the internals of some packages?","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"The SciML Developer Documentation describes the internals of some of the larger solver libraries at length.","category":"page"},{"location":"copies/SciMLBase/fundamentals/FAQ/#What-are-the-community-practices-that-SciML-developers-should-use?","page":"Frequently Asked Questions","title":"What are the community practices that SciML developers should use?","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"See ColPrac: Contributor's Guide on Collaborative Practices for Community Packages","category":"page"},{"location":"copies/SciMLBase/fundamentals/FAQ/#Are-there-developer-programs-to-help-fund-parties-interested-in-helping-develop-SciML?","page":"Frequently Asked Questions","title":"Are there developer programs to help fund parties interested in helping develop SciML?","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Yes! See the SciML Developer Programs webpage.","category":"page"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/#Neural-Differential-Equation-Layer-Functions","page":"Neural Differential Equation Layers","title":"Neural Differential Equation Layer Functions","text":"","category":"section"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/","page":"Neural Differential Equation Layers","title":"Neural Differential Equation Layers","text":"The following layers are helper functions for easily building neural differential equation architectures in the currently most efficient way. As demonstrated in the tutorials, they do not have to be used since automatic differentiation will just work over solve, but these cover common use cases and choose what's known to be the optimal mode of AD for the respective equation type.","category":"page"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/","page":"Neural Differential Equation Layers","title":"Neural Differential Equation Layers","text":"NeuralODE\nNeuralDSDE\nNeuralSDE\nNeuralCDDE\nNeuralDAE\nNeuralODEMM\nAugmentedNDELayer","category":"page"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/#DiffEqFlux.NeuralODE","page":"Neural Differential Equation Layers","title":"DiffEqFlux.NeuralODE","text":"Constructs a continuous-time recurrant neural network, also known as a neural ordinary differential equation (neural ODE), with a fast gradient calculation via adjoints [1]. At a high level this corresponds to solving the forward differential equation, using a second differential equation that propagates the derivatives of the loss backwards in time.\n\nNeuralODE(model,tspan,alg=nothing,args...;kwargs...)\nNeuralODE(model::FastChain,tspan,alg=nothing,args...;\n          sensealg=InterpolatingAdjoint(autojacvec=DiffEqSensitivity.ReverseDiffVJP(true)),\n          kwargs...)\n\nArguments:\n\nmodel: A Chain or FastChain neural network that defines the ̇x.\ntspan: The timespan to be solved on.\nalg: The algorithm used to solve the ODE. Defaults to nothing, i.e. the default algorithm from DifferentialEquations.jl.\nsensealg: The choice of differentiation algorthm used in the backpropogation. Defaults to an adjoint method, and with FastChain it defaults to utilizing a tape-compiled ReverseDiff vector-Jacobian product for extra efficiency. Seee the Local Sensitivity Analysis documentation for more details.\nkwargs: Additional arguments splatted to the ODE solver. See the Common Solver Arguments documentation for more details.\n\nReferences:\n\n[1] Pontryagin, Lev Semenovich. Mathematical theory of optimal processes. CRC press, 1987.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/#DiffEqFlux.NeuralDSDE","page":"Neural Differential Equation Layers","title":"DiffEqFlux.NeuralDSDE","text":"Constructs a neural stochastic differential equation (neural SDE) with diagonal noise.\n\nNeuralDSDE(model1,model2,tspan,alg=nothing,args...;\n           sensealg=TrackerAdjoint(),kwargs...)\nNeuralDSDE(model1::FastChain,model2::FastChain,tspan,alg=nothing,args...;\n           sensealg=TrackerAdjoint(),kwargs...)\n\nArguments:\n\nmodel1: A Chain or FastChain neural network that defines the drift function.\nmodel2: A Chain or FastChain neural network that defines the diffusion function. Should output a vector of the same size as the input.\ntspan: The timespan to be solved on.\nalg: The algorithm used to solve the ODE. Defaults to nothing, i.e. the default algorithm from DifferentialEquations.jl.\nsensealg: The choice of differentiation algorthm used in the backpropogation. Defaults to using reverse-mode automatic differentiation via Tracker.jl\nkwargs: Additional arguments splatted to the ODE solver. See the Common Solver Arguments documentation for more details.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/#DiffEqFlux.NeuralSDE","page":"Neural Differential Equation Layers","title":"DiffEqFlux.NeuralSDE","text":"Constructs a neural stochastic differential equation (neural SDE).\n\nNeuralSDE(model1,model2,tspan,nbrown,alg=nothing,args...;\n          sensealg=TrackerAdjoint(),kwargs...)\nNeuralSDE(model1::FastChain,model2::FastChain,tspan,nbrown,alg=nothing,args...;\n          sensealg=TrackerAdjoint(),kwargs...)\n\nArguments:\n\nmodel1: A Chain or FastChain neural network that defines the drift function.\nmodel2: A Chain or FastChain neural network that defines the diffusion function. Should output a matrix that is nbrown x size(x,1).\ntspan: The timespan to be solved on.\nnbrown: The number of Brownian processes\nalg: The algorithm used to solve the ODE. Defaults to nothing, i.e. the default algorithm from DifferentialEquations.jl.\nsensealg: The choice of differentiation algorthm used in the backpropogation. Defaults to using reverse-mode automatic differentiation via Tracker.jl\nkwargs: Additional arguments splatted to the ODE solver. See the Common Solver Arguments documentation for more details.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/#DiffEqFlux.NeuralCDDE","page":"Neural Differential Equation Layers","title":"DiffEqFlux.NeuralCDDE","text":"Constructs a neural delay differential equation (neural DDE) with constant delays.\n\nNeuralCDDE(model,tspan,hist,lags,alg=nothing,args...;\n          sensealg=TrackerAdjoint(),kwargs...)\nNeuralCDDE(model::FastChain,tspan,hist,lags,alg=nothing,args...;\n          sensealg=TrackerAdjoint(),kwargs...)\n\nArguments:\n\nmodel: A Chain or FastChain neural network that defines the derivative function. Should take an input of size [x;x(t-lag_1);...;x(t-lag_n)] and produce and output shaped like x.\ntspan: The timespan to be solved on.\nhist: Defines the history function h(t) for values before the start of the integration.\nlags: Defines the lagged values that should be utilized in the neural network.\nalg: The algorithm used to solve the ODE. Defaults to nothing, i.e. the default algorithm from DifferentialEquations.jl.\nsensealg: The choice of differentiation algorthm used in the backpropogation. Defaults to using reverse-mode automatic differentiation via Tracker.jl\nkwargs: Additional arguments splatted to the ODE solver. See the Common Solver Arguments documentation for more details.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/#DiffEqFlux.NeuralDAE","page":"Neural Differential Equation Layers","title":"DiffEqFlux.NeuralDAE","text":"Constructs a neural differential-algebraic equation (neural DAE).\n\nNeuralDAE(model,constraints_model,tspan,alg=nothing,args...;\n          sensealg=TrackerAdjoint(),kwargs...)\nNeuralDAE(model::FastChain,constraints_model,tspan,alg=nothing,args...;\n          sensealg=TrackerAdjoint(),kwargs...)\n\nArguments:\n\nmodel: A Chain or FastChain neural network that defines the derivative function. Should take an input of size x and produce the residual of f(dx,x,t) for only the differential variables.\nconstraints_model: A function constraints_model(u,p,t) for the fixed constaints to impose on the algebraic equations.\ntspan: The timespan to be solved on.\nalg: The algorithm used to solve the ODE. Defaults to nothing, i.e. the default algorithm from DifferentialEquations.jl.\nsensealg: The choice of differentiation algorthm used in the backpropogation. Defaults to using reverse-mode automatic differentiation via Tracker.jl\nkwargs: Additional arguments splatted to the ODE solver. See the Common Solver Arguments documentation for more details.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/#DiffEqFlux.NeuralODEMM","page":"Neural Differential Equation Layers","title":"DiffEqFlux.NeuralODEMM","text":"Constructs a physically-constrained continuous-time recurrant neural network, also known as a neural differential-algebraic equation (neural DAE), with a mass matrix and a fast gradient calculation via adjoints [1]. The mass matrix formulation is:\n\nMu = f(upt)\n\nwhere M is semi-explicit, i.e. singular with zeros for rows corresponding to the constraint equations.\n\nNeuralODEMM(model,constraints_model,tspan,mass_matrix,alg=nothing,args...;kwargs...)\nNeuralODEMM(model::FastChain,tspan,mass_matrix,alg=nothing,args...;\n          sensealg=InterpolatingAdjoint(autojacvec=DiffEqSensitivity.ReverseDiffVJP(true)),\n          kwargs...)\n\nArguments:\n\nmodel: A Chain or FastChain neural network that defines the ̇f(u,p,t)\nconstraints_model: A function constraints_model(u,p,t) for the fixed constaints to impose on the algebraic equations.\ntspan: The timespan to be solved on.\nmass_matrix: The mass matrix associated with the DAE\nalg: The algorithm used to solve the ODE. Defaults to nothing, i.e. the default algorithm from DifferentialEquations.jl. This method requires an implicit ODE solver compatible with singular mass matrices. Consult the DAE solvers documentation for more details.\nsensealg: The choice of differentiation algorthm used in the backpropogation. Defaults to an adjoint method, and with FastChain it defaults to utilizing a tape-compiled ReverseDiff vector-Jacobian product for extra efficiency. Seee the Local Sensitivity Analysis documentation for more details.\nkwargs: Additional arguments splatted to the ODE solver. See the Common Solver Arguments documentation for more details.\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/layers/NeuralDELayers/#DiffEqFlux.AugmentedNDELayer","page":"Neural Differential Equation Layers","title":"DiffEqFlux.AugmentedNDELayer","text":"Constructs an Augmented Neural Differential Equation Layer.\n\nAugmentedNDELayer(nde, adim::Int)\n\nArguments:\n\nnde: Any Neural Differential Equation Layer\nadim: The number of dimensions the initial conditions should be lifted\n\nReferences:\n\n[1] Dupont, Emilien, Arnaud Doucet, and Yee Whye Teh. \"Augmented neural ODEs.\" In Proceedings of the 33rd International Conference on Neural Information Processing Systems, pp. 3140-3150. 2019.\n\n\n\n\n\n","category":"type"},{"location":"copies/Surrogates/neural/#Neural-network-tutorial","page":"NeuralSurrogate","title":"Neural network tutorial","text":"","category":"section"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"note: Note\nThis surrogate requires the 'SurrogatesFlux' module which can be added by inputting \"]add SurrogatesFlux\" from the Julia command line. ","category":"page"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"It's possible to define a neural network as a surrogate, using Flux. This is useful because we can call optimization methods on it.","category":"page"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"First of all we will define the Schaffer function we are going to build surrogate for.","category":"page"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"using Plots\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\nusing Surrogates\nusing Flux\nusing SurrogatesFlux\n\nfunction schaffer(x)\n    x1=x[1]\n    x2=x[2]\n    fact1 = x1 ^2;\n    fact2 = x2 ^2;\n    y = fact1 + fact2;\nend","category":"page"},{"location":"copies/Surrogates/neural/#Sampling","page":"NeuralSurrogate","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension x to have bounds 0, 8, and 0, 8 for the second dimension. We are taking 60 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points.","category":"page"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"n_samples = 60\nlower_bound = [0.0, 0.0]\nupper_bound = [8.0, 8.0]\n\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\nzs = schaffer.(xys);","category":"page"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"x, y = 0:8, 0:8 # hide\np1 = surface(x, y, (x1,x2) -> schaffer((x1,x2))) # hide\nxs = [xy[1] for xy in xys] # hide\nys = [xy[2] for xy in xys] # hide\nscatter!(xs, ys, zs) # hide\np2 = contour(x, y, (x1,x2) -> schaffer((x1,x2))) # hide\nscatter!(xs, ys) # hide\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/neural/#Building-a-surrogate","page":"NeuralSurrogate","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"You can specify your own model, optimization function, loss functions and epochs. As always, getting the model right is hardest thing.","category":"page"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"model1 = Chain(\n  Dense(2, 5, σ),\n  Dense(5,2,σ),\n  Dense(2, 1)\n)\nneural = NeuralSurrogate(xys, zs, lower_bound, upper_bound, model = model1, n_echos = 10)","category":"page"},{"location":"copies/Surrogates/neural/#Optimization","page":"NeuralSurrogate","title":"Optimization","text":"","category":"section"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"We can now call an optimization function on the neural network:","category":"page"},{"location":"copies/Surrogates/neural/","page":"NeuralSurrogate","title":"NeuralSurrogate","text":"surrogate_optimize(schaffer, SRBF(), lower_bound, upper_bound, neural, SobolSample(), maxiters=20, num_new_samples=10)","category":"page"},{"location":"copies/NeuralOperators/introduction/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"copies/NeuralOperators/introduction/","page":"Introduction","title":"Introduction","text":"Neural operator is a novel deep learning architecture. It learns a operator, which is a mapping between infinite-dimensional function spaces. It can be used to resolve partial differential equations (PDE). Instead of solving by time-consuming finite element method, a PDE problem can be resolved by training a neural network to learn an operator mapping from infinite-dimensional space (u t) to infinite-dimensional space f(u t). Neural operator learns a continuous function between two continuous function spaces. The kernel can be trained on different geometry, including regular Euclidean space or a graph topology.","category":"page"},{"location":"copies/NeuralOperators/introduction/#[Fourier-Neural-Operators](https://github.com/SciML/NeuralOperators.jl/blob/master/src/model.jl)","page":"Introduction","title":"Fourier Neural Operators","text":"","category":"section"},{"location":"copies/NeuralOperators/introduction/","page":"Introduction","title":"Introduction","text":"Fourier neural operator (FNO) learns a neural operator with Dirichlet kernel to form a Fourier transformation. It performs Fourier transformation across infinite-dimensional function spaces and learns better than neural operator.","category":"page"},{"location":"copies/NeuralOperators/introduction/#[Markov-Neural-Operators](https://github.com/SciML/NeuralOperators.jl/blob/master/src/model.jl)","page":"Introduction","title":"Markov Neural Operators","text":"","category":"section"},{"location":"copies/NeuralOperators/introduction/","page":"Introduction","title":"Introduction","text":"Markov neural operator (MNO) learns a neural operator with Fourier operators. With only one time step information of learning, it can predict the following few steps with low loss by linking the operators into a Markov chain.","category":"page"},{"location":"copies/NeuralOperators/introduction/#[Deep-Operator-Network](https://github.com/SciML/NeuralOperators.jl/blob/master/src/DeepONet.jl)","page":"Introduction","title":"Deep Operator Network","text":"","category":"section"},{"location":"copies/NeuralOperators/introduction/","page":"Introduction","title":"Introduction","text":"Deep operator network (DeepONet) learns a neural operator with the help of two sub-neural network structures described as the branch and the trunk network. The branch network is fed the initial conditions data, whereas the trunk is fed with the locations where the target(output) is evaluated from the corresponding initial conditions. It is important that the output size of the branch and trunk subnets is same so that a dot product can be performed between them.","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/#Global-Sensitivity-Analysis-of-the-Lotka-Volterra-model","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"","category":"section"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"The tutorial covers a workflow of using GlobalSensitivity.jl on the Lotka-Volterra differential equation. We showcase how to use multiple GSA methods, analyse their results and leverage Julia's parallelism capabilities to perform Global Sensitivity analysis at scale.","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"using GlobalSensitivity, QuasiMonteCarlo, OrdinaryDiffEq, Statistics, CairoMakie\n\nfunction f(du,u,p,t)\n  du[1] = p[1]*u[1] - p[2]*u[1]*u[2] #prey\n  du[2] = -p[3]*u[2] + p[4]*u[1]*u[2] #predator\nend\n\nu0 = [1.0;1.0]\ntspan = (0.0,10.0)\np = [1.5,1.0,3.0,1.0]\nprob = ODEProblem(f,u0,tspan,p)\nt = collect(range(0, stop=10, length=200))\n\n\nf1 = function (p)\n    prob1 = remake(prob;p=p)\n    sol = solve(prob1,Tsit5();saveat=t)\nend\n\nbounds = [[1,5],[1,5],[1,5],[1,5]]\n\nreg_sens = gsa(f1, RegressionGSA(true), bounds)\nfig = Figure(resolution = (600, 400))\nax, hm = CairoMakie.heatmap(fig[1,1], reg_sens.partial_correlation, figure = (resolution = (600, 400),), axis = (xticksvisible = false,yticksvisible = false, yticklabelsvisible = false, xticklabelsvisible = false, title = \"Partial correlation\"))\nColorbar(fig[1, 2], hm)\nax, hm = CairoMakie.heatmap(fig[2,1], reg_sens.standard_regression, figure = (resolution = (600, 400),), axis = (xticksvisible = false,yticksvisible = false, yticklabelsvisible = false, xticklabelsvisible = false, title = \"Standard regression\"))\nColorbar(fig[2, 2], hm)\nfig","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"(Image: heatmapreg)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"using StableRNGs\n_rng = StableRNG(1234)\nmorris_sens = gsa(f1, Morris(), bounds, rng = _rng)\nfig = Figure(resolution = (600, 400))\nscatter(fig[1,1], [1,2,3,4], morris_sens.means_star[1,:], color = :green, axis = (xticksvisible = false, xticklabelsvisible = false, title = \"Prey\",))\nscatter(fig[1,2], [1,2,3,4], morris_sens.means_star[2,:], color = :red, axis = (xticksvisible = false, xticklabelsvisible = false, title = \"Predator\",))\nfig","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"(Image: morrisscat)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"sobol_sens = gsa(f1, Sobol(), bounds, N=5000)\nefast_sens = gsa(f1, eFAST(), bounds)\nfig = Figure(resolution = (600, 400))\nbarplot(fig[1,1], [1,2,3,4], sobol_sens.S1[1, :], color = :green, axis = (xticksvisible = false, xticklabelsvisible = false, title = \"Prey (Sobol)\", ylabel = \"First order\"))\nbarplot(fig[2,1], [1,2,3,4], sobol_sens.ST[1, :], color = :green, axis = (xticksvisible = false, xticklabelsvisible = false, ylabel = \"Total order\"))\nbarplot(fig[1,2], [1,2,3,4], efast_sens.S1[1, :], color = :red, axis = (xticksvisible = false, xticklabelsvisible = false, title = \"Prey (eFAST)\"))\nbarplot(fig[2,2], [1,2,3,4], efast_sens.ST[1, :], color = :red, axis = (xticksvisible = false, xticklabelsvisible = false))\nfig\n\nfig = Figure(resolution = (600, 400))\nbarplot(fig[1,1], [1,2,3,4], sobol_sens.S1[2, :], color = :green, axis = (xticksvisible = false, xticklabelsvisible = false, title = \"Predator (Sobol)\", ylabel = \"First order\"))\nbarplot(fig[2,1], [1,2,3,4], sobol_sens.ST[2, :], color = :green, axis = (xticksvisible = false, xticklabelsvisible = false, ylabel = \"Total order\"))\nbarplot(fig[1,2], [1,2,3,4], efast_sens.S1[2, :], color = :red, axis = (xticksvisible = false, xticklabelsvisible = false, title = \"Predator (eFAST)\"))\nbarplot(fig[2,2], [1,2,3,4], efast_sens.ST[2, :], color = :red, axis = (xticksvisible = false, xticklabelsvisible = false))\nfig","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"(Image: sobolefastprey) (Image: sobolefastpred)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"using QuasiMonteCarlo\nN = 5000\nlb = [1.0, 1.0, 1.0, 1.0]\nub = [5.0, 5.0, 5.0, 5.0]\nsampler = SobolSample()\nA,B = QuasiMonteCarlo.generate_design_matrices(N,lb,ub,sampler)\nsobol_sens_desmat = gsa(f1,Sobol(),A,B)\n\n\nf_batch = function (p)\n  prob_func(prob,i,repeat) = remake(prob;p=p[:,i])\n  ensemble_prob = EnsembleProblem(prob,prob_func=prob_func)\n\n  sol = solve(ensemble_prob, Tsit5(), EnsembleThreads(); saveat=t, trajectories=size(p,2))\n\n  out = zeros(2,size(p,2))\n\n  for i in 1:size(p,2)\n    out[1,i] = mean(sol[i][1,:])\n    out[2,i] = maximum(sol[i][2,:])\n  end\n\n  return out\nend\n\nsobol_sens_batch = gsa(f_batch,Sobol(),A,B,batch=true)\n\n@time gsa(f1,Sobol(),A,B)\n@time gsa(f_batch,Sobol(),A,B,batch=true)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"f1 = function (p)\n           prob1 = remake(prob;p=p)\n           sol = solve(prob1,Tsit5();saveat=t)\n       end\nsobol_sens = gsa(f1, Sobol(nboot = 20), bounds, N=5000)\nfig = Figure(resolution = (600, 400))\nax, hm = CairoMakie.scatter(fig[1,1], sobol_sens.S1[1][1,2:end], label = \"Prey\", markersize = 4)\nCairoMakie.scatter!(fig[1,1], sobol_sens.S1[1][2,2:end], label = \"Predator\", markersize = 4)\n\n# Legend(fig[1,2], ax)\n\nax, hm = CairoMakie.scatter(fig[1,2], sobol_sens.S1[2][1,2:end], label = \"Prey\", markersize = 4)\nCairoMakie.scatter!(fig[1,2], sobol_sens.S1[2][2,2:end], label = \"Predator\", markersize = 4)\n\nax, hm = CairoMakie.scatter(fig[2,1], sobol_sens.S1[3][1,2:end], label = \"Prey\", markersize = 4)\nCairoMakie.scatter!(fig[2,1], sobol_sens.S1[3][2,2:end], label = \"Predator\", markersize = 4)\n\nax, hm = CairoMakie.scatter(fig[2,2], sobol_sens.S1[4][1,2:end], label = \"Prey\", markersize = 4)\nCairoMakie.scatter!(fig[2,2], sobol_sens.S1[4][2,2:end], label = \"Predator\", markersize = 4)\n\ntitle = Label(fig[0,:], \"First order Sobol indices\")\nlegend = Legend(fig[2,3], ax)","category":"page"},{"location":"copies/GlobalSensitivity/tutorials/juliacon21/","page":"Global Sensitivity Analysis of the Lotka-Volterra model","title":"Global Sensitivity Analysis of the Lotka-Volterra model","text":"(Image: timeseriessobollv)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/#Parameter-Estimation-on-Highly-Stiff-Systems","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"This tutorial goes into training a model on stiff chemical reaction system data.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/#Copy-Pasteable-Code","page":"Parameter Estimation on Highly Stiff Systems","title":"Copy-Pasteable Code","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"Before getting to the explanation, here's some code to start with. We will follow a full explanation of the definition and training process:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"using DifferentialEquations, DiffEqFlux, LinearAlgebra\nusing ForwardDiff\nusing DiffEqBase: UJacobianWrapper\nusing Plots\nfunction rober(du,u,p,t)\n    y₁,y₂,y₃ = u\n    k₁,k₂,k₃ = p\n    du[1] = -k₁*y₁+k₃*y₂*y₃\n    du[2] =  k₁*y₁-k₂*y₂^2-k₃*y₂*y₃\n    du[3] =  k₂*y₂^2\n    nothing\nend\n\np = [0.04,3e7,1e4]\nu0 = [1.0,0.0,0.0]\nprob = ODEProblem(rober,u0,(0.0,1e5),p)\nsol = solve(prob,Rosenbrock23())\nts = sol.t\nJs = map(u->I + 0.1*ForwardDiff.jacobian(UJacobianWrapper(rober, 0.0, p), u), sol.u)\n\nfunction predict_adjoint(p)\n    p = exp.(p)\n    _prob = remake(prob,p=p)\n    Array(solve(_prob,Rosenbrock23(autodiff=false),saveat=ts,sensealg=QuadratureAdjoint(autojacvec=ReverseDiffVJP(true))))\nend\n\nfunction loss_adjoint(p)\n    prediction = predict_adjoint(p)\n    prediction = [prediction[:, i] for i in axes(prediction, 2)]\n    diff = map((J,u,data) -> J * (abs2.(u .- data)) , Js, prediction, sol.u)\n    loss = sum(abs, sum(diff)) |> sqrt\n    loss, prediction\nend\n\ncb = function (p,l,pred) #callback function to observe training\n    println(\"Loss: $l\")\n    println(\"Parameters: $(exp.(p))\")\n    # using `remake` to re-create our `prob` with current parameters `p`\n    plot(solve(remake(prob, p=exp.(p)), Rosenbrock23())) |> display\n    return false # Tell it to not halt the optimization. If return true, then optimization stops\nend\n\ninitp = ones(3)\n# Display the ODE with the initial parameter values.\ncb(initp,loss_adjoint(initp)...)\n\nres = DiffEqFlux.sciml_train(loss_adjoint, initp, ADAM(0.01), cb = cb, maxiters = 300)\nres2 = DiffEqFlux.sciml_train(loss_adjoint, res.u, BFGS(), cb = cb, maxiters = 30, allow_f_increases=true)\nprintln(\"Ground truth: $(p)\\nFinal parameters: $(round.(exp.(res2.u), sigdigits=5))\\nError: $(round(norm(exp.(res2.u) - p) ./ norm(p) .* 100, sigdigits=3))%\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"Output:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"Ground truth: [0.04, 3.0e7, 10000.0]\nFinal parameters: [0.040002, 3.0507e7, 10084.0]\nError: 1.69%","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/#Explanation","page":"Parameter Estimation on Highly Stiff Systems","title":"Explanation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"First, let's get a time series array from the Robertson's equation as data.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"using DifferentialEquations, DiffEqFlux, LinearAlgebra\nusing ForwardDiff\nusing DiffEqBase: UJacobianWrapper\nusing Plots\nfunction rober(du,u,p,t)\n    y₁,y₂,y₃ = u\n    k₁,k₂,k₃ = p\n    du[1] = -k₁*y₁+k₃*y₂*y₃\n    du[2] =  k₁*y₁-k₂*y₂^2-k₃*y₂*y₃\n    du[3] =  k₂*y₂^2\n    nothing\nend\n\np = [0.04,3e7,1e4]\nu0 = [1.0,0.0,0.0]\nprob = ODEProblem(rober,u0,(0.0,1e5),p)\nsol = solve(prob,Rosenbrock23())\nts = sol.t\nJs = map(u->I + 0.1*ForwardDiff.jacobian(UJacobianWrapper(rober, 0.0, p), u), sol.u)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"Note that we also computed a shifted and scaled Jacobian along with the solution. We will use this matrix to scale the loss later.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"We fit the parameters in log space, so we need to compute exp.(p) to get back the original parameters.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"function predict_adjoint(p)\n    p = exp.(p)\n    _prob = remake(prob,p=p)\n    Array(solve(_prob,Rosenbrock23(autodiff=false),saveat=ts,sensealg=QuadratureAdjoint(autojacvec=ReverseDiffVJP(true))))\nend\n\nfunction loss_adjoint(p)\n    prediction = predict_adjoint(p)\n    prediction = [prediction[:, i] for i in axes(prediction, 2)]\n    diff = map((J,u,data) -> J * (abs2.(u .- data)) , Js, prediction, sol.u)\n    loss = sum(abs, sum(diff)) |> sqrt\n    loss, prediction\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"The difference between the data and the prediction is weighted by the transformed Jacobian to do a relative scaling of the loss.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"We define a callback function.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"cb = function (p,l,pred) #callback function to observe training\n    println(\"Loss: $l\")\n    println(\"Parameters: $(exp.(p))\")\n    # using `remake` to re-create our `prob` with current parameters `p`\n    plot(solve(remake(prob, p=exp.(p)), Rosenbrock23())) |> display\n    return false # Tell it to not halt the optimization. If return true, then optimization stops\nend","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"We then use a combination of ADAM and BFGS to minimize the loss function to accelerate the optimization. The initial guess of the parameters are chosen to be [1, 1, 1.0].","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"initp = ones(3)\n# Display the ODE with the initial parameter values.\ncb(initp,loss_adjoint(initp)...)\n\nres = DiffEqFlux.sciml_train(loss_adjoint, initp, ADAM(0.01), cb = cb, maxiters = 300)\nres2 = DiffEqFlux.sciml_train(loss_adjoint, res.u, BFGS(), cb = cb, maxiters = 30, allow_f_increases=true)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"Finally, we can analyze the difference between the fitted parameters and the ground truth.","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"println(\"Ground truth: $(p)\\nFinal parameters: $(round.(exp.(res2.u), sigdigits=5))\\nError: $(round(norm(exp.(res2.u) - p) ./ norm(p) .* 100, sigdigits=3))%\")","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"It gives the output","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/stiff_ode_fit/","page":"Parameter Estimation on Highly Stiff Systems","title":"Parameter Estimation on Highly Stiff Systems","text":"Ground truth: [0.04, 3.0e7, 10000.0]\nFinal parameters: [0.040002, 3.0507e7, 10084.0]\nError: 1.69%","category":"page"},{"location":"copies/LinearSolve/advanced/developing/#Developing-New-Linear-Solvers","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"","category":"section"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"Developing new or custom linear solvers for the SciML interface can be done in one of two ways:","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"You can either create a completely new set of dispatches for init and solve.\nYou can extend LinearSolve.jl's internal mechanisms.","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"For developer ease, we highly recommend (2) as that will automatically make the caching API work. Thus this is the documentation for how to do that.","category":"page"},{"location":"copies/LinearSolve/advanced/developing/#Developing-New-Linear-Solvers-with-LinearSolve.jl-Primitives","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers with LinearSolve.jl Primitives","text":"","category":"section"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"Let's create a new wrapper for a simple LU-factorization which uses only the basic machinery. A simplified version is:","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"struct MyLUFactorization{P} <: SciMLBase.AbstractLinearAlgorithm end\r\n\r\ninit_cacheval(alg::MyLUFactorization, A, b, u, Pl, Pr, maxiters, abstol, reltol, verbose) = lu!(convert(AbstractMatrix,A))\r\n\r\nfunction SciMLBase.solve(cache::LinearCache, alg::MyLUFactorization; kwargs...)\r\n    if cache.isfresh\r\n        A = convert(AbstractMatrix,A)\r\n        fact = lu!(A)\r\n        cache = set_cacheval(cache, fact)\r\n    end\r\n    y = ldiv!(cache.u, cache.cacheval, cache.b)\r\n    SciMLBase.build_linear_solution(alg,y,nothing,cache)\r\nend","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"The way this works is as follows. LinearSolve.jl has a LinearCache that everything shares (this is what gives most of the ease of use). However, many algorithms need to cache their own things, and so there's one value cacheval that is for the algorithms to modify. The function:","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"init_cacheval(alg::MyLUFactorization, A, b, u, Pl, Pr, maxiters, abstol, reltol, verbose)","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"is what is called at init time to create the first cacheval. Note that this should match the type of the cache later used in solve as many algorithms, like those in OrdinaryDiffEq.jl, expect type-groundedness in the linear solver definitions. While there are cheaper ways to obtain this type for LU factorizations (specifically, ArrayInterfaceCore.lu_instance(A)), for a demonstration this just performs an LU-factorization to get an LU{T, Matrix{T}} which it puts into the cacheval so its typed for future use.","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"After the init_cacheval, the only thing left to do is to define SciMLBase.solve(cache::LinearCache, alg::MyLUFactorization). Many algorithms may use a lazy matrix-free representation of the operator A. Thus if the algorithm requires a concrete matrix, like LU-factorization does, the algorithm should convert(AbstractMatrix,cache.A). The flag cache.isfresh states whether A has changed since the last solve. Since we only need to factorize when A is new, the factorization part of the algorithm is done in a if cache.isfresh. cache = set_cacheval(cache, fact) puts the new factorization into the cache so it's updated for future solves. Then y = ldiv!(cache.u, cache.cacheval, cache.b) performs the solve and a linear solution is returned via SciMLBase.build_linear_solution(alg,y,nothing,cache).","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary:-Electrical-Components","page":"Electrical Components","title":"ModelingToolkitStandardLibrary: Electrical Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/","page":"Electrical Components","title":"Electrical Components","text":"CurrentModule = ModelingToolkitStandardLibrary.Electrical","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#Electrical-Utilities","page":"Electrical Components","title":"Electrical Utilities","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/","page":"Electrical Components","title":"Electrical Components","text":"Pin\nOnePort\nDigitalPin","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.Pin","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.Pin","text":"@connector function Pin(; name)\n\nA pin in an analog circuit.\n\nStates\n\nv(t): [V] The voltage at this pin\ni(t): [A] The current passing through this pin\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.OnePort","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.OnePort","text":"    OnePort(; name, v_start=0.0, i_start=0.0)\n\nComponent with two electrical pins p and n and current i from p to n.\n\nParameters:\n\nv_start: [V] Initial voltage across the component\ni_start: [A] Initial current through the component\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.DigitalPin","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.DigitalPin","text":"@connector function DigitalPin(; name)\n\nA pin in a digital circuit.\n\nStates\n\nv(t): [V] The voltage at this pin\ni(t): [A] The current passing through this pin\nval(t): The binary value of the pin at this point. A voltage from 0V to 0.8V is a binary value of 0. A voltage in the range 2.0V to 5.0V is 1. Any other value is X.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#Analog-Components","page":"Electrical Components","title":"Analog Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/","page":"Electrical Components","title":"Electrical Components","text":"Ground\nResistor\nConductor\nCapacitor\nInductor\nIdealOpAmp","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.Ground","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.Ground","text":"function Ground(; name)\n\nGround node with the potential of zero and connector g. Every circuit must have one ground node.\n\nConnectors\n\ng\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.Resistor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.Resistor","text":"function Resistor(; name, R)\n\nCreates an ideal Resistor following Ohm's Law.\n\nStates\n\nv(t): [V] The voltage across the resistor, given by p.i * R\n\nConnectors\n\np Positive pin\nn Negative pin\n\nParameters:\n\nR: [Ω] Resistance\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.Conductor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.Conductor","text":"Conductor(;name, G)\n\nIdeal linear electrical conductor.\n\nStates\n\nsee OnePort\n\nConnectors\n\np Positive pin\nn Negative pin\n\nParameters:\n\nG: [S] Conductance\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.Capacitor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.Capacitor","text":"function Capacitor(; name, C)\n\nCreates an ideal Capacitor.\n\nStates\n\nv(t): [V] The voltage across the capacitor, given by D(v) ~ p.i / C\n\nConnectors\n\np Positive pin\nn Negative pin\n\nParameters:\n\nC: [F] Capacitance\nv_start: [V] Initial voltage of capacitor\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.Inductor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.Inductor","text":"function Inductor(; name, L)\n\nCreates an ideal Inductor.\n\nStates\n\nv(t): [V] The voltage across the inductor, given by D(p.i) ~ v / L\n\nConnectors\n\np Positive pin\nn Negative pin\n\nParameters:\n\nL: [H] Inductance\ni_start: [A] Initial current through inductor\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.IdealOpAmp","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.IdealOpAmp","text":"function IdealOpAmp(; name)\n\nIdeal operational amplifier (norator-nullator pair). The ideal OpAmp is a two-port. The left port is fixed to v1 = 0 and i1 = 0 (nullator).  At the right port both any voltage v2 and any current i2 are possible (norator).\n\nStates\n\nv1(t): [V] Voltage of left port\nv2(t): [V] Voltage of right port\ni1(t): [A] Current of left port\ni2(t): [A] Current of right port\n\nConnectors\n\np1 Positive pin (left port)\np2 Positive pin (right port)\nn1 Negative pin (left port)\nn2 Negative pin (right port)\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#Analog-Sensors","page":"Electrical Components","title":"Analog Sensors","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/","page":"Electrical Components","title":"Electrical Components","text":"CurrentSensor\nPotentialSensor\nVoltageSensor\nPowerSensor\nMultiSensor","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.CurrentSensor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.CurrentSensor","text":"function CurrentSensor(; name)\n\nCreates a circuit component that measures the current flowing through it. Analogous to an ideal ammeter.\n\nStates\n\ni(t): [A] Current through the sensor\n\nConnectors\n\np\n\nPositive pin\n\nn Negative pin\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.PotentialSensor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.PotentialSensor","text":"function PotentialSensor(; name)\n\nCreates a circuit component which measures the potential at a pin.\n\nStates\n\nphi(t): [V] The potential at this point\n\nConnectors\n\np Pin at which potential is to be measured\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.VoltageSensor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.VoltageSensor","text":"function VoltageSensor(; name)\n\nCreates a circuit component that measures the voltage across it. Analogous to an ideal voltmeter.\n\nStates\n\nv(t): [V] The voltage across this component\n\nConnectors\n\np Positive pin\nn Negative pin\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.PowerSensor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.PowerSensor","text":"function PowerSensor(; name)\n\nCombines a VoltageSensor and a CurrentSensor to measure the power being consumed by a circuit.\n\nStates\n\npower(t): [W] The power being consumed, given by the product of voltage and current.\n\nConnectors\n\npc Corresponds to the p pin of the CurrentSensor\nnc Corresponds to the n pin of the CurrentSensor\npv Corresponds to the p pin of the VoltageSensor\nnv Corresponds to the n pin of the VoltageSensor\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.MultiSensor","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.MultiSensor","text":"function MultiSensor(; name)\n\nCombines a VoltageSensor and a CurrentSensor.\n\nStates\n\nv(t): [V] The voltage across the VoltageSensor\ni(t): [A] The current across the CurrentSensor\n\nConnectors\n\npc Corresponds to the p pin of the CurrentSensor\nnc Corresponds to the n pin of the CurrentSensor\npv Corresponds to the p pin of the VoltageSensor\nnv Corresponds to the n pin of the VoltageSensor\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#Analog-Sources","page":"Electrical Components","title":"Analog Sources","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/","page":"Electrical Components","title":"Electrical Components","text":"ConstantVoltage\nSineVoltage\nStepVoltage\nRampVoltage\nSquareVoltage\nTriangularVoltage\nCosineVoltage\nExpSineVoltage\nConstantCurrent\nSineCurrent\nStepCurrent\nRampCurrent\nSquareCurrent\nTriangularCurrent\nCosineCurrent\nExpSineCurrent","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.ConstantVoltage","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.ConstantVoltage","text":"function ConstantVoltage(; name, V)\n\nThe source for an ideal constant voltage.\n\nStates\n\nv(t): [V] The voltage across this source, given by p.v - n.v and is always constant\n\nConnectors\n\np Positive pin\nn Negative pin\n\nParameters:\n\nV: [V] The constant voltage across the terminals of this source\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.SineVoltage","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.SineVoltage","text":"function SineVoltage(; name, offset=0.0, amplitude=1.0, frequency=1.0, start_time=0.0, phase=0.0)\n\nA source in which the voltage across its terminals is a sine function of time.\n\nStates\n\nv(t): [V] The voltage across this source, given by p.v - n.v\n\nConnectors\n\np Positive port\nn Negative port\n\nParameters\n\noffset: [V] A constant offset added to the voltage output\namplitude: [V] The amplitude of the sine function\nfrequency: [Hz] The frequency of the sine function\nstart_time: [s] The time at which the source starts functioning. Before this time, the voltage across its terminals is offset.\nphase: [rad] The phase offset of the sine function\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.StepVoltage","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.StepVoltage","text":"function StepVoltage(; name, offset=0.0, start_time=0.0, height=1.0)\n\nA source in which the voltage across its terminals increases from offset to offset+height at start_time\n\nStates\n\nv(t): [V] The voltage across this source, given by p.v - n.v\n\nConnectors\n\np Positive port\nn Negative port\n\nObservables\n\noffset: [V] A constant offset added to the voltage output\nstart_time: [s] The time at which the source starts functioning, and the voltage jumps\nheight: [V] Magnitude of increase in voltage\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.RampVoltage","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.RampVoltage","text":"function RampVoltage(; name, offset=0.0, start_time=0.0, duration=1.0, height=1.0)\n\nA source in which the voltage across grows linearly from offset to offset+height over the time interval duration starting at start_time\n\nStates\n\nv(t): [V] The voltage across this source, given by p.v - n.v\n\nConnectors\n\np Positive port\nn Negative port\n\nParameters\n\noffset: [V] A constant offset added to the voltage output\nstart_time: [s] The time at which the voltage starts growing\nduration: [s] The duration of the ramp (0.0 gives a step)\nheight: [V] The amount that the voltage grows in the time interval\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.SquareVoltage","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.SquareVoltage","text":"function SquareVoltage(; name, offset=0.0, amplitude=1.0, frequency=1.0, start_time=0.0)\n\nA source in which the voltage across its terminals is a square function of time.\n\nStates\n\nv(t): [V] The voltage across this source, given by p.v - n.v\n\nConnectors\n\np Positive port\nn Negative port\n\nParameters\n\noffset: [V] A constant offset added to the voltage output\namplitude: [V] The amplitude of the square wave function\nfrequency: [Hz] The frequency of the square wave function\nstart_time: [s] The time at which the source starts functioning. Before this time, the voltage across its terminals is offset.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.TriangularVoltage","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.TriangularVoltage","text":"function TriangularVoltage(; name, offset=0.0, amplitude=1.0, frequency=1.0, start_time=0.0)\n\nA source in which the voltage across its terminals is a triangular function of time.\n\nStates\n\nv(t): [V] The voltage across this source, given by p.v - n.v\n\nConnectors\n\np Positive port\nn Negative port\n\nObservables\n\noffset: [V] A constant offset added to the voltage output\namplitude: [V] Amplitude of the triangular wave function\nfrequency: [Hz] Frequency of the triangular wave function\nstart_time: [s] The time at which the source starts functioning. Before this, the output of the source is offset\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.CosineVoltage","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.CosineVoltage","text":"function CosineVoltage(; name, offset=0.0, amplitude=1.0, frequency=1.0, starttime=0.0, phase=0.0)\n\nA source in which the voltage across its terminals is a cosine function of time.\n\nStates\n\nv(t): [V] The voltage across this source, given by p.v - n.v\n\nConnectors\n\np Positive port\nn Negative port\n\nObservables\n\noffset: [V] A constant offset added to the voltage output\namplitude: [V] The amplitude of the cosine function\nfrequency: [Hz] The frequency of the cosine function\nstarttime: [s] The time at which the source starts functioning. Before this time, the voltage across its terminals is 0.\nphase: [rad] The phase offset of the cosine function\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.ExpSineVoltage","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.ExpSineVoltage","text":"function ExpSineVoltage(; name, offset=0.0, amplitude=1.0, frequency=1.0, start_time=0.0, phase=0.0, damping=0.0)\n\nA source in which the voltage across its terminals is a damped sine function of time.\n\nStates\n\nv(t): [V] The voltage across this source, given by p.v - n.v\n\nConnectors\n\np Positive port\nn Negative port\n\nParameters\n\noffset: [V] A constant offset added to the voltage output\namplitude: [V] The amplitude of the damped sine function\nfrequency: [Hz] The frequency of the damped sine function\nstart_time: [s] The time at which the source starts functioning. Before this time, the voltage across its terminals is offset.\nphase: [rad] The phase offset of the damped sine function\ndamping_coef: [1/s] Damping coefficient of the damped sine function\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.ConstantCurrent","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.ConstantCurrent","text":"function ConstantCurrent(; name, I = 1.0)\n\nThe source for an ideal constant current.\n\nStates\n\ni(t): [A] The current through this source, which is always constant\n\nConnectors\n\np Positive pin\nn Negative pin\n\nParameters:\n\nI: [A] The constant current through the terminals of this source\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.SineCurrent","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.SineCurrent","text":"function SineCurrent(; name, offset=0.0, amplitude=1.0, frequency=1.0, start_time=0.0, phase=0.0)\n\nA source in which the current through its terminals is a sine function of time.\n\nStates\n\ni(t): [A] The current through this source\n\nConnectors\n\np Positive port\nn Negative port\n\nParameters\n\noffset: [A] A constant offset added to the current output\namplitude: [V] The amplitude of the sine function\nfrequency: [Hz] The frequency of the sine function\nstart_time: [s] The time at which the source starts functioning. Before this time, the current through its terminals is offset.\nphase: [rad] The phase offset of the sine function\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.StepCurrent","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.StepCurrent","text":"function StepCurrent(; name, offset=0.0, start_time=0.0, height=1.0)\n\nA source in which the current through its terminals increases from offset to offset+height at start_time\n\nStates\n\ni(t): [A] The current through this source\n\nConnectors\n\np Positive port\nn Negative port\n\nObservables\n\noffset: [A] A constant offset added to the current output\nstart_time: [s] The time at which the source starts functioning, and the current jumps\nheight: [A] Magnitude of increase in current\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.RampCurrent","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.RampCurrent","text":"function RampCurrent(; name, offset=0.0, start_time=0.0, duration=1.0, height=1.0)\n\nA source in which the current grows linearly from offset to offset+height over the time interval duration starting at start_time\n\nStates\n\ni(t): [A] The current through this source\n\nConnectors\n\np Positive port\nn Negative port\n\nParameters\n\noffset: [A] A constant offset added to the current output\nstart_time: [s] The time at which the current starts growing\nduration: [s] The duration of the ramp (0.0 gives a step)\nheight: [A] The amount that the current grows in the time interval\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.SquareCurrent","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.SquareCurrent","text":"function SquareCurrent(; name, offset=0.0, amplitude=1.0, frequency=1.0, start_time=0.0)\n\nA source in which the current through its terminals is a square function of time.\n\nStates\n\ni(t): [A] The current through this source\n\nConnectors\n\np Positive port\nn Negative port\n\nParameters\n\noffset: [A] A constant offset added to the current output\namplitude: [A] The amplitude of the square wave function\nfrequency: [Hz] The frequency of the square wave function\nstart_time: [s] The time at which the source starts functioning. Before this time, the current through its terminals is offset.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.TriangularCurrent","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.TriangularCurrent","text":"function TriangularCurrent(; name, offset=0.0, amplitude=1.0, frequency=1.0, start_time=0.0)\n\nA source in which the current through its terminals is a triangular function of time.\n\nStates\n\ni(t): [A] The current through this source\n\nConnectors\n\np Positive port\nn Negative port\n\nObservables\n\noffset: [A] A constant offset added to the current output\namplitude: [A] Amplitude of the triangular wave function\nfrequency: [Hz] Frequency of the triangular wave function\nstart_time: [s] The time at which the source starts functioning. Before this, the output of the source is offset\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.CosineCurrent","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.CosineCurrent","text":"function CosineCurrent(; name, offset=0.0, amplitude=1.0, frequency=1.0, starttime=0.0, phase=0.0)\n\nA source in which the current through its terminals is a cosine function of time.\n\nStates\n\ni(t): [A] The current through this source\n\nConnectors\n\np Positive port\nn Negative port\n\nObservables\n\noffset: [A] A constant offset added to the current output\namplitude: [A] The amplitude of the cosine function\nfrequency: [Hz] The frequency of the cosine function\nstarttime: [s] The time at which the source starts functioning. Before this time, the current through its terminals is 0.\nphase: [rad] The phase offset of the cosine function\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#ModelingToolkitStandardLibrary.Electrical.ExpSineCurrent","page":"Electrical Components","title":"ModelingToolkitStandardLibrary.Electrical.ExpSineCurrent","text":"function ExpSineCurrent(; name, offset=0.0, amplitude=1.0, frequency=1.0, start_time=0.0, phase=0.0, damping=0.0)\n\nA source in which the current through its terminals is a damped sine function of time.\n\nStates\n\ni(t): [A] The current through this source\n\nConnectors\n\np Positive port\nn Negative port\n\nParameters\n\noffset: [A] A constant offset added to the current output\namplitude: [A] The amplitude of the damped sine function\nfrequency: [Hz] The frequency of the damped sine function\nstart_time: [s] The time at which the source starts functioning. Before this time, the current through its terminals is offset.\nphase: [rad] The phase offset of the damped sine function\ndamping_coef: [1/s] Damping coefficient of the damped sine function\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#Digital-Gates","page":"Electrical Components","title":"Digital Gates","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/","page":"Electrical Components","title":"Electrical Components","text":"Not\nAnd\nNand\nOr\nNor\nXor\nXnor","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#Digital-Components","page":"Electrical Components","title":"Digital Components","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/","page":"Electrical Components","title":"Electrical Components","text":"HalfAdder\nFullAdder\nMUX\nDEMUX\nEncoder\nDecoder","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/#Digital-Sources","page":"Electrical Components","title":"Digital Sources","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/API/electrical/","page":"Electrical Components","title":"Electrical Components","text":"PulseDiff\nSet\nReset\nPulse","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLProblems","page":"SciMLProblems","title":"SciMLProblems","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"The cornerstone of the SciML common interface is the problem type definition. These definitions are the encoding of mathematical problems into a numerically computable form. ","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Note-About-Symbolics-and-ModelingToolkit","page":"SciMLProblems","title":"Note About Symbolics and ModelingToolkit","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"The symbolic analog to the problem interface is the ModelingToolkit AbstractSystem. For example, ODESystem is the symbolic analog to ODEProblem. Each of these system types have a method for constructing the associated problem and function types.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Definition-of-the-SciMLProblem-Interface","page":"SciMLProblems","title":"Definition of the SciMLProblem Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"The following standard principles should be adhered to across all  SciMLProblem instantiations.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#In-place-Specification","page":"SciMLProblems","title":"In-place Specification","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"Each SciMLProblem type can be called with an \"is inplace\" (iip) choice. For example:","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"ODEProblem(f,u0,tspan,p)\nODEProblem{iip}(f,u0,tspan,p)","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"which is a boolean for whether the function is in the inplace form (mutating to change the first value). This is automatically determined using the methods table but note that for full type-inferrability of the SciMLProblem this iip-ness should be specified.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"Additionally, the functions are fully specialized to reduce the runtimes. If one would instead like to not specialize on the functions to reduce compile time, then one can set recompile to false.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Default-Parameters","page":"SciMLProblems","title":"Default Parameters","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"By default, SciMLProblem types use the SciMLBase.NullParameters() singleton to define the absence of parameters by default. The reason is because this throws an informative error if the parameter is used or accessed within the user's function, for example, p[1] will throw an informative error about forgetting to pass parameters.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Keyword-Argument-Splatting","page":"SciMLProblems","title":"Keyword Argument Splatting","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"All SciMLProblem types allow for passing keyword arguments that would get forwarded to the solver. The reason for this is that in many cases, like in EnsembleProblem usage, a SciMLProblem might be associated with some solver configuration, such as a callback or tolerance. Thus, for flexibility the extra keyword arguments to the SciMLProblem are carried to the solver.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#problem_type","page":"SciMLProblems","title":"problem_type","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"SciMLProblem types include a non-public API definition of problem_type which holds a trait type corresponding to the way the SciMLProblem was constructed. For example, if a SecondOrderODEProblem constructor is used, the returned problem is simply a ODEProblem for interopability with any ODEProblem algorithm. However, in this case the problem_type will be populated with the SecondOrderODEProblem type, indicating the original definition and extra structure.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Remake","page":"SciMLProblems","title":"Remake","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"remake","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.remake","page":"SciMLProblems","title":"SciMLBase.remake","text":"remake(thing; <keyword arguments>)\n\nRe-construct thing with new field values specified by the keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Problems/#Problem-Traits","page":"SciMLProblems","title":"Problem Traits","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"SciMLBase.isinplace(prob::SciMLBase.DEProblem)\nSciMLBase.is_diagonal_noise","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.isinplace-Tuple{SciMLBase.DEProblem}","page":"SciMLProblems","title":"SciMLBase.isinplace","text":"isinplace(prob::SciMLProblem)\n\nDetermine whether the function of the given problem operates in place or not.\n\n\n\n\n\n","category":"method"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.is_diagonal_noise","page":"SciMLProblems","title":"SciMLBase.is_diagonal_noise","text":"is_diagonal_noise(prob::SciMLProblem)\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLProblem-API","page":"SciMLProblems","title":"SciMLProblem API","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/#Abstract-SciMLProblems","page":"SciMLProblems","title":"Abstract SciMLProblems","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"SciMLBase.SciMLProblem\nSciMLBase.DEProblem\nSciMLBase.AbstractLinearProblem\nSciMLBase.AbstractNonlinearProblem\nSciMLBase.AbstractQuadratureProblem\nSciMLBase.AbstractOptimizationProblem\nSciMLBase.AbstractNoiseProblem\nSciMLBase.AbstractODEProblem\nSciMLBase.AbstractDiscreteProblem\nSciMLBase.AbstractAnalyticalProblem\nSciMLBase.AbstractRODEProblem\nSciMLBase.AbstractSDEProblem\nSciMLBase.AbstractDAEProblem\nSciMLBase.AbstractDDEProblem\nSciMLBase.AbstractConstantLagDDEProblem\nSciMLBase.AbstractSecondOrderODEProblem\nSciMLBase.AbstractBVProblem\nSciMLBase.AbstractJumpProblem\nSciMLBase.AbstractSDDEProblem\nSciMLBase.AbstractConstantLagSDDEProblem\nSciMLBase.AbstractPDEProblem","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SciMLProblem","page":"SciMLProblems","title":"SciMLBase.SciMLProblem","text":"abstract type SciMLProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DEProblem","page":"SciMLProblems","title":"SciMLBase.DEProblem","text":"abstract type DEProblem <: SciMLBase.SciMLProblem\n\nBase type for all DifferentialEquations.jl problems. Concrete subtypes of DEProblem contain the necessary information to fully define a differential equation of the corresponding type.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractLinearProblem","page":"SciMLProblems","title":"SciMLBase.AbstractLinearProblem","text":"abstract type AbstractLinearProblem{bType, isinplace} <: SciMLBase.SciMLProblem\n\nBase for types which define linear systems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractNonlinearProblem","page":"SciMLProblems","title":"SciMLBase.AbstractNonlinearProblem","text":"abstract type AbstractNonlinearProblem{uType, isinplace} <: SciMLBase.DEProblem\n\nBase for types which define nonlinear solve problems (f(u)=0).\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractOptimizationProblem","page":"SciMLProblems","title":"SciMLBase.AbstractOptimizationProblem","text":"abstract type AbstractOptimizationProblem{isinplace} <: SciMLBase.SciMLProblem\n\nBase for types which define equations for optimization.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractNoiseProblem","page":"SciMLProblems","title":"SciMLBase.AbstractNoiseProblem","text":"abstract type AbstractNoiseProblem <: SciMLBase.DEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractODEProblem","text":"abstract type AbstractODEProblem{uType, tType, isinplace} <: SciMLBase.DEProblem\n\nBase for types which define ODE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractDiscreteProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDiscreteProblem","text":"abstract type AbstractDiscreteProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\nBase for types which define discrete problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractAnalyticalProblem","page":"SciMLProblems","title":"SciMLBase.AbstractAnalyticalProblem","text":"abstract type AbstractAnalyticalProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractRODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractRODEProblem","text":"abstract type AbstractRODEProblem{uType, tType, isinplace, ND} <: SciMLBase.DEProblem\n\nBase for types which define RODE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractSDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSDEProblem","text":"abstract type AbstractSDEProblem{uType, tType, isinplace, ND} <: SciMLBase.AbstractRODEProblem{uType, tType, isinplace, ND}\n\nBase for types which define SDE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractDAEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDAEProblem","text":"abstract type AbstractDAEProblem{uType, duType, tType, isinplace} <: SciMLBase.DEProblem\n\nBase for types which define DAE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDDEProblem","text":"abstract type AbstractDDEProblem{uType, tType, lType, isinplace} <: SciMLBase.DEProblem\n\nBase for types which define DDE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractConstantLagDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractConstantLagDDEProblem","text":"abstract type AbstractConstantLagDDEProblem{uType, tType, lType, isinplace} <: SciMLBase.AbstractDDEProblem{uType, tType, lType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractSecondOrderODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSecondOrderODEProblem","text":"abstract type AbstractSecondOrderODEProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractBVProblem","page":"SciMLProblems","title":"SciMLBase.AbstractBVProblem","text":"abstract type AbstractBVProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\nBase for types which define BVP problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractJumpProblem","page":"SciMLProblems","title":"SciMLBase.AbstractJumpProblem","text":"abstract type AbstractJumpProblem{P, J} <: SciMLBase.DEProblem\n\nBase for types which define jump problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractSDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSDDEProblem","text":"abstract type AbstractSDDEProblem{uType, tType, lType, isinplace, ND} <: SciMLBase.DEProblem\n\nBase for types which define SDDE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractConstantLagSDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractConstantLagSDDEProblem","text":"abstract type AbstractConstantLagSDDEProblem{uType, tType, lType, isinplace, ND} <: SciMLBase.AbstractSDDEProblem{uType, tType, lType, isinplace, ND}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractPDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractPDEProblem","text":"abstract type AbstractPDEProblem <: SciMLBase.DEProblem\n\nBase for types which define PDE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#Concrete-SciMLProblems","page":"SciMLProblems","title":"Concrete SciMLProblems","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"LinearProblem\nNonlinearProblem\nQuadratureProblem\nOptimizationProblem\nBVProblem\nDAEProblem\nDDEProblem\nDynamicalDDEProblem\nSecondOrderDDEProblem\nDiscreteProblem\nNoiseProblem\nODEProblem\nDynamicalODEProblem\nSecondOrderODEProblem\nSplitODEProblem\nIncrementingODEProblem\nRODEProblem\nSDDEProblem\nSplitSDEProblem\nDynamicalSDEProblem\nSteadyStateProblem\nPDEProblem","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.BVProblem","page":"SciMLProblems","title":"SciMLBase.BVProblem","text":"Defines an BVP problem. Documentation Page: https://diffeq.sciml.ai/stable/types/bvp_types/\n\nMathematical Specification of a BVP Problem\n\nTo define a BVP Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\nfracdudt = f(upt)\n\nalong with an implicit function bc! which defines the residual equation, where\n\nbc(upt) = 0\n\nis the manifold on which the solution must live. A common form for this is the two-point BVProblem where the manifold defines the solution at two points:\n\nu(t_0) = a\nu(t_f) = b\n\nProblem Type\n\nConstructors\n\nTwoPointBVProblem{isinplace}(f,bc!,u0,tspan,p=NullParameters();kwargs...)\nBVProblem{isinplace}(f,bc!,u0,tspan,p=NullParameters();kwargs...)\n\nFor any BVP problem type, bc! is the inplace function:\n\nbc!(residual, u, p, t)\n\nwhere residual computed from the current u. u is an array of solution values where u[i] is at time t[i], while p are the parameters. For a TwoPointBVProblem, t = tspan. For the more general BVProblem, u can be all of the internal time points, and for shooting type methods u=sol the ODE solution. Note that all features of the ODESolution are present in this form. In both cases, the size of the residual matches the size of the initial condition.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFields\n\nf: The function for the ODE.\nbc: The boundary condition function.\nu0: The initial condition. Either the initial condition for the ODE as an initial value problem, or a Vector of values for u(t_i) for collocation methods\ntspan: The timespan for the problem.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DAEProblem","page":"SciMLProblems","title":"SciMLBase.DAEProblem","text":"Defines an implicit ordinary differential equation (ODE) or  differential-algebraic equation (DAE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/dae_types/\n\nMathematical Specification of an DAE Problem\n\nTo define a DAE Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\n0 = f(duupt)\n\nf should be specified as f(du,u,p,t) (or in-place as f(resid,du,u,p,t)). Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nDAEProblem(f::DAEFunction,du0,u0,tspan,p=NullParameters();kwargs...)\nDAEProblem{isinplace}(f,du0,u0,tspan,p=NullParameters();kwargs...) : Defines the DAE with the specified functions. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The function in the ODE.\ndu0: The initial condition for the derivative.\nu0: The initial condition.\ntspan: The timespan for the problem.\ndifferential_vars: A logical array which declares which variables are the differential (non algebraic) vars (i.e. du' is in the equations for this variable). Defaults to nothing. Some solvers may require this be set if an initial condition needs to be determined.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\nExample Problems\n\nExamples problems can be found in DiffEqProblemLibrary.jl.\n\nTo use a sample problem, such as prob_dae_resrob, you can do something like:\n\n#] add DiffEqProblemLibrary\nusing DiffEqProblemLibrary.DAEProblemLibrary\n# load problems\nDAEProblemLibrary.importdaeproblems()\nprob = DAEProblemLibrary.prob_dae_resrob\nsol = solve(prob,IDA())\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DDEProblem","page":"SciMLProblems","title":"SciMLBase.DDEProblem","text":"Defines a delay differential equation (DDE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/dde_types/\n\nMathematical Specification of a DDE Problem\n\nTo define a DDE Problem, you simply need to give the function f, the initial condition u_0 at time point t_0, and the history function h which together define a DDE:\n\nfracdudt = f(uhpt) qquad (t geq t_0)\n\nu(t_0) = u_0\n\nu(t) = h(t) qquad (t  t_0)\n\nf should be specified as f(u, h, p, t) (or in-place as f(du, u, h, p, t)), u_0 should be an AbstractArray (or number) whose geometry matches the desired geometry of u, and h should be specified as described below. The history function h is accessed for all delayed values. Note that we are not limited to numbers or vectors for u_0; one is allowed to provide u_0 as arbitrary matrices / higher dimension tensors as well.\n\nFunctional Forms of the History Function\n\nThe history function h can be called in the following ways:\n\nh(p, t): out-of-place calculation\nh(out, p, t): in-place calculation\nh(p, t, deriv::Type{Val{i}}): out-of-place calculation of the ith derivative\nh(out, p, t, deriv::Type{Val{i}}): in-place calculation of the ith derivative\nh(args...; idxs): calculation of h(args...) for indices idxs\n\nNote that a dispatch for the supplied history function of matching form is required for whichever function forms are used in the user derivative function f.\n\nDeclaring Lags\n\nLags are declared separately from their use. One can use any lag by simply using the interpolant of h at that point. However, one should use caution in order to achieve the best accuracy. When lags are declared, the solvers can more efficiently be more accurate and thus this is recommended.\n\nNeutral and Retarded Delay Differential Equations\n\nNote that the history function specification can be used to specify general retarded arguments, i.e. h(p,α(u,t)). Neutral delay differential equations can be specified by using the deriv value in the history interpolation. For example, h(p,t-τ, Val{1}) returns the first derivative of the history values at time t-τ.\n\nNote that algebraic equations can be specified by using a singular mass matrix.\n\nProblem Type\n\nConstructors\n\nDDEProblem(f[, u0], h, tspan[, p]; <keyword arguments>)\nDDEProblem{isinplace}(f[, u0], h, tspan[, p]; <keyword arguments>)\n\nParameter isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nArguments\n\nf: The function in the DDE.\nu0: The initial condition. Defaults to the value h(p, first(tspan)) of the history function evaluated at the initial time point.\nh: The history function for the DDE before t0.\ntspan: The timespan for the problem.\np: The parameters with which function f is called. Defaults to NullParameters.\nconstant_lags: A collection of constant lags used by the history function h. Defaults to ().\ndependent_lags A tuple of functions (u, p, t) -> lag for the state-dependent lags used by the history function h. Defaults to ().\nneutral: If the DDE is neutral, i.e., if delays appear in derivative terms.\norder_discontinuity_t0: The order of the discontinuity at the initial time point. Defaults to 0 if an initial condition u0 is provided. Otherwise it is forced to be greater or equal than 1.\nkwargs: The keyword arguments passed onto the solves.\n\nDynamical Delay Differential Equations\n\nMuch like Dynamical ODEs, a Dynamical DDE is a Partitioned DDE of the form:\n\nfracdvdt = f_1(uth) \nfracdudt = f_2(vh) \n\nConstructors\n\nDynamicalDDEProblem(f1, f2[, v0, u0], h, tspan[, p]; <keyword arguments>)\nDynamicalDDEProblem{isinplace}(f1, f2[, v0, u0], h, tspan[, p]; <keyword arguments>)\n\nParameter isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nArguments\n\nf: The function in the DDE.\nv0 and u0: The initial condition. Defaults to the values h(p, first(tspan))... of the history function evaluated at the initial time point.\nh: The history function for the DDE before t0. Must return an object with the indices 1 and 2, with the values of v and u respectively.\ntspan: The timespan for the problem.\np: The parameters with which function f is called. Defaults to NullParameters.\nconstant_lags: A collection of constant lags used by the history function h. Defaults to ().\ndependent_lags A tuple of functions (v, u, p, t) -> lag for the state-dependent lags used by the history function h. Defaults to ().\nneutral: If the DDE is neutral, i.e., if delays appear in derivative terms.\norder_discontinuity_t0: The order of the discontinuity at the initial time point. Defaults to 0 if an initial condition u0 is provided. Otherwise it is forced to be greater or equal than 1.\nkwargs: The keyword arguments passed onto the solves.\n\nThe for dynamical and second order DDEs, the history function will return an object with the indicies 1 and 2 defined, where h(p, t_prev)[1] is the value of f_2(v u h p t_mathrmprev) and h(p, t_prev)[2] is the value of f_1(v u h p t_mathrmprev) (this is for consistency with the ordering of the intitial conditions in the constructor). The supplied history function must also return such a 2-index object, which can be accomplished with a tuple (v,u) or vector [v,u].\n\n2nd Order Delay Differential Equations\n\nTo define a 2nd Order DDE Problem, you simply need to give the function f and the initial condition u_0 which define an DDE:\n\nu = f(uuhpt)\n\nf should be specified as f(du,u,p,t) (or in-place as f(ddu,du,u,p,t)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nFrom this form, a dynamical ODE:\n\nv = f(vuhpt) \nu = v \n\nConstructors\n\nSecondOrderDDEProblem(f, [, du0, u0], h, tspan[, p]; <keyword arguments>)\nSecondOrderDDEProblem{isinplace}(f, [, du0, u0], h, tspan[, p]; <keyword arguments>)\n\nParameter isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nArguments\n\nf: The function in the DDE.\ndu0 and u0: The initial condition. Defaults to the values h(p, first(tspan))... of the history function evaluated at the initial time point.\nh: The history function for the DDE before t0. Must return an object with the indices 1 and 2, with the values of v and u respectively.\ntspan: The timespan for the problem.\np: The parameters with which function f is called. Defaults to NullParameters.\nconstant_lags: A collection of constant lags used by the history function h. Defaults to ().\ndependent_lags A tuple of functions (v, u, p, t) -> lag for the state-dependent lags used by the history function h. Defaults to ().\nneutral: If the DDE is neutral, i.e., if delays appear in derivative terms.\norder_discontinuity_t0: The order of the discontinuity at the initial time point. Defaults to 0 if an initial condition u0 is provided. Otherwise it is forced to be greater or equal than 1.\nkwargs: The keyword arguments passed onto the solves.\n\nAs above, the history function will return an object with indices 1 and 2, with the values of du and u respectively. The supplied history function must also match this return type, e.g. by returning a 2-element tuple or vector.\n\nExample Problems\n\nExample problems can be found in DiffEqProblemLibrary.jl.\n\nTo use a sample problem, such as prob_ode_linear, you can do something like:\n\n#] add DiffEqProblemLibrary\nusing DiffEqProblemLibrary.ODEProblemLibrary\n# load problems\nODEProblemLibrary.importodeproblems()\nprob = ODEProblemLibrary.prob_ode_linear\nsol = solve(prob)\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DynamicalDDEProblem","page":"SciMLProblems","title":"SciMLBase.DynamicalDDEProblem","text":"struct DynamicalDDEProblem{iip} <: SciMLBase.AbstractDynamicalDDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SecondOrderDDEProblem","page":"SciMLProblems","title":"SciMLBase.SecondOrderDDEProblem","text":"struct SecondOrderDDEProblem{iip} <: SciMLBase.AbstractDynamicalDDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.NoiseProblem","page":"SciMLProblems","title":"SciMLBase.NoiseProblem","text":"struct NoiseProblem{N<:SciMLBase.AbstractNoiseProcess, T, K} <: SciMLBase.AbstractNoiseProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DynamicalODEProblem","page":"SciMLProblems","title":"SciMLBase.DynamicalODEProblem","text":"Defines an dynamical ordinary differential equation (ODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/dynamical_types/\n\nDynamical ordinary differential equations, such as those arising from the definition of a Hamiltonian system or a second order ODE, have a special structure that can be utilized in the solution of the differential equation. On this page we describe how to define second order differential equations for their efficient numerical solution.\n\nMathematical Specification of a Dynamical ODE Problem\n\nThese algorithms require a Partitioned ODE of the form:\n\nfracdvdt = f_1(ut) \nfracdudt = f_2(v) \n\nThis is a Partitioned ODE partitioned into two groups, so the functions should be specified as f1(dv,v,u,p,t) and f2(du,v,u,p,t) (in the inplace form), where f1 is independent of v (unless specified by the solver), and f2 is independent of u and t. This includes discretizations arising from SecondOrderODEProblems where the velocity is not used in the acceleration function, and Hamiltonians where the potential is (or can be) time-dependent but the kinetic energy is only dependent on v.\n\nNote that some methods assume that the integral of f2 is a quadratic form. That means that f2=v'*M*v, i.e. int f_2 = frac12 m v^2, giving du = v. This is equivalent to saying that the kinetic energy is related to v^2. The methods which require this assumption will lose accuracy if this assumption is violated. Methods listed make note of this requirement with \"Requires quadratic kinetic energy\".\n\nConstructor\n\nDynamicalODEProblem(f::DynamicalODEFunction,v0,u0,tspan,p=NullParameters();kwargs...)\nDynamicalODEProblem{isinplace}(f1,f2,v0,u0,tspan,p=NullParameters();kwargs...)\n\nDefines the ODE with the specified functions. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFields\n\nf1 and f2: The functions in the ODE.\nv0 and u0: The initial conditions.\ntspan: The timespan for the problem.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SecondOrderODEProblem","page":"SciMLProblems","title":"SciMLBase.SecondOrderODEProblem","text":"Defines a second order ordinary differential equation (ODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/dynamical_types/\n\nMathematical Specification of a 2nd Order ODE Problem\n\nTo define a 2nd Order ODE Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\nu = f(uupt)\n\nf should be specified as f(du,u,p,t) (or in-place as f(ddu,du,u,p,t)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nFrom this form, a dynamical ODE:\n\nv = f(vupt) \nu = v \n\nis generated.\n\nConstructors\n\nSecondOrderODEProblem{isinplace}(f,du0,u0,tspan,callback=CallbackSet())\n\nDefines the ODE with the specified functions.\n\nFields\n\nf: The function for the second derivative.\ndu0: The initial derivative.\nu0: The initial condition.\ntspan: The timespan for the problem.\ncallback: A callback to be applied to every solver which uses the problem. Defaults to nothing.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SplitODEProblem","page":"SciMLProblems","title":"SciMLBase.SplitODEProblem","text":"Defines a split ordinary differential equation (ODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/splitodetypes/\n\nMathematical Specification of a Split ODE Problem\n\nTo define a SplitODEProblem, you simply need to give a two functions  f_1 and f_2 along with an initial condition u_0 which define an ODE:\n\nfracdudt =  f_1(upt) + f_2(upt)\n\nf should be specified as f(u,p,t) (or in-place as f(du,u,p,t)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nMany splits are at least partially linear. That is the equation:\n\nfracdudt =  Au + f_2(upt)\n\nFor how to define a linear function A, see the documentation for the DiffEqOperators.\n\nConstructors\n\nSplitODEProblem(f::SplitFunction,u0,tspan,p=NullParameters();kwargs...)\nSplitODEProblem{isinplace}(f1,f2,u0,tspan,p=NullParameters();kwargs...)\n\nThe isinplace parameter can be omitted and will be determined using the signature of f2. Note that both f1 and f2 should support the in-place style if isinplace is true or they should both support the out-of-place style if isinplace is false. You cannot mix up the two styles.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nUnder the hood, a SplitODEProblem is just a regular ODEProblem whose f is a SplitFunction. Therefore you can solve a SplitODEProblem using the same solvers for ODEProblem. For solvers dedicated to split problems, see Split ODE Solvers.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf1, f2: The functions in the ODE.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.IncrementingODEProblem","page":"SciMLProblems","title":"SciMLBase.IncrementingODEProblem","text":"Experimental\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.RODEProblem","page":"SciMLProblems","title":"SciMLBase.RODEProblem","text":"Defines a random ordinary differential equation (RODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/rode_types/\n\nMathematical Specification of a RODE Problem\n\nTo define a RODE Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\nfracdudt = f(uptW(t))\n\nwhere W(t) is a random process. f should be specified as f(u,p,t,W) (or in-place as f(du,u,p,t,W)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nConstructors\n\nRODEProblem(f::RODEFunction,u0,tspan,p=NullParameters();noise=WHITE_NOISE,rand_prototype=nothing,callback=nothing)\nRODEProblem{isinplace}(f,u0,tspan,p=NullParameters();noise=WHITE_NOISE,rand_prototype=nothing,callback=nothing,mass_matrix=I) : Defines the RODE with the specified functions. The default noise is WHITE_NOISE. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The drift function in the SDE.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The optional parameters for the problem. Defaults to NullParameters.\nnoise: The noise process applied to the noise upon generation. Defaults to Gaussian white noise. For information on defining different noise processes, see the noise process documentation page\nrand_prototype: A prototype type instance for the noise vector. It defaults to nothing, which means the problem should be interpreted as having a noise vector whose size matches u0.\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SDDEProblem","page":"SciMLProblems","title":"SciMLBase.SDDEProblem","text":"Defines a stochastic delay differential equation (SDDE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/sdde_types/\n\nMathematical Specification of a Stochastic Delay Differential Equation (SDDE) Problem\n\nTo define a SDDE Problem, you simply need to give the drift function f, the diffusion function g, the initial condition u_0 at time point t_0, and the history function h which together define a SDDE:\n\ndu = f(uhpt)dt + g(uhpt)dW_t qquad (t geq t_0)\n\nu(t_0) = u_0\n\nu(t) = h(t) qquad (t  t_0)\n\nf should be specified as f(u, h, p, t) (or in-place as f(du, u, h, p, t)) (and g should match). u_0 should be an AbstractArray (or number) whose geometry matches the desired geometry of u, and h should be specified as described below. The history function h is accessed for all delayed values. Note that we are not limited to numbers or vectors for u_0; one is allowed to provide u_0 as arbitrary matrices / higher dimension tensors as well.\n\nNote that this functionality should be considered experimental.\n\nFunctional Forms of the History Function\n\nThe history function h can be called in the following ways:\n\nh(p, t): out-of-place calculation\nh(out, p, t): in-place calculation\nh(p, t, deriv::Type{Val{i}}): out-of-place calculation of the ith derivative\nh(out, p, t, deriv::Type{Val{i}}): in-place calculation of the ith derivative\nh(args...; idxs): calculation of h(args...) for indices idxs\n\nNote that a dispatch for the supplied history function of matching form is required for whichever function forms are used in the user derivative function f.\n\nDeclaring Lags\n\nLags are declared separately from their use. One can use any lag by simply using the interpolant of h at that point. However, one should use caution in order to achieve the best accuracy. When lags are declared, the solvers can more efficiently be more accurate and thus this is recommended.\n\nNeutral, Retarded, and Algebraic Stochastic Delay Differential Equations\n\nNote that the history function specification can be used to specify general retarded arguments, i.e. h(p,α(u,t)). Neutral delay differential equations can be specified by using the deriv value in the history interpolation. For example, h(p,t-τ, Val{1}) returns the first derivative of the history values at time t-τ.\n\nNote that algebraic equations can be specified by using a singular mass matrix.\n\nProblem Type\n\nConstructors\n\nSDDEProblem(f,g[, u0], h, tspan[, p]; <keyword arguments>)\nSDDEProblem{isinplace}(f,g[, u0], h, tspan[, p]; <keyword arguments>)\n\nParameter isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nArguments\n\nf: The drift function in the SDDE.\ng: The diffusion function in the SDDE.\nu0: The initial condition. Defaults to the value h(p, first(tspan)) of the history function evaluated at the initial time point.\nh: The history function for the DDE before t0.\ntspan: The timespan for the problem.\np: The parameters with which function f is called. Defaults to NullParameters.\nconstant_lags: A collection of constant lags used by the history function h. Defaults to ().\ndependent_lags A tuple of functions (u, p, t) -> lag for the state-dependent lags used by the history function h. Defaults to ().\nneutral: If the DDE is neutral, i.e., if delays appear in derivative terms.\norder_discontinuity_t0: The order of the discontinuity at the initial time point. Defaults to 0 if an initial condition u0 is provided. Otherwise it is forced to be greater or equal than 1.\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SplitSDEProblem","page":"SciMLProblems","title":"SciMLBase.SplitSDEProblem","text":"struct SplitSDEProblem{iip} <: SciMLBase.AbstractSplitSDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DynamicalSDEProblem","page":"SciMLProblems","title":"SciMLBase.DynamicalSDEProblem","text":"struct DynamicalSDEProblem{iip} <: SciMLBase.AbstractDynamicalSDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.PDEProblem","page":"SciMLProblems","title":"SciMLBase.PDEProblem","text":"struct PDEProblem{P, E, S} <: SciMLBase.AbstractPDEProblem\n\n\n\n\n\n","category":"type"},{"location":"#The-SciML-Open-Souce-Software-Ecoystem","page":"The SciML Open Souce Software Ecoystem","title":"The SciML Open Souce Software Ecoystem","text":"","category":"section"},{"location":"","page":"The SciML Open Souce Software Ecoystem","title":"The SciML Open Souce Software Ecoystem","text":"The SciML organization is an collection of tools for solving equations and modeling systems developed in the Julia programming language with bindings to other languages such as R and Python. The organization provides well-maintained  tools which compose together as a coherent ecosystem. It has a coherent development principle, unified APIs over large collections of equation solvers, pervasive differentiability and sensitivitiy analysis, and features many of the highest performance and parallel implementations one can find.","category":"page"},{"location":"#Contributing","page":"The SciML Open Souce Software Ecoystem","title":"Contributing","text":"","category":"section"},{"location":"","page":"The SciML Open Souce Software Ecoystem","title":"The SciML Open Souce Software Ecoystem","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to ModelingToolkit.\nThere are a few community forums:\nthe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\non the Julia Discourse forums\nsee also SciML Community page","category":"page"},{"location":"copies/Surrogates/BraninFunction/#Branin-Function","page":"Branin function","title":"Branin Function","text":"","category":"section"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"The Branin Function is commonly used as a test function for metamodelling in computer experiments, especially in the context of optimization.","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"The expression of the Branin Function is given as: f(x) = (x_2 - frac514pi^2x_1^2 + frac5pix_1 - 6)^2 + 10(1-frac18pi)cos(x_1) + 10","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"where x = (x_1 x_2) with -5leq x_1 leq 10 0 leq x_2 leq 15","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"First of all we will import these two packages Surrogates and Plots.","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"using Surrogates\r\nusing Plots\r\ndefault()","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"Now, let's define our objective function:","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"function branin(x)\r\n      x1 = x[1]\r\n      x2 = x[2]\r\n      b = 5.1 / (4*pi^2);\r\n      c = 5/pi;\r\n      r = 6;\r\n      a = 1;\r\n      s = 10;\r\n      t = 1 / (8*pi);\r\n      term1 = a * (x2 - b*x1^2 + c*x1 - r)^2;\r\n      term2 = s*(1-t)*cos(x1);\r\n      y = term1 + term2 + s;\r\nend","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"Now, let's plot it:","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"n_samples = 80\r\nlower_bound = [-5, 0]\r\nupper_bound = [10,15]\r\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\nzs = branin.(xys);\r\nx, y = -5:10, 0:15 # hide\r\np1 = surface(x, y, (x1,x2) -> branin((x1,x2))) # hide\r\nxs = [xy[1] for xy in xys] # hide\r\nys = [xy[2] for xy in xys] # hide\r\nscatter!(xs, ys, zs) # hide\r\np2 = contour(x, y, (x1,x2) -> branin((x1,x2))) # hide\r\nscatter!(xs, ys) # hide\r\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"Now it's time to fitting different surrogates and then we will plot them. We will have a look on Kriging Surrogate:","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"kriging_surrogate = Kriging(xys, zs, lower_bound, upper_bound, p=[1.9, 1.9])","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"p1 = surface(x, y, (x, y) -> kriging_surrogate([x y])) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> kriging_surrogate([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2, title=\"Kriging Surrogate\") # hide","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"Now, we will have a look on Inverse Distance Surrogate:","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"InverseDistance = InverseDistanceSurrogate(xys, zs,  lower_bound, upper_bound)","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"p1 = surface(x, y, (x, y) -> InverseDistance([x y])) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> InverseDistance([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2, title=\"Inverse Distance Surrogate\") # hide","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"Now, let's talk about Lobachevsky Surrogate:","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"Lobachevsky = LobachevskySurrogate(xys, zs,  lower_bound, upper_bound, alpha = [2.8,2.8], n=8)","category":"page"},{"location":"copies/Surrogates/BraninFunction/","page":"Branin function","title":"Branin function","text":"p1 = surface(x, y, (x, y) -> Lobachevsky([x y])) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> Lobachevsky([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2, title=\"Lobachevsky Surrogate\") # hide","category":"page"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/#CMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"CMAEvolutionStrategy is a Julia package implementing the Covariance Matrix Adaptation Evolution Strategy algorithm. ","category":"page"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The CMAEvolutionStrategy algorithm is called by CMAEvolutionStrategyOpt()","category":"page"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/#Installation:-OptimizationCMAEvolutionStrategy.jl","page":"CMAEvolutionStrategy.jl","title":"Installation: OptimizationCMAEvolutionStrategy.jl","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"To use this package, install the OptimizationCMAEvolutionStrategy package:","category":"page"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"import Pkg; Pkg.add(\"OptimizationCMAEvolutionStrategy\")","category":"page"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/#Global-Optimizer","page":"CMAEvolutionStrategy.jl","title":"Global Optimizer","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/#Without-Constraint-Equations","page":"CMAEvolutionStrategy.jl","title":"Without Constraint Equations","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The method in CMAEvolutionStrategy is performing global optimization on problems without constraint equations. However, lower and upper constraints set by lb and ub in the OptimizationProblem are required.","category":"page"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/#Example","page":"CMAEvolutionStrategy.jl","title":"Example","text":"","category":"section"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"The Rosenbrock function can optimized using the CMAEvolutionStrategyOpt() as follows:","category":"page"},{"location":"copies/Optimization/optimization_packages/cmaevolutionstrategy/","page":"CMAEvolutionStrategy.jl","title":"CMAEvolutionStrategy.jl","text":"rosenbrock(x, p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0, 100.0]\nf = OptimizationFunction(rosenbrock)\nprob = Optimization.OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob, CMAEvolutionStrategyOpt())","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/#Sobol-Method","page":"Sobol Method","title":"Sobol Method","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"struct Sobol <: GSAMethod\n    order::Vector{Int}\n    nboot::Int\n    conf_level::Float64\nend","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"The Sobol object has as its fields the order of the indices to be estimated. ","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"order - the order of the indices to calculate. Defaults to [0,1], which means the Total and First order indices. Passing 2 enables calculation of the Second order indices as well.","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"For confidence interval calculation nboot should be specified for the number (>0) of bootstrap runs  and conf_level for the confidence level, the default for which is 0.95.","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/#Sobol-Method-Details","page":"Sobol Method","title":"Sobol Method Details","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"Sobol is a variance-based method and it decomposes the variance of the output of the model or system into fractions which can be attributed to inputs or sets of inputs. This helps to get not just the individual parameter's sensitivities but also gives a way to quantify the affect and sensitivity from the interaction between the parameters.","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":" Y = f_0+ sum_i=1^d f_i(X_i)+ sum_i  j^d f_ij(X_iX_j)  + f_12d(X_1X_2X_d)","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":" Var(Y) = sum_i=1^d V_i + sum_i  j^d V_ij +  + V_12d","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"The Sobol Indices are \"order\"ed, the first order indices given by S_i = fracV_iVar(Y) the contribution to the output variance of the main effect of X_i, therefore it measures the effect of varying X_i alone, but averaged over variations in other input parameters. It is standardised by the total variance to provide a fractional contribution. Higher-order interaction indices S_ij S_ijk and so on can be formed by dividing other terms in the variance decomposition by Var(Y).","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/#API","page":"Sobol Method","title":"API","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"function gsa(f, method::Sobol, A::AbstractMatrix{TA}, B::AbstractMatrix;\n             batch=false, Ei_estimator = :Jansen1999, distributed::Val{SHARED_ARRAY} = Val(false), kwargs...) where {TA, SHARED_ARRAY}\n","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"Ei_estimator can take :Homma1996, :Sobol2007 and :Jansen1999 for which   Monte Carlo estimator is used for the Ei term. Defaults to :Jansen1999. Details for these can be found in the    corresponding papers:     - :Homma1996 - Homma, T. and Saltelli, A., 1996. Importance measures in global sensitivity analysis of nonlinear models. Reliability Engineering & System Safety, 52(1), pp.1-17.     - :Sobol2007 - I.M. Sobol, S. Tarantola, D. Gatelli, S.S. Kucherenko and W. Mauntz, 2007, Estimating the approx- imation errors when fixing unessential factors in global sensitivity analysis, Reliability Engineering and System Safety, 92, 957–960.     A. Saltelli, P. Annoni, I. Azzini, F. Campolongo, M. Ratto and S. Tarantola, 2010, Variance based sensitivity analysis of model output. Design and estimator for the total sensitivity index, Computer Physics Communications 181, 259–270.     - :Jansen1999 - M.J.W. Jansen, 1999, Analysis of variance designs for model output, Computer Physics Communi- cation, 117, 35–43.","category":"page"},{"location":"copies/GlobalSensitivity/methods/sobol/#Example","page":"Sobol Method","title":"Example","text":"","category":"section"},{"location":"copies/GlobalSensitivity/methods/sobol/","page":"Sobol Method","title":"Sobol Method","text":"using GlobalSensitivity, QuasiMonteCarlo\n\nfunction ishi(X)\n    A= 7\n    B= 0.1\n    sin(X[1]) + A*sin(X[2])^2+ B*X[3]^4 *sin(X[1])\nend\n\nn = 600000\nlb = -ones(4)*π\nub = ones(4)*π\nsampler = SobolSample()\nA,B = QuasiMonteCarlo.generate_design_matrices(n,lb,ub,sampler)\n\nres1 = gsa(ishi,Sobol(order=[0,1,2]),A,B)\n\nfunction ishi_batch(X)\n    A= 7\n    B= 0.1\n    @. sin(X[1,:]) + A*sin(X[2,:])^2+ B*X[3,:]^4 *sin(X[1,:])\nend\n\nres2 = gsa(ishi_batch,Sobol(),A,B,batch=true)","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/rc_circuit/#RC-Circuit-Model","page":"RC Circuit","title":"RC Circuit Model","text":"","category":"section"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/rc_circuit/","page":"RC Circuit","title":"RC Circuit","text":"This tutorial is a simplified version of the RC circuit tutorial in the ModelingToolkit.jl documentation. In that tutorial, the full RC circuit is built from scratch. Here, we will use the components of the Electrical model in the ModelingToolkit Standard Library to simply connect pre-made components and simulate the model.","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/rc_circuit/","page":"RC Circuit","title":"RC Circuit","text":"using ModelingToolkit, OrdinaryDiffEq, Plots\nusing ModelingToolkitStandardLibrary.Electrical\n\nR = 1.0\nC = 1.0\nV = 1.0\n@variables t\n@named resistor = Resistor(R=R)\n@named capacitor = Capacitor(C=C)\n@named source = ConstantVoltage(V=V)\n@named ground = Ground()\n\nrc_eqs = [\n        connect(source.p, resistor.p)\n        connect(resistor.n, capacitor.p)\n        connect(capacitor.n, source.n, ground.g)\n        ]\n\n@named rc_model = ODESystem(rc_eqs, t, systems=[resistor, capacitor, source, ground])\nsys = structural_simplify(rc_model)\nprob = ODAEProblem(sys, Pair[], (0, 10.0))\nsol = solve(prob, Tsit5())\nplot(sol, vars = [capacitor.v,resistor.i],\n     title = \"RC Circuit Demonstration\",\n     labels = [\"Capacitor Voltage\" \"Resistor Current\"])\nsavefig(\"plot.png\")","category":"page"},{"location":"copies/ModelingToolkitStandardLibrary/tutorials/rc_circuit/","page":"RC Circuit","title":"RC Circuit","text":"(Image: )","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#The-PDE-Definition-Interface","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"While ODEs u = f(upt) can be defined by a user-function f, for PDEs the function form can be different for every PDE. How many functions, and how many inputs? This can always change. The SciML ecosystem solves this problem by using ModelingToolkit.jl to define PDESystem, a high-level symbolic description of the PDE to be consumed by other packages.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"The vision for the common PDE interface is that a user should only have to specify their PDE once, mathematically, and have instant access to everything as simple as a finite difference method with constant grid spacing, to something as complex as a distributed multi-GPU discontinuous Galerkin method.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"The key to the common PDE interface is a separation of the symbolic handling from the numerical world. All of the discretizers should not \"solve\" the PDE, but instead be a conversion of the mathematical specification to a numerical problem. Preferably, the transformation should be to another ModelingToolkit.jl AbstractSystem via a symbolic_discretize dispatch, but in some cases this cannot be done or will  not be performant. Thus in some cases, only a discretize definition is given to a  SciMLProblem, with symbolic_discretize simply providing diagnostic or lower level information about the construction process.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"These elementary problems, such as solving linear systems Ax=b, solving nonlinear systems f(x)=0, ODEs, etc. are all defined by SciMLBase.jl, which then numerical solvers can all target these common forms. Thus someone who works on linear solvers doesn't necessarily need to be working on a Discontinuous Galerkin or finite element library, but instead \"linear solvers that are good for matrices A with properties ...\" which are then accessible by every other discretization method in the common PDE interface.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"Similar to the rest of the AbstractSystem types, transformation and analyses functions will allow for simplifying the PDE before solving it, and constructing block symbolic functions like Jacobians.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#Constructors","page":"The PDE Definition Interface","title":"Constructors","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"ModelingToolkit.PDESystem","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#Domains-(WIP)","page":"The PDE Definition Interface","title":"Domains (WIP)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"Domains are specifying by saying indepvar in domain, where indepvar is a single or a collection of independent variables, and domain is the chosen domain type. A 2-tuple can be used to indicate an Interval. Thus forms for the indepvar can be like:","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"t ∈ (0.0,1.0)\n(t,x) ∈ UnitDisk()\n[v,w,x,y,z] ∈ VectorUnitBall(5)","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#Domain-Types-(WIP)","page":"The PDE Definition Interface","title":"Domain Types (WIP)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"Interval(a,b): Defines the domain of an interval from a to b (requires explicit","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"import from DomainSets.jl, but a 2-tuple can be used instead)","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#discretize-and-symbolic_discretize","page":"The PDE Definition Interface","title":"discretize and symbolic_discretize","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"The only functions which act on a PDESystem are the following:","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"discretize(sys,discretizer): produces the outputted AbstractSystem or SciMLProblem.\nsymbolic_discretize(sys,discretizer): produces a debugging symbolic description of the discretized problem.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#Boundary-Conditions-(WIP)","page":"The PDE Definition Interface","title":"Boundary Conditions (WIP)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/#Transformations","page":"The PDE Definition Interface","title":"Transformations","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/#Analyses","page":"The PDE Definition Interface","title":"Analyses","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/#Discretizer-Ecosystem","page":"The PDE Definition Interface","title":"Discretizer Ecosystem","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/#NeuralPDE.jl:-PhysicsInformedNN","page":"The PDE Definition Interface","title":"NeuralPDE.jl: PhysicsInformedNN","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"NeuralPDE.jl defines the PhysicsInformedNN discretizer which uses a DiffEqFlux.jl neural network to solve the differential equation.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#MethodOfLines.jl:-MOLFiniteDifference-(WIP)","page":"The PDE Definition Interface","title":"MethodOfLines.jl: MOLFiniteDifference (WIP)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"MethodOfLines.jl defines the MOLFiniteDifference discretizer which performs a finite difference discretization using the DiffEqOperators.jl stencils. These stencils make use of NNLib.jl for fast operations on semi-linear domains.","category":"page"},{"location":"copies/Surrogates/water_flow/#Water-flow-function","page":"Water Flow function","title":"Water flow function","text":"","category":"section"},{"location":"copies/Surrogates/water_flow/","page":"Water Flow function","title":"Water Flow function","text":"The water flow function is defined as: f(r_wrT_uH_uT_lH_lLK_w) = frac2*pi*T_u(H_u - H_l)log(fracrr_w)*1 + frac2LT_ulog(fracrr_w)*r_w^2*K_w+ fracT_uT_l ","category":"page"},{"location":"copies/Surrogates/water_flow/","page":"Water Flow function","title":"Water Flow function","text":"It has 8 dimension.","category":"page"},{"location":"copies/Surrogates/water_flow/","page":"Water Flow function","title":"Water Flow function","text":"using Surrogates\nusing Plots\nusing LinearAlgebra\ndefault()","category":"page"},{"location":"copies/Surrogates/water_flow/","page":"Water Flow function","title":"Water Flow function","text":"Define the objective function:","category":"page"},{"location":"copies/Surrogates/water_flow/","page":"Water Flow function","title":"Water Flow function","text":"function f(x)\n    r_w = x[1]\n    r = x[2]\n    T_u = x[3]\n    H_u = x[4]\n    T_l = x[5]\n    H_l = x[6]\n    L = x[7]\n    K_w = x[8]\n    log_val = log(r/r_w)\n    return (2*pi*T_u*(H_u - H_l))/ ( log_val*(1 + (2*L*T_u/(log_val*r_w^2*K_w)) + T_u/T_l))\nend","category":"page"},{"location":"copies/Surrogates/water_flow/","page":"Water Flow function","title":"Water Flow function","text":"n = 180\nd = 8\nlb = [0.05,100,63070,990,63.1,700,1120,9855]\nub = [0.15,50000,115600,1110,116,820,1680,12045]\nx = sample(n,lb,ub,SobolSample())\ny = f.(x)\nn_test = 1000\nx_test = sample(n_test,lb,ub,GoldenSample());\ny_true = f.(x_test);","category":"page"},{"location":"copies/Surrogates/water_flow/","page":"Water Flow function","title":"Water Flow function","text":"my_rad = RadialBasis(x,y,lb,ub)\ny_rad = my_rad.(x_test)\nmy_poly = PolynomialChaosSurrogate(x,y,lb,ub)\ny_poli = my_poli.(x_test)\nmse_rad = norm(y_true - y_rad,2)/n_test\nmse_poli = norm(y_true - y_poli,2)/n_test\nprint(\"MSE Radial: $mse_rad\")\nprint(\"MSE Radial: $mse_poli\")","category":"page"},{"location":"copies/Surrogates/polychaos/#Polynomial-chaos-surrogate","page":"Polynomial Chaos","title":"Polynomial chaos surrogate","text":"","category":"section"},{"location":"copies/Surrogates/polychaos/","page":"Polynomial Chaos","title":"Polynomial Chaos","text":"note: Note\nThis surrogate requires the 'SurrogatesPolyChaos' module which can be added by inputting \"]add SurrogatesPolyChaos\" from the Julia command line. ","category":"page"},{"location":"copies/Surrogates/polychaos/","page":"Polynomial Chaos","title":"Polynomial Chaos","text":"We can create a surrogate using a polynomial expansion, with a different polynomial basis depending on the distribution of the data we are trying to fit. Under the hood, PolyChaos.jl has been used. It is possible to specify a type of polynomial for each dimension of the problem.","category":"page"},{"location":"copies/Surrogates/polychaos/#Sampling","page":"Polynomial Chaos","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/polychaos/","page":"Polynomial Chaos","title":"Polynomial Chaos","text":"We choose to sample f in 25 points between 0 and 10 using the sample function. The sampling points are chosen using a Low Discrepancy, this can be done by passing LowDiscrepancySample() to the sample function.","category":"page"},{"location":"copies/Surrogates/polychaos/","page":"Polynomial Chaos","title":"Polynomial Chaos","text":"using Surrogates\nusing SurrogatesPolyChaos\nusing Plots\ndefault()\n\nn = 20\nlower_bound = 1.0\nupper_bound = 6.0\nx = sample(n,lower_bound,upper_bound,LowDiscrepancySample(2))\nf = x -> log(x)*x + sin(x)\ny = f.(x)\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\nplot!(f, label=\"True function\", xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Surrogates/polychaos/#Building-a-Surrogate","page":"Polynomial Chaos","title":"Building a Surrogate","text":"","category":"section"},{"location":"copies/Surrogates/polychaos/","page":"Polynomial Chaos","title":"Polynomial Chaos","text":"poly1 = PolynomialChaosSurrogate(x,y,lower_bound,upper_bound)\npoly2 = PolynomialChaosSurrogate(x,y,lower_bound,upper_bound, op = SurrogatesPolyChaos.GaussOrthoPoly(5))\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound), legend=:top)\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound), legend=:top)\nplot!(poly1, label=\"First polynomial\",  xlims=(lower_bound, upper_bound), legend=:top)\nplot!(poly2, label=\"Second polynomial\",  xlims=(lower_bound, upper_bound), legend=:top)","category":"page"},{"location":"copies/Optimization/API/optimization_problem/#Defining-OptimizationProblems","page":"OptimizationProblem","title":"Defining OptimizationProblems","text":"","category":"section"},{"location":"copies/Optimization/API/optimization_problem/","page":"OptimizationProblem","title":"OptimizationProblem","text":"OptimizationProblem","category":"page"},{"location":"copies/ModelingToolkit/systems/ControlSystem/#ControlSystem","page":"ControlSystem","title":"ControlSystem","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ControlSystem/#System-Constructors","page":"ControlSystem","title":"System Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ControlSystem/","page":"ControlSystem","title":"ControlSystem","text":"ControlSystem","category":"page"},{"location":"copies/ModelingToolkit/systems/ControlSystem/#ModelingToolkit.ControlSystem","page":"ControlSystem","title":"ModelingToolkit.ControlSystem","text":"struct ControlSystem <: ModelingToolkit.AbstractControlSystem\n\nA system describing an optimal control problem. This contains a loss function and ordinary differential equations with control variables that describe the dynamics.\n\nFields\n\nloss\nThe Loss function\neqs\nThe ODEs defining the system.\niv\nIndependent variable.\nstates\nDependent (state) variables. Must not contain the independent variable.\ncontrols\nControl variables.\nps\nParameter variables. Must not contain the independent variable.\nobserved\nname\nName: the name of the system. These are required to have unique names.\n\nsystems\nsystems: The internal systems\n\ndefaults\ndefaults: The default values to use when initial conditions and/or parameters are not supplied in ODEProblem.\n\nExample\n\nusing ModelingToolkit\n\n@variables t x(t) v(t) u(t)\nD = Differential(t)\n\nloss = (4-x)^2 + 2v^2 + u^2\neqs = [\n    D(x) ~ v\n    D(v) ~ u^3\n]\n\nsys = ControlSystem(loss,eqs,t,[x,v],[u],[])\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/ControlSystem/#Composition-and-Accessor-Functions","page":"ControlSystem","title":"Composition and Accessor Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ControlSystem/","page":"ControlSystem","title":"ControlSystem","text":"get_eqs(sys) or equations(sys): The equations that define the system.\nget_states(sys) or states(sys): The set of states in the system.\nget_ps(sys) or parameters(sys): The parameters of the system.\nget_controls(sys) or controls(sys): The control variables of the system","category":"page"},{"location":"copies/ModelingToolkit/systems/ControlSystem/#Transformations","page":"ControlSystem","title":"Transformations","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/ControlSystem/","page":"ControlSystem","title":"ControlSystem","text":"ModelingToolkit.runge_kutta_discretize\nstructural_simplify","category":"page"},{"location":"copies/ModelingToolkit/systems/ControlSystem/#ModelingToolkit.runge_kutta_discretize","page":"ControlSystem","title":"ModelingToolkit.runge_kutta_discretize","text":"runge_kutta_discretize(sys::ControlSystem,dt,tspan;\n                       tab = ModelingToolkit.constructRadauIIA5())\n\nTransforms a nonlinear optimal control problem into a constrained OptimizationProblem according to a Runge-Kutta tableau that describes a collocation method. Requires a fixed dt over a given timespan. Defaults to using the 5th order RadauIIA tableau, and altnerative tableaus can be specified using the SciML tableau style.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/systems/ControlSystem/#ModelingToolkit.structural_simplify","page":"ControlSystem","title":"ModelingToolkit.structural_simplify","text":"structural_simplify(sys; simplify, kwargs...)\n\n\nStructurally simplify algebraic equations in a system and compute the topological sort of the observed equations. When simplify=true, the simplify function will be applied during the tearing process. It also takes kwargs allow_symbolic=false and allow_parameter=true which limits the coefficient types during tearing.\n\n\n\n\n\n","category":"function"},{"location":"copies/ModelingToolkit/systems/ControlSystem/#Analyses","page":"ControlSystem","title":"Analyses","text":"","category":"section"},{"location":"copies/Surrogates/lp/#Lp-norm-function","page":"Lp norm","title":"Lp norm function","text":"","category":"section"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"The Lp norm function is defined as: f(x) = sqrtp sum_i=1^d vert x_i vert ^p","category":"page"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"Let's import Surrogates and Plots:","category":"page"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"using Surrogates\nusing Plots\nusing LinearAlgebra\ndefault()","category":"page"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"Define the objective function:","category":"page"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"function f(x,p)\n    return norm(x,p)\nend","category":"page"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"Let's see a simple 1D case:","category":"page"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"n = 30\nlb = -5.0\nub = 5.0\np = 1.3\nx = sample(n,lb,ub,SobolSample())\ny = f.(x,p)\nxs = lb:0.001:ub\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lb, ub), ylims=(0, 5), legend=:top)\nplot!(xs,f.(xs,p), label=\"True function\", legend=:top)","category":"page"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"Fitting different Surrogates:","category":"page"},{"location":"copies/Surrogates/lp/","page":"Lp norm","title":"Lp norm","text":"my_pol = PolynomialChaosSurrogate(x,y,lb,ub)\nloba_1 = LobachevskySurrogate(x,y,lb,ub)\nkrig = Kriging(x,y,lb,ub)\nplot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lb, ub), ylims=(0, 5), legend=:top)\nplot!(xs,f.(xs,p), label=\"True function\", legend=:top)\nplot!(xs, my_pol.(xs), label=\"Polynomial expansion\", legend=:top)\nplot!(xs, loba_1.(xs), label=\"Lobachevsky\", legend=:top)\nplot!(xs, krig.(xs), label=\"Kriging\", legend=:top)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/#shadowing_methods","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"Let us define the instantaneous objective g(up) which depends on the state u and the parameter p of the differential equation. Then, if the objective is a long-time average quantity","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"langle g rangle_ = lim_T rightarrow  langle g rangle_T","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"where","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"langle g rangle_T = frac1T int_0^T g(up) textdt","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"under the assumption of ergodicity, langle g rangle_ only depends on p.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"In the case of chaotic systems, the trajectories diverge with O(1) error]. This can be seen, for instance, when solving the Lorenz system at 1e-14 tolerances with 9th order integrators and a small machine-epsilon perturbation:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"using OrdinaryDiffEq\n\nfunction lorenz!(du, u, p, t)\n  du[1] = 10 * (u[2] - u[1])\n  du[2] = u[1] * (p[1] - u[3]) - u[2]\n  du[3] = u[1] * u[2] - (8 // 3) * u[3]\nend\n\np = [28.0]\ntspan = (0.0, 100.0)\nu0 = [1.0, 0.0, 0.0]\nprob = ODEProblem(lorenz!, u0, tspan, p)\nsol = solve(prob, Vern9(), abstol = 1e-14, reltol = 1e-14)\nsol2 = solve(prob, Vern9(), abstol = 1e-14 + eps(Float64), reltol = 1e-14)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"(Image: Chaotic behavior of the Lorenz system)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"More formally, such chaotic behavior can be analyzed using tools from uncertainty quantification. This effect of diverging trajectories is known as the butterfly effect and can be formulated as \"most (small) perturbations on initial conditions or parameters lead to new trajectories diverging exponentially fast from the original trajectory\".","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"The latter statement can be roughly translated to the level of sensitivity calculation as follows: \"For most initial conditions, the (homogeneous) tangent solutions grow exponentially fast.\"","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"To compute derivatives of an objective langle g rangle_ with respect to the parameters p of a chaotic systems, one thus encounters that \"traditional\" forward and adjoint sensitivity methods diverge because the tangent space diverges with a rate given by the Lyapunov exponent. Taking the average of these derivative can then also fail, i.e., one finds that the average derivative is not the derivative of the average.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"Although numerically computed chaotic trajectories diverge from the true/original trajectory, the shadowing theorem guarantees that there exists an errorless trajectory with a slightly different initial condition that stays near (\"shadows\") the numerically computed one, see, e.g, the blog post or the non-intrusive least squares shadowing paper for more details. Essentially, the idea is to replace the ill-conditioned ODE by a well-conditioned optimization problem. Shadowing methods use the shadowing theorem within a renormalization procedure to distill the long-time effect from the joint observation of the long-time and the butterfly effect. This allows us to accurately compute derivatives w.r.t. the long-time average quantities.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"The following sensealg choices exist","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"ForwardLSS(;alpha=CosWindowing(),ADKwargs...): An implementation of the forward least square shadowing method. For alpha, one can choose between two different windowing options, CosWindowing (default) and Cos2Windowing, and alpha::Number which corresponds to the weight of the time dilation term in ForwardLSS.\nAdjointLSS(;alpha=10.0,ADKwargs...): An implementation of the adjoint-mode least square shadowing method. alpha controls the weight of the time dilation term in AdjointLSS.\nNILSS(nseg, nstep; rng = Xorshifts.Xoroshiro128Plus(rand(UInt64)), ADKwargs...):   An implementation of the non-intrusive least squares shadowing (NILSS) method. nseg is the number of segments. nstep is the number of steps per segment.\nNILSAS(nseg, nstep, M=nothing; rng = Xorshifts.Xoroshiro128Plus(rand(UInt64)), ADKwargs...):   An implementation of the non-intrusive least squares adjoint shadowing (NILSAS) method. nseg is the number of segments. nstep is the number of steps per segment, M >= nus + 1 has to be provided, where nus is the number of unstable covariant Lyapunov vectors.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"Recommendation: Since the computational and memory costs of NILSS() scale with the number of positive (unstable) Lyapunov, it is typically less expensive than ForwardLSS(). AdjointLSS() and NILSAS() are favorable for a large number of system parameters.","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"As an example, for the Lorenz system with g(u,p,t) = u[3], i.e., the z coordinate, as the instantaneous objective, we can use the direct interface by passing ForwardLSS as the sensealg:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"function lorenz!(du,u,p,t)\n  du[1] = p[1]*(u[2]-u[1])\n  du[2] = u[1]*(p[2]-u[3]) - u[2]\n  du[3] = u[1]*u[2] - p[3]*u[3]\nend\n\np = [10.0, 28.0, 8/3]\n\ntspan_init = (0.0,30.0)\ntspan_attractor = (30.0,50.0)\nu0 = rand(3)\nprob_init = ODEProblem(lorenz!,u0,tspan_init,p)\nsol_init = solve(prob_init,Tsit5())\nprob_attractor = ODEProblem(lorenz!,sol_init[end],tspan_attractor,p)\n\ng(u,p,t) = u[end]\n\nfunction G(p)\n  _prob = remake(prob_attractor,p=p)\n  _sol = solve(_prob,Vern9(),abstol=1e-14,reltol=1e-14,saveat=0.01,sensealg=ForwardLSS(alpha=10),g=g)\n  sum(getindex.(_sol.u,3))\nend\ndp1 = Zygote.gradient(p->G(p),p)","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"Alternatively, we can define the ForwardLSSProblem and solve it via shadow_forward as follows:","category":"page"},{"location":"copies/DiffEqSensitivity/ad_examples/chaotic_ode/","page":"Sensitivity analysis for chaotic systems (shadowing methods)","title":"Sensitivity analysis for chaotic systems (shadowing methods)","text":"lss_problem = ForwardLSSProblem(sol_attractor, ForwardLSS(alpha=10), g)\nresfw = shadow_forward(lss_problem)\n@test res ≈ dp1[1] atol=1e-10","category":"page"},{"location":"copies/Surrogates/surrogate/#Surrogate","page":"Surrogates","title":"Surrogate","text":"","category":"section"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Every surrogate has a different definition depending on the parameters needed. However, they have in common:","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"add_point!(::AbstractSurrogate,x_new,y_new)\nAbstractSurrogate(value)","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"The first function adds a sample point to the surrogate, thus changing the internal coefficients. The second one calculates the approximation at value.","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Linear surrogate","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"LinearSurrogate(x,y,lb,ub)","category":"page"},{"location":"copies/Surrogates/surrogate/#Surrogates.LinearSurrogate-NTuple{4, Any}","page":"Surrogates","title":"Surrogates.LinearSurrogate","text":"LinearSurrogate(x,y,lb,ub)\n\nBuilds a linear surrogate using GLM.jl\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Radial basis function surrogate","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"RadialBasis(x, y, lb, ub; rad::RadialFunction = linearRadial, scale_factor::Real=1.0, sparse = false)","category":"page"},{"location":"copies/Surrogates/surrogate/#Surrogates.RadialBasis-NTuple{4, Any}","page":"Surrogates","title":"Surrogates.RadialBasis","text":"RadialBasis(x,y,lb,ub,rad::RadialFunction, scale_factor::Float = 1.0)\n\nConstructor for RadialBasis surrogate\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Kriging surrogate","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Kriging(x,y,p,theta)","category":"page"},{"location":"copies/Surrogates/surrogate/#Surrogates.Kriging-NTuple{4, Any}","page":"Surrogates","title":"Surrogates.Kriging","text":"Kriging(x,y,lb,ub;p=collect(one.(x[1])),theta=collect(one.(x[1])))\n\nConstructor for Kriging surrogate.\n\n(x,y): sampled points\np: array of values 0<=p<2 modeling the    smoothness of the function being approximated in the i-th variable.    low p -> rough, high p -> smooth\ntheta: array of values > 0 modeling how much the function is         changing in the i-th variable.\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Lobachevsky surrogate","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"LobachevskySurrogate(x,y,lb,ub; alpha = collect(one.(x[1])),n::Int = 4, sparse = false)\nlobachevsky_integral(loba::LobachevskySurrogate,lb,ub)","category":"page"},{"location":"copies/Surrogates/surrogate/#Surrogates.LobachevskySurrogate-NTuple{4, Any}","page":"Surrogates","title":"Surrogates.LobachevskySurrogate","text":"LobachevskySurrogate(x,y,alpha,n::Int,lb,ub,sparse = false)\n\nBuild the Lobachevsky surrogate with parameters alpha and n.\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/surrogate/#Surrogates.lobachevsky_integral-Tuple{LobachevskySurrogate, Any, Any}","page":"Surrogates","title":"Surrogates.lobachevsky_integral","text":"lobachevsky_integral(loba::LobachevskySurrogate,lb,ub)\n\nCalculates the integral of the Lobachevsky surrogate, which has a closed form.\n\n\n\n\n\n","category":"method"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Support vector machine surrogate, requires using LIBSVM","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"SVMSurrogate(x,y,lb::Number,ub::Number)","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Random forest surrogate, requires using XGBoost","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"RandomForestSurrogate(x,y,lb,ub;num_round::Int = 1)","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Neural network surrogate, requires using Flux","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"NeuralSurrogate(x,y,lb,ub; model = Chain(Dense(length(x[1]),1), first), loss = (x,y) -> Flux.mse(model(x), y),opt = Descent(0.01),n_echos::Int = 1)","category":"page"},{"location":"copies/Surrogates/surrogate/#Creating-another-surrogate","page":"Surrogates","title":"Creating another surrogate","text":"","category":"section"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"It's great that you want to add another surrogate to the library! You will need to:","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Define a new mutable struct and a constructor function\nDefine add_point!(your_surrogate::AbstactSurrogate,x_new,y_new)\nDefine your_surrogate(value) for the approximation","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"Example","category":"page"},{"location":"copies/Surrogates/surrogate/","page":"Surrogates","title":"Surrogates","text":"mutable struct NewSurrogate{X,Y,L,U,C,A,B} <: AbstractSurrogate\n  x::X\n  y::Y\n  lb::L\n  ub::U\n  coeff::C\n  alpha::A\n  beta::B\nend\n\nfunction NewSurrogate(x,y,lb,ub,parameters)\n    ...\n    return NewSurrogate(x,y,lb,ub,calculated\\_coeff,alpha,beta)\nend\n\nfunction add_point!(NewSurrogate,x\\_new,y\\_new)\n\n  nothing\nend\n\nfunction (s::NewSurrogate)(value)\n  return s.coeff*value + s.alpha\nend","category":"page"},{"location":"copies/ModelingToolkit/comparison/#Comparison-of-ModelingToolkit-vs-Equation-Based-and-Block-Modeling-Languages","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","text":"","category":"section"},{"location":"copies/ModelingToolkit/comparison/#Comparison-Against-Modelica","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison Against Modelica","text":"","category":"section"},{"location":"copies/ModelingToolkit/comparison/","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","text":"Both Modelica and ModelingToolkit.jl are acausal modeling languages.\nModelica is a language with many different implementations, such as Dymola and OpenModelica, which have differing levels of performance and can give different results on the same model. Many of the commonly used Modelica compilers are not open source. ModelingToolkit.jl is a language with a single canonical open source implementation.\nAll current Modelica compiler implementations are fixed and not extendable by the users from the Modelica language itself. For example, the Dymola compiler shares its symbolic processing pipeline which is roughly equivalent to the dae_index_lowering and structural_simplify of ModelingToolkit.jl. ModelingToolkit.jl is an open and hackable transformation system which allows users to add new non-standard transformations and control the order of application.\nModelica is a declarative programming language. ModelingToolkit.jl is a declarative symbolic modeling language used from within the Julia programming language. Its programming language semantics, such as loop constructs and conditionals, can be used to more easily generate models.\nModelica is an object-oriented single dispatch language. ModelingToolkit.jl, built on Julia, uses multiple dispatch extensively to simplify code.\nMany Modelica compilers supply a GUI. ModelingToolkit.jl does not.\nModelica can be used to simulate ODE and DAE systems. ModelingToolkit.jl has a much more expansive set of system types, including nonlinear systems, SDEs, PDEs, and more.","category":"page"},{"location":"copies/ModelingToolkit/comparison/#Comparison-Against-Simulink","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison Against Simulink","text":"","category":"section"},{"location":"copies/ModelingToolkit/comparison/","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","text":"Simulink is a causal modeling environment, whereas ModelingToolkit.jl is an acausal modeling environment. For an overview of the differences, consult academic reviews such as this one. In this sense, ModelingToolkit.jl is more similar to the Simscape sub-environment.\nSimulink is used from MATLAB while ModelingToolkit.jl is used from Julia. Thus any user defined functions have the performance of their host language. For information on the performance differences between Julia and MATLAB, consult open benchmarks which demonstrate Julia as an order of magnitude or more faster in many cases due to its JIT compilation.\nSimulink uses the MATLAB differential equation solvers while ModelingToolkit.jl uses DifferentialEquations.jl. For a systematic comparison between the solvers, consult open benchmarks which demonstrate two orders of magnitude performance advantage for the native Julia solvers across many benchmark problems.\nSimulink comes with a Graphical User Interface (GUI), ModelingToolkit.jl does not.\nSimulink is a proprietary software, meaning users cannot actively modify or extend the software. ModelingToolkit.jl is built in Julia and used in Julia, where users can actively extend and modify the software interactively in the REPL and contribute to its open source repositories.\nSimulink covers ODE and DAE systems. ModelingToolkit.jl has a much more expansive set of system types, including SDEs, PDEs, optimization problems, and more.","category":"page"},{"location":"copies/ModelingToolkit/comparison/#Comparison-Against-CASADI","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison Against CASADI","text":"","category":"section"},{"location":"copies/ModelingToolkit/comparison/","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","text":"CASADI is written in C++ but used from Python/MATLAB, meaning that it cannot be directly extended by users unless they are using the C++ interface and run a local build of CASADI. ModelingToolkit.jl is both written and used from Julia, meaning that users can easily extend the library on the fly, even interactively in the REPL.\nCASADI includes limited support for Computer Algebra System (CAS) functionality, while ModelingToolkit.jl is built on the full Symbolics.jl CAS.\nCASADI supports DAE and ODE problems via SUNDIALS IDAS and CVODES. ModelingToolkit.jl supports DAE and ODE problems via DifferentialEquations.jl, of which Sundials.jl is <1% of the total available solvers and is outperformed by the native Julia solvers on the vast majority of the benchmark equations. In addition, the DifferentialEquations.jl interface is confederated, meaning that any user can dynamically extend the system to add new solvers to the interface by defining new dispatches of solve.\nCASADI's DAEBuilder does not implement efficiency transformations like tearing which are standard in the ModelingToolkit.jl transformation pipeline.\nCASADI supports special functionality for quadratic programming problems while ModelingToolkit only provides nonlinear programming via OptimizationSystem.\nModelingToolkit.jl integrates with its host language Julia, so Julia code can be automatically converted into ModelingToolkit expressions. Users of CASADI must explicitly create CASADI expressions.","category":"page"},{"location":"copies/ModelingToolkit/comparison/#Comparison-Against-Modia.jl","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison Against Modia.jl","text":"","category":"section"},{"location":"copies/ModelingToolkit/comparison/","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","text":"Modia.jl uses Julia's expression objects for representing its equations. ModelingToolkit.jl uses Symbolics.jl, and thus the Julia expressions follow Julia semantics and can be manipulated using a computer algebra system (CAS).\nModia's compilation pipeline is similar to the Dymola symbolic processing pipeline with some improvements. ModelingToolkit.jl has an open transformation pipeline that allows for users to extend and reorder transformation passes, where structural_simplify is an adaptation of the Modia.jl-improved alias elimination and tearing algorithms.\nBoth Modia and ModelingToolkit generate DAEProblem and ODEProblem forms for solving with DifferentialEquations.jl.\nModelingToolkit.jl integrates with its host language Julia, so Julia code can be automatically converted into ModelingToolkit expressions. Users of Modia must explicitly create Modia expressions.\nModia covers DAE systems. ModelingToolkit.jl has a much more expansive set of system types, including SDEs, PDEs, optimization problems, and more.","category":"page"},{"location":"copies/ModelingToolkit/comparison/#Comparison-Against-Causal.jl","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison Against Causal.jl","text":"","category":"section"},{"location":"copies/ModelingToolkit/comparison/","page":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","title":"Comparison of ModelingToolkit vs Equation-Based and Block Modeling Languages","text":"Causal.jl is a causal modeling environment, whereas ModelingToolkit.jl is an acausal modeling environment. For an overview of the differences, consult academic reviews such as this one.\nBoth ModelingToolkit.jl and Causal.jl use DifferentialEquations.jl as the backend solver library.\nCausal.jl lets one add arbitrary equation systems to a given node, and allow the output to effect the next node. This means an SDE may drive an ODE. These two portions are solved with different solver methods in tandem. In ModelingToolkit.jl, such connections promote the whole system to an SDE. This results in better accuracy and stability, though in some cases it can be less performant.\nCausal.jl, similar to Simulink, breaks algebraic loops via inexact heuristics. ModelingToolkit.jl treats algebraic loops exactly through algebraic equations in the generated model.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/#Bayesian-Neural-ODEs:-SGLD","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"Recently, Neural Ordinary Differential Equations has emerged as a powerful framework for modeling physical simulations without explicitly defining the ODEs governing the system, but learning them via machine learning. However, the question: Can Bayesian learning frameworks be integrated with Neural ODEs to robustly quantify the uncertainty in the weights of a Neural ODE? remains unanswered.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"In this tutorial, a working example of the Bayesian Neural ODE: SGLD sampler is shown. SGLD stands for Stochastic Langevin Gradient Descent.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"For an introduction to SGLD, please refer to Introduction to SGLD in Julia","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"For more details regarding Bayesian Neural ODEs, please refer to Bayesian Neural Ordinary Differential Equations.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/#Copy-Pasteable-Code","page":"Bayesian Neural ODEs: SGLD","title":"Copy-Pasteable Code","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"Before getting to the explanation, here's some code to start with. We will follow with a full explanation of the definition and training process:","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"using DiffEqFlux, DifferentialEquations, Flux\nusing Plots, StatsPlots\n\nu0 = Float32[1., 1.]\np = [1.5, 1., 3., 1.]\ndatasize = 45\ntspan = (0.0f0, 14.f0)\ntsteps = tspan[1]:0.1:tspan[2]\n\nfunction lv(u, p, t)\n    x, y = u\n    α, β, γ, δ = p\n    dx = α*x - β*x*y\n    dy = δ*x*y - γ*y\n    du = [dx, dy]\nend\n\ntrueodeprob = ODEProblem(lv, u0, tspan, p)\node_data = Array(solve(trueodeprob, Tsit5(), saveat = tsteps))\ny_train = ode_data[:, 1:35]\n\ndudt = FastChain(FastDense(2, 50, tanh), FastDense(50, 2))\nprob_node = NeuralODE(dudt, (0., 14.), Tsit5(), saveat = tsteps)\ntrain_prob = NeuralODE(dudt, (0., 3.5), Tsit5(), saveat = tsteps[1:35])\n\nfunction predict(p)\n    Array(train_prob(u0, p))\nend\n\nfunction loss(p)\n    sum(abs2, y_train .- predict(p))\nend\n\nsgld(∇L, θᵢ, t, a = 2.5e-3, b = 0.05, γ = 0.35) = begin\n    ϵ = a*(b + t)^-γ\n    η = ϵ.*randn(size(θᵢ))\n    Δθᵢ = .5ϵ*∇L + η\n    θᵢ .-= Δθᵢ\nend\n\nparameters = []\nlosses = Float64[]\ngrad_norm = Float64[]\n\nθ = deepcopy(prob_node.p)\n@time for t in 1:45000\n    grad = gradient(loss, θ)[1]\n    sgld(grad, θ, t)\n    tmp = deepcopy(θ)\n    append!(losses, loss(θ))\n    append!(grad_norm, sum(abs2, grad))\n    append!(parameters, [tmp])\n    println(loss(θ))\nend\nplot(losses, yscale = :log10)\nplot(grad_norm, yscale =:log10)\n\nusing StatsPlots\nsampled_par = parameters[43000: 45000]\n\n\n##################### PLOTS: LOSSES ###############\n\nsampled_loss = [loss(p) for p in sampled_par]\ndensity(sampled_loss)\n\n#################### RETRODICTED PLOTS - TIME SERIES AND CONTOUR PLOTS ####################\n\n_, i_min = findmin(sampled_loss)\n\nplt = scatter(tsteps,ode_data[1,:], colour = :blue, label = \"Data: u1\", ylim = (-.5, 10.))\nscatter!(plt, tsteps, ode_data[2,:], colour = :red, label = \"Data: u2\")\nphase_plt = scatter(ode_data[1,:], ode_data[2,:], colour = :red, label = \"Data\", xlim = (-.25, 7.), ylim = (-2., 6.5))\n\nfor p in sampled_par\n    s = prob_node(u0, p)\n    plot!(plt, tsteps[1:35], s[1,1:35], colour = :blue, lalpha = 0.04, label =:none)\n    plot!(plt, tsteps[35:end], s[1, 35:end], colour =:purple, lalpha = 0.04, label =:none)\n    plot!(plt, tsteps[1:35], s[2,1:35], colour = :red, lalpha = 0.04, label=:none)\n    plot!(plt, tsteps[35:end], s[2,35:end], colour = :purple, lalpha = 0.04, label=:none)\n    plot!(phase_plt, s[1,1:35], s[2,1:35], colour =:red, lalpha = 0.04, label=:none)\n    plot!(phase_plt, s[1,35:end], s[2, 35:end], colour = :purple, lalpha = 0.04, label=:none)\nend\n\nplt\nphase_plt\nplot!(plt, [3.5], seriestype =:vline, colour = :green, linestyle =:dash,label = \"Training Data End\")\n\nbestfit = prob_node(u0, sampled_par[i_min])\nplot(bestfit)\n\n\nplot!(plt, tsteps[1:35], bestfit[2, 1:35], colour =:black, label = \"Training: Best fit prediction\")\nplot!(plt, tsteps[35:end], bestfit[2, 35:end], colour =:purple, label = \"Forecasting: Best fit prediction\")\nplot!(plt, tsteps[1:35], bestfit[1, 1:35], colour =:black, label = :none)\nplot!(plt, tsteps[35:end], bestfit[1, 35:end], colour =:purple, label = :none)\n\nplot!(phase_plt,bestfit[1,1:40], bestfit[2, 1:40], colour = :black, label = \"Training: Best fit prediction\")\nplot!(phase_plt,bestfit[1, 40:end], bestfit[2, 40:end], colour = :purple, label = \"Forecasting: Best fit prediction\")\n\nsavefig(plt, \"C:/Users/16174/Desktop/Julia Lab/MSML2021/BayesianNODE_SGLD_Plot1.png\")\nsavefig(phase_plt, \"C:/Users/16174/Desktop/Julia Lab/MSML2021/BayesianNODE_SGLD_Plot2.png\")\n","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"Time Series Plots:","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"Contour Plots:","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"(Image: )","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/#Explanation","page":"Bayesian Neural ODEs: SGLD","title":"Explanation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/#Step1:-Get-the-data-from-the-Lotka-Volterra-ODE-example","page":"Bayesian Neural ODEs: SGLD","title":"Step1: Get the data from the Lotka Volterra ODE example","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"u0 = Float32[1., 1.]\np = [1.5, 1., 3., 1.]\ndatasize = 45\ntspan = (0.0f0, 14.f0)\ntsteps = tspan[1]:0.1:tspan[2]\n\nfunction lv(u, p, t)\n    x, y = u\n    α, β, γ, δ = p\n    dx = α*x - β*x*y\n    dy = δ*x*y - γ*y\n    du = [dx, dy]\nend\n\ntrueodeprob = ODEProblem(lv, u0, tspan, p)\node_data = Array(solve(trueodeprob, Tsit5(), saveat = tsteps))\ny_train = ode_data[:, 1:35]\n","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/#Step2:-Define-the-Neural-ODE-architecture.-Note-that-this-step-potentially-offers-a-lot-of-flexibility-in-the-number-of-layers/-number-of-units-in-each-layer.","page":"Bayesian Neural ODEs: SGLD","title":"Step2: Define the Neural ODE architecture. Note that this step potentially offers a lot of flexibility in the number of layers/ number of units in each layer.","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"dudt = FastChain(FastDense(2, 50, tanh), FastDense(50, 2))\nprob_node = NeuralODE(dudt, (0., 14.), Tsit5(), saveat = tsteps)\ntrain_prob = NeuralODE(dudt, (0., 3.5), Tsit5(), saveat = tsteps[1:35])","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/#Step3:-Define-the-loss-function-for-the-Neural-ODE.","page":"Bayesian Neural ODEs: SGLD","title":"Step3: Define the loss function for the Neural ODE.","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"function predict(p)\n    Array(train_prob(u0, p))\nend\n\nfunction loss(p)\n    sum(abs2, y_train .- predict(p))\nend","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/#Step4:-Now-we-start-integrating-the-Stochastic-Langevin-Gradient-Descent(SGLD)-framework.","page":"Bayesian Neural ODEs: SGLD","title":"Step4: Now we start integrating the Stochastic Langevin Gradient Descent(SGLD) framework.","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"The SGLD (Stochastic Langevin Gradient Descent) sampler is seen to have a better performance than NUTS whose tutorial is also shown in a separate document. Have a look at https://sebastiancallh.github.io/post/langevin/ for a quick introduction to SGLD.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"Note that we sample from the last 2000 iterations.","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"sgld(∇L, θᵢ, t, a = 2.5e-3, b = 0.05, γ = 0.35) = begin\n    ϵ = a*(b + t)^-γ\n    η = ϵ.*randn(size(θᵢ))\n    Δθᵢ = .5ϵ*∇L + η\n    θᵢ .-= Δθᵢ\nend\n\nparameters = []\nlosses = Float64[]\ngrad_norm = Float64[]\n\nθ = deepcopy(prob_node.p)\n@time for t in 1:45000\n    grad = gradient(loss, θ)[1]\n    sgld(grad, θ, t)\n    tmp = deepcopy(θ)\n    append!(losses, loss(θ))\n    append!(grad_norm, sum(abs2, grad))\n    append!(parameters, [tmp])\n    println(loss(θ))\nend\nplot(losses, yscale = :log10)\nplot(grad_norm, yscale =:log10)\n\nusing StatsPlots\nsampled_par = parameters[43000: 45000]","category":"page"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/#Step5:-Plot-Retrodicted-Plots-(Estimation-and-Forecasting).","page":"Bayesian Neural ODEs: SGLD","title":"Step5: Plot Retrodicted Plots (Estimation and Forecasting).","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/bayesian/BayesianNODE_SGLD/","page":"Bayesian Neural ODEs: SGLD","title":"Bayesian Neural ODEs: SGLD","text":"################### RETRODICTED PLOTS - TIME SERIES AND CONTOUR PLOTS ####################\n\n_, i_min = findmin(sampled_loss)\n\nplt = scatter(tsteps,ode_data[1,:], colour = :blue, label = \"Data: u1\", ylim = (-.5, 10.))\nscatter!(plt, tsteps, ode_data[2,:], colour = :red, label = \"Data: u2\")\nphase_plt = scatter(ode_data[1,:], ode_data[2,:], colour = :red, label = \"Data\", xlim = (-.25, 7.), ylim = (-2., 6.5))\n\nfor p in sampled_par\n    s = prob_node(u0, p)\n    plot!(plt, tsteps[1:35], s[1,1:35], colour = :blue, lalpha = 0.04, label =:none)\n    plot!(plt, tsteps[35:end], s[1, 35:end], colour =:purple, lalpha = 0.04, label =:none)\n    plot!(plt, tsteps[1:35], s[2,1:35], colour = :red, lalpha = 0.04, label=:none)\n    plot!(plt, tsteps[35:end], s[2,35:end], colour = :purple, lalpha = 0.04, label=:none)\n    plot!(phase_plt, s[1,1:35], s[2,1:35], colour =:red, lalpha = 0.04, label=:none)\n    plot!(phase_plt, s[1,35:end], s[2, 35:end], colour = :purple, lalpha = 0.04, label=:none)\nend\n\nplt\nphase_plt\nplot!(plt, [3.5], seriestype =:vline, colour = :green, linestyle =:dash,label = \"Training Data End\")\n\nbestfit = prob_node(u0, sampled_par[i_min])\nplot(bestfit)\n\n\nplot!(plt, tsteps[1:35], bestfit[2, 1:35], colour =:black, label = \"Training: Best fit prediction\")\nplot!(plt, tsteps[35:end], bestfit[2, 35:end], colour =:purple, label = \"Forecasting: Best fit prediction\")\nplot!(plt, tsteps[1:35], bestfit[1, 1:35], colour =:black, label = :none)\nplot!(plt, tsteps[35:end], bestfit[1, 35:end], colour =:purple, label = :none)\n\nplot!(phase_plt,bestfit[1,1:40], bestfit[2, 1:40], colour = :black, label = \"Training: Best fit prediction\")\nplot!(phase_plt,bestfit[1, 40:end], bestfit[2, 40:end], colour = :purple, label = \"Forecasting: Best fit prediction\")\n","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/#The-SciML-init-and-solve-Functions","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"solve function has the default definition","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"solve(args...; kwargs...) = solve!(init(args...; kwargs...))","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"The interface for the three functions is as follows:","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"init(::ProblemType, args...; kwargs...) :: IteratorType\nsolve!(::SolverType) :: SolutionType","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"where ProblemType, IteratorType, and SolutionType are the types defined in your package.","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"To avoid method ambiguity, the first argument of solve, solve!, and init must be dispatched on the type defined in your package.  For example, do not define a method such as","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"init(::AbstractVector, ::AlgorithmType)","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/#init-and-the-Iterator-Interface","page":"The SciML init and solve Functions","title":"init and the Iterator Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"init's return gives an IteratorType which is designed to allow the user to have more direct handling over the internal solving process. Because of this internal nature, the IteratorType has a less unified interface across problem types than other portions like ProblemType and SolutionType. For example, for differential equations this is the  Integrator Interface designed for mutating solutions in a manner for callback implementation, which is distinctly different from the  LinearSolve init interface which is designed for caching efficiency with reusing factorizations.","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/#__solve-and-High-Level-Handling","page":"The SciML init and solve Functions","title":"__solve and High-Level Handling","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"While init and solve are the common entry point for users, solver packages will mostly define dispatches on SciMLBase.__init and SciMLBase.__solve. The reason is because this allows for SciMLBase.init and SciMLBase.solve to have common implementations across all solvers for doing things such as checking for common errors and throwing high level messages. Solvers can opt-out of the high level error handling by directly defining SciMLBase.init and SciMLBase.solve instead, though this is not recommended in order to allow for uniformity of the error messages.","category":"page"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#JumpSystem","page":"JumpSystem","title":"JumpSystem","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#System-Constructors","page":"JumpSystem","title":"System Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/JumpSystem/","page":"JumpSystem","title":"JumpSystem","text":"JumpSystem","category":"page"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#ModelingToolkit.JumpSystem","page":"JumpSystem","title":"ModelingToolkit.JumpSystem","text":"struct JumpSystem{U<:RecursiveArrayTools.ArrayPartition} <: AbstractTimeDependentSystem\n\nA system of jump processes.\n\nFields\n\neqs\nThe jumps of the system. Allowable types are ConstantRateJump, VariableRateJump, MassActionJump.\n\niv\nThe independent variable, usually time.\nstates\nThe dependent variables, representing the state of the system.  Must not contain the independent variable.\nps\nThe parameters of the system. Must not contain the independent variable.\nvar_to_name\nArray variables.\nobserved\nname\nThe name of the system. . These are required to have unique names.\nsystems\nThe internal systems.\ndefaults\ndefaults: The default values to use when initial conditions and/or parameters are not supplied in ODEProblem.\n\nconnector_type\ntype: type of the system\n\nExample\n\nusing ModelingToolkit\n\n@parameters β γ\n@variables t S(t) I(t) R(t)\nrate₁   = β*S*I\naffect₁ = [S ~ S - 1, I ~ I + 1]\nrate₂   = γ*I\naffect₂ = [I ~ I - 1, R ~ R + 1]\nj₁      = ConstantRateJump(rate₁,affect₁)\nj₂      = ConstantRateJump(rate₂,affect₂)\nj₃      = MassActionJump(2*β+γ, [R => 1], [S => 1, R => -1])\n@named js      = JumpSystem([j₁,j₂,j₃], t, [S,I,R], [β,γ])\n\n\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#Composition-and-Accessor-Functions","page":"JumpSystem","title":"Composition and Accessor Functions","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/JumpSystem/","page":"JumpSystem","title":"JumpSystem","text":"get_eqs(sys) or equations(sys): The equations that define the jump system.\nget_states(sys) or states(sys): The set of states in the jump system.\nget_ps(sys) or parameters(sys): The parameters of the jump system.\nget_iv(sys): The independent variable of the jump system.","category":"page"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#Transformations","page":"JumpSystem","title":"Transformations","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/JumpSystem/","page":"JumpSystem","title":"JumpSystem","text":"structural_simplify","category":"page"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#Analyses","page":"JumpSystem","title":"Analyses","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#Problem-Constructors","page":"JumpSystem","title":"Problem Constructors","text":"","category":"section"},{"location":"copies/ModelingToolkit/systems/JumpSystem/","page":"JumpSystem","title":"JumpSystem","text":"DiscreteProblem\nJumpProblem","category":"page"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#SciMLBase.DiscreteProblem","page":"JumpSystem","title":"SciMLBase.DiscreteProblem","text":"Defines a discrete dynamical system problem. Documentation Page: https://diffeq.sciml.ai/stable/types/discrete_types/\n\nMathematical Specification of a Discrete Problem\n\nTo define an Discrete Problem, you simply need to give the function f and the initial condition u_0 which define a function map:\n\nu_n+1 = f(u_npt_n+1)\n\nf should be specified as f(un,p,t) (or in-place as f(unp1,un,p,t)), and u_0 should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well. u_n+1 only depends on the previous iteration u_n and t_n+1. The default t_n+1 of FunctionMap is t_n = t_0 + n*dt (with dt=1 being the default). For continuous-time Markov chains this is the time at which the change is occuring.\n\nNote that if the discrete solver is set to have scale_by_time=true, then the problem is interpreted as the map:\n\nu_n+1 = u_n + dt f(u_npt_n+1)\n\nProblem Type\n\nConstructors\n\nDiscreteProblem{isinplace}(f::ODEFunction,u0,tspan,p=NullParameters();kwargs...) : Defines the discrete problem with the specified functions.\nDiscreteProblem{isinplace}(f,u0,tspan,p=NullParameters();kwargs...) : Defines the discrete problem with the specified functions.\nDiscreteProblem{isinplace}(u0,tspan,p=NullParameters();kwargs...) : Defines the discrete problem with the identity map.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The function in the map.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\nNote About Timing\n\nNote that if no dt and not tstops is given, it's assumed that dt=1 and thus tspan=(0,n) will solve for n iterations. If in the solver dt is given, then the number of iterations will change. And if tstops is not empty, the solver will revert to the standard behavior of fixed timestep methods, which is \"step to each tstop\".\n\n\n\n","category":"type"},{"location":"copies/ModelingToolkit/systems/JumpSystem/#DiffEqJump.JumpProblem","page":"JumpSystem","title":"DiffEqJump.JumpProblem","text":"function DiffEqBase.JumpProblem(js::JumpSystem, prob, aggregator; kwargs...)\n\nGenerates a JumpProblem from a JumpSystem.\n\nContinuing the example from the DiscreteProblem definition:\n\njprob = JumpProblem(js, dprob, Direct())\nsol = solve(jprob, SSAStepper())\n\n\n\n\n\n","category":"type"},{"location":"copies/DiffEqFlux/utilities/Collocation/#Smoothed-Collocation","page":"Smoothed Collocation","title":"Smoothed Collocation","text":"","category":"section"},{"location":"copies/DiffEqFlux/utilities/Collocation/","page":"Smoothed Collocation","title":"Smoothed Collocation","text":"Smoothed collocation, also referred to as the two-stage method, allows for fitting differential equations to time series data without relying on a numerical differential equation solver by building a smoothed collocating polynomial and using this to estimate the true (u',u) pairs, at which point u'-f(u,p,t) can be directly estimated as a loss to determine the correct parameters p. This method can be extremely fast and robust to noise, though, because it does not accumulate through time, is not as exact as other methods.","category":"page"},{"location":"copies/DiffEqFlux/utilities/Collocation/","page":"Smoothed Collocation","title":"Smoothed Collocation","text":"collocate_data","category":"page"},{"location":"copies/DiffEqFlux/utilities/Collocation/#DiffEqFlux.collocate_data","page":"Smoothed Collocation","title":"DiffEqFlux.collocate_data","text":"u′,u = collocate_data(data,tpoints,kernel=SigmoidKernel())\nu′,u = collocate_data(data,tpoints,tpoints_sample,interp,args...)\n\nComputes a non-parametrically smoothed estimate of u' and u given the data, where each column is a snapshot of the timeseries at tpoints[i].\n\nFor kernels, the following exist:\n\nEpanechnikovKernel\nUniformKernel\nTriangularKernel\nQuarticKernel\nTriweightKernel\nTricubeKernel\nGaussianKernel\nCosineKernel\nLogisticKernel\nSigmoidKernel\nSilvermanKernel\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC2631937/\n\nAdditionally, we can use interpolation methods from DataInterpolations.jl to generate data from intermediate timesteps. In this case, pass any of the methods like QuadraticInterpolation as interp, and the timestamps to sample from as tpoints_sample.\n\n\n\n\n\n","category":"function"},{"location":"copies/DiffEqFlux/utilities/Collocation/#Kernel-Choice","page":"Smoothed Collocation","title":"Kernel Choice","text":"","category":"section"},{"location":"copies/DiffEqFlux/utilities/Collocation/","page":"Smoothed Collocation","title":"Smoothed Collocation","text":"Note that the kernel choices of DataInterpolations.jl, such as CubicSpline(), are exact, i.e. go through the data points, while the smoothed kernels are regression splines. Thus CubicSpline() is preferred if the data is not too noisy or is relatively sparse. If data is sparse and very noisy, a BSpline()  can be the best regression spline, otherwise one of the other kernels such as as EpanechnikovKernel.","category":"page"},{"location":"copies/DiffEqFlux/utilities/Collocation/#Non-Allocating-Forward-Mode-L2-Collocation-Loss","page":"Smoothed Collocation","title":"Non-Allocating Forward-Mode L2 Collocation Loss","text":"","category":"section"},{"location":"copies/DiffEqFlux/utilities/Collocation/","page":"Smoothed Collocation","title":"Smoothed Collocation","text":"The following is an example of a loss function over the collocation that is non-allocating and compatible with forward-mode automatic differentiation:","category":"page"},{"location":"copies/DiffEqFlux/utilities/Collocation/","page":"Smoothed Collocation","title":"Smoothed Collocation","text":"using PreallocationTools\ndu = PreallocationTools.dualcache(similar(prob.u0))\npreview_est_sol = [@view estimated_solution[:,i] for i in 1:size(estimated_solution,2)]\npreview_est_deriv = [@view estimated_derivative[:,i] for i in 1:size(estimated_solution,2)]\n\nfunction construct_iip_cost_function(f,du,preview_est_sol,preview_est_deriv,tpoints)\n  function (p)\n      _du = PreallocationTools.get_tmp(du,p)\n      vecdu = vec(_du)\n      cost = zero(first(p))\n      for i in 1:length(preview_est_sol)\n        est_sol = preview_est_sol[i]\n        f(_du,est_sol,p,tpoints[i])\n        vecdu .= vec(preview_est_deriv[i]) .- vec(_du)\n        cost += sum(abs2,vecdu)\n      end\n      sqrt(cost)\n  end\nend\ncost_function = construct_iip_cost_function(f,du,preview_est_sol,preview_est_deriv,tpoints)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_neural/#Neural-Second-Order-Ordinary-Differential-Equation","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"","category":"section"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"The neural ODE focuses and finding a neural network such that:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"u^prime = NN(u)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"However, in many cases in physics-based modeling, the key object is not the velocity but the acceleration: knowing the acceleration tells you the force field and thus the generating process for the dynamical system. Thus what we want to do is find the force, i.e.:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"u^primeprime = NN(u)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"(Note that in order to be the acceleration, we should divide the output of the neural network by the mass!)","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"An example of training a neural network on a second order ODE is as follows:","category":"page"},{"location":"copies/DiffEqSensitivity/ode_fitting/second_order_neural/","page":"Neural Second Order Ordinary Differential Equation","title":"Neural Second Order Ordinary Differential Equation","text":"using DifferentialEquations, DiffEqFlux, RecursiveArrayTools\n\nu0 = Float32[0.; 2.]\ndu0 = Float32[0.; 0.]\ntspan = (0.0f0, 1.0f0)\nt = range(tspan[1], tspan[2], length=20)\n\nmodel = FastChain(FastDense(2, 50, tanh), FastDense(50, 2))\np = initial_params(model)\nff(du,u,p,t) = model(u,p)\nprob = SecondOrderODEProblem{false}(ff, du0, u0, tspan, p)\n\nfunction predict(p)\n    Array(solve(prob, Tsit5(), p=p, saveat=t))\nend\n\ncorrect_pos = Float32.(transpose(hcat(collect(0:0.05:1)[2:end], collect(2:-0.05:1)[2:end])))\n\nfunction loss_n_ode(p)\n    pred = predict(p)\n    sum(abs2, correct_pos .- pred[1:2, :]), pred\nend\n\ndata = Iterators.repeated((), 1000)\nopt = ADAM(0.01)\n\nl1 = loss_n_ode(p)\n\ncb = function (p,l,pred)\n    println(l)\n    l < 0.01\nend\n\nres = DiffEqFlux.sciml_train(loss_n_ode, p, opt, cb=cb, maxiters = 1000)","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/#Linear-Surrogate","page":"Linear","title":"Linear Surrogate","text":"","category":"section"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"Linear Surrogate is a linear approach to modeling the relationship between a scalar response or dependent variable and one or more explanatory variables. We will use Linear Surrogate to optimize following function:","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"f(x) = sin(x) + log(x)","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":".","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"First of all we have to import these two packages: Surrogates and Plots.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"using Surrogates\r\nusing Plots\r\ndefault()","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/#Sampling","page":"Linear","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"We choose to sample f in 20 points between 0 and 10 using the sample function. The sampling points are chosen using a Sobol sequence, this can be done by passing SobolSample() to the sample function.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"f(x) = sin(x) + log(x)\r\nn_samples = 20\r\nlower_bound = 5.2\r\nupper_bound = 12.5\r\nx = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\ny = f.(x)\r\nscatter(x, y, label=\"Sampled points\", xlims=(lower_bound, upper_bound))\r\nplot!(f, label=\"True function\", xlims=(lower_bound, upper_bound))","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/#Building-a-Surrogate","page":"Linear","title":"Building a Surrogate","text":"","category":"section"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"With our sampled points we can build the Linear Surrogate using the LinearSurrogate function.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"We can simply calculate linear_surrogate for any value.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"my_linear_surr_1D = LinearSurrogate(x, y, lower_bound, upper_bound)\r\nadd_point!(my_linear_surr_1D,4.0,7.2)\r\nadd_point!(my_linear_surr_1D,[5.0,6.0],[8.3,9.7])\r\nval = my_linear_surr_1D(5.0)","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"Now, we will simply plot linear_surrogate:","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"plot(x, y, seriestype=:scatter, label=\"Sampled points\", xlims=(lower_bound, upper_bound))\r\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound))\r\nplot!(my_linear_surr_1D, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound))","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/#Optimizing","page":"Linear","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"Having built a surrogate, we can now use it to search for minimas in our original function f.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"To optimize using our surrogate we call surrogate_optimize method. We choose to use Stochastic RBF as optimization technique and again Sobol sampling as sampling technique.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"@show surrogate_optimize(f, SRBF(), lower_bound, upper_bound, my_linear_surr_1D, SobolSample())\r\nscatter(x, y, label=\"Sampled points\")\r\nplot!(f, label=\"True function\",  xlims=(lower_bound, upper_bound))\r\nplot!(my_linear_surr_1D, label=\"Surrogate function\",  xlims=(lower_bound, upper_bound))","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/#Linear-Surrogate-tutorial-(ND)","page":"Linear","title":"Linear Surrogate tutorial (ND)","text":"","category":"section"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"First of all we will define the Egg Holder function we are going to build surrogate for. Notice, one how its argument is a vector of numbers, one for each coordinate, and its output is a scalar.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"using Plots # hide\r\ndefault(c=:matter, legend=false, xlabel=\"x\", ylabel=\"y\") # hide\r\nusing Surrogates # hide\r\n\r\nfunction egg(x)\r\n    x1=x[1]\r\n    x2=x[2]\r\n    term1 = -(x2+47) * sin(sqrt(abs(x2+x1/2+47)));\r\n    term2 = -x1 * sin(sqrt(abs(x1-(x2+47))));\r\n    y = term1 + term2;\r\nend","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/#Sampling-2","page":"Linear","title":"Sampling","text":"","category":"section"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"Let's define our bounds, this time we are working in two dimensions. In particular we want our first dimension x to have bounds -10, 5, and 0, 15 for the second dimension. We are taking 50 samples of the space using Sobol Sequences. We then evaluate our function on all of the sampling points.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"n_samples = 50\r\nlower_bound = [-10.0, 0.0]\r\nupper_bound = [5.0, 15.0]\r\n\r\nxys = sample(n_samples, lower_bound, upper_bound, SobolSample())\r\nzs = egg.(xys);","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"x, y = -10:5, 0:15 # hide\r\np1 = surface(x, y, (x1,x2) -> egg((x1,x2))) # hide\r\nxs = [xy[1] for xy in xys] # hide\r\nys = [xy[2] for xy in xys] # hide\r\nscatter!(xs, ys, zs) # hide\r\np2 = contour(x, y, (x1,x2) -> egg((x1,x2))) # hide\r\nscatter!(xs, ys) # hide\r\nplot(p1, p2, title=\"True function\") # hide","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/#Building-a-surrogate","page":"Linear","title":"Building a surrogate","text":"","category":"section"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"Using the sampled points we build the surrogate, the steps are analogous to the 1-dimensional case.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"my_linear_ND = LinearSurrogate(xys, zs,  lower_bound, upper_bound)","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"p1 = surface(x, y, (x, y) -> my_linear_ND([x y])) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> my_linear_ND([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2, title=\"Surrogate\") # hide","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/#Optimizing-2","page":"Linear","title":"Optimizing","text":"","category":"section"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"With our surrogate we can now search for the minimas of the function.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"Notice how the new sampled points, which were created during the optimization process, are appended to the xys array. This is why its size changes.","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"surrogate_optimize(egg, SRBF(), lower_bound, upper_bound, my_linear_ND, SobolSample(), maxiters=10)","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"size(xys)","category":"page"},{"location":"copies/Surrogates/LinearSurrogate/","page":"Linear","title":"Linear","text":"p1 = surface(x, y, (x, y) -> my_linear_ND([x y])) # hide\r\nxs = [xy[1] for xy in xys] # hide\r\nys = [xy[2] for xy in xys] # hide\r\nzs = egg.(xys) # hide\r\nscatter!(xs, ys, zs, marker_z=zs) # hide\r\np2 = contour(x, y, (x, y) -> my_linear_ND([x y])) # hide\r\nscatter!(xs, ys, marker_z=zs) # hide\r\nplot(p1, p2) # hide","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/#Generalized-Likelihood-Inference","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"","category":"section"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"In this example we will demo the likelihood-based approach to parameter fitting. First let's generate a dataset to fit. We will re-use the Lotka-Volterra equation but in this case fit just two parameters.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"f1 = function (du,u,p,t)\n  du[1] = p[1] * u[1] - p[2] * u[1]*u[2]\n  du[2] = -3.0 * u[2] + u[1]*u[2]\nend\np = [1.5,1.0]\nu0 = [1.0;1.0]\ntspan = (0.0,10.0)\nprob1 = ODEProblem(f1,u0,tspan,p)\nsol = solve(prob1,Tsit5())","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"This is a function with two parameters, [1.5,1.0] which generates the same ODE solution as before. This time, let's generate 100 datasets where at each point adds a little bit of randomness:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"using RecursiveArrayTools # for VectorOfArray\nt = collect(range(0,stop=10,length=200))\nfunction generate_data(sol,t)\n  randomized = VectorOfArray([(sol(t[i]) + .01randn(2)) for i in 1:length(t)])\n  data = convert(Array,randomized)\nend\naggregate_data = convert(Array,VectorOfArray([generate_data(sol,t) for i in 1:100]))","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"here with t we measure the solution at 200 evenly spaced points. Thus aggregate_data is a 2x200x100 matrix where aggregate_data[i,j,k] is the ith component at time j of the kth dataset. What we first want to do is get a matrix of distributions where distributions[i,j] is the likelihood of component i at take j. We can do this via fit_mle on a chosen distributional form. For simplicity we choose the Normal distribution. aggregate_data[i,j,:] is the array of points at the given component and time, and thus we find the distribution parameters which fits best at each time point via:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"using Distributions\ndistributions = [fit_mle(Normal,aggregate_data[i,j,:]) for i in 1:2, j in 1:200]","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"Notice for example that we have:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"julia> distributions[1,1]\nDistributions.Normal{Float64}(μ=1.0022440583676806, σ=0.009851964521952437)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"that is, it fit the distribution to have its mean just about where our original solution was and the variance is about how much noise we added to the dataset. This this is a good check to see that the distributions we are trying to fit our parameters to makes sense.","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"Note that in this case the Normal distribution was a good choice, and in many cases it's a nice go-to choice, but one should experiment with other choices of distributions as well. For example, a TDist can be an interesting way to incorporate robustness to outliers since low degrees of free T-distributions act like Normal distributions but with longer tails (though fit_mle does not work with a T-distribution, you can get the means/variances and build appropriate distribution objects yourself).","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"Once we have the matrix of distributions, we can build the objective function corresponding to that distribution fit:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"using DiffEqParamEstim\nobj = build_loss_objective(prob1,Tsit5(),LogLikeLoss(t,distributions),\n                                     maxiters=10000,verbose=false)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"First let's use the objective function to plot the likelihood landscape:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"using Plots; plotly()\nprange = 0.5:0.1:5.0\nheatmap(prange,prange,[obj([j,i]) for i in prange, j in prange],\n        yscale=:log10,xlabel=\"Parameter 1\",ylabel=\"Parameter 2\",\n        title=\"Likelihood Landscape\")","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"(Image: 2 Parameter Likelihood)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"Recall that this is the negative loglikelihood and thus the minimum is the maximum of the likelihood. There is a clear valley where the first parameter is 1.5, while the second parameter's likelihood is more muddled. By taking a one-dimensional slice:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"plot(prange,[obj([1.5,i]) for i in prange],lw=3,\n     title=\"Parameter 2 Likelihood (Parameter 1 = 1.5)\",\n     xlabel = \"Parameter 2\", ylabel = \"Objective Function Value\")","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"(Image: 1 Parameter Likelihood)","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"we can see that there's still a clear minimum at the true value. Thus we will use the global optimizers from BlackBoxOptim.jl to find the values. We set our search range to be from 0.5 to 5.0 for both of the parameters and let it optimize:","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"using BlackBoxOptim\nbound1 = Tuple{Float64, Float64}[(0.5, 5),(0.5, 5)]\nresult = bboptimize(obj;SearchRange = bound1, MaxSteps = 11e3)\n\nStarting optimization with optimizer BlackBoxOptim.DiffEvoOpt{BlackBoxOptim.FitPopulation{Float64},B\nlackBoxOptim.RadiusLimitedSelector,BlackBoxOptim.AdaptiveDiffEvoRandBin{3},BlackBoxOptim.RandomBound\n{BlackBoxOptim.RangePerDimSearchSpace}}\n0.00 secs, 0 evals, 0 steps\n0.50 secs, 1972 evals, 1865 steps, improv/step: 0.266 (last = 0.2665), fitness=-737.311433781\n1.00 secs, 3859 evals, 3753 steps, improv/step: 0.279 (last = 0.2913), fitness=-739.658421879\n1.50 secs, 5904 evals, 5799 steps, improv/step: 0.280 (last = 0.2830), fitness=-739.658433715\n2.00 secs, 7916 evals, 7811 steps, improv/step: 0.225 (last = 0.0646), fitness=-739.658433715\n2.50 secs, 9966 evals, 9861 steps, improv/step: 0.183 (last = 0.0220), fitness=-739.658433715\n\nOptimization stopped after 11001 steps and 2.7839999198913574 seconds\nTermination reason: Max number of steps (11000) reached\nSteps per second = 3951.50873439296\nFunction evals per second = 3989.2242527195904\nImprovements/step = 0.165\nTotal function evaluations = 11106\n\n\nBest candidate found: [1.50001, 1.00001]\n\nFitness: -739.658433715","category":"page"},{"location":"copies/DiffEqParamEstim/tutorials/generalized_likelihood/","page":"Generalized Likelihood Inference","title":"Generalized Likelihood Inference","text":"This shows that it found the true parameters as the best fit to the likelihood.","category":"page"},{"location":"copies/Optimization/tutorials/intro/#Basic-usage","page":"Basic usage","title":"Basic usage","text":"","category":"section"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"In this tutorial we introduce the basics of GalcticOptim.jl by showing how to easily mix local optimizers from Optim.jl and global optimizers from BlackBoxOptim.jl on the Rosenbrock equation. The simplest copy-pasteable code to get started is the following:","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"using Optimization\nrosenbrock(x,p) =  (p[1] - x[1])^2 + p[2] * (x[2] - x[1]^2)^2\nx0 = zeros(2)\np  = [1.0,100.0]\n\nprob = OptimizationProblem(rosenbrock,x0,p)\n\nusing OptimizationOptimJL\nsol = solve(prob,NelderMead())\n\n\nusing OptimizationBBO\nprob = OptimizationProblem(rosenbrock, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\nsol = solve(prob,BBO_adaptive_de_rand_1_bin_radiuslimited())","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"Notice that Optimization.jl is the core glue package that holds all of the common pieces, but to solve the equations we need to use a solver package. Here, GalcticOptimJL is for Optim.jl and OptimizationBBO is for BlackBoxOptim.jl.","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"The output of the first optimization task (with the NelderMead() algorithm) is given below:","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"sol = solve(prob,NelderMead())\nu: 2-element Vector{Float64}:\n 0.9999634355313174\n 0.9999315506115275","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"The solution from the original solver can always be obtained via original:","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"julia> sol.original\n * Status: success\n\n * Candidate solution\n    Final objective value:     3.525527e-09\n\n * Found with\n    Algorithm:     Nelder-Mead\n\n * Convergence measures\n    √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    60\n    f(x) calls:    117","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"We can also explore other methods in a similar way:","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"using ForwardDiff\nf = OptimizationFunction(rosenbrock, Optimization.AutoForwardDiff())\nprob = OptimizationProblem(f, x0, p)\nsol = solve(prob,BFGS())","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"For instance, the above optimization task produces the following output:","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"* Status: success\n\n* Candidate solution\n   Final objective value:     7.645684e-21\n\n* Found with\n   Algorithm:     BFGS\n\n* Convergence measures\n   |x - x'|               = 3.48e-07 ≰ 0.0e+00\n   |x - x'|/|x'|          = 3.48e-07 ≰ 0.0e+00\n   |f(x) - f(x')|         = 6.91e-14 ≰ 0.0e+00\n   |f(x) - f(x')|/|f(x')| = 9.03e+06 ≰ 0.0e+00\n   |g(x)|                 = 2.32e-09 ≤ 1.0e-08\n\n* Work counters\n   Seconds run:   0  (vs limit Inf)\n   Iterations:    16\n   f(x) calls:    53\n   ∇f(x) calls:   53","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":" prob = OptimizationProblem(f, x0, p, lb = [-1.0,-1.0], ub = [1.0,1.0])\n sol = solve(prob, Fminbox(GradientDescent()))","category":"page"},{"location":"copies/Optimization/tutorials/intro/","page":"Basic usage","title":"Basic usage","text":"The examples clearly demonstrate that Optimization.jl provides an intuitive way of specifying optimization tasks and offers a relatively easy access to a wide range of optimization algorithms.","category":"page"},{"location":"copies/Surrogates/cantilever/#Cantilever-beam-function","page":"Cantilever beam","title":"Cantilever beam function","text":"","category":"section"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"The Cantilever Beam function is defined as: f(wt) = frac4L^3Ewt*sqrt (fracYt^2)^2 + (fracXw^2)^2  With parameters L,E,X and Y given.","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"Let's import Surrogates and Plots:","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"using Surrogates\nusing Plots\ndefault()","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"Define the objective function:","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"function f(x)\n    t = x[1]\n    w = x[2]\n    L = 100.0\n    E = 2.770674127819261e7\n    X = 530.8038576066307\n    Y = 997.8714938733949\n    return (4*L^3)/(E*w*t)*sqrt( (Y/t^2)^2 + (X/w^2)^2)\nend","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"Let's plot it:","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"n = 100\nlb = [1.0,1.0]\nub = [8.0,8.0]\nxys = sample(n,lb,ub,SobolSample());\nzs = f.(xys);\nx, y = 0:8, 0:8\np1 = surface(x, y, (x1,x2) -> f((x1,x2)))\nxs = [xy[1] for xy in xys]\nys = [xy[2] for xy in xys]\nscatter!(xs, ys, zs) # hide\np2 = contour(x, y, (x1,x2) -> f((x1,x2)))\nscatter!(xs, ys)\nplot(p1, p2, title=\"True function\")","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"Fitting different Surrogates:","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"mypoly = PolynomialChaosSurrogate(xys, zs,  lb, ub)\nloba = PolynomialChaosSurrogate(xys, zs,  lb, ub)\nrad = RadialBasis(xys,zs,lb,ub)","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"Plotting:","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"p1 = surface(x, y, (x, y) -> mypoly([x y]))\nscatter!(xs, ys, zs, marker_z=zs)\np2 = contour(x, y, (x, y) -> mypoly([x y]))\nscatter!(xs, ys, marker_z=zs)\nplot(p1, p2, title=\"Polynomial expansion\")","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"p1 = surface(x, y, (x, y) -> loba([x y]))\nscatter!(xs, ys, zs, marker_z=zs)\np2 = contour(x, y, (x, y) -> loba([x y]))\nscatter!(xs, ys, marker_z=zs)\nplot(p1, p2, title=\"Lobachevsky\")","category":"page"},{"location":"copies/Surrogates/cantilever/","page":"Cantilever beam","title":"Cantilever beam","text":"p1 = surface(x, y, (x, y) -> rad([x y]))\nscatter!(xs, ys, zs, marker_z=zs)\np2 = contour(x, y, (x, y) -> rad([x y]))\nscatter!(xs, ys, marker_z=zs)\nplot(p1, p2, title=\"Inverse distance surrogate\")","category":"page"},{"location":"copies/Surrogates/contributing/#Contributions","page":"Contributing","title":"Contributions","text":"","category":"section"},{"location":"copies/Surrogates/contributing/","page":"Contributing","title":"Contributing","text":"Contributions are very welcome! There are many ways do help:","category":"page"},{"location":"copies/Surrogates/contributing/","page":"Contributing","title":"Contributing","text":"Opening/solving issues\nMaking the code more efficient\nOpening a new PR with a new Sampling technique, Surrogate or optimization method\nWriting more tutorials with your own unique use case of the library\nYour own idea!","category":"page"},{"location":"copies/Surrogates/contributing/","page":"Contributing","title":"Contributing","text":"You can also contact me on the Julia slack channel at @ludoro.","category":"page"},{"location":"copies/Surrogates/contributing/#List-of-contributors","page":"Contributing","title":"List of contributors","text":"","category":"section"},{"location":"copies/Surrogates/contributing/","page":"Contributing","title":"Contributing","text":"Ludovico Bessi (@ludoro)\nChris Rackauckas (@ChrisRackauckas)\nRohit Singh Rathaur (@RohitRathore1)\nAndrea Cognolato (@mrandri19)\nKanav Gupta (@kanav99)","category":"page"}]
}
