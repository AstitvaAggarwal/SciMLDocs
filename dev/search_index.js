var documenterSearchIndex = {"docs":
[{"location":"copies/NonlinearSolve/basics/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Ask more questions.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#nonlinearsystemsolvers","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"solve(prob::NonlinearProblem,alg;kwargs)","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"Solves for f(u)=0 in the problem defined by prob using the algorithm alg. If no algorithm is given, a default algorithm will be chosen.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"This page is solely focused on the methods for nonlinear systems.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#Recommended-Methods","page":"Nonlinear System Solvers","title":"Recommended Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"NewtonRaphson is a good choice for most problems. It is non-allocating on static arrays and thus really well-optimized for small systems, while for large systems it can make use of sparsity patterns for sparse automatic differentiation and sparse linear solving of very large systems. That said, as a classic Newton method, its stability region can be smaller than other methods. NLSolveJL's :trust_region method can be a good choice for high stability, along with CMINPACK.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"For a system which is very non-stiff (i.e., the condition number of the Jacobian is small, or the eigenvalues of the Jacobian are within a few orders of magnitude), then NLSolveJL's :anderson can be a good choice.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#Full-List-of-Methods","page":"Nonlinear System Solvers","title":"Full List of Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#NonlinearSolve.jl","page":"Nonlinear System Solvers","title":"NonlinearSolve.jl","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"These are the core solvers.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"NewtonRaphson(;autodiff=true,chunk_size=12,diff_type=Val{:forward},linsolve=DEFAULT_LINSOLVE): A Newton-Raphson method with swappable nonlinear solvers and autodiff methods for high performance on large and sparse systems. When used on objects like static arrays, this method is non-allocating.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#SciMLNLSolve.jl","page":"Nonlinear System Solvers","title":"SciMLNLSolve.jl","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"This is a wrapper package for importing solvers from other packages into this interface. Note that these solvers do not come by default, and thus one needs to install the package before using these solvers:","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"]add SciMLNLSolve\nusing SciMLNLSolve","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"CMINPACK(): A wrapper for using the classic MINPACK method through MINPACK.jl\nNLSolveJL(): A wrapper for NLsolve.jl","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"NLSolveJL(;\n          method=:trust_region,\n          autodiff=:central,\n          store_trace=false,\n          extended_trace=false,\n          linesearch=LineSearches.Static(),\n          linsolve=(x, A, b) -> copyto!(x, A\\b),\n          factor = one(Float64),\n          autoscale=true,\n          m=10,\n          beta=one(Float64),\n          show_trace=false,\n       )","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"Choices for methods in NLSolveJL:","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":":fixedpoint: Fixed-point iteration\n:anderson: Anderson-accelerated fixed-point iteration\n:newton: Classical Newton method with an optional line search\n:trust_region: Trust region Newton method (the default choice)","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"For more information on these arguments, consult the NLsolve.jl documentation.","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/#Sundials.jl","page":"Nonlinear System Solvers","title":"Sundials.jl","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"This is a wrapper package for the SUNDIALS C library, specifically the KINSOL nonlinear solver included in that ecosystem. Note that these solvers do not come by default, and thus one needs to install the package before using these solvers:","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"]add Sundials\nusing Sundials","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"KINSOL: The KINSOL method of the SUNDIALS C library","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"KINSOL(;\n    linear_solver = :Dense,\n    jac_upper = 0,\n    jac_lower = 0,\n    userdata = nothing,\n)","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":"The choices for the linear solver are:","category":"page"},{"location":"copies/NonlinearSolve/solvers/NonlinearSystemSolvers/","page":"Nonlinear System Solvers","title":"Nonlinear System Solvers","text":":Dense: A dense linear solver\n:Band: A solver specialized for banded Jacobians. If used, you must set the position of the upper and lower non-zero diagonals via jac_upper and jac_lower.\n:LapackDense: A version of the dense linear solver that uses the Julia-provided OpenBLAS-linked LAPACK for multithreaded operations. This will be faster than :Dense on larger systems but has noticeable overhead on smaller (<100 ODE) systems.\n:LapackBand: A version of the banded linear solver that uses the Julia-provided OpenBLAS-linked LAPACK for multithreaded operations. This will be faster than :Band on larger systems but has noticeable overhead on smaller (<100 ODE) systems.\n:Diagonal: This method is specialized for diagonal Jacobians.\n:GMRES: A GMRES method. Recommended first choice Krylov method.\n:BCG: A biconjugate gradient method\n:PCG: A preconditioned conjugate gradient method. Only for symmetric linear systems.\n:TFQMR: A TFQMR method.\n:KLU: A sparse factorization method. Requires that the user specify a Jacobian. The Jacobian must be set as a sparse matrix in the ODEProblem type.","category":"page"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/#nonlinearfunctions","page":"NonlinearFunctions and Jacobian Types","title":"NonlinearFunctions and Jacobian Types","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/","page":"NonlinearFunctions and Jacobian Types","title":"NonlinearFunctions and Jacobian Types","text":"The SciML ecosystem provides an extensive interface for declaring extra functions associated with the differential equation's data. In traditional libraries there is usually only one option: the Jacobian. However, we allow for a large array of pre-computed functions to speed up the calculations. This is offered via the NonlinearFunction types, which can be passed to the problems.","category":"page"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/#Function-Type-Definitions","page":"NonlinearFunctions and Jacobian Types","title":"Function Type Definitions","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/","page":"NonlinearFunctions and Jacobian Types","title":"NonlinearFunctions and Jacobian Types","text":"SciMLBase.NonlinearFunction","category":"page"},{"location":"copies/NonlinearSolve/basics/NonlinearFunctions/#SciMLBase.NonlinearFunction","page":"NonlinearFunctions and Jacobian Types","title":"SciMLBase.NonlinearFunction","text":"NonlinearFunction{iip,F,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractNonlinearFunction{iip}\n\nA representation of an nonlinear system of equations f, defined by:\n\n0 = f(up)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nNonlinearFunction{iip,recompile}(f;\n                           analytic=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           paramjac = nothing,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p) or du = f(u,p). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nanalytic(u0,p): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\njac(J,u,p) or J=jac(u,p): returns fracdfdu\njvp(Jv,v,u,p) or Jv=jvp(v,u,p): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p) or Jv=vjp(v,u,p): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the NonlinearFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/LinearSolve/#LinearSolve.jl:-High-Performance-Unified-Linear-Solvers","page":"Home","title":"LinearSolve.jl: High-Performance Unified Linear Solvers","text":"","category":"section"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"LinearSolve.jl is a unified interface for the linear solving packages of Julia. It interfaces with other packages of the Julia ecosystem to make it easy to test alternative solver packages and pass small types to control algorithm swapping. It also interfaces with the ModelingToolkit.jl world of symbolic modeling to allow for automatically generating high-performance code.","category":"page"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"Performance is key: the current methods are made to be highly performant on scalar and statically sized small problems, with options for large-scale systems. If you run into any performance issues, please file an issue.","category":"page"},{"location":"copies/LinearSolve/#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"To install LinearSolve.jl, use the Julia package manager:","category":"page"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"LinearSolve\")","category":"page"},{"location":"copies/LinearSolve/#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to ModelingToolkit.\nThere are a few community forums:\nthe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\non the Julia Discourse forums\nsee also SciML Community page","category":"page"},{"location":"copies/LinearSolve/#Roadmap","page":"Home","title":"Roadmap","text":"","category":"section"},{"location":"copies/LinearSolve/","page":"Home","title":"Home","text":"Wrappers for every linear solver in the Julia language is on the roadmap. If there are any important ones that are missing that you would like to see added, please open an issue. The current algorithms should support automatic differentiation. Pre-defined preconditioners would be a welcome addition.","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLAlgorithms","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Definition-of-the-SciMLAlgorithm-Interface","page":"SciMLAlgorithms","title":"Definition of the SciMLAlgorithm Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"SciMLAlgorithms are defined as types which have dispatches to the function signature:","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"CommonSolve.solve(prob::SciMLProblem,alg::SciMLAlgorithm;kwargs...)","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Algorithm-Specific-Arguments","page":"SciMLAlgorithms","title":"Algorithm-Specific Arguments","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"Note that because the keyword arguments of solve are designed to be common across the whole problem type, algorithms should have the algorithm-specific keyword arguments defined as part of the algorithm constructor. For example, Rodas5 has a choice of autodiff::Bool which is not common across all ODE solvers, and thus autodiff is a algorithm-specific keyword argument handled via Rodas5(autodiff=true).","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Remake","page":"SciMLAlgorithms","title":"Remake","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"Note that remake is applicable to SciMLAlgorithm types, but this is not used in the public API. It's used for solvers to swap out components like ForwardDiff chunk sizes.","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Common-Algorithm-Keyword-Arguments","page":"SciMLAlgorithms","title":"Common Algorithm Keyword Arguments","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"Commonly used algorithm keyword arguments are:","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Traits","page":"SciMLAlgorithms","title":"Traits","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"SciMLBase.isautodifferentiable\nSciMLBase.allows_arbitrary_number_types\nSciMLBase.allowscomplex\nSciMLBase.isadaptive\nSciMLBase.isdiscrete","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.isautodifferentiable","page":"SciMLAlgorithms","title":"SciMLBase.isautodifferentiable","text":"isautodifferentiable(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with direct automatic differentiation, i.e. can have algorithms like ForwardDiff or ReverseDiff attempt to differentiate directly through the solver.\n\nDefaults to false as only pure-Julia algorithms can have this be true.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.allows_arbitrary_number_types","page":"SciMLAlgorithms","title":"SciMLBase.allows_arbitrary_number_types","text":"allowsarbitrarynumber_types(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with direct automatic differentiation, i.e. can have algorithms like ForwardDiff or ReverseDiff attempt to differentiate directly through the solver.\n\nDefaults to false as only pure-Julia algorithms can have this be true.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.allowscomplex","page":"SciMLAlgorithms","title":"SciMLBase.allowscomplex","text":"allowscomplex(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with having complex numbers as the state variables.\n\nDefaults to false.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.isadaptive","page":"SciMLAlgorithms","title":"SciMLBase.isadaptive","text":"isadaptive(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm uses adaptivity, i.e. has a non-quasi-static compute graph.\n\nDefaults to true.\n\n\n\n\n\nis_integrator_adaptive(i::DEIntegrator)\n\nChecks if the integrator is adaptive\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.isdiscrete","page":"SciMLAlgorithms","title":"SciMLBase.isdiscrete","text":"isdiscrete(alg::DEAlgorithm)\n\nTrait declaration for whether an algorithm allows for discrete state values, such as integers.\n\nDefaults to false.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Abstract-SciML-Algorithms","page":"SciMLAlgorithms","title":"Abstract SciML Algorithms","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"SciMLBase.SciMLAlgorithm\nSciMLBase.DEAlgorithm\nSciMLBase.AbstractLinearAlgorithm\nSciMLBase.AbstractNonlinearAlgorithm\nSciMLBase.AbstractQuadratureAlgorithm\nSciMLBase.AbstractOptimizationAlgorithm\nSciMLBase.AbstractSteadyStateAlgorithm\nSciMLBase.AbstractODEAlgorithm\nSciMLBase.AbstractSecondOrderODEAlgorithm\nSciMLBase.AbstractRODEAlgorithm\nSciMLBase.AbstractSDEAlgorithm\nSciMLBase.AbstractDAEAlgorithm\nSciMLBase.AbstractDDEAlgorithm\nSciMLBase.AbstractSDDEAlgorithm","category":"page"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.SciMLAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.SciMLAlgorithm","text":"abstract type SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.DEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.DEAlgorithm","text":"abstract type DEAlgorithm <: SciMLBase.SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractLinearAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractLinearAlgorithm","text":"abstract type AbstractLinearAlgorithm <: SciMLBase.SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractNonlinearAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractNonlinearAlgorithm","text":"abstract type AbstractNonlinearAlgorithm <: SciMLBase.SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractQuadratureAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractQuadratureAlgorithm","text":"abstract type AbstractIntegralAlgorithm <: SciMLBase.SciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractOptimizationAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractOptimizationAlgorithm","text":"abstract type AbstractOptimizationAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractSteadyStateAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSteadyStateAlgorithm","text":"abstract type AbstractSteadyStateAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractODEAlgorithm","text":"abstract type AbstractODEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractSecondOrderODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSecondOrderODEAlgorithm","text":"abstract type AbstractSecondOrderODEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractRODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractRODEAlgorithm","text":"abstract type AbstractRODEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractSDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSDEAlgorithm","text":"abstract type AbstractSDEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractDAEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractDAEAlgorithm","text":"abstract type AbstractDAEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractDDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractDDEAlgorithm","text":"abstract type AbstractDDEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#SciMLBase.AbstractSDDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSDDEAlgorithm","text":"abstract type AbstractSDDEAlgorithm <: SciMLBase.DEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Algorithms/#Concrete-SciML-Algorithms","page":"SciMLAlgorithms","title":"Concrete SciML Algorithms","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Algorithms/","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"The concrete SciML algorithms are found in the respective solver documentations.","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/#Solving-Nonlinear-Systems","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"","category":"section"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"A nonlinear system f(u) = 0 is specified by defining a function f(u,p), where p are the parameters of the system. For example, the following solves the vector equation f(u) = u^2 - p for a vector of equations:","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"using NonlinearSolve, StaticArrays\n\nf(u,p) = u .* u .- p\nu0 = @SVector[1.0, 1.0]\np = 2.0\nprobN = NonlinearProblem{false}(f, u0, p)\nsolver = solve(probN, NewtonRaphson(), tol = 1e-9)","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"where u0 is the initial condition for the rootfind. Native NonlinearSolve.jl solvers use the given type of u0 to determine the type used within the solver and the return. Note that the parameters p can be any type, but most are an AbstractArray for automatic differentiation.","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/#Using-Bracketing-Methods","page":"Solving Nonlinear Systems","title":"Using Bracketing Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"For scalar rootfinding problems, bracketing methods exist. In this case, one passes a bracket instead of an initial condition, for example:","category":"page"},{"location":"copies/NonlinearSolve/tutorials/nonlinear/","page":"Solving Nonlinear Systems","title":"Solving Nonlinear Systems","text":"f(u, p) = u .* u .- 2.0\nu0 = (1.0, 2.0) # brackets\nprobB = NonlinearProblem(f, u0)\nsol = solve(probB, Falsi())","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#The-PDE-Definition-Interface","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"While ODEs u = f(upt) can be defined by a user-function f, for PDEs the function form can be different for every PDE. How many functions, and how many inputs? This can always change. The SciML ecosystem solves this problem by using ModelingToolkit.jl to define PDESystem, a high-level symbolic description of the PDE to be consumed by other packages.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"The vision for the common PDE interface is that a user should only have to specify their PDE once, mathematically, and have instant access to everything as simple as a finite difference method with constant grid spacing, to something as complex as a distributed multi-GPU discontinuous Galerkin method.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"The key to the common PDE interface is a separation of the symbolic handling from the numerical world. All of the discretizers should not \"solve\" the PDE, but instead be a conversion of the mathematical specification to a numerical problem. Preferably, the transformation should be to another ModelingToolkit.jl AbstractSystem via a symbolic_discretize dispatch, but in some cases this cannot be done or will  not be performant. Thus in some cases, only a discretize definition is given to a  SciMLProblem, with symbolic_discretize simply providing diagnostic or lower level information about the construction process.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"These elementary problems, such as solving linear systems Ax=b, solving nonlinear systems f(x)=0, ODEs, etc. are all defined by SciMLBase.jl, which then numerical solvers can all target these common forms. Thus someone who works on linear solvers doesn't necessarily need to be working on a Discontinuous Galerkin or finite element library, but instead \"linear solvers that are good for matrices A with properties ...\" which are then accessible by every other discretization method in the common PDE interface.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"Similar to the rest of the AbstractSystem types, transformation and analyses functions will allow for simplifying the PDE before solving it, and constructing block symbolic functions like Jacobians.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#Constructors","page":"The PDE Definition Interface","title":"Constructors","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"ModelingToolkit.PDESystem","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#Domains-(WIP)","page":"The PDE Definition Interface","title":"Domains (WIP)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"Domains are specifying by saying indepvar in domain, where indepvar is a single or a collection of independent variables, and domain is the chosen domain type. A 2-tuple can be used to indicate an Interval. Thus forms for the indepvar can be like:","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"t ∈ (0.0,1.0)\n(t,x) ∈ UnitDisk()\n[v,w,x,y,z] ∈ VectorUnitBall(5)","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#Domain-Types-(WIP)","page":"The PDE Definition Interface","title":"Domain Types (WIP)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"Interval(a,b): Defines the domain of an interval from a to b (requires explicit","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"import from DomainSets.jl, but a 2-tuple can be used instead)","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#discretize-and-symbolic_discretize","page":"The PDE Definition Interface","title":"discretize and symbolic_discretize","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"The only functions which act on a PDESystem are the following:","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"discretize(sys,discretizer): produces the outputted AbstractSystem or SciMLProblem.\nsymbolic_discretize(sys,discretizer): produces a debugging symbolic description of the discretized problem.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#Boundary-Conditions-(WIP)","page":"The PDE Definition Interface","title":"Boundary Conditions (WIP)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/#Transformations","page":"The PDE Definition Interface","title":"Transformations","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/#Analyses","page":"The PDE Definition Interface","title":"Analyses","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/#Discretizer-Ecosystem","page":"The PDE Definition Interface","title":"Discretizer Ecosystem","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/#NeuralPDE.jl:-PhysicsInformedNN","page":"The PDE Definition Interface","title":"NeuralPDE.jl: PhysicsInformedNN","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"NeuralPDE.jl defines the PhysicsInformedNN discretizer which uses a DiffEqFlux.jl neural network to solve the differential equation.","category":"page"},{"location":"copies/SciMLBase/interfaces/PDE/#MethodOfLines.jl:-MOLFiniteDifference-(WIP)","page":"The PDE Definition Interface","title":"MethodOfLines.jl: MOLFiniteDifference (WIP)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/PDE/","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"MethodOfLines.jl defines the MOLFiniteDifference discretizer which performs a finite difference discretization using the DiffEqOperators.jl stencils. These stencils make use of NNLib.jl for fast operations on semi-linear domains.","category":"page"},{"location":"copies/SciMLBase/fundamentals/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/#What-are-the-code-styling-rules-for-SciML?","page":"Frequently Asked Questions","title":"What are the code styling rules for SciML?","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"All SciML libraries are supposed to follow SciMLStyle. Any deviation from that style is something to be fixed.","category":"page"},{"location":"copies/SciMLBase/fundamentals/FAQ/#Where-do-I-find-more-information-on-the-internals-of-some-packages?","page":"Frequently Asked Questions","title":"Where do I find more information on the internals of some packages?","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"The SciML Developer Documentation describes the internals of some of the larger solver libraries at length.","category":"page"},{"location":"copies/SciMLBase/fundamentals/FAQ/#What-are-the-community-practices-that-SciML-developers-should-use?","page":"Frequently Asked Questions","title":"What are the community practices that SciML developers should use?","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"See ColPrac: Contributor's Guide on Collaborative Practices for Community Packages","category":"page"},{"location":"copies/SciMLBase/fundamentals/FAQ/#Are-there-developer-programs-to-help-fund-parties-interested-in-helping-develop-SciML?","page":"Frequently Asked Questions","title":"Are there developer programs to help fund parties interested in helping develop SciML?","text":"","category":"section"},{"location":"copies/SciMLBase/fundamentals/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Yes! See the SciML Developer Programs webpage.","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"Ask more questions.","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/#How-do-I-use-IterativeSolvers-solvers-with-a-weighted-tolerance-vector?","page":"Frequently Asked Questions","title":"How do I use IterativeSolvers solvers with a weighted tolerance vector?","text":"","category":"section"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"IterativeSolvers.jl computes the norm after the application of the left precondtioner Pl. Thus in order to use a vector tolerance weights, one can mathematically hack the system via the following formulation:","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"using LinearSolve, LinearAlgebra\nPl = LinearSolve.InvPreconditioner(Diagonal(weights))\nPr = Diagonal(weights)\n\nA = rand(n,n)\nb = rand(n)\n\nprob = LinearProblem(A,b)\nsol = solve(prob,IterativeSolvers_GMRES(),Pl=Pl,Pr=Pr)","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"If you want to use a \"real\" preconditioner under the norm weights, then one can use ComposePreconditioner to apply the preconditioner after the application of the weights like as follows:","category":"page"},{"location":"copies/LinearSolve/basics/FAQ/","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"using LinearSolve, LinearAlgebra\nPl = ComposePreconitioner(LinearSolve.InvPreconditioner(Diagonal(weights),realprec))\nPr = Diagonal(weights)\n\nA = rand(n,n)\nb = rand(n)\n\nprob = LinearProblem(A,b)\nsol = solve(prob,IterativeSolvers_GMRES(),Pl=Pl,Pr=Pr)","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLSolutions","page":"SciMLSolutions","title":"SciMLSolutions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/#Definition-of-the-SciMLSolution-Interface","page":"SciMLSolutions","title":"Definition of the SciMLSolution Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"All SciMLSolution types are a subset of some AbstractArray. Types with time series (like ODESolution) are subtypes of RecursiveArrayTools.AbstractVectorOfArray and  RecursiveArrayTools.AbstractDiffEqArray where appropriate. Types without a time series (like OptimizationSolution) are directly subsets of AbstractArray. ","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#Array-Interface","page":"SciMLSolutions","title":"Array Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"Instead of working on the Vector{uType} directly, we can use the provided array interface.","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol[j]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"to access the value at timestep j (if the timeseries was saved), and","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol.t[j]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"to access the value of t at timestep j. For multi-dimensional systems, this will address first by component and lastly by time, and thus","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol[i,j]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"will be the ith component at timestep j. Hence, sol[j][i] == sol[i, j]. This is done because Julia is column-major, so the leading dimension should be contiguous in memory. If the independent variables had shape (for example, was a matrix), then i is the linear index. We can also access solutions with shape:","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol[i,k,j]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"gives the [i,k] component of the system at timestep j. The colon operator is supported, meaning that","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"sol[i,:]","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"gives the timeseries for the ith component.","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#Common-Field-Names","page":"SciMLSolutions","title":"Common Field Names","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"u: the solution values\nt: the independent variable values, matching the length of the solution, if applicable\nresid: the residual of the solution, if applicable\noriginal: the solution object from the original solver, if it's a wrapper algorithm\nretcode: see the documentation section on return codes\nprob: the problem that was solved\nalg: the algorithm used to solve the problem","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#retcodes","page":"SciMLSolutions","title":"Return Codes (RetCodes)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"The solution types have a retcode field which returns a symbol signifying the error state of the solution. The retcodes are as follows:","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":":Default: The solver did not set retcodes.\n:Success: The integration completed without erroring or the steady state solver from SteadyStateDiffEq found the steady state.\n:Terminated: The integration is terminated with terminate!(integrator). Note that this may occur by using TerminateSteadyState from the callback library DiffEqCallbacks.\n:MaxIters: The integration exited early because it reached its maximum number of iterations.\n:DtLessThanMin: The timestep method chose a stepsize which is smaller than the allowed minimum timestep, and exited early.\n:Unstable: The solver detected that the solution was unstable and exited early.\n:InitialFailure: The DAE solver could not find consistent initial conditions.\n:ConvergenceFailure: The internal implicit solvers failed to converge.\n:Failure: General uncategorized failures or errors.","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#Traits","page":"SciMLSolutions","title":"Traits","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLSolution-API","page":"SciMLSolutions","title":"SciMLSolution API","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/#Abstract-SciML-Solutions","page":"SciMLSolutions","title":"Abstract SciML Solutions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"SciMLBase.SciMLSolution\nSciMLBase.AbstractNoTimeSolution\nSciMLBase.AbstractTimeseriesSolution\nSciMLBase.AbstractNoiseProcess\nSciMLBase.AbstractEnsembleSolution\nSciMLBase.AbstractLinearSolution\nSciMLBase.AbstractNonlinearSolution\nSciMLBase.AbstractQuadratureSolution\nSciMLBase.AbstractSteadyStateSolution\nSciMLBase.AbstractAnalyticalSolution\nSciMLBase.AbstractODESolution\nSciMLBase.AbstractDDESolution\nSciMLBase.AbstractRODESolution\nSciMLBase.AbstractDAESolution","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.SciMLSolution","page":"SciMLSolutions","title":"SciMLBase.SciMLSolution","text":"Union of all base solution types.\n\nUses a Union so that solution types can be <: AbstractArray\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractNoTimeSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractNoTimeSolution","text":"abstract type AbstractNoTimeSolution{T, N} <: AbstractArray{T, N}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractTimeseriesSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractTimeseriesSolution","text":"abstract type AbstractTimeseriesSolution{T, N, A} <: RecursiveArrayTools.AbstractDiffEqArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractNoiseProcess","page":"SciMLSolutions","title":"SciMLBase.AbstractNoiseProcess","text":"abstract type AbstractNoiseProcess{T, N, A, isinplace} <: RecursiveArrayTools.AbstractDiffEqArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractEnsembleSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractEnsembleSolution","text":"abstract type AbstractEnsembleSolution{T, N, A} <: RecursiveArrayTools.AbstractVectorOfArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractLinearSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractLinearSolution","text":"abstract type AbstractLinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractNonlinearSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractNonlinearSolution","text":"abstract type AbstractNonlinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractSteadyStateSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractSteadyStateSolution","text":"abstract type AbstractNonlinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractAnalyticalSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractAnalyticalSolution","text":"abstract type AbstractAnalyticalSolution{T, N, S} <: SciMLBase.AbstractTimeseriesSolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractODESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractODESolution","text":"abstract type AbstractODESolution{T, N, S} <: SciMLBase.AbstractTimeseriesSolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractDDESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractDDESolution","text":"abstract type AbstractDDESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractRODESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractRODESolution","text":"abstract type AbstractRODESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.AbstractDAESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractDAESolution","text":"abstract type AbstractDAESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#Concrete-SciML-Solutions","page":"SciMLSolutions","title":"Concrete SciML Solutions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Solutions/","page":"SciMLSolutions","title":"SciMLSolutions","text":"SciMLBase.LinearSolution\nSciMLBase.QuadratureSolution\nSciMLBase.DAESolution\nSciMLBase.NonlinearSolution\nSciMLBase.ODESolution\nSciMLBase.OptimizationSolution\nSciMLBase.RODESolution","category":"page"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.LinearSolution","page":"SciMLSolutions","title":"SciMLBase.LinearSolution","text":"struct LinearSolution{T, N, uType, R, A, C} <: SciMLBase.AbstractLinearSolution{T, N}\n\nRepresentation of the solution to an linear system Ax=b defined by a LinearProblem\n\nFields\n\nu: the representation of the optimization's solution.\nresid: the residual of the solver, if the method is an iterative method.\nalg: the algorithm type used by the solver.\niters: the number of iterations used to solve the equation, if the method is an iterative method.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\ncache: the LinearCache object containing the solver's internal cached variables. This is given to allow continuation of solver usage, for example, solving Ax=b with the same A and a new b without refactorizing A. See the caching interface tutorial for details on how to use the cache effectively: http://linearsolve.sciml.ai/dev/tutorials/caching_interface/ \n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.DAESolution","page":"SciMLSolutions","title":"SciMLBase.DAESolution","text":"struct DAESolution{T, N, uType, duType, uType2, DType, tType, P, A, ID, DE} <: SciMLBase.AbstractDAESolution{T, N, uType}\n\nRepresentation of the solution to an differential-algebraic equation defined by an DAEProblem.\n\nDESolution Interface\n\nFor more information on interacting with DESolution types, check out the Solution Handling page of the DifferentialEquations.jl documentation.\n\nhttps://diffeq.sciml.ai/stable/basics/solution/\n\nFields\n\nu: the representation of the DAE solution. Given as an array of solutions, where u[i] corresponds to the solution at time t[i]. It is recommended in most cases one does not access sol.u directly and instead use the array interface described in the Solution  Handling page of the DifferentialEquations.jl documentation.\ndu: the representation fo the derivatives of the DAE solution.\nt: the time points corresponding to the saved values of the DAE solution.\nprob: the original DAEProblem that was solved.\nalg: the algorithm type used by the solver.\ndestats: statistics of the solver, such as the number of function evaluations required, number of Jacobians computed, and more.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.NonlinearSolution","page":"SciMLSolutions","title":"SciMLBase.NonlinearSolution","text":"struct NonlinearSolution{T, N, uType, R, P, A, O, uType2} <: SciMLBase.AbstractNonlinearSolution{T, N}\n\nRepresentation of the solution to an nonlinear equation defined by an NonlinearProblem, or the steady state solution to a differential equation defined by a SteadyStateProblem.\n\nFields\n\nu: the representation of the nonlinear equation's solution.\nresid: the residual of the solution.\nprob: the original NonlinearProblem/SteadyStateProblem that was solved.\nalg: the algorithm type used by the solver.\noriginal: if the solver is wrapped from an alternative solver ecosystem, such as NLsolve.jl, then this is the original return from said solver library.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\nleft: if the solver is bracketing method, this is the final left bracket value.\nright: if the solver is bracketing method, this is the final right bracket value.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.ODESolution","page":"SciMLSolutions","title":"SciMLBase.ODESolution","text":"struct ODESolution{T, N, uType, uType2, DType, tType, rateType, P, A, IType, DE} <: SciMLBase.AbstractODESolution{T, N, uType}\n\nRepresentation of the solution to an ordinary differential equation defined by an ODEProblem.\n\nDESolution Interface\n\nFor more information on interacting with DESolution types, check out the Solution Handling page of the DifferentialEquations.jl documentation.\n\nhttps://diffeq.sciml.ai/stable/basics/solution/\n\nFields\n\nu: the representation of the ODE solution. Given as an array of solutions, where u[i] corresponds to the solution at time t[i]. It is recommended in most cases one does not access sol.u directly and instead use the array interface described in the Solution  Handling page of the DifferentialEquations.jl documentation.\nt: the time points corresponding to the saved values of the ODE solution.\nprob: the original ODEProblem that was solved.\nalg: the algorithm type used by the solver.\ndestats: statistics of the solver, such as the number of function evaluations required, number of Jacobians computed, and more.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.OptimizationSolution","page":"SciMLSolutions","title":"SciMLBase.OptimizationSolution","text":"struct OptimizationSolution{T, N, uType, P, A, Tf, O} <: SciMLBase.AbstractOptimizationSolution{T, N}\n\nRepresentation of the solution to an nonlinear optimization defined by an OptimizationProblem\n\nFields\n\nu: the representation of the optimization's solution.\nprob: the original NonlinearProblem/SteadyStateProblem that was solved.\nalg: the algorithm type used by the solver.\noriginal: if the solver is wrapped from an alternative solver ecosystem, such as Optim.jl, then this is the original return from said solver library.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Solutions/#SciMLBase.RODESolution","page":"SciMLSolutions","title":"SciMLBase.RODESolution","text":"struct RODESolution{T, N, uType, uType2, DType, tType, randType, P, A, IType, DE} <: SciMLBase.AbstractRODESolution{T, N, uType}\n\nRepresentation of the solution to an stochastic differential equation defined by an SDEProblem, or of a random ordinary differential equation defined by an RODEProblem.\n\nDESolution Interface\n\nFor more information on interacting with DESolution types, check out the Solution Handling page of the DifferentialEquations.jl documentation.\n\nhttps://diffeq.sciml.ai/stable/basics/solution/\n\nFields\n\nu: the representation of the SDE or RODE solution. Given as an array of solutions, where u[i] corresponds to the solution at time t[i]. It is recommended in most cases one does not access sol.u directly and instead use the array interface described in the Solution  Handling page of the DifferentialEquations.jl documentation.\nt: the time points corresponding to the saved values of the ODE solution.\nW: the representation of the saved noise process from the solution. See the Noise Processes page of the DifferentialEquations.jl documentation for more details:  https://diffeq.sciml.ai/stable/features/noiseprocess/ . Note that this noise is only saved in full if `savenoise=true` in the solver.\nprob: the original SDEProblem/RODEProblem that was solved.\nalg: the algorithm type used by the solver.\ndestats: statistics of the solver, such as the number of function evaluations required, number of Jacobians computed, and more.\nretcode: the return code from the solver. Used to determine whether the solver solved successfully (sol.retcode === :Success), whether it terminated due to a user-defined callback (sol.retcode === :Terminated), or whether it exited due to an error. For more details, see the return code section of the DifferentialEquations.jl documentation.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Init_Solve/#The-SciML-init-and-solve-Functions","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"solve function has the default definition","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"solve(args...; kwargs...) = solve!(init(args...; kwargs...))","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"The interface for the three functions is as follows:","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"init(::ProblemType, args...; kwargs...) :: IteratorType\nsolve!(::SolverType) :: SolutionType","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"where ProblemType, IteratorType, and SolutionType are the types defined in your package.","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"To avoid method ambiguity, the first argument of solve, solve!, and init must be dispatched on the type defined in your package.  For example, do not define a method such as","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"init(::AbstractVector, ::AlgorithmType)","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/#init-and-the-Iterator-Interface","page":"The SciML init and solve Functions","title":"init and the Iterator Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"init's return gives an IteratorType which is designed to allow the user to have more direct handling over the internal solving process. Because of this internal nature, the IteratorType has a less unified interface across problem types than other portions like ProblemType and SolutionType. For example, for differential equations this is the  Integrator Interface designed for mutating solutions in a manner for callback implementation, which is distinctly different from the  LinearSolve init interface which is designed for caching efficiency with reusing factorizations.","category":"page"},{"location":"copies/SciMLBase/interfaces/Init_Solve/#__solve-and-High-Level-Handling","page":"The SciML init and solve Functions","title":"__solve and High-Level Handling","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Init_Solve/","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"While init and solve are the common entry point for users, solver packages will mostly define dispatches on SciMLBase.__init and SciMLBase.__solve. The reason is because this allows for SciMLBase.init and SciMLBase.solve to have common implementations across all solvers for doing things such as checking for common errors and throwing high level messages. Solvers can opt-out of the high level error handling by directly defining SciMLBase.init and SciMLBase.solve instead, though this is not recommended in order to allow for uniformity of the error messages.","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/#Linear-Solve-with-Caching-Interface","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"","category":"section"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"In many cases one may want to cache information that is reused between different linear solves. For example, if one is going to perform:","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"A\\b1\nA\\b2","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"then it would be more efficient to LU-factorize one time and reuse the factorization:","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"lu!(A)\nA\\b1\nA\\b2","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"LinearSolve.jl's caching interface automates this process to use the most efficient means of solving and resolving linear systems. To do this with LinearSolve.jl, you simply init a cache, solve, replace b, and solve again. This looks like:","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"using LinearSolve\n\nn = 4\nA = rand(n,n)\nb1 = rand(n); b2 = rand(n)\nprob = LinearProblem(A, b1)\n\nlinsolve = init(prob)\nsol1 = solve(linsolve)\n\nsol1.u\n#=\n4-element Vector{Float64}:\n -0.9247817429364165\n -0.0972021708185121\n  0.6839050402960025\n  1.8385599677530706\n=#\n\nlinsolve = LinearSolve.set_b(sol1.cache,b2)\nsol2 = solve(linsolve)\n\nsol2.u\n#=\n4-element Vector{Float64}:\n  1.0321556637762768\n  0.49724400693338083\n -1.1696540870182406\n -0.4998342686003478\n=#","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"Then refactorization will occur when a new A is given:","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"A2 = rand(n,n)\nlinsolve = LinearSolve.set_A(sol2.cache,A2)\nsol3 = solve(linsolve)\n\nsol3.u\n#=\n4-element Vector{Float64}:\n -6.793605395935224\n  2.8673042300837466\n  1.1665136934977371\n -0.4097250749016653\n=#","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"The factorization occurs on the first solve, and it stores the factorization in the cache. You can retrieve this cache via sol.cache, which is the same object as the init but updated to know not to re-solve the factorization.","category":"page"},{"location":"copies/LinearSolve/tutorials/caching_interface/","page":"Linear Solve with Caching Interface","title":"Linear Solve with Caching Interface","text":"The advantage of course with using LinearSolve.jl in this form is that it is efficient while being agnostic to the linear solver. One can easily swap in iterative solvers, sparse solvers, etc. and it will do all of the tricks like caching symbolic factorizations if the sparsity pattern is unchanged.","category":"page"},{"location":"copies/NonlinearSolve/tutorials/iterator_interface/#Nonlinear-Solver-Iterator-Interface","page":"Nonlinear Solver Iterator Interface","title":"Nonlinear Solver Iterator Interface","text":"","category":"section"},{"location":"copies/NonlinearSolve/tutorials/iterator_interface/","page":"Nonlinear Solver Iterator Interface","title":"Nonlinear Solver Iterator Interface","text":"There is an iterator form of the nonlinear solver which mirrors the DiffEq integrator interface:","category":"page"},{"location":"copies/NonlinearSolve/tutorials/iterator_interface/","page":"Nonlinear Solver Iterator Interface","title":"Nonlinear Solver Iterator Interface","text":"f(u, p) = u .* u .- 2.0\nu0 = (1.0, 2.0) # brackets\nprobB = NonlinearProblem(f, u0)\nsolver = init(probB, Falsi()) # Can iterate the solver object\nsolver = solve!(solver)","category":"page"},{"location":"copies/NonlinearSolve/tutorials/iterator_interface/","page":"Nonlinear Solver Iterator Interface","title":"Nonlinear Solver Iterator Interface","text":"Note that the solver object is actually immutable since we want to make it live on the stack for the sake of performance.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Common-Keyword-Arguments","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"The following defines the keyword arguments which are meant to be preserved throughout all of the SciMLProblem cases (where applicable).","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Default-Algorithm-Hinting","page":"Common Keyword Arguments","title":"Default Algorithm Hinting","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"To help choose the default algorithm, the keyword argument alg_hints is provided to solve. alg_hints is a Vector{Symbol} which describe the problem at a high level to the solver. The options are:","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"This functionality is derived via the benchmarks in SciMLBenchmarks.jl","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"Currently this is only implemented for the differential equation solvers.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Output-Control","page":"Common Keyword Arguments","title":"Output Control","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"These arguments control the output behavior of the solvers. It defaults to maximum output to give the best interactive user experience, but can be reduced all the way to only saving the solution at the final timepoint.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"The following options are all related to output control. See the \"Examples\" section at the end of this page for some example usage.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"dense: Denotes whether to save the extra pieces required for dense (continuous) output. Default is save_everystep && !isempty(saveat) for algorithms which have the ability to produce dense output, i.e. by default it's true unless the user has turned off saving on steps or has chosen a saveat value. If dense=false, the solution still acts like a function, and sol(t) is a linear interpolation between the saved time points.\nsaveat: Denotes specific times to save the solution at, during the solving phase. The solver will save at each of the timepoints in this array in the most efficient manner available to the solver. If only saveat is given, then the arguments save_everystep and dense are false by default. If saveat is given a number, then it will automatically expand to tspan[1]:saveat:tspan[2]. For methods where interpolation is not possible, saveat may be equivalent to tstops. The default value is [].\nsave_idxs: Denotes the indices for the components of the equation to save. Defaults to saving all indices. For example, if you are solving a 3-dimensional ODE, and given save_idxs = [1, 3], only the first and third components of the solution will be outputted. Notice that of course in this case the outputed solution will be two-dimensional.\ntstops: Denotes extra times that the timestepping algorithm must step to. This should be used to help the solver deal with discontinuities and singularities, since stepping exactly at the time of the discontinuity will improve accuracy. If a method cannot change timesteps (fixed timestep multistep methods), then tstops will use an interpolation, matching the behavior of saveat. If a method cannot change timesteps and also cannot interpolate, then tstops must be a multiple of dt or else an error will be thrown. Default is [].\nd_discontinuities: Denotes locations of discontinuities in low order derivatives. This will force FSAL algorithms which assume derivative continuity to re-evaluate the derivatives at the point of discontinuity. The default is [].\nsave_everystep: Saves the result at every step. Default is true if isempty(saveat).\nsave_on: Denotes whether intermediate solutions are saved. This overrides the settings of dense, saveat and save_everystep and is used by some applicatioins to manually turn off saving temporarily. Everyday use of the solvers should leave this unchanged. Defaults to true.\nsave_start: Denotes whether the initial condition should be included in the solution type as the first timepoint. Defaults to true.\nsave_end: Denotes whether the final timepoint is forced to be saved, regardless of the other saving settings. Defaults to true.\ninitialize_save: Denotes whether to save after the callback initialization phase (when u_modified=true). Defaults to true.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"Note that dense requires save_everystep=true and saveat=false.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Stepsize-Control","page":"Common Keyword Arguments","title":"Stepsize Control","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"These arguments control the timestepping routines.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Basic-Stepsize-Control","page":"Common Keyword Arguments","title":"Basic Stepsize Control","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"adaptive: Turns on adaptive timestepping for appropriate methods. Default is true.\nabstol: Absolute tolerance in adaptive timestepping. This is the tolerance on local error estimates, not necessarily the global error (though these quantities are related).\nreltol: Relative tolerance in adaptive timestepping.  This is the tolerance on local error estimates, not necessarily the global error (though these quantities are related).\ndt: Sets the initial stepsize. This is also the stepsize for fixed timestep methods. Defaults to an automatic choice if the method is adaptive.\ndtmax: Maximum dt for adaptive timestepping. Defaults are package-dependent.\ndtmin: Minimum dt for adaptive timestepping. Defaults are package-dependent.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Fixed-Stepsize-Usage","page":"Common Keyword Arguments","title":"Fixed Stepsize Usage","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"Note that if a method does not have adaptivity, the following rules apply:","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"If dt is set, then the algorithm will step with size dt each iteration.\nIf tstops and dt are both set, then the algorithm will step with either a size dt, or use a smaller step to hit the tstops point.\nIf tstops is set without dt, then the algorithm will step directly to each value in tstops\nIf neither dt nor tstops are set, the solver will throw an error.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Memory-Optimizations","page":"Common Keyword Arguments","title":"Memory Optimizations","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"alias_u0: allows the solver to alias the initial condition array that is contained in the problem struct. Defaults to false.\ncache: pass a solver cache to decrease the construction time. This is not implemented for any of the problem interfaces at this moment.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Miscellaneous","page":"Common Keyword Arguments","title":"Miscellaneous","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"maxiters: Maximum number of iterations before stopping.\ncallback: Specifies a callback function that is called between iterations.\nverbose: Toggles whether warnings are thrown when the solver exits early. Defaults to true.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Progress-Monitoring","page":"Common Keyword Arguments","title":"Progress Monitoring","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"These arguments control the usage of the progressbar in the logger.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"progress: Turns on/off the Juno progressbar. Default is false.\nprogress_steps: Numbers of steps between updates of the progress bar. Default is 1000.\nprogress_name: Controls the name of the progressbar. Default is the name of the problem type.\nprogress_message: Controls the message with the progressbar. Defaults to showing dt, t, the maximum of u.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"The progress bars all use the Julia Logging interface in order to be generic to the IDE or programming tool that is used. For more information on how this is all put together, see this discussion.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Error-Calculations","page":"Common Keyword Arguments","title":"Error Calculations","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"If you are using the test problems (i.e. SciMLFunctions where f.analytic is defined), then options control the errors which are calculated. By default, any cheap error estimates are always calculated. Extra keyword arguments include:","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"timeseries_errors\ndense_errors","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"for specifying more expensive errors.","category":"page"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/#Automatic-Differentiation-Control","page":"Common Keyword Arguments","title":"Automatic Differentiation Control","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Common_Keywords/","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"See the Automatic Differentiation page for a full description of sensealg","category":"page"},{"location":"copies/LinearSolve/basics/LinearProblem/#Linear-Problems","page":"Linear Problems","title":"Linear Problems","text":"","category":"section"},{"location":"copies/LinearSolve/basics/LinearProblem/","page":"Linear Problems","title":"Linear Problems","text":"LinearProblem","category":"page"},{"location":"copies/LinearSolve/basics/LinearProblem/#SciMLBase.LinearProblem","page":"Linear Problems","title":"SciMLBase.LinearProblem","text":"Defines a linear system problem. Documentation Page: http://linearsolve.sciml.ai/dev/basics/LinearProblem/\n\nMathematical Specification of a Linear Problem\n\nConcrete LinearProblem\n\nTo define a LinearProblem, you simply need to give the AbstractMatrix A and an AbstractVector b which defines the linear system:\n\nAu = b\n\nMatrix-Free LinearProblem\n\nFor matrix-free versions, the specification of the problem is given by an operator A(u,p,t) which computes A*u, or in-place as A(du,u,p,t). These are specified via the AbstractSciMLOperator interface. For more details, see the SciMLBase Documentation.\n\nNote that matrix-free versions of LinearProblem definitions are not compatible with all solvers. To check a solver for compatibility, use the function xxxxx.\n\nProblem Type\n\nConstructors\n\nOptionally, an initial guess u₀ can be supplied which is used for iterative methods.\n\nLinearProblem{isinplace}(A,x,p=NullParameters();u0=nothing,kwargs...)\nLinearProblem(f::AbstractDiffEqOperator,u0,p=NullParameters();u0=nothing,kwargs...)\n\nisinplace optionally sets whether the function is in-place or not, i.e. whether the solvers are allowed to mutate. By default this is true for AbstractMatrix, and for AbstractSciMLOperators it matches the choice of the operator definition.\n\nParameters are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers.\n\nFields\n\nA: The representation of the linear operator.\nb: The right-hand side of the linear system.\np: The parameters for the problem. Defaults to NullParameters. Currently unused.\nu0: The initial condition used by iterative solvers.\nkwargs: The keyword arguments passed on to the solvers.\n\n\n\n","category":"type"},{"location":"copies/LinearSolve/basics/Preconditioners/#prec","page":"Preconditioners","title":"Preconditioners","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"Many linear solvers can be accelerated by using what is known as a preconditioner, an approximation to the matrix inverse action which is cheap to evaluate. These can improve the numerical conditioning of the solver process and in turn improve the performance. LinearSolve.jl provides an interface for the definition of preconditioners which works with the wrapped packages.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#Using-Preconditioners","page":"Preconditioners","title":"Using Preconditioners","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/#Mathematical-Definition","page":"Preconditioners","title":"Mathematical Definition","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"Preconditioners are specified in the keyword arguments of init or solve. The right preconditioner, Pr transforms the linear system Au = b into the form:","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"AP_r^-1(Pu) = AP_r^-1y = b","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"to add the solving step P_r u = y. The left preconditioner, Pl, transforms the linear system into the form:","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"P_l^-1(Au - b) = 0","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"A two-sided preconditioned system is of the form:","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"P_l A P_r^-1 (P_r u) = P_l b","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"By default, if no preconditioner is given the preconditioner is assumed to be the identity I.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#Using-Preconditioners-2","page":"Preconditioners","title":"Using Preconditioners","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"In the following, we will use the DiagonalPreconditioner to define a two-sided preconditioned system which first divides by some random numbers and then multiplies by the same values. This is commonly used in the case where if, instead of random, s is an approximation to the eigenvalues of a system.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"using LinearSolve, LinearAlgebra\r\ns = rand(n)\r\nPl = Diagonal(s)\r\n\r\nA = rand(n,n)\r\nb = rand(n)\r\n\r\nprob = LinearProblem(A,b)\r\nsol = solve(prob,IterativeSolvers_GMRES(),Pl=Pl)","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#Preconditioner-Interface","page":"Preconditioners","title":"Preconditioner Interface","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"To define a new preconditioner you define a Julia type which satisfies the following interface:","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"Base.eltype(::Preconditioner) (Required only for Krylov.jl)\nLinearAlgebra.ldiv!(::AbstractVector,::Preconditioner,::AbstractVector) and LinearAlgebra.ldiv!(::Preconditioner,::AbstractVector)","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/#Curated-List-of-Pre-Defined-Preconditioners","page":"Preconditioners","title":"Curated List of Pre-Defined Preconditioners","text":"","category":"section"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"The following preconditioners match the interface of LinearSolve.jl.","category":"page"},{"location":"copies/LinearSolve/basics/Preconditioners/","page":"Preconditioners","title":"Preconditioners","text":"LinearSolve.ComposePreconditioner(prec1,prec2): composes the preconditioners to apply prec1 before prec2.\nLinearSolve.InvPreconditioner(prec): inverts mul! and ldiv! in a preconditioner definition as a lazy inverse.\nLinearAlgera.Diagonal(s::Union{Number,AbstractVector}): the lazy Diagonal matrix type of Base.LinearAlgebra. Used for efficient construction of a diagonal preconditioner.\nOther Base.LinearAlgera types: all define the full Preconditioner interface.\nIncompleteLU.ilu: an implementation of the incomplete LU-factorization preconditioner. This requires A as a SparseMatrixCSC.\nPreconditioners.CholeskyPreconditioner(A, i): An incomplete Cholesky preconditioner with cut-off level i. Requires A as a AbstractMatrix and positive semi-definite.\nAlgebraicMultiGrid: Implementations of the algebraic multigrid method. Must be converted to a preconditioner via AlgebraicMultiGrid.aspreconditioner(AlgebraicMultiGrid.precmethod(A)). Requires A as a AbstractMatrix. Provides the following methods:\nAlgebraicMultiGrid.ruge_stuben(A)\nAlgebraicMultiGrid.smoothed_aggregation(A)\nPyAMG: Implementations of the algebraic multigrid method. Must be converted to a preconditioner via PyAMG.aspreconditioner(PyAMG.precmethod(A)). Requires A as a AbstractMatrix. Provides the following methods:\nPyAMG.RugeStubenSolver(A)\nPyAMG.SmoothedAggregationSolver(A)\nILUZero.ILU0Precon(A::SparseMatrixCSC{T,N}, b_type = T): An incomplete LU implementation. Requires A as a SparseMatrixCSC.\nLimitedLDLFactorizations.lldl: A limited-memory LDLᵀ factorization for symmetric matrices. Requires A as a SparseMatrixCSC. Applying F = lldl(A); F.D .= abs.(F.D) before usage as a preconditioner makes the preconditioner symmetric postive definite and thus is required for Krylov methods which are specialized for symmetric linear systems.\nRandomizedPreconditioners.NystromPreconditioner A randomized sketching method for positive semidefinite matrices A. Builds a preconditioner P  A + μ*I for the system (A + μ*I)x = b","category":"page"},{"location":"copies/NonlinearSolve/basics/NonlinearProblem/#Nonlinear-Problems","page":"Nonlinear Problems","title":"Nonlinear Problems","text":"","category":"section"},{"location":"copies/NonlinearSolve/basics/NonlinearProblem/","page":"Nonlinear Problems","title":"Nonlinear Problems","text":"NonlinearProblem","category":"page"},{"location":"copies/NonlinearSolve/basics/NonlinearProblem/#SciMLBase.NonlinearProblem","page":"Nonlinear Problems","title":"SciMLBase.NonlinearProblem","text":"Defines a nonlinear system problem. Documentation Page: https://nonlinearsolve.sciml.ai/dev/basics/NonlinearProblem/\n\nMathematical Specification of a Nonlinear Problem\n\nTo define a Nonlinear Problem, you simply need to give the function f which defines the nonlinear system:\n\nf(up) = 0\n\nand an initial guess u₀ of where f(u,p)=0. f should be specified as f(u,p) (or in-place as f(du,u,p)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher-dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nNonlinearProblem(f::NonlinearFunction,u0,p=NullParameters();kwargs...)\nNonlinearProblem{isinplace}(f,u0,p=NullParameters();kwargs...)\n\nisinplace optionally sets whether the function is in-place or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the NonlinearFunctions page.\n\nFields\n\nf: The function in the problem.\nu0: The initial guess for the steady state.\np: The parameters for the problem. Defaults to NullParameters.\nkwargs: The keyword arguments passed on to the solvers.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#scimlfunctions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The SciML ecosystem provides an extensive interface for declaring extra functions associated with the differential equation's data. In traditional libraries there is usually only one option: the Jacobian. However, we allow for a large array of pre-computed functions to speed up the calculations. This is offered via the SciMLFunction types which can be passed to the problems.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Definition-of-the-AbstractSciMLFunction-Interface","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Definition of the AbstractSciMLFunction Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The following standard principles should be adhered to across all  AbstractSciMLFunction instantiations.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Common-Function-Choice-Definitions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Common Function Choice Definitions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The full interface available to the solvers is as follows:","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"jac: The Jacobian of the differential equation with respect to the state variable u at a time t with parameters p.\nparamjac: The Jacobian of the differential equation with respect to p at state u at time t.\nanalytic: Defines an analytical solution using u0 at time t with p which will cause the solvers to return errors. Used for testing.\nsyms: Allows you to name your variables for automatic names in plots and other output.\njac_prototype: Defines the type to be used for any internal Jacobians within the solvers.\nsparsity: Defines the sparsity pattern to be used for the sparse differentiation schemes. By default this is equal to jac_prototype. See the sparsity handling portion of this page for more information.\ncolorvec: The coloring pattern used by the sparse differentiator. See the sparsity handling portion of this page for more information.\nobserved: A function which allows for generating other observables from a solution.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"Each function type additionally has some specific arguments, refer to their documentation for details.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#In-place-Specification-and-No-Recompile-Mode","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"In-place Specification and No-Recompile Mode","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"Each SciMLFunction type can be called with an \"is inplace\" (iip) choice.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"ODEFunction(f)\nODEFunction{iip}(f)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"which is a boolean for whether the function is in the inplace form (mutating to change the first value). This is automatically determined using the methods table but note that for full type-inferrability of the SciMLProblem this iip-ness should be specified.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"Additionally, the functions are fully specialized to reduce the runtimes. If one would instead like to not specialize on the functions to reduce compile time, then one can set recompile to false.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"ODEFunction{iip,false}(f)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"This makes the ODE solver compilation independent of the function and so changing the function will not cause recompilation. One can change the default value by changing the const RECOMPILE_BY_DEFAULT = true to false in the SciMLBase.jl source code.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Specifying-Jacobian-Types","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Specifying Jacobian Types","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The jac field of an inplace style SciMLFunction has the signature jac(J,u,p,t), which updates the jacobian J in-place. The intended type for J can sometimes be inferred (e.g. when it is just a dense Matrix), but not in general. To supply the type information, you can provide a jac_prototype in the function's constructor.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The following example creates an inplace ODEFunction whose jacobian is a Diagonal:","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"using LinearAlgebra\nf = (du,u,p,t) -> du .= t .* u\njac = (J,u,p,t) -> (J[1,1] = t; J[2,2] = t; J)\njp = Diagonal(zeros(2))\nfun = ODEFunction(f; jac=jac, jac_prototype=jp)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"Note that the integrators will always make a deep copy of fun.jac_prototype, so there's no worry of aliasing.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"In general the jacobian prototype can be anything that has mul! defined, in particular sparse matrices or custom lazy types that support mul!. A special case is when the jac_prototype is a AbstractDiffEqLinearOperator, in which case you do not need to supply jac as it is automatically set to update_coefficients!. Refer to the DiffEqOperators section for more information on setting up time/parameter dependent operators.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Sparsity-Handling","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Sparsity Handling","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The solver libraries internally use packages such as FiniteDiff.jl and SparseDiffTools.jl for high performance calculation of sparse Jacobians and Hessians, along with matrix-free calculations of Jacobian-Vector products (Jv), vector-Jacobian products (v'J), and Hessian-vector products (H*v). The SciML interface gives users the ability to control these connections in order to allow for top notch performance.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The key arguments in the SciMLFunction is the prototype, which is an object that will be used as the underlying Jacobian/Hessian. Thus if one wants to use a sparse Jacobian, one should specify jac_prototype to be a sparse matrix. The sparsity pattern used in the differentiation scheme is defined by sparsity. By default, sparsity=jac_prototype, meaning that the sparse automatic differentiation scheme should specialize on the sparsity pattern given by the actual sparsity pattern. This can be overridden to say perform partial matrix coloring approximations. Additionally, the color vector for the sparse differentiation directions can be specified directly via colorvec. For more information on how these arguments control the differentiation process, see the aforementioned differentiation library documentations.","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Traits","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Traits","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"SciMLBase.isinplace(f::SciMLBase.AbstractSciMLFunction)","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#AbstractSciMLFunction-API","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"AbstractSciMLFunction API","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Abstract-SciML-Functions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Abstract SciML Functions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"SciMLBase.AbstractDiffEqFunction\nSciMLBase.AbstractODEFunction\nSciMLBase.AbstractSDEFunction\nSciMLBase.AbstractDDEFunction\nSciMLBase.AbstractDAEFunction\nSciMLBase.AbstractRODEFunction\nSciMLBase.AbstractDiscreteFunction\nSciMLBase.AbstractSDDEFunction\nSciMLBase.AbstractNonlinearFunction","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractDiffEqFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDiffEqFunction","text":"abstract type AbstractDiffEqFunction{iip} <: SciMLBase.AbstractSciMLFunction{iip}\n\nBase for types defining differential equation functions.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractODEFunction","text":"abstract type AbstractODEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractSDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractSDEFunction","text":"abstract type AbstractSDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDDEFunction","text":"abstract type AbstractDDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractDAEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDAEFunction","text":"abstract type AbstractDAEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractRODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractRODEFunction","text":"abstract type AbstractRODEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractDiscreteFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDiscreteFunction","text":"abstract type AbstractDiscreteFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractSDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractSDDEFunction","text":"abstract type AbstractSDDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.AbstractNonlinearFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractNonlinearFunction","text":"abstract type AbstractNonlinearFunction{iip} <: SciMLBase.AbstractSciMLFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#Concrete-SciML-Functions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Concrete SciML Functions","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"ODEFunction\nSplitFunction\nDynamicalODEFunction\nDDEFunction\nDynamicalDDEFunction\nDiscreteFunction\nSDEFunction\nSplitSDEFunction\nDynamicalSDEFunction\nRODEFunction\nDAEFunction\nSDDEFunction\nNonlinearFunction\nOptimizationFunction","category":"page"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.ODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.ODEFunction","text":"ODEFunction{iip,F,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,S2,O,TCV} <: AbstractODEFunction{iip}\n\nA representation of an ODE function f, defined by:\n\nM fracdudt = f(upt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nODEFunction{iip,recompile}(f;\n                           mass_matrix=I,\n                           analytic=nothing,\n                           tgrad=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           paramjac = nothing,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p,t) or du = f(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\niip is the the optional boolean for determining whether a given function is written to be used in-place or out-of-place. In-place functions are f!(du,u,p,t) where the return is ignored and the result is expected to be mutated into the value of du. Out-of-place functions are du=f(u,p,t).\n\nNormally this is determined automatically by looking at the method table for f and seeing the maximum number of arguments in available dispatches. For this reason, the constructor ODEFunction(f) generally works (but is type-unstable). However, for type-stability or to enforce correctness, this option is passed via ODEFunction{true}(f).\n\nrecompile: Controlling Compilation and Specialization\n\nThe recompile parameter controls whether the ODEFunction will fully specialize on the typeof(f). This causes recompilation of the solver for each new f function, but gives the maximum compiler information and runtime speed. By default recompile = true. If recompile = false, the ODEFunction uses Any type parameters for each of the functions, allowing for the reuse of compilation caches but adding a dynamic dispatch at the f call sites, potentially leading to runtime regressions.\n\nOverriding the true default is done by passing a second type parameter after iip, for example ODEFunction{true,false}(f) is an in-place function with no recompilation specialization.\n\nFields\n\nThe fields of the ODEFunction type directly match the names of the inputs.\n\nMore Details on Jacobians\n\nThe following example creates an inplace ODEFunction whose jacobian is a Diagonal:\n\nusing LinearAlgebra\nf = (du,u,p,t) -> du .= t .* u\njac = (J,u,p,t) -> (J[1,1] = t; J[2,2] = t; J)\njp = Diagonal(zeros(2))\nfun = ODEFunction(f; jac=jac, jac_prototype=jp)\n\nNote that the integrators will always make a deep copy of fun.jac_prototype, so there's no worry of aliasing.\n\nIn general the jacobian prototype can be anything that has mul! defined, in particular sparse matrices or custom lazy types that support mul!. A special case is when the jac_prototype is a AbstractDiffEqLinearOperator, in which case you do not need to supply jac as it is automatically set to update_coefficients!. Refer to the AbstractSciMLOperators documentation for more information on setting up time/parameter dependent operators.\n\nExamples\n\nDeclaring Explicit Jacobians for ODEs\n\nThe most standard case, declaring a function for a Jacobian is done by overloading the function f(du,u,p,t) with an in-place updating function for the Jacobian: f_jac(J,u,p,t) where the value type is used for dispatch. For example, take the LotkaVolterra model:\n\nfunction f(du,u,p,t)\n  du[1] = 2.0 * u[1] - 1.2 * u[1]*u[2]\n  du[2] = -3 * u[2] + u[1]*u[2]\nend\n\nTo declare the Jacobian we simply add the dispatch:\n\nfunction f_jac(J,u,p,t)\n  J[1,1] = 2.0 - 1.2 * u[2]\n  J[1,2] = -1.2 * u[1]\n  J[2,1] = 1 * u[2]\n  J[2,2] = -3 + u[1]\n  nothing\nend\n\nThen we can supply the Jacobian with our ODE as:\n\nff = ODEFunction(f;jac=f_jac)\n\nand use this in an ODEProblem:\n\nprob = ODEProblem(ff,ones(2),(0.0,10.0))\n\nSymbolically Generating the Functions\n\nSee the modelingtoolkitize function from ModelingToolkit.jl for automatically symbolically generating the Jacobian and more from the  numerically-defined functions.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.SplitFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.SplitFunction","text":"SplitFunction{iip,F1,F2,TMM,C,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractODEFunction{iip}\n\nA representation of a split ODE function f, defined by:\n\nM fracdudt = f_1(upt) + f_2(upt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nGenerally, for ODE integrators the f_1 portion should be considered the \"stiff portion of the model\" with larger time scale separation, while the f_2 portion should be considered the \"non-stiff portion\". This interpretation is directly used in integrators like IMEX (implicit-explicit integrators) and exponential integrators.\n\nConstructor\n\nSplitFunction{iip,recompile}(f1,f2;\n                             mass_matrix=I,\n                             analytic=nothing,\n                             tgrad=nothing,\n                             jac=nothing,\n                             jvp=nothing,\n                             vjp=nothing,\n                             jac_prototype=nothing,\n                             sparsity=jac_prototype,\n                             paramjac = nothing,\n                             syms = nothing,\n                             indepsym = nothing,\n                             colorvec = nothing)\n\nNote that only the functions f_i themselves are required. These functions should be given as f_i!(du,u,p,t) or du = f_i(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f_1(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdf_1du\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdf_1du v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdf_1du^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdf_1dp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\nNote on the Derivative Definition\n\nThe derivatives, such as the Jacobian, are only defined on the f1 portion of the split ODE. This is used to treat the f1 implicit while keeping the f2 portion explicit.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the SplitFunction type directly match the names of the inputs.\n\nSymbolically Generating the Functions\n\nSee the modelingtoolkitize function from ModelingToolkit.jl for automatically symbolically generating the Jacobian and more from the  numerically-defined functions. See ModelingToolkit.SplitODEProblem for information on generating the SplitFunction from this symbolic engine.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DynamicalODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DynamicalODEFunction","text":"DynamicalODEFunction{iip,F1,F2,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractODEFunction{iip}\n\nA representation of an ODE function f, defined by:\n\nM fracdudt = f(upt)\n\nas a partitioned ODE:\n\nM_1 fracdudt = f_1(upt)\nM_2 fracdudt = f_2(upt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDynamicalODEFunction{iip,recompile}(f1,f2;\n                                    mass_matrix=I,\n                                    analytic=nothing,\n                                    tgrad=nothing,\n                                    jac=nothing,\n                                    jvp=nothing,\n                                    vjp=nothing,\n                                    jac_prototype=nothing,\n                                    sparsity=jac_prototype,\n                                    paramjac = nothing,\n                                    syms = nothing,\n                                    indepsym = nothing,\n                                    colorvec = nothing)\n\nNote that only the functions f_i themselves are required. These functions should be given as f_i!(du,u,p,t) or du = f_i(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M_i represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/daesolve/. Must be an AbstractArray or an AbstractSciMLOperator. Should be given as a tuple of mass matrices, i.e. `(M1, M_2)` for the mass matrices of equations 1 and 2 respectively.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DynamicalODEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DDEFunction","text":"DDEFunction{iip,F,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractDDEFunction{iip}\n\nA representation of a DDE function f, defined by:\n\nM fracdudt = f(uhpt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDDEFunction{iip,recompile}(f;\n                 mass_matrix=I,\n                 analytic=nothing,\n                 tgrad=nothing,\n                 jac=nothing,\n                 jvp=nothing,\n                 vjp=nothing,\n                 jac_prototype=nothing,\n                 sparsity=jac_prototype,\n                 paramjac = nothing,\n                 syms = nothing,\n                 indepsym = nothing,\n                 colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,h,p,t) or du = f(u,h,p,t). See the section on iip for more details on in-place vs out-of-place handling. The histroy function h acts as an interpolator over time, i.e. h(t) with options matching the solution interface, i.e. h(t; save_idxs = 2).\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,h,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,h,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,h,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,h,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,h,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DynamicalDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DynamicalDDEFunction","text":"DynamicalDDEFunction{iip,F1,F2,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractDDEFunction{iip}\n\nA representation of a DDE function f, defined by:\n\nM fracdudt = f(uhpt)\n\nas a partitioned ODE:\n\nM_1 fracdudt = f_1(uhpt)\nM_2 fracdudt = f_2(uhpt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDynamicalDDEFunction{iip,recompile}(f1,f2;\n                                    mass_matrix=I,\n                                    analytic=nothing,\n                                    tgrad=nothing,\n                                    jac=nothing,\n                                    jvp=nothing,\n                                    vjp=nothing,\n                                    jac_prototype=nothing,\n                                    sparsity=jac_prototype,\n                                    paramjac = nothing,\n                                    syms = nothing,\n                                    indepsym = nothing,\n                                    colorvec = nothing)\n\nNote that only the functions f_i themselves are required. These functions should be given as f_i!(du,u,h,p,t) or du = f_i(u,h,p,t). See the section on iip for more details on in-place vs out-of-place handling. The histroy function h acts as an interpolator over time, i.e. h(t) with options matching the solution interface, i.e. h(t; save_idxs = 2).\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M_i represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/daesolve/. Must be an AbstractArray or an AbstractSciMLOperator. Should be given as a tuple of mass matrices, i.e. `(M1, M_2)` for the mass matrices of equations 1 and 2 respectively.\nanalytic(u0,h,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,h,p,t) or dT=tgrad(u,h,p,t): returns fracpartial f(upt)partial t\njac(J,u,h,p,t) or J=jac(u,h,p,t): returns fracdfdu\njvp(Jv,v,u,h,p,t) or Jv=jvp(v,u,h,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,h,p,t) or Jv=vjp(v,u,h,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,h,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DynamicalDDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DiscreteFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DiscreteFunction","text":"DiscreteFunction{iip,F,Ta,S,O} <: AbstractDiscreteFunction{iip}\n\nA representation of an discrete dynamical system f, defined by:\n\nu_n+1 = f(upt_n+1)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDiscreteFunction{iip,recompile}(f;\n                                analytic=nothing, \n                                syms=nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p,t) or du = f(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DiscreteFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.SDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.SDEFunction","text":"SDEFunction{iip,F,G,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,GG,S,O,TCV} <: AbstractSDEFunction{iip}\n\nA representation of an SDE function f, defined by:\n\nM du = f(upt)dt + g(upt) dW \n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nSDEFunction{iip,recompile}(f,g;\n                           mass_matrix=I,\n                           analytic=nothing,\n                           tgrad=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           ggprime = nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           paramjac = nothing,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p,t) or du = f(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\nggprime(J,u,p,t) or J = ggprime(u,p,t): returns the Milstein derivative  fracdg(upt)du g(upt)\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the ODEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.SplitSDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.SplitSDEFunction","text":"SplitSDEFunction{iip,F1,F2,G,TMM,C,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractSDEFunction{iip}\n\nA representation of a split SDE function f, defined by:\n\nM fracdudt = f_1(upt) + f_2(upt) + g(upt) dW\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nGenerally, for SDE integrators the f_1 portion should be considered the \"stiff portion of the model\" with larger time scale separation, while the f_2 portion should be considered the \"non-stiff portion\". This interpretation is directly used in integrators like IMEX (implicit-explicit integrators) and exponential integrators.\n\nConstructor\n\nSplitSDEFunction{iip,recompile}(f1,f2,g;\n                 mass_matrix=I,\n                 analytic=nothing,\n                 tgrad=nothing,\n                 jac=nothing,\n                 jvp=nothing,\n                 vjp=nothing,\n                 ggprime = nothing,\n                 jac_prototype=nothing,\n                 sparsity=jac_prototype,\n                 paramjac = nothing,\n                 syms = nothing,\n                 indepsym = nothing,\n                 colorvec = nothing)\n\nNote that only the function f itself is required. All of the remaining functions are optional for improving or accelerating the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the SDE function. Can be used to determine that the equation is actually a stochastic differential-algebraic equation (SDAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/sdae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f_1(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdf_1du\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdf_1du v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdf_1du^ast v\nggprime(J,u,p,t) or J = ggprime(u,p,t): returns the Milstein derivative  fracdg(upt)du g(upt)\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdf_1dp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\nNote on the Derivative Definition\n\nThe derivatives, such as the Jacobian, are only defined on the f1 portion of the split ODE. This is used to treat the f1 implicit while keeping the f2 portion explicit.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the SplitSDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DynamicalSDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DynamicalSDEFunction","text":"DynamicalSDEFunction{iip,F1,F2,G,TMM,C,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractSDEFunction{iip}\n\nA representation of an SDE function f and g, defined by:\n\nM du = f(upt) dt + g(upt) dW_t\n\nas a partitioned ODE:\n\nM_1 du = f_1(upt) dt + g(upt) dW_t\nM_2 du = f_2(upt) dt + g(upt) dW_t\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDynamicalSDEFunction{iip,recompile}(f1,f2;\n                                    mass_matrix=I,\n                                    analytic=nothing,\n                                    tgrad=nothing,\n                                    jac=nothing,\n                                    jvp=nothing,\n                                    vjp=nothing,\n                                    ggprime=nothing,\n                                    jac_prototype=nothing,\n                                    sparsity=jac_prototype,\n                                    paramjac = nothing,\n                                    syms = nothing,\n                                    indepsym = nothing,\n                                    colorvec = nothing)\n\nNote that only the functions f_i themselves are required. These functions should be given as f_i!(du,u,p,t) or du = f_i(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M_i represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/daesolve/. Must be an AbstractArray or an AbstractSciMLOperator. Should be given as a tuple of mass matrices, i.e. `(M1, M_2)` for the mass matrices of equations 1 and 2 respectively.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\nggprime(J,u,p,t) or J = ggprime(u,p,t): returns the Milstein derivative  fracdg(upt)du g(upt)\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DynamicalSDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.RODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.RODEFunction","text":"RODEFunction{iip,F,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractRODEFunction{iip}\n\nA representation of an RODE function f, defined by:\n\nM fracdudt = f(uptW)dt\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nRODEFunction{iip,recompile}(f;\n                           mass_matrix=I,\n                           analytic=nothing,\n                           tgrad=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           paramjac = nothing,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,p,t) or du = f(u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the RODEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.DAEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.DAEFunction","text":"DAEFunction{iip,F,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,S,O,TCV} <: AbstractDAEFunction{iip}\n\nA representation of an implicit DAE function f, defined by:\n\n0 = f(fracdudtupt)\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nDAEFunction{iip,recompile}(f;\n                           analytic=nothing,\n                           jac=nothing,\n                           jvp=nothing,\n                           vjp=nothing,\n                           jac_prototype=nothing,\n                           sparsity=jac_prototype,\n                           syms = nothing,\n                           indepsym = nothing,\n                           colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(out,du,u,p,t) or out = f(du,u,p,t). See the section on iip for more details on in-place vs out-of-place handling.\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\njac(J,du,u,p,gamma,t) or J=jac(du,u,p,gamma,t): returns the implicit DAE Jacobian defined as gamma fracdGd(du) + fracdGdu\njvp(Jv,v,du,u,p,gamma,t) or Jv=jvp(v,du,u,p,gamma,t): returns the directional  derivativefracdfdu v\nvjp(Jv,v,du,u,p,gamma,t) or Jv=vjp(v,du,u,p,gamma,t): returns the adjoint  derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DAEFunction type directly match the names of the inputs.\n\nExamples\n\nDeclaring Explicit Jacobians for DAEs\n\nFor fully implicit ODEs (DAEProblems), a slightly different Jacobian function is necessary. For the DAE\n\nG(duupt) = res\n\nThe Jacobian should be given in the form gamma*dG/d(du) + dG/du where gamma is given by the solver. This means that the signature is:\n\nf(J,du,u,p,gamma,t)\n\nFor example, for the equation\n\nfunction testjac(res,du,u,p,t)\n  res[1] = du[1] - 2.0 * u[1] + 1.2 * u[1]*u[2]\n  res[2] = du[2] -3 * u[2] - u[1]*u[2]\nend\n\nwe would define the Jacobian as:\n\nfunction testjac(J,du,u,p,gamma,t)\n  J[1,1] = gamma - 2.0 + 1.2 * u[2]\n  J[1,2] = 1.2 * u[1]\n  J[2,1] = - 1 * u[2]\n  J[2,2] = gamma - 3 - u[1]\n  nothing\nend\n\nSymbolically Generating the Functions\n\nSee the modelingtoolkitize function from ModelingToolkit.jl for automatically symbolically generating the Jacobian and more from the  numerically-defined functions.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.SDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.SDDEFunction","text":"SDDEFunction{iip,F,G,TMM,Ta,Tt,TJ,JVP,VJP,JP,SP,TW,TWt,TPJ,GG,S,O,TCV} <: AbstractSDDEFunction{iip}\n\nA representation of a SDDE function f, defined by:\n\nM du = f(uhpt) dt + g(uhpt) dW_t\n\nand all of its related functions, such as the Jacobian of f, its gradient with respect to time, and more. For all cases, u0 is the initial condition, p are the parameters, and t is the independent variable.\n\nConstructor\n\nSDDEFunction{iip,recompile}(f,g;\n                 mass_matrix=I,\n                 analytic=nothing,\n                 tgrad=nothing,\n                 jac=nothing,\n                 jvp=nothing,\n                 vjp=nothing,\n                 jac_prototype=nothing,\n                 sparsity=jac_prototype,\n                 paramjac = nothing,\n                 syms = nothing,\n                 indepsym = nothing,\n                 colorvec = nothing)\n\nNote that only the function f itself is required. This function should be given as f!(du,u,h,p,t) or du = f(u,h,p,t). See the section on iip for more details on in-place vs out-of-place handling. The histroy function h acts as an interpolator over time, i.e. h(t) with options matching the solution interface, i.e. h(t; save_idxs = 2).\n\nAll of the remaining functions are optional for improving or accelerating  the usage of f. These include:\n\nmass_matrix: the mass matrix M represented in the ODE function. Can be used to determine that the equation is actually a differential-algebraic equation (DAE) if M is singular. Note that in this case special solvers are required, see the DAE solver page for more details: https://diffeq.sciml.ai/stable/solvers/dae_solve/. Must be an AbstractArray or an AbstractSciMLOperator.\nanalytic(u0,p,t): used to pass an analytical solution function for the analytical  solution of the ODE. Generally only used for testing and development of the solvers.\ntgrad(dT,u,h,p,t) or dT=tgrad(u,p,t): returns fracpartial f(upt)partial t\njac(J,u,h,p,t) or J=jac(u,p,t): returns fracdfdu\njvp(Jv,v,h,u,p,t) or Jv=jvp(v,u,p,t): returns the directional derivativefracdfdu v\nvjp(Jv,v,h,u,p,t) or Jv=vjp(v,u,p,t): returns the adjoint derivativefracdfdu^ast v\njac_prototype: a prototype matrix matching the type that matches the Jacobian. For example, if the Jacobian is tridiagonal, then an appropriately sized Tridiagonal matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Jacobian. The default is nothing, which means a dense Jacobian.\nparamjac(pJ,h,u,p,t): returns the parameter Jacobian fracdfdp.\nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u0 = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nindepsym: the canonical naming for the independent variable. Defaults to nothing, which internally uses t as the representation in any plots.\ncolorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the jac_prototype. This specializes the Jacobian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the DDEFunction type directly match the names of the inputs.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/SciMLFunctions/#SciMLBase.OptimizationFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.OptimizationFunction","text":"OptimizationFunction{iip,AD,F,G,H,HV,C,CJ,CH,HP,CJP,CHP,S,HCV,CJCV,CHCV} <: AbstractOptimizationFunction{iip}\n\nA representation of an optimization of an objective function f, defined by:\n\nmin_u f(up)\n\nand all of its related functions, such as the gradient of f, its Hessian,  and more. For all cases, u is the state and p are the parameters.\n\nConstructor\n\nOptimizationFunction{iip}(f,adtype::AbstractADType=NoAD();                           grad=nothing,hess=nothing,hv=nothing,                           cons=nothing, consj=nothing,consh=nothing,                           hessprototype=nothing,consjacprototype=nothing,                           conshessprototype = nothing,                           syms = nothing, hesscolorvec = nothing,                           consjaccolorvec = nothing,                           conshesscolorvec = nothing)\n\nadtype: see the section \"Defining Optimization Functions via AD\"\ngrad(G,u,p) or G=grad(u,p): the gradient of f with respect to u\nhess(H,u,p) or H=hess(u,p): the Hessian of f with respect to u\nhv(Hv,u,v,p) or Hv=hv(u,v,p): the Hessian-vector product racd^2 fdu^2 v.\ncons(res,x,p) or res=cons(x,p): the equality constraints vector, where the constraints are satisfied when res = 0.\ncons_j(res,x,p) or res=cons_j(x,p): the Jacobian of the equality constraints.\ncons_h(res,x,p) or res=cons_h(x,p): the Hessian of the equality constratins, provided as and array of Hessians with res[i] being the Hessian with respect to the ith output on cons.\nparamjac(pJ,u,p): returns the parameter Jacobian racdfdp.\nhess_prototype: a prototype matrix matching the type that matches the Hessian. For example, if the Hessian is tridiagonal, then an appropriately sized Hessian matrix can be used as the prototype and integrators will specialize on this structure where possible. Non-structured sparsity patterns should use a SparseMatrixCSC with a correct sparsity pattern for the Hessian. The default is nothing, which means a dense Hessian.\ncons_jac_prototype: a prototype matrix matching the type that matches the constraint Jacobian.  The default is nothing, which means a dense constraint Jacobian.\ncons_hess_prototype: a prototype matrix matching the type that matches the constraint Hessian. This is defined as an array of matrices, where hess[i] is the Hessian w.r.t. the ith output. For example, if the Hessian is sparse, then hess is a Vector{SparseMatrixCSC}. The default is nothing, which means a dense constraint Hessian.  \nsyms: the symbol names for the elements of the equation. This should match u0 in size. For example, if u = [0.0,1.0] and syms = [:x, :y], this will apply a canonical naming to the values, allowing sol[:x] in the solution and automatically naming values in plots.\nhess_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the hess_prototype. This specializes the Hessian construction when using finite differences and automatic differentiation to be computed in an accelerated manner based on the sparsity pattern. Defaults to nothing, which means a color vector will be internally computed on demand when required. The cost of this operation is highly dependent on the sparsity pattern.\ncons_jac_colorvec: a color vector according to the SparseDiffTools.jl definition for the sparsity pattern of the cons_jac_prototype.\ncons_hess_colorvec: an array of color vector according to the SparseDiffTools.jl definition for  the sparsity pattern of the cons_hess_prototype.\n\nDefining Optimization Functions Via AD\n\nWhile using the keyword arguments gives the user control over defining all of the possible functions, the simplest way to handle the generation of an OptimizationFunction is by specifying an AD type. By doing so, this will automatically fill in all of the extra functions. For example,\n\nOptimizationFunction(f,AutoZygote())\n\nwill use Zygote.jl to define all of the necessary functions. Note that if any functions are defined directly, the auto-AD definition does not overwrite the user's choice.\n\nEach of the AD-based constructors are documented separately via their own dispatches.\n\niip: In-Place vs Out-Of-Place\n\nFor more details on this argument, see the ODEFunction documentation.\n\nrecompile: Controlling Compilation and Specialization\n\nFor more details on this argument, see the ODEFunction documentation.\n\nFields\n\nThe fields of the OptimizationFunction type directly match the names of the inputs.\n\n\n\n\n\n","category":"type"},{"location":"copies/LinearSolve/basics/common_solver_opts/#Common-Solver-Options-(Keyword-Arguments-for-Solve)","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"","category":"section"},{"location":"copies/LinearSolve/basics/common_solver_opts/","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"While many algorithms have specific arguments within their constructor, the keyword arguments for solve are common across all of the algorithms in order to give composability. These are also the options taken at init time. The following are the options these algorithms take, along with their defaults.","category":"page"},{"location":"copies/LinearSolve/basics/common_solver_opts/#General-Controls","page":"Common Solver Options (Keyword Arguments for Solve)","title":"General Controls","text":"","category":"section"},{"location":"copies/LinearSolve/basics/common_solver_opts/","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"alias_A: Whether to alias the matrix A or use a copy by default. When true, algorithms like LU-factorization can be faster by reusing the memory via lu!, but care must be taken as the original input will be modified. Default is false.\nalias_b: Whether to alias the matrix b or use a copy by default. When true, algorithms can write and change b upon usage. Care must be taken as the original input will be modified. Default is false.\nverbose: Whether to print extra information. Defaults to false.","category":"page"},{"location":"copies/LinearSolve/basics/common_solver_opts/#Iterative-Solver-Controls","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Iterative Solver Controls","text":"","category":"section"},{"location":"copies/LinearSolve/basics/common_solver_opts/","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"Error controls are not used by all algorithms. Specifically, direct solves always solve completely. Error controls only apply to iterative solvers.","category":"page"},{"location":"copies/LinearSolve/basics/common_solver_opts/","page":"Common Solver Options (Keyword Arguments for Solve)","title":"Common Solver Options (Keyword Arguments for Solve)","text":"abstol: The absolute tolerance. Defaults to √(eps(eltype(A)))\nreltol: The relative tolerance. Defaults to √(eps(eltype(A)))\nmaxiters: The number of iterations allowed. Defaults to length(prob.b)\nPl,Pr: The left and right preconditioners respectively. For more information see the Preconditioners page.","category":"page"},{"location":"copies/LinearSolve/advanced/custom/#Passing-in-a-Custom-Linear-Solver","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"","category":"section"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"Julia users are building a wide variety of applications in the SciML ecosystem, often requiring problem-specific handling of their linear solves. As existing solvers in LinearSolve.jl may not be optimally suited for novel applications, it is essential for the linear solve interface to be easily extendable by users. To that end, the linear solve algorithm LinearSolveFunction() accepts a user-defined function for handling the solve. A user can pass in their custom linear solve function, say my_linsolve, to LinearSolveFunction(). A contrived example of solving a linear system with a custom solver is below.","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"using LinearSolve, LinearAlgebra\n\nfunction my_linsolve(A,b,u,p,newA,Pl,Pr,solverdata;verbose=true, kwargs...)\n    if verbose == true\n        println(\"solving Ax=b\")\n    end\n    u = A \\ b\n    return u\nend\n\nprob = LinearProblem(Diagonal(rand(4)), rand(4))\nalg  = LinearSolveFunction(my_linsolve)\nsol  = solve(prob, alg)","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"The inputs to the function are as follows:","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"A, the linear operator\nb, the right-hand-side\nu, the solution initialized as zero(b),\np, a set of parameters\nnewA, a Bool which is true if A has been modified since last solve\nPl, left-preconditioner\nPr, right-preconditioner\nsolverdata, solver cache set to nothing if solver hasn't been initialized\nkwargs, standard SciML keyword arguments such as verbose, maxiters, abstol, reltol","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"The function my_linsolve must accept the above specified arguments, and return the solution, u. As memory for u is already allocated, the user may choose to modify u in place as follows:","category":"page"},{"location":"copies/LinearSolve/advanced/custom/","page":"Passing in a Custom Linear Solver","title":"Passing in a Custom Linear Solver","text":"function my_linsolve!(A,b,u,p,newA,Pl,Pr,solverdata;verbose=true, kwargs...)\n    if verbose == true\n        println(\"solving Ax=b\")\n    end\n    u .= A \\ b # in place\n    return u\nend\n\nalg  = LinearSolveFunction(my_linsolve!)\nsol  = solve(prob, alg)","category":"page"},{"location":"copies/LinearSolve/advanced/developing/#Developing-New-Linear-Solvers","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"","category":"section"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"Developing new or custom linear solvers for the SciML interface can be done in one of two ways:","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"You can either create a completely new set of dispatches for init and solve.\nYou can extend LinearSolve.jl's internal mechanisms.","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"For developer ease, we highly recommend (2) as that will automatically make the caching API work. Thus this is the documentation for how to do that.","category":"page"},{"location":"copies/LinearSolve/advanced/developing/#Developing-New-Linear-Solvers-with-LinearSolve.jl-Primitives","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers with LinearSolve.jl Primitives","text":"","category":"section"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"Let's create a new wrapper for a simple LU-factorization which uses only the basic machinery. A simplified version is:","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"struct MyLUFactorization{P} <: SciMLBase.AbstractLinearAlgorithm end\r\n\r\ninit_cacheval(alg::MyLUFactorization, A, b, u, Pl, Pr, maxiters, abstol, reltol, verbose) = lu!(convert(AbstractMatrix,A))\r\n\r\nfunction SciMLBase.solve(cache::LinearCache, alg::MyLUFactorization; kwargs...)\r\n    if cache.isfresh\r\n        A = convert(AbstractMatrix,A)\r\n        fact = lu!(A)\r\n        cache = set_cacheval(cache, fact)\r\n    end\r\n    y = ldiv!(cache.u, cache.cacheval, cache.b)\r\n    SciMLBase.build_linear_solution(alg,y,nothing,cache)\r\nend","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"The way this works is as follows. LinearSolve.jl has a LinearCache that everything shares (this is what gives most of the ease of use). However, many algorithms need to cache their own things, and so there's one value cacheval that is for the algorithms to modify. The function:","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"init_cacheval(alg::MyLUFactorization, A, b, u, Pl, Pr, maxiters, abstol, reltol, verbose)","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"is what is called at init time to create the first cacheval. Note that this should match the type of the cache later used in solve as many algorithms, like those in OrdinaryDiffEq.jl, expect type-groundedness in the linear solver definitions. While there are cheaper ways to obtain this type for LU factorizations (specifically, ArrayInterfaceCore.lu_instance(A)), for a demonstration this just performs an LU-factorization to get an LU{T, Matrix{T}} which it puts into the cacheval so its typed for future use.","category":"page"},{"location":"copies/LinearSolve/advanced/developing/","page":"Developing New Linear Solvers","title":"Developing New Linear Solvers","text":"After the init_cacheval, the only thing left to do is to define SciMLBase.solve(cache::LinearCache, alg::MyLUFactorization). Many algorithms may use a lazy matrix-free representation of the operator A. Thus if the algorithm requires a concrete matrix, like LU-factorization does, the algorithm should convert(AbstractMatrix,cache.A). The flag cache.isfresh states whether A has changed since the last solve. Since we only need to factorize when A is new, the factorization part of the algorithm is done in a if cache.isfresh. cache = set_cacheval(cache, fact) puts the new factorization into the cache so it's updated for future solves. Then y = ldiv!(cache.u, cache.cacheval, cache.b) performs the solve and a linear solution is returned via SciMLBase.build_linear_solution(alg,y,nothing,cache).","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#linearsystemsolvers","page":"Linear System Solvers","title":"Linear System Solvers","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"solve(prob::LinearProlem,alg;kwargs)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Solves for Au=b in the problem defined by prob using the algorithm alg. If no algorithm is given, a default algorithm will be chosen.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Recommended-Methods","page":"Linear System Solvers","title":"Recommended Methods","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The default algorithm nothing is good for choosing an algorithm that will work, but one may need to change this to receive more performance or precision. If more precision is necessary, QRFactorization() and SVDFactorization() are the best choices, with SVD being the slowest but most precise.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"For efficiency, RFLUFactorization is the fastest for dense LU-factorizations. For sparse LU-factorizations, KLUFactorization if there is less structure to the sparsity pattern and UMFPACKFactorization if there is more structure. Pardiso.jl's methods are also known to be very efficient sparse linear solvers.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"As sparse matrices get larger, iterative solvers tend to get more efficient than factorization methods if a lower tolerance of the solution is required.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"IterativeSolvers.jl uses a low-rank Q update in its GMRES so it tends to be faster than Krylov.jl for CPU-based arrays, but it's only compatible with CPU-based arrays while Krylov.jl is more general and will support accelerators like CUDA. Krylov.jl works with CPUs and GPUs and tends to be more efficient than other Krylov-based methods.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Finally, a user can pass a custom function for handling the linear solve using LinearSolveFunction() if existing solvers are not optimally suited for their application. The interface is detailed here","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Full-List-of-Methods","page":"Linear System Solvers","title":"Full List of Methods","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/#RecursiveFactorization.jl","page":"Linear System Solvers","title":"RecursiveFactorization.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"RFLUFactorization(): a fast pure Julia LU-factorization implementation using RecursiveFactorization.jl. This is by far the fastest LU-factorization implementation, usually outperforming OpenBLAS and MKL, but generally optimized only for Base Array with Float32, Float64, ComplexF32, and ComplexF64.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Base.LinearAlgebra","page":"Linear System Solvers","title":"Base.LinearAlgebra","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"These overloads tend to work for many array types, such as CuArrays for GPU-accelerated solving, using the overloads provided by the respective packages. Given that this can be customized per-package, details given below describe a subset of important arrays (Matrix, SparseMatrixCSC, CuMatrix, etc.)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"LUFactorization(pivot=LinearAlgebra.RowMaximum()): Julia's built in lu.\nOn dense matrices this uses the current BLAS implementation of the user's computer which by default is OpenBLAS but will use MKL if the user does using MKL in their system.\nOn sparse matrices this will use UMFPACK from SuiteSparse. Note that this will not cache the symbolic factorization.\nOn CuMatrix it will use a CUDA-accelerated LU from CuSolver.\nOn BandedMatrix and BlockBandedMatrix it will use a banded LU.\nQRFactorization(pivot=LinearAlgebra.NoPivot(),blocksize=16): Julia's built in qr.\nOn dense matrices this uses the current BLAS implementation of the user's computer which by default is OpenBLAS but will use MKL if the user does using MKL in their system.\nOn sparse matrices this will use SPQR from SuiteSparse\nOn CuMatrix it will use a CUDA-accelerated QR from CuSolver.\nOn BandedMatrix and BlockBandedMatrix it will use a banded QR.\nSVDFactorization(full=false,alg=LinearAlgebra.DivideAndConquer()): Julia's built in svd.\nOn dense matrices this uses the current BLAS implementation of the user's computer which by default is OpenBLAS but will use MKL if the user does using MKL in their system.\nGenericFactorization(fact_alg): Constructs a linear solver from a generic factorization algorithm fact_alg which complies with the Base.LinearAlgebra factorization API. Quoting from Base:\nIf A is upper or lower triangular (or diagonal), no factorization of A is required and the system is solved with either forward or backward substitution. For non-triangular square matrices, an LU factorization is used. For rectangular A the result is the minimum-norm least squares solution computed by a pivoted QR factorization of A and a rank estimate of A based on the R factor. When A is sparse, a similar polyalgorithm is used. For indefinite matrices, the LDLt factorization does not use pivoting during the numerical factorization and therefore the procedure can fail even for invertible matrices.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#LinearSolve.jl","page":"Linear System Solvers","title":"LinearSolve.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"LinearSolve.jl contains some linear solvers built in.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"SimpleLUFactorization: a simple LU-factorization implementation without BLAS. Fast for small matrices.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#SuiteSparse.jl","page":"Linear System Solvers","title":"SuiteSparse.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"By default, the SuiteSparse.jl are implemented for efficiency by caching the symbolic factorization. I.e. if set_A is used, it is expected that the new A has the same sparsity pattern as the previous A. If this algorithm is to be used in a context where that assumption does not hold, set reuse_symbolic=false.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"KLUFactorization(;reuse_symbolic=true): A fast sparse LU-factorization which specializes on sparsity patterns with \"less structure\".\nUMFPACKFactorization(;reuse_symbolic=true): A fast sparse multithreaded LU-factorization which specializes on sparsity patterns that are more structured.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Pardiso.jl","page":"Linear System Solvers","title":"Pardiso.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"note: Note\nUsing this solver requires adding the package LinearSolvePardiso.jl","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The following algorithms are pre-specified:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"MKLPardisoFactorize(;kwargs...): A sparse factorization method.\nMKLPardisoIterate(;kwargs...): A mixed factorization+iterative method.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Those algorithms are defined via:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"MKLPardisoFactorize(;kwargs...) = PardisoJL(;fact_phase=Pardiso.NUM_FACT,\n                                             solve_phase=Pardiso.SOLVE_ITERATIVE_REFINE,\n                                             kwargs...)\nMKLPardisoIterate(;kwargs...) = PardisoJL(;solve_phase=Pardiso.NUM_FACT_SOLVE_REFINE,\n                                           kwargs...)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The full set of keyword arguments for PardisoJL are:                         ","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Base.@kwdef struct PardisoJL <: SciMLLinearSolveAlgorithm\n    nprocs::Union{Int, Nothing} = nothing\n    solver_type::Union{Int, Pardiso.Solver, Nothing} = nothing\n    matrix_type::Union{Int, Pardiso.MatrixType, Nothing} = nothing\n    fact_phase::Union{Int, Pardiso.Phase, Nothing} = nothing\n    solve_phase::Union{Int, Pardiso.Phase, Nothing} = nothing\n    release_phase::Union{Int, Nothing} = nothing\n    iparm::Union{Vector{Tuple{Int,Int}}, Nothing} = nothing\n    dparm::Union{Vector{Tuple{Int,Int}}, Nothing} = nothing\nend","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#CUDA.jl","page":"Linear System Solvers","title":"CUDA.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"Note that CuArrays are supported by GenericFactorization in the \"normal\" way. The following are non-standard GPU factorization routines.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"note: Note\nUsing this solver requires adding the package LinearSolveCUDA.jl","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"CudaOffloadFactorization(): An offloading technique used to GPU-accelerate CPU-based computations. Requires a sufficiently large A to overcome the data transfer costs.","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#IterativeSolvers.jl","page":"Linear System Solvers","title":"IterativeSolvers.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"IterativeSolversJL_CG(args...;kwargs...): A generic CG implementation\nIterativeSolversJL_GMRES(args...;kwargs...): A generic GMRES implementation\nIterativeSolversJL_BICGSTAB(args...;kwargs...): A generic BICGSTAB implementation\nIterativeSolversJL_MINRES(args...;kwargs...): A generic MINRES implementation","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The general algorithm is:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"IterativeSolversJL(args...;\n                   generate_iterator = IterativeSolvers.gmres_iterable!,\n                   Pl=nothing, Pr=nothing,\n                   gmres_restart=0, kwargs...)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#Krylov.jl","page":"Linear System Solvers","title":"Krylov.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"KrylovJL_CG(args...;kwargs...): A generic CG implementation\nKrylovJL_GMRES(args...;kwargs...): A generic GMRES implementation\nKrylovJL_BICGSTAB(args...;kwargs...): A generic BICGSTAB implementation\nKrylovJL_MINRES(args...;kwargs...): A generic MINRES implementation","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The general algorithm is:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"KrylovJL(args...; KrylovAlg = Krylov.gmres!,\n                  Pl=nothing, Pr=nothing,\n                  gmres_restart=0, window=0,\n                  kwargs...)","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/#KrylovKit.jl","page":"Linear System Solvers","title":"KrylovKit.jl","text":"","category":"section"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"KrylovKitJL_CG(args...;kwargs...): A generic CG implementation\nKrylovKitJL_GMRES(args...;kwargs...): A generic GMRES implementation","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"The general algorithm is:","category":"page"},{"location":"copies/LinearSolve/solvers/solvers/","page":"Linear System Solvers","title":"Linear System Solvers","text":"function KrylovKitJL(args...;\n                     KrylovAlg = KrylovKit.GMRES, gmres_restart = 0,\n                     kwargs...)","category":"page"},{"location":"copies/LinearSolve/basics/CachingAPI/#Caching-Interface-API-Functions","page":"Caching Interface API Functions","title":"Caching Interface API Functions","text":"","category":"section"},{"location":"copies/LinearSolve/basics/CachingAPI/","page":"Caching Interface API Functions","title":"Caching Interface API Functions","text":"LinearSolve.set_A\r\nLinearSolve.set_b\r\nLinearSolve.set_u\r\nLinearSolve.set_p\r\nLinearSolve.set_prec","category":"page"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_A","page":"Caching Interface API Functions","title":"LinearSolve.set_A","text":"set_A(cache, A)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_b","page":"Caching Interface API Functions","title":"LinearSolve.set_b","text":"set_b(cache, b)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_u","page":"Caching Interface API Functions","title":"LinearSolve.set_u","text":"set_u(cache, u)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_p","page":"Caching Interface API Functions","title":"LinearSolve.set_p","text":"set_p(cache, p)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/basics/CachingAPI/#LinearSolve.set_prec","page":"Caching Interface API Functions","title":"LinearSolve.set_prec","text":"set_prec(cache, Pl, Pr)\n\n\n\n\n\n\n","category":"function"},{"location":"copies/LinearSolve/tutorials/linear/#Solving-Linear-Systems-in-Julia","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"","category":"section"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"A linear system Au=b is specified by defining an AbstractMatrix A, or by providing a matrix-free operator for performing A*x operations via the function A(u,p,t) out-of-place and A(du,u,p,t) for in-place. For the sake of simplicity, this tutorial will only showcase concrete matrices.","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"The following defines a matrix and a LinearProblem which is subsequently solved by the default linear solver.","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"using LinearSolve\n\nA = rand(4,4)\nb = rand(4)\nprob = LinearProblem(A, b)\nsol = solve(prob)\nsol.u\n\n#=\n4-element Vector{Float64}:\n  0.3784870087078603\n  0.07275749718047864\n  0.6612816064734302\n -0.10598367531463938\n=#","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"Note that solve(prob) is equivalent to solve(prob,nothing) where nothing denotes the choice of the default linear solver. This is equivalent to the Julia built-in A\\b, where the solution is recovered via sol.u. The power of this package comes into play when changing the algorithms. For example, IterativeSolvers.jl has some nice methods like GMRES which can be faster in some cases. With LinearSolve.jl, there is one interface and changing linear solvers is simply the switch of the algorithm choice:","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"sol = solve(prob,IterativeSolversJL_GMRES())\n\n#=\nu: 4-element Vector{Float64}:\n  0.37848700870786\n  0.07275749718047908\n  0.6612816064734302\n -0.10598367531463923\n=#","category":"page"},{"location":"copies/LinearSolve/tutorials/linear/","page":"Solving Linear Systems in Julia","title":"Solving Linear Systems in Julia","text":"Thus a package which uses LinearSolve.jl simply needs to allow the user to pass in an algorithm struct and all wrapped linear solvers are immediately available as tweaks to the general algorithm.","category":"page"},{"location":"copies/NonlinearSolve/#NonlinearSolve.jl:-High-Performance-Unified-Nonlinear-Solvers","page":"Home","title":"NonlinearSolve.jl: High-Performance Unified Nonlinear Solvers","text":"","category":"section"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"NonlinearSolve.jl is a unified interface for the nonlinear solving packages of Julia. It includes its own high-performance nonlinear solvers which include the ability to swap out to fast direct and iterative linear solvers, along with the ability to use sparse automatic differentiation for Jacobian construction and Jacobian-vector products. It interfaces with other packages of the Julia ecosystem to make it easy to test alternative solver packages and pass small types to control algorithm swapping. It also interfaces with the ModelingToolkit.jl world of symbolic modeling to allow for automatically generating high-performance code.","category":"page"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"Performance is key: the current methods are made to be highly performant on scalar and statically sized small problems, with options for large-scale systems. If you run into any performance issues, please file an issue. Note that this package is distinct from SciMLNLSolve.jl. Consult the NonlinearSystemSolvers page for information on how to import solvers from different packages.","category":"page"},{"location":"copies/NonlinearSolve/#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"To install NonlinearSolve.jl, use the Julia package manager:","category":"page"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"NonlinearSolve\")","category":"page"},{"location":"copies/NonlinearSolve/#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to ModelingToolkit.\nThere are a few community forums:\nthe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\non the Julia Discourse forums (look for the modelingtoolkit tag\nsee also SciML Community page","category":"page"},{"location":"copies/NonlinearSolve/#Roadmap","page":"Home","title":"Roadmap","text":"","category":"section"},{"location":"copies/NonlinearSolve/","page":"Home","title":"Home","text":"The current algorithms should support automatic differentiation, though improved adjoint overloads are planned to be added in the current update (which will make use of the f(u,p) form). Future updates will include standard methods for larger scale nonlinear solving like Newton-Krylov methods.","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/#Bracketing-Solvers","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"solve(prob::NonlinearProblem,alg;kwargs)","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"Solves for f(u)=0 in the problem defined by prob using the algorithm alg. If no algorithm is given, a default algorithm will be chosen.","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"This page is solely focused on the bracketing methods for scalar nonlinear equations.","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/#Recommended-Methods","page":"Bracketing Solvers","title":"Recommended Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"Falsi() can have a faster convergence and is discretely differentiable, but is less stable than Bisection.","category":"page"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/#Full-List-of-Methods","page":"Bracketing Solvers","title":"Full List of Methods","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/#NonlinearSolve.jl","page":"Bracketing Solvers","title":"NonlinearSolve.jl","text":"","category":"section"},{"location":"copies/NonlinearSolve/solvers/BracketingSolvers/","page":"Bracketing Solvers","title":"Bracketing Solvers","text":"Falsi: A non-allocating regula falsi method\nBisection: A common bisection method","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/#sensealg","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"Automatic differentiation control is done through the sensealg keyword argument. Hooks exist in the high level interfaces for solve which shuttle the definitions of automatic differentiation overloads to dispatches defined in DiffEqSensitivity.jl (should be renamed SciMLSensitivity.jl as it expands). This is done by first entering a top-level solve definition, for example:","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"function solve(prob::DEProblem, args...; sensealg=nothing,\n  u0=nothing, p=nothing, kwargs...)\n  u0 = u0 !== nothing ? u0 : prob.u0\n  p = p !== nothing ? p : prob.p\n  if sensealg === nothing && haskey(prob.kwargs, :sensealg)\n    sensealg = prob.kwargs[:sensealg]\n  end\n  solve_up(prob, sensealg, u0, p, args...; kwargs...)\nend","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"solve_up then drops down the differentiable arguments as positional arguments, which is required for the ChainRules.jl interface. Then the ChainRules overloads are written on the solve_up calls, like:","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"function ChainRulesCore.frule(::typeof(solve_up), prob,\n  sensealg::Union{Nothing,AbstractSensitivityAlgorithm},\n  u0, p, args...;\n  kwargs...)\n  _solve_forward(prob, sensealg, u0, p, args...; kwargs...)\nend\n\nfunction ChainRulesCore.rrule(::typeof(solve_up), prob::SciMLBase.DEProblem,\n  sensealg::Union{Nothing,AbstractSensitivityAlgorithm},\n  u0, p, args...;\n  kwargs...)\n  _solve_adjoint(prob, sensealg, u0, p, args...; kwargs...)\nend","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"Default definitions then exist to throw an informative error if the sensitivity mechanism is not added:","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"function _concrete_solve_adjoint(args...; kwargs...)\n  error(\"No adjoint rules exist. Check that you added `using DiffEqSensitivity`\")\nend\n\nfunction _concrete_solve_forward(args...; kwargs...)\n  error(\"No sensitivity rules exist. Check that you added `using DiffEqSensitivity`\")\nend","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"The sensitivity mechanism is kept in a separate package because of the high dependency and load time cost introduced by the automatic differentiation libraries. Different choices of automatic differentiation are then selected by the sensealg keyword argument in solve, which is made into a positional argument in the _solve_adjoint and other functions in order to allow dispatch.","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/#SensitivityADPassThrough","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"SensitivityADPassThrough","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"The special sensitivity algorithm SensitivityADPassThrough is used to ignore the internal sensitivity dispatches and instead do automatic differentiation directly through the solver. Generally this sensealg is only used internally.","category":"page"},{"location":"copies/SciMLBase/interfaces/Differentiation/#Note-about-ForwardDiff","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Note about ForwardDiff","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Differentiation/","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"ForwardDiff does not use ChainRules.jl and thus it completely ignores the special handling.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLProblems","page":"SciMLProblems","title":"SciMLProblems","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"The cornerstone of the SciML common interface is the problem type definition. These definitions are the encoding of mathematical problems into a numerically computable form. ","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Note-About-Symbolics-and-ModelingToolkit","page":"SciMLProblems","title":"Note About Symbolics and ModelingToolkit","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"The symbolic analog to the problem interface is the ModelingToolkit AbstractSystem. For example, ODESystem is the symbolic analog to ODEProblem. Each of these system types have a method for constructing the associated problem and function types.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Definition-of-the-SciMLProblem-Interface","page":"SciMLProblems","title":"Definition of the SciMLProblem Interface","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"The following standard principles should be adhered to across all  SciMLProblem instantiations.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#In-place-Specification","page":"SciMLProblems","title":"In-place Specification","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"Each SciMLProblem type can be called with an \"is inplace\" (iip) choice. For example:","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"ODEProblem(f,u0,tspan,p)\nODEProblem{iip}(f,u0,tspan,p)","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"which is a boolean for whether the function is in the inplace form (mutating to change the first value). This is automatically determined using the methods table but note that for full type-inferrability of the SciMLProblem this iip-ness should be specified.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"Additionally, the functions are fully specialized to reduce the runtimes. If one would instead like to not specialize on the functions to reduce compile time, then one can set recompile to false.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Default-Parameters","page":"SciMLProblems","title":"Default Parameters","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"By default, SciMLProblem types use the SciMLBase.NullParameters() singleton to define the absence of parameters by default. The reason is because this throws an informative error if the parameter is used or accessed within the user's function, for example, p[1] will throw an informative error about forgetting to pass parameters.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Keyword-Argument-Splatting","page":"SciMLProblems","title":"Keyword Argument Splatting","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"All SciMLProblem types allow for passing keyword arguments that would get forwarded to the solver. The reason for this is that in many cases, like in EnsembleProblem usage, a SciMLProblem might be associated with some solver configuration, such as a callback or tolerance. Thus, for flexibility the extra keyword arguments to the SciMLProblem are carried to the solver.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#problem_type","page":"SciMLProblems","title":"problem_type","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"SciMLProblem types include a non-public API definition of problem_type which holds a trait type corresponding to the way the SciMLProblem was constructed. For example, if a SecondOrderODEProblem constructor is used, the returned problem is simply a ODEProblem for interopability with any ODEProblem algorithm. However, in this case the problem_type will be populated with the SecondOrderODEProblem type, indicating the original definition and extra structure.","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#Remake","page":"SciMLProblems","title":"Remake","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"remake","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.remake","page":"SciMLProblems","title":"SciMLBase.remake","text":"remake(thing; <keyword arguments>)\n\nRe-construct thing with new field values specified by the keyword arguments.\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Problems/#Problem-Traits","page":"SciMLProblems","title":"Problem Traits","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"SciMLBase.isinplace(prob::SciMLBase.DEProblem)\nSciMLBase.is_diagonal_noise","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.isinplace-Tuple{SciMLBase.DEProblem}","page":"SciMLProblems","title":"SciMLBase.isinplace","text":"isinplace(prob::SciMLProblem)\n\nDetermine whether the function of the given problem operates in place or not.\n\n\n\n\n\n","category":"method"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.is_diagonal_noise","page":"SciMLProblems","title":"SciMLBase.is_diagonal_noise","text":"is_diagonal_noise(prob::SciMLProblem)\n\n\n\n\n\n","category":"function"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLProblem-API","page":"SciMLProblems","title":"SciMLProblem API","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/#Abstract-SciMLProblems","page":"SciMLProblems","title":"Abstract SciMLProblems","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"SciMLBase.SciMLProblem\nSciMLBase.DEProblem\nSciMLBase.AbstractLinearProblem\nSciMLBase.AbstractNonlinearProblem\nSciMLBase.AbstractQuadratureProblem\nSciMLBase.AbstractOptimizationProblem\nSciMLBase.AbstractNoiseProblem\nSciMLBase.AbstractODEProblem\nSciMLBase.AbstractDiscreteProblem\nSciMLBase.AbstractAnalyticalProblem\nSciMLBase.AbstractRODEProblem\nSciMLBase.AbstractSDEProblem\nSciMLBase.AbstractDAEProblem\nSciMLBase.AbstractDDEProblem\nSciMLBase.AbstractConstantLagDDEProblem\nSciMLBase.AbstractSecondOrderODEProblem\nSciMLBase.AbstractBVProblem\nSciMLBase.AbstractJumpProblem\nSciMLBase.AbstractSDDEProblem\nSciMLBase.AbstractConstantLagSDDEProblem\nSciMLBase.AbstractPDEProblem","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SciMLProblem","page":"SciMLProblems","title":"SciMLBase.SciMLProblem","text":"abstract type SciMLProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DEProblem","page":"SciMLProblems","title":"SciMLBase.DEProblem","text":"abstract type DEProblem <: SciMLBase.SciMLProblem\n\nBase type for all DifferentialEquations.jl problems. Concrete subtypes of DEProblem contain the necessary information to fully define a differential equation of the corresponding type.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractLinearProblem","page":"SciMLProblems","title":"SciMLBase.AbstractLinearProblem","text":"abstract type AbstractLinearProblem{bType, isinplace} <: SciMLBase.SciMLProblem\n\nBase for types which define linear systems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractNonlinearProblem","page":"SciMLProblems","title":"SciMLBase.AbstractNonlinearProblem","text":"abstract type AbstractNonlinearProblem{uType, isinplace} <: SciMLBase.DEProblem\n\nBase for types which define nonlinear solve problems (f(u)=0).\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractOptimizationProblem","page":"SciMLProblems","title":"SciMLBase.AbstractOptimizationProblem","text":"abstract type AbstractOptimizationProblem{isinplace} <: SciMLBase.SciMLProblem\n\nBase for types which define equations for optimization.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractNoiseProblem","page":"SciMLProblems","title":"SciMLBase.AbstractNoiseProblem","text":"abstract type AbstractNoiseProblem <: SciMLBase.DEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractODEProblem","text":"abstract type AbstractODEProblem{uType, tType, isinplace} <: SciMLBase.DEProblem\n\nBase for types which define ODE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractDiscreteProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDiscreteProblem","text":"abstract type AbstractDiscreteProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\nBase for types which define discrete problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractAnalyticalProblem","page":"SciMLProblems","title":"SciMLBase.AbstractAnalyticalProblem","text":"abstract type AbstractAnalyticalProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractRODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractRODEProblem","text":"abstract type AbstractRODEProblem{uType, tType, isinplace, ND} <: SciMLBase.DEProblem\n\nBase for types which define RODE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractSDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSDEProblem","text":"abstract type AbstractSDEProblem{uType, tType, isinplace, ND} <: SciMLBase.AbstractRODEProblem{uType, tType, isinplace, ND}\n\nBase for types which define SDE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractDAEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDAEProblem","text":"abstract type AbstractDAEProblem{uType, duType, tType, isinplace} <: SciMLBase.DEProblem\n\nBase for types which define DAE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDDEProblem","text":"abstract type AbstractDDEProblem{uType, tType, lType, isinplace} <: SciMLBase.DEProblem\n\nBase for types which define DDE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractConstantLagDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractConstantLagDDEProblem","text":"abstract type AbstractConstantLagDDEProblem{uType, tType, lType, isinplace} <: SciMLBase.AbstractDDEProblem{uType, tType, lType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractSecondOrderODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSecondOrderODEProblem","text":"abstract type AbstractSecondOrderODEProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractBVProblem","page":"SciMLProblems","title":"SciMLBase.AbstractBVProblem","text":"abstract type AbstractBVProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\nBase for types which define BVP problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractJumpProblem","page":"SciMLProblems","title":"SciMLBase.AbstractJumpProblem","text":"abstract type AbstractJumpProblem{P, J} <: SciMLBase.DEProblem\n\nBase for types which define jump problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractSDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSDDEProblem","text":"abstract type AbstractSDDEProblem{uType, tType, lType, isinplace, ND} <: SciMLBase.DEProblem\n\nBase for types which define SDDE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractConstantLagSDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractConstantLagSDDEProblem","text":"abstract type AbstractConstantLagSDDEProblem{uType, tType, lType, isinplace, ND} <: SciMLBase.AbstractSDDEProblem{uType, tType, lType, isinplace, ND}\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.AbstractPDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractPDEProblem","text":"abstract type AbstractPDEProblem <: SciMLBase.DEProblem\n\nBase for types which define PDE problems.\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#Concrete-SciMLProblems","page":"SciMLProblems","title":"Concrete SciMLProblems","text":"","category":"section"},{"location":"copies/SciMLBase/interfaces/Problems/","page":"SciMLProblems","title":"SciMLProblems","text":"LinearProblem\nNonlinearProblem\nQuadratureProblem\nOptimizationProblem\nBVProblem\nDAEProblem\nDDEProblem\nDynamicalDDEProblem\nSecondOrderDDEProblem\nDiscreteProblem\nNoiseProblem\nODEProblem\nDynamicalODEProblem\nSecondOrderODEProblem\nSplitODEProblem\nIncrementingODEProblem\nRODEProblem\nSDDEProblem\nSplitSDEProblem\nDynamicalSDEProblem\nSteadyStateProblem\nPDEProblem","category":"page"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.OptimizationProblem","page":"SciMLProblems","title":"SciMLBase.OptimizationProblem","text":"Defines a optimization problem. Documentation Page: https://galacticoptim.sciml.ai/dev/API/optimization_problem/\n\nMathematical Specification of a Optimization Problem\n\nTo define an Optimization Problem, you simply need to give the function f which defines the cost function to minimize:\n\nmin_u f(up) = 0\n\nu₀ is an initial guess of the minimum. f should be specified as f(u,p) and u₀ should be an AbstractArray (or number) whose geometry matches the  desired geometry of u. Note that we are not limited to numbers or vectors  for u₀; one is allowed to provide u₀ as arbitrary matrices /  higher-dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nOptimizationProblem{iip}(f, x, p = SciMLBase.NullParameters(),;\n                        lb = nothing,\n                        ub = nothing,\n                        lcons = nothing,\n                        ucons = nothing,\n                        sense = nothing,\n                        kwargs...)\n\nisinplace optionally sets whether the function is in-place or not. This is determined automatically, but not inferred. Note that for OptimizationProblem, in-place only refers to the Jacobian and Hessian functions, and thus by default if the OptimizationFunction is not defined directly then iip = true is done by default.\n\nParameters are optional, and if not given, then a NullParameters() singleton will be used, which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nlb and ub are the upper and lower bounds for box constraints on the optimization. They should be an AbstractArray matching the geometry of u, where (lb[I],ub[I]) is the box constraint (lower and upper bounds) for u[I].\n\nlcons and ucons are the upper and lower bounds for equality constraints on the optimization. They should be an AbstractArray matching the geometry of u, where (lcons[I],ucons[I]) is the constraint (lower and upper bounds) for cons[I].\n\nIf f is a standard Julia function, it is automatically converted into an OptimizationFunction with NoAD(), i.e., no automatic generation of the derivative functions.\n\nAny extra keyword arguments are captured to be sent to the optimizers.\n\nFields\n\nf: The function in the problem.\nu0: The initial guess for the optima.\np: The parameters for the problem. Defaults to NullParameters.\nlb: the lower bounds for the optimization of u.\nub: the upper bounds for the optimization of u.\nlcons:\nucons:\nsense:\nkwargs: The keyword arguments passed on to the solvers.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.BVProblem","page":"SciMLProblems","title":"SciMLBase.BVProblem","text":"Defines an BVP problem. Documentation Page: https://diffeq.sciml.ai/stable/types/bvp_types/\n\nMathematical Specification of a BVP Problem\n\nTo define a BVP Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\nfracdudt = f(upt)\n\nalong with an implicit function bc! which defines the residual equation, where\n\nbc(upt) = 0\n\nis the manifold on which the solution must live. A common form for this is the two-point BVProblem where the manifold defines the solution at two points:\n\nu(t_0) = a\nu(t_f) = b\n\nProblem Type\n\nConstructors\n\nTwoPointBVProblem{isinplace}(f,bc!,u0,tspan,p=NullParameters();kwargs...)\nBVProblem{isinplace}(f,bc!,u0,tspan,p=NullParameters();kwargs...)\n\nFor any BVP problem type, bc! is the inplace function:\n\nbc!(residual, u, p, t)\n\nwhere residual computed from the current u. u is an array of solution values where u[i] is at time t[i], while p are the parameters. For a TwoPointBVProblem, t = tspan. For the more general BVProblem, u can be all of the internal time points, and for shooting type methods u=sol the ODE solution. Note that all features of the ODESolution are present in this form. In both cases, the size of the residual matches the size of the initial condition.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFields\n\nf: The function for the ODE.\nbc: The boundary condition function.\nu0: The initial condition. Either the initial condition for the ODE as an initial value problem, or a Vector of values for u(t_i) for collocation methods\ntspan: The timespan for the problem.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DAEProblem","page":"SciMLProblems","title":"SciMLBase.DAEProblem","text":"Defines an implicit ordinary differential equation (ODE) or  differential-algebraic equation (DAE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/dae_types/\n\nMathematical Specification of an DAE Problem\n\nTo define a DAE Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\n0 = f(duupt)\n\nf should be specified as f(du,u,p,t) (or in-place as f(resid,du,u,p,t)). Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nProblem Type\n\nConstructors\n\nDAEProblem(f::DAEFunction,du0,u0,tspan,p=NullParameters();kwargs...)\nDAEProblem{isinplace}(f,du0,u0,tspan,p=NullParameters();kwargs...) : Defines the DAE with the specified functions. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The function in the ODE.\ndu0: The initial condition for the derivative.\nu0: The initial condition.\ntspan: The timespan for the problem.\ndifferential_vars: A logical array which declares which variables are the differential (non algebraic) vars (i.e. du' is in the equations for this variable). Defaults to nothing. Some solvers may require this be set if an initial condition needs to be determined.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\nExample Problems\n\nExamples problems can be found in DiffEqProblemLibrary.jl.\n\nTo use a sample problem, such as prob_dae_resrob, you can do something like:\n\n#] add DiffEqProblemLibrary\nusing DiffEqProblemLibrary.DAEProblemLibrary\n# load problems\nDAEProblemLibrary.importdaeproblems()\nprob = DAEProblemLibrary.prob_dae_resrob\nsol = solve(prob,IDA())\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DDEProblem","page":"SciMLProblems","title":"SciMLBase.DDEProblem","text":"Defines a delay differential equation (DDE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/dde_types/\n\nMathematical Specification of a DDE Problem\n\nTo define a DDE Problem, you simply need to give the function f, the initial condition u_0 at time point t_0, and the history function h which together define a DDE:\n\nfracdudt = f(uhpt) qquad (t geq t_0)\n\nu(t_0) = u_0\n\nu(t) = h(t) qquad (t  t_0)\n\nf should be specified as f(u, h, p, t) (or in-place as f(du, u, h, p, t)), u_0 should be an AbstractArray (or number) whose geometry matches the desired geometry of u, and h should be specified as described below. The history function h is accessed for all delayed values. Note that we are not limited to numbers or vectors for u_0; one is allowed to provide u_0 as arbitrary matrices / higher dimension tensors as well.\n\nFunctional Forms of the History Function\n\nThe history function h can be called in the following ways:\n\nh(p, t): out-of-place calculation\nh(out, p, t): in-place calculation\nh(p, t, deriv::Type{Val{i}}): out-of-place calculation of the ith derivative\nh(out, p, t, deriv::Type{Val{i}}): in-place calculation of the ith derivative\nh(args...; idxs): calculation of h(args...) for indices idxs\n\nNote that a dispatch for the supplied history function of matching form is required for whichever function forms are used in the user derivative function f.\n\nDeclaring Lags\n\nLags are declared separately from their use. One can use any lag by simply using the interpolant of h at that point. However, one should use caution in order to achieve the best accuracy. When lags are declared, the solvers can more efficiently be more accurate and thus this is recommended.\n\nNeutral and Retarded Delay Differential Equations\n\nNote that the history function specification can be used to specify general retarded arguments, i.e. h(p,α(u,t)). Neutral delay differential equations can be specified by using the deriv value in the history interpolation. For example, h(p,t-τ, Val{1}) returns the first derivative of the history values at time t-τ.\n\nNote that algebraic equations can be specified by using a singular mass matrix.\n\nProblem Type\n\nConstructors\n\nDDEProblem(f[, u0], h, tspan[, p]; <keyword arguments>)\nDDEProblem{isinplace}(f[, u0], h, tspan[, p]; <keyword arguments>)\n\nParameter isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nArguments\n\nf: The function in the DDE.\nu0: The initial condition. Defaults to the value h(p, first(tspan)) of the history function evaluated at the initial time point.\nh: The history function for the DDE before t0.\ntspan: The timespan for the problem.\np: The parameters with which function f is called. Defaults to NullParameters.\nconstant_lags: A collection of constant lags used by the history function h. Defaults to ().\ndependent_lags A tuple of functions (u, p, t) -> lag for the state-dependent lags used by the history function h. Defaults to ().\nneutral: If the DDE is neutral, i.e., if delays appear in derivative terms.\norder_discontinuity_t0: The order of the discontinuity at the initial time point. Defaults to 0 if an initial condition u0 is provided. Otherwise it is forced to be greater or equal than 1.\nkwargs: The keyword arguments passed onto the solves.\n\nDynamical Delay Differential Equations\n\nMuch like Dynamical ODEs, a Dynamical DDE is a Partitioned DDE of the form:\n\nfracdvdt = f_1(uth) \nfracdudt = f_2(vh) \n\nConstructors\n\nDynamicalDDEProblem(f1, f2[, v0, u0], h, tspan[, p]; <keyword arguments>)\nDynamicalDDEProblem{isinplace}(f1, f2[, v0, u0], h, tspan[, p]; <keyword arguments>)\n\nParameter isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nArguments\n\nf: The function in the DDE.\nv0 and u0: The initial condition. Defaults to the values h(p, first(tspan))... of the history function evaluated at the initial time point.\nh: The history function for the DDE before t0. Must return an object with the indices 1 and 2, with the values of v and u respectively.\ntspan: The timespan for the problem.\np: The parameters with which function f is called. Defaults to NullParameters.\nconstant_lags: A collection of constant lags used by the history function h. Defaults to ().\ndependent_lags A tuple of functions (v, u, p, t) -> lag for the state-dependent lags used by the history function h. Defaults to ().\nneutral: If the DDE is neutral, i.e., if delays appear in derivative terms.\norder_discontinuity_t0: The order of the discontinuity at the initial time point. Defaults to 0 if an initial condition u0 is provided. Otherwise it is forced to be greater or equal than 1.\nkwargs: The keyword arguments passed onto the solves.\n\nThe for dynamical and second order DDEs, the history function will return an object with the indicies 1 and 2 defined, where h(p, t_prev)[1] is the value of f_2(v u h p t_mathrmprev) and h(p, t_prev)[2] is the value of f_1(v u h p t_mathrmprev) (this is for consistency with the ordering of the intitial conditions in the constructor). The supplied history function must also return such a 2-index object, which can be accomplished with a tuple (v,u) or vector [v,u].\n\n2nd Order Delay Differential Equations\n\nTo define a 2nd Order DDE Problem, you simply need to give the function f and the initial condition u_0 which define an DDE:\n\nu = f(uuhpt)\n\nf should be specified as f(du,u,p,t) (or in-place as f(ddu,du,u,p,t)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nFrom this form, a dynamical ODE:\n\nv = f(vuhpt) \nu = v \n\nConstructors\n\nSecondOrderDDEProblem(f, [, du0, u0], h, tspan[, p]; <keyword arguments>)\nSecondOrderDDEProblem{isinplace}(f, [, du0, u0], h, tspan[, p]; <keyword arguments>)\n\nParameter isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nArguments\n\nf: The function in the DDE.\ndu0 and u0: The initial condition. Defaults to the values h(p, first(tspan))... of the history function evaluated at the initial time point.\nh: The history function for the DDE before t0. Must return an object with the indices 1 and 2, with the values of v and u respectively.\ntspan: The timespan for the problem.\np: The parameters with which function f is called. Defaults to NullParameters.\nconstant_lags: A collection of constant lags used by the history function h. Defaults to ().\ndependent_lags A tuple of functions (v, u, p, t) -> lag for the state-dependent lags used by the history function h. Defaults to ().\nneutral: If the DDE is neutral, i.e., if delays appear in derivative terms.\norder_discontinuity_t0: The order of the discontinuity at the initial time point. Defaults to 0 if an initial condition u0 is provided. Otherwise it is forced to be greater or equal than 1.\nkwargs: The keyword arguments passed onto the solves.\n\nAs above, the history function will return an object with indices 1 and 2, with the values of du and u respectively. The supplied history function must also match this return type, e.g. by returning a 2-element tuple or vector.\n\nExample Problems\n\nExample problems can be found in DiffEqProblemLibrary.jl.\n\nTo use a sample problem, such as prob_ode_linear, you can do something like:\n\n#] add DiffEqProblemLibrary\nusing DiffEqProblemLibrary.ODEProblemLibrary\n# load problems\nODEProblemLibrary.importodeproblems()\nprob = ODEProblemLibrary.prob_ode_linear\nsol = solve(prob)\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DynamicalDDEProblem","page":"SciMLProblems","title":"SciMLBase.DynamicalDDEProblem","text":"struct DynamicalDDEProblem{iip} <: SciMLBase.AbstractDynamicalDDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SecondOrderDDEProblem","page":"SciMLProblems","title":"SciMLBase.SecondOrderDDEProblem","text":"struct SecondOrderDDEProblem{iip} <: SciMLBase.AbstractDynamicalDDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DiscreteProblem","page":"SciMLProblems","title":"SciMLBase.DiscreteProblem","text":"Defines a discrete dynamical system problem. Documentation Page: https://diffeq.sciml.ai/stable/types/discrete_types/\n\nMathematical Specification of a Discrete Problem\n\nTo define an Discrete Problem, you simply need to give the function f and the initial condition u_0 which define a function map:\n\nu_n+1 = f(u_npt_n+1)\n\nf should be specified as f(un,p,t) (or in-place as f(unp1,un,p,t)), and u_0 should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well. u_n+1 only depends on the previous iteration u_n and t_n+1. The default t_n+1 of FunctionMap is t_n = t_0 + n*dt (with dt=1 being the default). For continuous-time Markov chains this is the time at which the change is occuring.\n\nNote that if the discrete solver is set to have scale_by_time=true, then the problem is interpreted as the map:\n\nu_n+1 = u_n + dt f(u_npt_n+1)\n\nProblem Type\n\nConstructors\n\nDiscreteProblem{isinplace}(f::ODEFunction,u0,tspan,p=NullParameters();kwargs...) : Defines the discrete problem with the specified functions.\nDiscreteProblem{isinplace}(f,u0,tspan,p=NullParameters();kwargs...) : Defines the discrete problem with the specified functions.\nDiscreteProblem{isinplace}(u0,tspan,p=NullParameters();kwargs...) : Defines the discrete problem with the identity map.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The function in the map.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\nNote About Timing\n\nNote that if no dt and not tstops is given, it's assumed that dt=1 and thus tspan=(0,n) will solve for n iterations. If in the solver dt is given, then the number of iterations will change. And if tstops is not empty, the solver will revert to the standard behavior of fixed timestep methods, which is \"step to each tstop\".\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.NoiseProblem","page":"SciMLProblems","title":"SciMLBase.NoiseProblem","text":"struct NoiseProblem{N<:SciMLBase.AbstractNoiseProcess, T, K} <: SciMLBase.AbstractNoiseProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.ODEProblem","page":"SciMLProblems","title":"SciMLBase.ODEProblem","text":"Defines an ordinary differential equation (ODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/ode_types/\n\nMathematical Specification of an ODE Problem\n\nTo define an ODE Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\nM fracdudt = f(upt)\n\nThere are two different ways of specifying f:\n\nf(du,u,p,t): in-place. Memory-efficient when avoiding allocations. Best option for most cases unless mutation is not allowed. \nf(u,p,t): returning du. Less memory-efficient way, particularly suitable when mutation is not allowed (e.g. with certain automatic differentiation packages such as Zygote).\n\nu₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nFor the mass matrix M, see the documentation of ODEFunction.\n\nProblem Type\n\nConstructors\n\nODEProblem can be constructed by first building an ODEFunction or by simply passing the ODE right-hand side to the constructor. The constructors are:\n\nODEProblem(f::ODEFunction,u0,tspan,p=NullParameters();kwargs...)\nODEProblem{isinplace}(f,u0,tspan,p=NullParameters();kwargs...) : Defines the ODE with the specified functions. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the ODEFunction documentation.\n\nFields\n\nf: The function in the ODE.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The parameters.\nkwargs: The keyword arguments passed onto the solves.\n\nExample Problems\n\nExample problems can be found in DiffEqProblemLibrary.jl.\n\nTo use a sample problem, such as prob_ode_linear, you can do something like:\n\n#] add DiffEqProblemLibrary\nusing DiffEqProblemLibrary.ODEProblemLibrary\n# load problems\nODEProblemLibrary.importodeproblems()\nprob = ODEProblemLibrary.prob_ode_linear\nsol = solve(prob)\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DynamicalODEProblem","page":"SciMLProblems","title":"SciMLBase.DynamicalODEProblem","text":"Defines an dynamical ordinary differential equation (ODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/dynamical_types/\n\nDynamical ordinary differential equations, such as those arising from the definition of a Hamiltonian system or a second order ODE, have a special structure that can be utilized in the solution of the differential equation. On this page we describe how to define second order differential equations for their efficient numerical solution.\n\nMathematical Specification of a Dynamical ODE Problem\n\nThese algorithms require a Partitioned ODE of the form:\n\nfracdvdt = f_1(ut) \nfracdudt = f_2(v) \n\nThis is a Partitioned ODE partitioned into two groups, so the functions should be specified as f1(dv,v,u,p,t) and f2(du,v,u,p,t) (in the inplace form), where f1 is independent of v (unless specified by the solver), and f2 is independent of u and t. This includes discretizations arising from SecondOrderODEProblems where the velocity is not used in the acceleration function, and Hamiltonians where the potential is (or can be) time-dependent but the kinetic energy is only dependent on v.\n\nNote that some methods assume that the integral of f2 is a quadratic form. That means that f2=v'*M*v, i.e. int f_2 = frac12 m v^2, giving du = v. This is equivalent to saying that the kinetic energy is related to v^2. The methods which require this assumption will lose accuracy if this assumption is violated. Methods listed make note of this requirement with \"Requires quadratic kinetic energy\".\n\nConstructor\n\nDynamicalODEProblem(f::DynamicalODEFunction,v0,u0,tspan,p=NullParameters();kwargs...)\nDynamicalODEProblem{isinplace}(f1,f2,v0,u0,tspan,p=NullParameters();kwargs...)\n\nDefines the ODE with the specified functions. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFields\n\nf1 and f2: The functions in the ODE.\nv0 and u0: The initial conditions.\ntspan: The timespan for the problem.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SecondOrderODEProblem","page":"SciMLProblems","title":"SciMLBase.SecondOrderODEProblem","text":"Defines a second order ordinary differential equation (ODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/dynamical_types/\n\nMathematical Specification of a 2nd Order ODE Problem\n\nTo define a 2nd Order ODE Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\nu = f(uupt)\n\nf should be specified as f(du,u,p,t) (or in-place as f(ddu,du,u,p,t)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nFrom this form, a dynamical ODE:\n\nv = f(vupt) \nu = v \n\nis generated.\n\nConstructors\n\nSecondOrderODEProblem{isinplace}(f,du0,u0,tspan,callback=CallbackSet())\n\nDefines the ODE with the specified functions.\n\nFields\n\nf: The function for the second derivative.\ndu0: The initial derivative.\nu0: The initial condition.\ntspan: The timespan for the problem.\ncallback: A callback to be applied to every solver which uses the problem. Defaults to nothing.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SplitODEProblem","page":"SciMLProblems","title":"SciMLBase.SplitODEProblem","text":"Defines a split ordinary differential equation (ODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/splitodetypes/\n\nMathematical Specification of a Split ODE Problem\n\nTo define a SplitODEProblem, you simply need to give a two functions  f_1 and f_2 along with an initial condition u_0 which define an ODE:\n\nfracdudt =  f_1(upt) + f_2(upt)\n\nf should be specified as f(u,p,t) (or in-place as f(du,u,p,t)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nMany splits are at least partially linear. That is the equation:\n\nfracdudt =  Au + f_2(upt)\n\nFor how to define a linear function A, see the documentation for the DiffEqOperators.\n\nConstructors\n\nSplitODEProblem(f::SplitFunction,u0,tspan,p=NullParameters();kwargs...)\nSplitODEProblem{isinplace}(f1,f2,u0,tspan,p=NullParameters();kwargs...)\n\nThe isinplace parameter can be omitted and will be determined using the signature of f2. Note that both f1 and f2 should support the in-place style if isinplace is true or they should both support the out-of-place style if isinplace is false. You cannot mix up the two styles.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nUnder the hood, a SplitODEProblem is just a regular ODEProblem whose f is a SplitFunction. Therefore you can solve a SplitODEProblem using the same solvers for ODEProblem. For solvers dedicated to split problems, see Split ODE Solvers.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf1, f2: The functions in the ODE.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.IncrementingODEProblem","page":"SciMLProblems","title":"SciMLBase.IncrementingODEProblem","text":"Experimental\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.RODEProblem","page":"SciMLProblems","title":"SciMLBase.RODEProblem","text":"Defines a random ordinary differential equation (RODE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/rode_types/\n\nMathematical Specification of a RODE Problem\n\nTo define a RODE Problem, you simply need to give the function f and the initial condition u_0 which define an ODE:\n\nfracdudt = f(uptW(t))\n\nwhere W(t) is a random process. f should be specified as f(u,p,t,W) (or in-place as f(du,u,p,t,W)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nConstructors\n\nRODEProblem(f::RODEFunction,u0,tspan,p=NullParameters();noise=WHITE_NOISE,rand_prototype=nothing,callback=nothing)\nRODEProblem{isinplace}(f,u0,tspan,p=NullParameters();noise=WHITE_NOISE,rand_prototype=nothing,callback=nothing,mass_matrix=I) : Defines the RODE with the specified functions. The default noise is WHITE_NOISE. isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The drift function in the SDE.\nu0: The initial condition.\ntspan: The timespan for the problem.\np: The optional parameters for the problem. Defaults to NullParameters.\nnoise: The noise process applied to the noise upon generation. Defaults to Gaussian white noise. For information on defining different noise processes, see the noise process documentation page\nrand_prototype: A prototype type instance for the noise vector. It defaults to nothing, which means the problem should be interpreted as having a noise vector whose size matches u0.\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SDDEProblem","page":"SciMLProblems","title":"SciMLBase.SDDEProblem","text":"Defines a stochastic delay differential equation (SDDE) problem. Documentation Page: https://diffeq.sciml.ai/stable/types/sdde_types/\n\nMathematical Specification of a Stochastic Delay Differential Equation (SDDE) Problem\n\nTo define a SDDE Problem, you simply need to give the drift function f, the diffusion function g, the initial condition u_0 at time point t_0, and the history function h which together define a SDDE:\n\ndu = f(uhpt)dt + g(uhpt)dW_t qquad (t geq t_0)\n\nu(t_0) = u_0\n\nu(t) = h(t) qquad (t  t_0)\n\nf should be specified as f(u, h, p, t) (or in-place as f(du, u, h, p, t)) (and g should match). u_0 should be an AbstractArray (or number) whose geometry matches the desired geometry of u, and h should be specified as described below. The history function h is accessed for all delayed values. Note that we are not limited to numbers or vectors for u_0; one is allowed to provide u_0 as arbitrary matrices / higher dimension tensors as well.\n\nNote that this functionality should be considered experimental.\n\nFunctional Forms of the History Function\n\nThe history function h can be called in the following ways:\n\nh(p, t): out-of-place calculation\nh(out, p, t): in-place calculation\nh(p, t, deriv::Type{Val{i}}): out-of-place calculation of the ith derivative\nh(out, p, t, deriv::Type{Val{i}}): in-place calculation of the ith derivative\nh(args...; idxs): calculation of h(args...) for indices idxs\n\nNote that a dispatch for the supplied history function of matching form is required for whichever function forms are used in the user derivative function f.\n\nDeclaring Lags\n\nLags are declared separately from their use. One can use any lag by simply using the interpolant of h at that point. However, one should use caution in order to achieve the best accuracy. When lags are declared, the solvers can more efficiently be more accurate and thus this is recommended.\n\nNeutral, Retarded, and Algebraic Stochastic Delay Differential Equations\n\nNote that the history function specification can be used to specify general retarded arguments, i.e. h(p,α(u,t)). Neutral delay differential equations can be specified by using the deriv value in the history interpolation. For example, h(p,t-τ, Val{1}) returns the first derivative of the history values at time t-τ.\n\nNote that algebraic equations can be specified by using a singular mass matrix.\n\nProblem Type\n\nConstructors\n\nSDDEProblem(f,g[, u0], h, tspan[, p]; <keyword arguments>)\nSDDEProblem{isinplace}(f,g[, u0], h, tspan[, p]; <keyword arguments>)\n\nParameter isinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred.\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nArguments\n\nf: The drift function in the SDDE.\ng: The diffusion function in the SDDE.\nu0: The initial condition. Defaults to the value h(p, first(tspan)) of the history function evaluated at the initial time point.\nh: The history function for the DDE before t0.\ntspan: The timespan for the problem.\np: The parameters with which function f is called. Defaults to NullParameters.\nconstant_lags: A collection of constant lags used by the history function h. Defaults to ().\ndependent_lags A tuple of functions (u, p, t) -> lag for the state-dependent lags used by the history function h. Defaults to ().\nneutral: If the DDE is neutral, i.e., if delays appear in derivative terms.\norder_discontinuity_t0: The order of the discontinuity at the initial time point. Defaults to 0 if an initial condition u0 is provided. Otherwise it is forced to be greater or equal than 1.\nkwargs: The keyword arguments passed onto the solves.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SplitSDEProblem","page":"SciMLProblems","title":"SciMLBase.SplitSDEProblem","text":"struct SplitSDEProblem{iip} <: SciMLBase.AbstractSplitSDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.DynamicalSDEProblem","page":"SciMLProblems","title":"SciMLBase.DynamicalSDEProblem","text":"struct DynamicalSDEProblem{iip} <: SciMLBase.AbstractDynamicalSDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.SteadyStateProblem","page":"SciMLProblems","title":"SciMLBase.SteadyStateProblem","text":"Defines an Defines a steady state ODE problem. Documentation Page: https://diffeq.sciml.ai/stable/types/steadystatetypes/\n\nMathematical Specification of a Steady State Problem\n\nTo define an Steady State Problem, you simply need to give the function f which defines the ODE:\n\nfracdudt = f(upt)\n\nand an initial guess u_0 of where f(u,p,t)=0. f should be specified as f(u,p,t) (or in-place as f(du,u,p,t)), and u₀ should be an AbstractArray (or number) whose geometry matches the desired geometry of u. Note that we are not limited to numbers or vectors for u₀; one is allowed to provide u₀ as arbitrary matrices / higher dimension tensors as well.\n\nNote that for the steady-state to be defined, we must have that f is autonomous, that is f is independent of t. But the form which matches the standard ODE solver should still be used. The steady state solvers interpret the f by fixing t=0.\n\nProblem Type\n\nConstructors\n\nSteadyStateProblem(f::ODEFunction,u0,p=NullParameters();kwargs...)\nSteadyStateProblem{isinplace}(f,u0,p=NullParameters();kwargs...)\n\nisinplace optionally sets whether the function is inplace or not. This is determined automatically, but not inferred. Additionally, the constructor from ODEProblems is provided:\n\nSteadyStateProblem(prob::ODEProblem)\n\nParameters are optional, and if not given then a NullParameters() singleton will be used which will throw nice errors if you try to index non-existent parameters. Any extra keyword arguments are passed on to the solvers. For example, if you set a callback in the problem, then that callback will be added in every solve call.\n\nFor specifying Jacobians and mass matrices, see the DiffEqFunctions page.\n\nFields\n\nf: The function in the ODE.\nu0: The initial guess for the steady state.\np: The parameters for the problem. Defaults to NullParameters\nkwargs: The keyword arguments passed onto the solves.\n\nSpecial Solution Fields\n\nThe SteadyStateSolution type is different from the other DiffEq solutions because it does not have temporal information.\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/interfaces/Problems/#SciMLBase.PDEProblem","page":"SciMLProblems","title":"SciMLBase.PDEProblem","text":"struct PDEProblem{P, E, S} <: SciMLBase.AbstractPDEProblem\n\n\n\n\n\n","category":"type"},{"location":"copies/SciMLBase/#The-SciML-Common-Interface-for-Julia-Equation-Solvers","page":"Home","title":"The SciML Common Interface for Julia Equation Solvers","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The SciML common interface ties together the numerical solvers of the Julia package ecosystem into a single unified interface. It is designed for maximal efficiency and parallelism, while incorporating essential features for large-scale scientific machine learning such as differentiability, composability, and sparsity.","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"This documentation is made to pool together the docs of the various SciML libraries to paint the overarching picture, establish development norms, and document the shared/common functionality.","category":"page"},{"location":"copies/SciMLBase/#Domains-of-SciML","page":"Home","title":"Domains of SciML","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The SciML common interface covers the following domains:","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"Linear systems (LinearProblem)\nDirect methods for dense and sparse\nIterative solvers with preconditioning\nNonlinear Systems (NonlinearProblem)\nSystems of nonlinear equations\nScalar bracketing systems\nIntegrals (quadrature) (QuadratureProblem)\nDifferential Equations\nDiscrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations) (DiscreteProblem)\nOrdinary differential equations (ODEs) (ODEProblem)\nSplit and Partitioned ODEs (Symplectic integrators, IMEX Methods) (SplitODEProblem)\nStochastic ordinary differential equations (SODEs or SDEs) (SDEProblem)\nStochastic differential-algebraic equations (SDAEs) (SDEProblem with mass matrices)\nRandom differential equations (RODEs or RDEs) (RODEProblem)\nDifferential algebraic equations (DAEs) (DAEProblem and ODEProblem with mass matrices)\nDelay differential equations (DDEs) (DDEProblem)\nNeutral, retarded, and algebraic delay differential equations (NDDEs, RDDEs, and DDAEs)\nStochastic delay differential equations (SDDEs) (SDDEProblem)\nExperimental support for stochastic neutral, retarded, and algebraic delay differential equations (SNDDEs, SRDDEs, and SDDAEs)\nMixed discrete and continuous equations (Hybrid Equations, Jump Diffusions) (DEProblems with callbacks)\nOptimization (OptimizationProblem)\nNonlinear (constrained) optimization\n(Stochastic/Delay/Differential-Algebraic) Partial Differential Equations (PDESystem)\nFinite difference and finite volume methods\nInterfaces to finite element methods\nPhysics-Informed Neural Networks (PINNs)\nIntegro-Differential Equations\nFractional Differential Equations","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The SciML common interface also includes ModelingToolkit.jl for defining such systems symbolically, allowing for optimizations like automated generation of parallel code, symbolic simplification, and generation of sparsity patterns.","category":"page"},{"location":"copies/SciMLBase/#Extended-SciML-Domain","page":"Home","title":"Extended SciML Domain","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"In addition to the purely numerical representations of mathematical objects, there are also sets of problem types associated with common mathematical algorithms. These are:","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"Data-driven modeling\nDiscrete-time data-driven dynamical systems (DiscreteDataDrivenProblem)\nContinuous-time data-driven dynamical systems (ContinuousDataDrivenProblem)\nSymbolic regression (DirectDataDrivenProblem)\nUncertainty quantification and expected values (ExpectationProblem)","category":"page"},{"location":"copies/SciMLBase/#Inverse-Problems,-Parameter-Estimation,-and-Structural-Identification","page":"Home","title":"Inverse Problems, Parameter Estimation, and Structural Identification","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"We note that parameter estimation and inverse problems are solved directly on their constituant problem types using tools like DiffEqFlux.jl. Thus for example, there is no ODEInverseProblem, and instead ODEProblem is used to find the parameters p that solve the inverse problem.","category":"page"},{"location":"copies/SciMLBase/#Common-Interface-High-Level","page":"Home","title":"Common Interface High Level","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The SciML interface is common as the usage of arguments is standardized across all of the problem domains. Underlying high level ideas include:","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"All domains use the same interface of defining a SciMLProblem which is then solved via solve(prob,alg;kwargs), where alg is a SciMLAlgorithm. The keyword argument namings are standardized across the organization.\nSciMLProblems are generally defined by a SciMLFunction which can define extra details about a model function, such as its analytical Jacobian, its sparsity patterns and so on.\nThere is an organization-wide method for defining linear and nonlinear solvers used within other solvers, giving maximum control of performance to the user.\nTypes used within the packages are defined by the input types. For example, packages attempt to internally use the type of the initial condition as the type for the state within differential equation solvers.\nsolve calls should be thread-safe and parallel-safe.\ninit(prob,alg;kwargs) returns an iterator which allows for directly iterating over the solution process\nHigh performance is key. Any performance that is not at the top level is considered a bug and should be reported as such.\nAll functions have an in-place and out-of-place form, where the in-place form is made to utilize mutation for high performance on large-scale problems and the out-of-place form is for compatibility with tooling like static arrays and some reverse-mode automatic differentiation systems.","category":"page"},{"location":"copies/SciMLBase/#User-Facing-Solver-Libraries","page":"Home","title":"User-Facing Solver Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"DifferentialEquations.jl\nMulti-package interface of high performance numerical solvers of differential equations\nModelingToolkit.jl\nThe symbolic modeling package which implements the SciML symbolic common interface.\nLinearSolve.jl\nMulti-package interface for specifying linear solvers (direct, sparse, and iterative), along with tools for caching and preconditioners for use in large-scale modeling.\nNonlinearSolve.jl\nHigh performance numerical solving of nonlinear systems.\nQuadrature.jl\nMulti-package interface for high performance, batched, and parallelized  numerical quadrature.\nGalacticOptim.jl\nMulti-package interface for numerical solving of optimization problems.\nNeuralPDE.jl\nPhysics-Informed Neural Network (PINN) package for transforming partial differential equations into optimization problems.\nDiffEqOperators.jl\nAutomated finite difference method (FDM) package for transforming partial differential equations into nonlinear problems and ordinary differential equations.\nDiffEqFlux.jl\nHigh level package for scientific machine learning applications, such as neural and universal differential equations, solving of inverse problems, parameter estimation, nonlinear optimal control, and more.\nDataDrivenDiffEq.jl\nMulti-package interface for data-driven modeling, Koopman dynamic mode decomposition, symbolic regression/sparsification, and automated model discovery.\nDiffEqUncertainty.jl\nExtension to the dynamical modeling tools for performing uncertainty quantification and calculating expectations.","category":"page"},{"location":"copies/SciMLBase/#Interface-Implementation-Libraries","page":"Home","title":"Interface Implementation Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"SciMLBase.jl\nThe core package defining the interface which is consumed by the modeling and solver packages.\nDiffEqBase.jl\nThe core package defining the extended interface which is consumed by the differential equation solver packages.\nDiffEqSensitivity.jl\nA package which pools together the definition of derivative overloads to define the common sensealg automatic differentiation interface.\nDiffEqNoiseProcess.jl\nA package which defines the stochastic AbstractNoiseProcess interface for the SciML ecosystem.\nRecursiveArrayTools.jl\nA package which defines the underlying AbstractVectorOfArray structure used as the output for all time series results.\nArrayInterface.jl\nThe package which defines the extended AbstractArray interface employed throughout the SciML ecosystem.","category":"page"},{"location":"copies/SciMLBase/#Using-Facing-Modeling-Libraries","page":"Home","title":"Using-Facing Modeling Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"There are too many to name here and this will be populated when there is time!","category":"page"},{"location":"copies/SciMLBase/#Flowchart-Example-for-PDE-Constrained-Optimal-Control","page":"Home","title":"Flowchart Example for PDE-Constrained Optimal Control","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"The following example showcases how the pieces of the common interface connect to solve a problem that mixes inference, symbolics, and numerics.","category":"page"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"(Image: )","category":"page"},{"location":"copies/SciMLBase/#External-Binding-Libraries","page":"Home","title":"External Binding Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"diffeqr\nSolving differential equations in R using DifferentialEquations.jl with ModelingToolkit for JIT compilation and GPU-acceleration\ndiffeqpy\nSolving differential equations in Python using DifferentialEquations.jl","category":"page"},{"location":"copies/SciMLBase/#Solver-Libraries","page":"Home","title":"Solver Libraries","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"There are too many to name here. Check out the SciML Organization Github Page for details.","category":"page"},{"location":"copies/SciMLBase/#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"copies/SciMLBase/","page":"Home","title":"Home","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nJuliaDiffEq on Gitter\nOn the Julia Discourse forums (look for the modelingtoolkit tag\nSee also SciML Community page","category":"page"},{"location":"#The-SciML-Open-Souce-Software-Ecoystem:-Equation-Solvers,-Mixing-Machine-Learning-and-Classical-Techniques","page":"The SciML Open Souce Software Ecoystem: Equation Solvers, Mixing Machine Learning and Classical Techniques","title":"The SciML Open Souce Software Ecoystem: Equation Solvers, Mixing Machine Learning and Classical Techniques","text":"","category":"section"},{"location":"","page":"The SciML Open Souce Software Ecoystem: Equation Solvers, Mixing Machine Learning and Classical Techniques","title":"The SciML Open Souce Software Ecoystem: Equation Solvers, Mixing Machine Learning and Classical Techniques","text":"The SciML organization is an collection of tools for solving equations and modeling systems developed in the Julia programming language with bindings to other languages such as R and Python. The organization provides well-maintained  tools which compose together as a coherent ecosystem. It has a coherent development principle, unified APIs over large collections of equation solvers, pervasive differentiability and sensitivitiy analysis, and features many of the highest performance and parallel implementations one can find.","category":"page"},{"location":"#Contributing","page":"The SciML Open Souce Software Ecoystem: Equation Solvers, Mixing Machine Learning and Classical Techniques","title":"Contributing","text":"","category":"section"},{"location":"","page":"The SciML Open Souce Software Ecoystem: Equation Solvers, Mixing Machine Learning and Classical Techniques","title":"The SciML Open Souce Software Ecoystem: Equation Solvers, Mixing Machine Learning and Classical Techniques","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to ModelingToolkit.\nThere are a few community forums:\nthe #diffeq-bridged channel in the Julia Slack\nJuliaDiffEq on Gitter\non the Julia Discourse forums\nsee also SciML Community page","category":"page"}]
}
